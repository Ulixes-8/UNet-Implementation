{
    "_best_ema": "None",
    "batch_size": "12",
    "configuration_manager": "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True}",
    "configuration_name": "2d",
    "cudnn_version": 90100,
    "current_epoch": "0",
    "dataloader_train": "<batchgenerators.dataloading.nondet_multi_threaded_augmenter.NonDetMultiThreadedAugmenter object at 0x79b614f8eb10>",
    "dataloader_train.generator": "<nnunetv2.training.dataloading.data_loader.nnUNetDataLoader object at 0x79b614f8e990>",
    "dataloader_train.num_processes": "12",
    "dataloader_train.transform": "None",
    "dataloader_val": "<batchgenerators.dataloading.nondet_multi_threaded_augmenter.NonDetMultiThreadedAugmenter object at 0x79b614f8eae0>",
    "dataloader_val.generator": "<nnunetv2.training.dataloading.data_loader.nnUNetDataLoader object at 0x79b61618a1e0>",
    "dataloader_val.num_processes": "6",
    "dataloader_val.transform": "None",
    "dataset_json": "{'name': 'PetSegmentation', 'description': 'Oxford-IIIT Pet Dataset for semantic segmentation', 'reference': 'Parkhi et al., Cats and Dogs, IEEE Conference on Computer Vision and Pattern Recognition, 2012', 'licence': 'Creative Commons Attribution 4.0 International License', 'release': '1.0', 'channel_names': {'0': 'R', '1': 'G', '2': 'B'}, 'labels': {'background': 0, 'cat': 1, 'dog': 2}, 'numTraining': 11660, 'numTest': 0, 'file_ending': '.png'}",
    "device": "cuda:0",
    "disable_checkpointing": "False",
    "enable_deep_supervision": "True",
    "fold": "0",
    "folder_with_segs_from_previous_stage": "None",
    "gpu_name": "NVIDIA GeForce RTX 4090",
    "grad_scaler": "<torch.amp.grad_scaler.GradScaler object at 0x79b618c9c230>",
    "hostname": "viserion",
    "inference_allowed_mirroring_axes": "(0, 1)",
    "initial_lr": "0.01",
    "is_cascaded": "False",
    "is_ddp": "False",
    "label_manager": "<nnunetv2.utilities.label_handling.label_handling.LabelManager object at 0x79b618eeb740>",
    "local_rank": "0",
    "log_file": "/home/ulixes/segmentation_cv/unet/nnUNet/nnUNet_results/Dataset001_PetSegmentation/nnUNetTrainer__nnUNetPlans__2d/fold_0/training_log_2025_3_30_17_22_42.txt",
    "logger": "<nnunetv2.training.logging.nnunet_logger.nnUNetLogger object at 0x79b61a6000b0>",
    "loss": "DeepSupervisionWrapper(\n  (loss): DC_and_CE_loss(\n    (ce): RobustCrossEntropyLoss()\n    (dc): OptimizedModule(\n      (_orig_mod): MemoryEfficientSoftDiceLoss()\n    )\n  )\n)",
    "lr_scheduler": "<nnunetv2.training.lr_scheduler.polylr.PolyLRScheduler object at 0x79b6162676e0>",
    "my_init_kwargs": "{'plans': {'dataset_name': 'Dataset001_PetSegmentation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 512], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'configurations': {'2d': {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True}}, 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 117.32851047786093, 'median': 115.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 69.96227389587656}, '1': {'max': 255.0, 'mean': 106.84117987089277, 'median': 101.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 68.34967881989432}, '2': {'max': 255.0, 'mean': 98.83487158765632, 'median': 89.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 68.17635546096933}}}, 'configuration': '2d', 'fold': 0, 'dataset_json': {'name': 'PetSegmentation', 'description': 'Oxford-IIIT Pet Dataset for semantic segmentation', 'reference': 'Parkhi et al., Cats and Dogs, IEEE Conference on Computer Vision and Pattern Recognition, 2012', 'licence': 'Creative Commons Attribution 4.0 International License', 'release': '1.0', 'channel_names': {'0': 'R', '1': 'G', '2': 'B'}, 'labels': {'background': 0, 'cat': 1, 'dog': 2}, 'numTraining': 11660, 'numTest': 0, 'file_ending': '.png'}, 'device': device(type='cuda')}",
    "network": "OptimizedModule",
    "num_epochs": "1000",
    "num_input_channels": "3",
    "num_iterations_per_epoch": "250",
    "num_val_iterations_per_epoch": "50",
    "optimizer": "SGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    fused: None\n    initial_lr: 0.01\n    lr: 0.01\n    maximize: False\n    momentum: 0.99\n    nesterov: True\n    weight_decay: 3e-05\n)",
    "output_folder": "/home/ulixes/segmentation_cv/unet/nnUNet/nnUNet_results/Dataset001_PetSegmentation/nnUNetTrainer__nnUNetPlans__2d/fold_0",
    "output_folder_base": "/home/ulixes/segmentation_cv/unet/nnUNet/nnUNet_results/Dataset001_PetSegmentation/nnUNetTrainer__nnUNetPlans__2d",
    "oversample_foreground_percent": "0.33",
    "plans_manager": "{'dataset_name': 'Dataset001_PetSegmentation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 512], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'configurations': {'2d': {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True}}, 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 117.32851047786093, 'median': 115.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 69.96227389587656}, '1': {'max': 255.0, 'mean': 106.84117987089277, 'median': 101.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 68.34967881989432}, '2': {'max': 255.0, 'mean': 98.83487158765632, 'median': 89.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 68.17635546096933}}}",
    "preprocessed_dataset_folder": "/home/ulixes/segmentation_cv/unet/nnUNet/nnUNet_preprocessed/Dataset001_PetSegmentation/nnUNetPlans_2d",
    "preprocessed_dataset_folder_base": "/home/ulixes/segmentation_cv/unet/nnUNet/nnUNet_preprocessed/Dataset001_PetSegmentation",
    "probabilistic_oversampling": "False",
    "save_every": "50",
    "torch_version": "2.6.0+cu124",
    "was_initialized": "True",
    "weight_decay": "3e-05"
}