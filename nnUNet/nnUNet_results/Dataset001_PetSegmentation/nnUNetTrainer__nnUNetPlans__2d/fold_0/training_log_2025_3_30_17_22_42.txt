
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-30 17:22:43.546248: Using torch.compile... 
2025-03-30 17:22:44.624197: do_dummy_2d_data_aug: False 
2025-03-30 17:22:44.646017: Using splits from existing split file: /home/ulixes/segmentation_cv/unet/nnUNet/nnUNet_preprocessed/Dataset001_PetSegmentation/splits_final.json 
2025-03-30 17:22:44.649622: The split file contains 5 splits. 
2025-03-30 17:22:44.649675: Desired fold for training: 0 
2025-03-30 17:22:44.649707: This split has 9329 training and 2331 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_PetSegmentation', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 512], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 117.32851047786093, 'median': 115.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 69.96227389587656}, '1': {'max': 255.0, 'mean': 106.84117987089277, 'median': 101.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 68.34967881989432}, '2': {'max': 255.0, 'mean': 98.83487158765632, 'median': 89.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 255.0, 'std': 68.17635546096933}}} 
 
2025-03-30 17:22:49.687489: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-03-30 17:22:49.736393:  
2025-03-30 17:22:49.737846: Epoch 0 
2025-03-30 17:22:49.738156: Current learning rate: 0.01 
2025-03-30 17:24:23.802353: train_loss 0.4542 
2025-03-30 17:24:23.803233: val_loss 0.2945 
2025-03-30 17:24:23.803319: Pseudo dice [np.float32(0.2745), np.float32(0.2582)] 
2025-03-30 17:24:23.803412: Epoch time: 94.07 s 
2025-03-30 17:24:23.803472: Yayy! New best EMA pseudo Dice: 0.2662999927997589 
2025-03-30 17:24:25.064298:  
2025-03-30 17:24:25.064590: Epoch 1 
2025-03-30 17:24:25.064798: Current learning rate: 0.00999 
2025-03-30 17:24:54.623150: train_loss 0.2615 
2025-03-30 17:24:54.623359: val_loss 0.2097 
2025-03-30 17:24:54.623417: Pseudo dice [np.float32(0.3005), np.float32(0.3781)] 
2025-03-30 17:24:54.623491: Epoch time: 29.56 s 
2025-03-30 17:24:54.623588: Yayy! New best EMA pseudo Dice: 0.2736000120639801 
2025-03-30 17:24:56.005093:  
2025-03-30 17:24:56.005250: Epoch 2 
2025-03-30 17:24:56.005332: Current learning rate: 0.00998 
2025-03-30 17:25:26.634748: train_loss 0.2163 
2025-03-30 17:25:26.634888: val_loss 0.1811 
2025-03-30 17:25:26.634953: Pseudo dice [np.float32(0.4268), np.float32(0.3343)] 
2025-03-30 17:25:26.635064: Epoch time: 30.63 s 
2025-03-30 17:25:26.635167: Yayy! New best EMA pseudo Dice: 0.2842999994754791 
2025-03-30 17:25:27.931757:  
2025-03-30 17:25:27.931860: Epoch 3 
2025-03-30 17:25:27.931943: Current learning rate: 0.00997 
2025-03-30 17:25:54.789455: train_loss 0.1714 
2025-03-30 17:25:54.789592: val_loss 0.1443 
2025-03-30 17:25:54.789647: Pseudo dice [np.float32(0.4361), np.float32(0.4375)] 
2025-03-30 17:25:54.789709: Epoch time: 26.86 s 
2025-03-30 17:25:54.789756: Yayy! New best EMA pseudo Dice: 0.2996000051498413 
2025-03-30 17:25:56.045059:  
2025-03-30 17:25:56.045176: Epoch 4 
2025-03-30 17:25:56.045258: Current learning rate: 0.00996 
2025-03-30 17:26:22.694687: train_loss 0.1616 
2025-03-30 17:26:22.694830: val_loss 0.1456 
2025-03-30 17:26:22.694888: Pseudo dice [np.float32(0.4739), np.float32(0.3541)] 
2025-03-30 17:26:22.694950: Epoch time: 26.65 s 
2025-03-30 17:26:22.694999: Yayy! New best EMA pseudo Dice: 0.3109999895095825 
2025-03-30 17:26:23.970292:  
2025-03-30 17:26:23.970399: Epoch 5 
2025-03-30 17:26:23.970477: Current learning rate: 0.00995 
2025-03-30 17:26:58.411743: train_loss 0.1491 
2025-03-30 17:26:58.411888: val_loss 0.1195 
2025-03-30 17:26:58.412006: Pseudo dice [np.float32(0.4496), np.float32(0.4479)] 
2025-03-30 17:26:58.412091: Epoch time: 34.44 s 
2025-03-30 17:26:58.412142: Yayy! New best EMA pseudo Dice: 0.3248000144958496 
2025-03-30 17:26:59.679324:  
2025-03-30 17:26:59.679459: Epoch 6 
2025-03-30 17:26:59.679519: Current learning rate: 0.00995 
2025-03-30 17:27:26.371254: train_loss 0.1254 
2025-03-30 17:27:26.371370: val_loss 0.082 
2025-03-30 17:27:26.371426: Pseudo dice [np.float32(0.4709), np.float32(0.4963)] 
2025-03-30 17:27:26.371493: Epoch time: 26.69 s 
2025-03-30 17:27:26.371574: Yayy! New best EMA pseudo Dice: 0.3407000005245209 
2025-03-30 17:27:31.999935:  
2025-03-30 17:27:32.000042: Epoch 7 
2025-03-30 17:27:32.000124: Current learning rate: 0.00994 
2025-03-30 17:28:00.407960: train_loss 0.1021 
2025-03-30 17:28:00.408209: val_loss 0.0679 
2025-03-30 17:28:00.408268: Pseudo dice [np.float32(0.5155), np.float32(0.4092)] 
2025-03-30 17:28:00.408333: Epoch time: 28.41 s 
2025-03-30 17:28:00.408382: Yayy! New best EMA pseudo Dice: 0.35280001163482666 
2025-03-30 17:28:01.699353:  
2025-03-30 17:28:01.699461: Epoch 8 
2025-03-30 17:28:01.699542: Current learning rate: 0.00993 
2025-03-30 17:28:28.454321: train_loss 0.0975 
2025-03-30 17:28:28.454478: val_loss 0.1149 
2025-03-30 17:28:28.454534: Pseudo dice [np.float32(0.5024), np.float32(0.3441)] 
2025-03-30 17:28:28.454599: Epoch time: 26.76 s 
2025-03-30 17:28:28.454647: Yayy! New best EMA pseudo Dice: 0.35989999771118164 
2025-03-30 17:28:29.743644:  
2025-03-30 17:28:29.743794: Epoch 9 
2025-03-30 17:28:29.743875: Current learning rate: 0.00992 
2025-03-30 17:29:02.207599: train_loss 0.078 
2025-03-30 17:29:02.207777: val_loss 0.0235 
2025-03-30 17:29:02.207837: Pseudo dice [np.float32(0.5361), np.float32(0.5028)] 
2025-03-30 17:29:02.207901: Epoch time: 32.47 s 
2025-03-30 17:29:02.207949: Yayy! New best EMA pseudo Dice: 0.3758000135421753 
2025-03-30 17:29:05.249575:  
2025-03-30 17:29:05.249747: Epoch 10 
2025-03-30 17:29:05.249850: Current learning rate: 0.00991 
2025-03-30 17:29:32.078197: train_loss 0.0752 
2025-03-30 17:29:32.078335: val_loss 0.0559 
2025-03-30 17:29:32.078390: Pseudo dice [np.float32(0.5192), np.float32(0.4861)] 
2025-03-30 17:29:32.078460: Epoch time: 26.83 s 
2025-03-30 17:29:32.078506: Yayy! New best EMA pseudo Dice: 0.38850000500679016 
2025-03-30 17:29:33.352673:  
2025-03-30 17:29:33.352840: Epoch 11 
2025-03-30 17:29:33.352927: Current learning rate: 0.0099 
2025-03-30 17:30:05.164028: train_loss 0.0606 
2025-03-30 17:30:05.164170: val_loss 0.0014 
2025-03-30 17:30:05.164227: Pseudo dice [np.float32(0.5657), np.float32(0.4993)] 
2025-03-30 17:30:05.164291: Epoch time: 31.81 s 
2025-03-30 17:30:05.164340: Yayy! New best EMA pseudo Dice: 0.40290001034736633 
2025-03-30 17:30:06.431067:  
2025-03-30 17:30:06.431149: Epoch 12 
2025-03-30 17:30:06.431222: Current learning rate: 0.00989 
2025-03-30 17:30:33.143227: train_loss 0.0436 
2025-03-30 17:30:33.143368: val_loss -0.0309 
2025-03-30 17:30:33.143425: Pseudo dice [np.float32(0.5685), np.float32(0.5578)] 
2025-03-30 17:30:33.143486: Epoch time: 26.71 s 
2025-03-30 17:30:33.143533: Yayy! New best EMA pseudo Dice: 0.4189000129699707 
2025-03-30 17:30:35.475632:  
2025-03-30 17:30:35.475741: Epoch 13 
2025-03-30 17:30:35.475838: Current learning rate: 0.00988 
2025-03-30 17:31:06.261932: train_loss 0.0132 
2025-03-30 17:31:06.262087: val_loss -0.0496 
2025-03-30 17:31:06.262161: Pseudo dice [np.float32(0.5805), np.float32(0.5558)] 
2025-03-30 17:31:06.262245: Epoch time: 30.79 s 
2025-03-30 17:31:06.262340: Yayy! New best EMA pseudo Dice: 0.43389999866485596 
2025-03-30 17:31:07.587012:  
2025-03-30 17:31:07.587174: Epoch 14 
2025-03-30 17:31:07.587269: Current learning rate: 0.00987 
2025-03-30 17:31:39.772277: train_loss 0.0009 
2025-03-30 17:31:39.772429: val_loss -0.077 
2025-03-30 17:31:39.772564: Pseudo dice [np.float32(0.612), np.float32(0.5561)] 
2025-03-30 17:31:39.772637: Epoch time: 32.19 s 
2025-03-30 17:31:39.772692: Yayy! New best EMA pseudo Dice: 0.4489000141620636 
2025-03-30 17:31:41.076659:  
2025-03-30 17:31:41.076816: Epoch 15 
2025-03-30 17:31:41.076914: Current learning rate: 0.00986 
2025-03-30 17:32:07.725554: train_loss -0.0208 
2025-03-30 17:32:07.725724: val_loss -0.1014 
2025-03-30 17:32:07.725823: Pseudo dice [np.float32(0.5894), np.float32(0.6026)] 
2025-03-30 17:32:07.725886: Epoch time: 26.65 s 
2025-03-30 17:32:07.725935: Yayy! New best EMA pseudo Dice: 0.4636000096797943 
2025-03-30 17:32:09.019417:  
2025-03-30 17:32:09.019495: Epoch 16 
2025-03-30 17:32:09.019566: Current learning rate: 0.00986 
2025-03-30 17:32:35.728079: train_loss -0.0344 
2025-03-30 17:32:35.728197: val_loss -0.0802 
2025-03-30 17:32:35.728252: Pseudo dice [np.float32(0.6065), np.float32(0.5898)] 
2025-03-30 17:32:35.728311: Epoch time: 26.71 s 
2025-03-30 17:32:35.728359: Yayy! New best EMA pseudo Dice: 0.4771000146865845 
2025-03-30 17:32:37.038348:  
2025-03-30 17:32:37.038517: Epoch 17 
2025-03-30 17:32:37.038591: Current learning rate: 0.00985 
2025-03-30 17:33:03.709822: train_loss -0.0655 
2025-03-30 17:33:03.709950: val_loss -0.1061 
2025-03-30 17:33:03.710007: Pseudo dice [np.float32(0.5601), np.float32(0.6221)] 
2025-03-30 17:33:03.710067: Epoch time: 26.67 s 
2025-03-30 17:33:03.710114: Yayy! New best EMA pseudo Dice: 0.4884999990463257 
2025-03-30 17:33:05.018046:  
2025-03-30 17:33:05.018208: Epoch 18 
2025-03-30 17:33:05.018290: Current learning rate: 0.00984 
2025-03-30 17:33:31.766499: train_loss -0.0556 
2025-03-30 17:33:31.766659: val_loss -0.1261 
2025-03-30 17:33:31.766756: Pseudo dice [np.float32(0.598), np.float32(0.6139)] 
2025-03-30 17:33:31.766847: Epoch time: 26.75 s 
2025-03-30 17:33:31.766897: Yayy! New best EMA pseudo Dice: 0.5001999735832214 
2025-03-30 17:33:40.400863:  
2025-03-30 17:33:40.401005: Epoch 19 
2025-03-30 17:33:40.401080: Current learning rate: 0.00983 
2025-03-30 17:34:07.116751: train_loss -0.0795 
2025-03-30 17:34:07.116913: val_loss -0.1011 
2025-03-30 17:34:07.116969: Pseudo dice [np.float32(0.6193), np.float32(0.6136)] 
2025-03-30 17:34:07.117030: Epoch time: 26.72 s 
2025-03-30 17:34:07.117079: Yayy! New best EMA pseudo Dice: 0.5117999911308289 
2025-03-30 17:34:08.405862:  
2025-03-30 17:34:08.405967: Epoch 20 
2025-03-30 17:34:08.406048: Current learning rate: 0.00982 
2025-03-30 17:34:35.072755: train_loss -0.1088 
2025-03-30 17:34:35.072941: val_loss -0.1702 
2025-03-30 17:34:35.073107: Pseudo dice [np.float32(0.6258), np.float32(0.6561)] 
2025-03-30 17:34:35.073177: Epoch time: 26.67 s 
2025-03-30 17:34:35.073236: Yayy! New best EMA pseudo Dice: 0.5246999859809875 
2025-03-30 17:34:36.392435:  
2025-03-30 17:34:36.392551: Epoch 21 
2025-03-30 17:34:36.392647: Current learning rate: 0.00981 
2025-03-30 17:35:03.094962: train_loss -0.1144 
2025-03-30 17:35:03.095119: val_loss -0.1675 
2025-03-30 17:35:03.095176: Pseudo dice [np.float32(0.6342), np.float32(0.6455)] 
2025-03-30 17:35:03.095271: Epoch time: 26.7 s 
2025-03-30 17:35:03.095322: Yayy! New best EMA pseudo Dice: 0.536300003528595 
2025-03-30 17:35:04.382557:  
2025-03-30 17:35:04.382664: Epoch 22 
2025-03-30 17:35:04.382740: Current learning rate: 0.0098 
2025-03-30 17:35:31.072039: train_loss -0.0986 
2025-03-30 17:35:31.072171: val_loss -0.1905 
2025-03-30 17:35:31.072254: Pseudo dice [np.float32(0.6305), np.float32(0.6572)] 
2025-03-30 17:35:31.072320: Epoch time: 26.69 s 
2025-03-30 17:35:31.072368: Yayy! New best EMA pseudo Dice: 0.546999990940094 
2025-03-30 17:35:32.367757:  
2025-03-30 17:35:32.367878: Epoch 23 
2025-03-30 17:35:32.367959: Current learning rate: 0.00979 
2025-03-30 17:36:01.493307: train_loss -0.1542 
2025-03-30 17:36:01.493478: val_loss -0.1924 
2025-03-30 17:36:01.493535: Pseudo dice [np.float32(0.6544), np.float32(0.6727)] 
2025-03-30 17:36:01.493600: Epoch time: 29.13 s 
2025-03-30 17:36:01.493700: Yayy! New best EMA pseudo Dice: 0.5587000250816345 
2025-03-30 17:36:02.741017:  
2025-03-30 17:36:02.741138: Epoch 24 
2025-03-30 17:36:02.741221: Current learning rate: 0.00978 
2025-03-30 17:36:29.553172: train_loss -0.1613 
2025-03-30 17:36:29.553330: val_loss -0.1765 
2025-03-30 17:36:29.553400: Pseudo dice [np.float32(0.6307), np.float32(0.6543)] 
2025-03-30 17:36:29.553462: Epoch time: 26.81 s 
2025-03-30 17:36:29.553510: Yayy! New best EMA pseudo Dice: 0.5670999884605408 
2025-03-30 17:36:30.822946:  
2025-03-30 17:36:30.823037: Epoch 25 
2025-03-30 17:36:30.823113: Current learning rate: 0.00977 
2025-03-30 17:36:58.177250: train_loss -0.148 
2025-03-30 17:36:58.177401: val_loss -0.1861 
2025-03-30 17:36:58.177456: Pseudo dice [np.float32(0.6476), np.float32(0.663)] 
2025-03-30 17:36:58.177520: Epoch time: 27.36 s 
2025-03-30 17:36:58.177568: Yayy! New best EMA pseudo Dice: 0.5759000182151794 
2025-03-30 17:36:59.425590:  
2025-03-30 17:36:59.425672: Epoch 26 
2025-03-30 17:36:59.425747: Current learning rate: 0.00977 
2025-03-30 17:37:26.112394: train_loss -0.1772 
2025-03-30 17:37:26.112537: val_loss -0.1746 
2025-03-30 17:37:26.112595: Pseudo dice [np.float32(0.626), np.float32(0.6626)] 
2025-03-30 17:37:26.112656: Epoch time: 26.69 s 
2025-03-30 17:37:26.112705: Yayy! New best EMA pseudo Dice: 0.5827000141143799 
2025-03-30 17:37:28.436505:  
2025-03-30 17:37:28.436671: Epoch 27 
2025-03-30 17:37:28.436754: Current learning rate: 0.00976 
2025-03-30 17:37:55.105553: train_loss -0.1756 
2025-03-30 17:37:55.105712: val_loss -0.1707 
2025-03-30 17:37:55.105785: Pseudo dice [np.float32(0.6412), np.float32(0.6276)] 
2025-03-30 17:37:55.105860: Epoch time: 26.67 s 
2025-03-30 17:37:55.105910: Yayy! New best EMA pseudo Dice: 0.5878999829292297 
2025-03-30 17:37:56.383626:  
2025-03-30 17:37:56.383703: Epoch 28 
2025-03-30 17:37:56.383783: Current learning rate: 0.00975 
2025-03-30 17:38:24.280217: train_loss -0.1931 
2025-03-30 17:38:24.280343: val_loss -0.2282 
2025-03-30 17:38:24.280399: Pseudo dice [np.float32(0.6792), np.float32(0.678)] 
2025-03-30 17:38:24.280462: Epoch time: 27.9 s 
2025-03-30 17:38:24.280509: Yayy! New best EMA pseudo Dice: 0.597000002861023 
2025-03-30 17:38:26.561401:  
2025-03-30 17:38:26.561545: Epoch 29 
2025-03-30 17:38:26.561627: Current learning rate: 0.00974 
2025-03-30 17:38:53.205190: train_loss -0.2107 
2025-03-30 17:38:53.205325: val_loss -0.2253 
2025-03-30 17:38:53.205381: Pseudo dice [np.float32(0.6643), np.float32(0.6606)] 
2025-03-30 17:38:53.205454: Epoch time: 26.64 s 
2025-03-30 17:38:53.205501: Yayy! New best EMA pseudo Dice: 0.6035000085830688 
2025-03-30 17:38:54.463728:  
2025-03-30 17:38:54.463836: Epoch 30 
2025-03-30 17:38:54.463910: Current learning rate: 0.00973 
2025-03-30 17:39:21.146472: train_loss -0.2133 
2025-03-30 17:39:21.146601: val_loss -0.2108 
2025-03-30 17:39:21.146674: Pseudo dice [np.float32(0.6459), np.float32(0.6832)] 
2025-03-30 17:39:21.146734: Epoch time: 26.68 s 
2025-03-30 17:39:21.146796: Yayy! New best EMA pseudo Dice: 0.6096000075340271 
2025-03-30 17:39:22.429183:  
2025-03-30 17:39:22.429342: Epoch 31 
2025-03-30 17:39:22.429423: Current learning rate: 0.00972 
2025-03-30 17:39:50.022055: train_loss -0.2135 
2025-03-30 17:39:50.022205: val_loss -0.2032 
2025-03-30 17:39:50.022262: Pseudo dice [np.float32(0.6457), np.float32(0.6569)] 
2025-03-30 17:39:50.022363: Epoch time: 27.59 s 
2025-03-30 17:39:50.022413: Yayy! New best EMA pseudo Dice: 0.6137999892234802 
2025-03-30 17:39:52.728932:  
2025-03-30 17:39:52.729052: Epoch 32 
2025-03-30 17:39:52.729156: Current learning rate: 0.00971 
2025-03-30 17:40:19.422054: train_loss -0.2093 
2025-03-30 17:40:19.422280: val_loss -0.244 
2025-03-30 17:40:19.422337: Pseudo dice [np.float32(0.6881), np.float32(0.6754)] 
2025-03-30 17:40:19.422398: Epoch time: 26.69 s 
2025-03-30 17:40:19.422445: Yayy! New best EMA pseudo Dice: 0.6205999851226807 
2025-03-30 17:40:20.689581:  
2025-03-30 17:40:20.689742: Epoch 33 
2025-03-30 17:40:20.689831: Current learning rate: 0.0097 
2025-03-30 17:40:47.388472: train_loss -0.2311 
2025-03-30 17:40:47.388630: val_loss -0.2278 
2025-03-30 17:40:47.388685: Pseudo dice [np.float32(0.6701), np.float32(0.6816)] 
2025-03-30 17:40:47.388749: Epoch time: 26.7 s 
2025-03-30 17:40:47.388807: Yayy! New best EMA pseudo Dice: 0.6261000037193298 
2025-03-30 17:40:48.644001:  
2025-03-30 17:40:48.644115: Epoch 34 
2025-03-30 17:40:48.644192: Current learning rate: 0.00969 
2025-03-30 17:41:15.306355: train_loss -0.2685 
2025-03-30 17:41:15.306499: val_loss -0.2828 
2025-03-30 17:41:15.306556: Pseudo dice [np.float32(0.7084), np.float32(0.6965)] 
2025-03-30 17:41:15.306650: Epoch time: 26.66 s 
2025-03-30 17:41:15.306698: Yayy! New best EMA pseudo Dice: 0.6337000131607056 
2025-03-30 17:41:16.581597:  
2025-03-30 17:41:16.581753: Epoch 35 
2025-03-30 17:41:16.581845: Current learning rate: 0.00968 
2025-03-30 17:41:43.272711: train_loss -0.2667 
2025-03-30 17:41:43.272895: val_loss -0.2993 
2025-03-30 17:41:43.272953: Pseudo dice [np.float32(0.682), np.float32(0.7119)] 
2025-03-30 17:41:43.273013: Epoch time: 26.69 s 
2025-03-30 17:41:43.273059: Yayy! New best EMA pseudo Dice: 0.6401000022888184 
2025-03-30 17:41:44.539795:  
2025-03-30 17:41:44.539942: Epoch 36 
2025-03-30 17:41:44.540023: Current learning rate: 0.00968 
2025-03-30 17:42:11.297193: train_loss -0.224 
2025-03-30 17:42:11.297361: val_loss -0.2219 
2025-03-30 17:42:11.297463: Pseudo dice [np.float32(0.647), np.float32(0.6436)] 
2025-03-30 17:42:11.297535: Epoch time: 26.76 s 
2025-03-30 17:42:11.297584: Yayy! New best EMA pseudo Dice: 0.6406000256538391 
2025-03-30 17:42:12.591666:  
2025-03-30 17:42:12.591776: Epoch 37 
2025-03-30 17:42:12.591864: Current learning rate: 0.00967 
2025-03-30 17:42:41.668592: train_loss -0.2586 
2025-03-30 17:42:41.668718: val_loss -0.2881 
2025-03-30 17:42:41.668781: Pseudo dice [np.float32(0.7126), np.float32(0.6946)] 
2025-03-30 17:42:41.668845: Epoch time: 29.08 s 
2025-03-30 17:42:41.668892: Yayy! New best EMA pseudo Dice: 0.6468999981880188 
2025-03-30 17:42:43.684868:  
2025-03-30 17:42:43.685042: Epoch 38 
2025-03-30 17:42:43.685138: Current learning rate: 0.00966 
2025-03-30 17:43:10.443351: train_loss -0.2748 
2025-03-30 17:43:10.443472: val_loss -0.2879 
2025-03-30 17:43:10.443529: Pseudo dice [np.float32(0.7105), np.float32(0.699)] 
2025-03-30 17:43:10.443589: Epoch time: 26.76 s 
2025-03-30 17:43:10.443637: Yayy! New best EMA pseudo Dice: 0.6527000069618225 
2025-03-30 17:43:11.708994:  
2025-03-30 17:43:11.709161: Epoch 39 
2025-03-30 17:43:11.709237: Current learning rate: 0.00965 
2025-03-30 17:43:41.190187: train_loss -0.2905 
2025-03-30 17:43:41.190310: val_loss -0.323 
2025-03-30 17:43:41.190391: Pseudo dice [np.float32(0.7043), np.float32(0.6977)] 
2025-03-30 17:43:41.190451: Epoch time: 29.48 s 
2025-03-30 17:43:41.190496: Yayy! New best EMA pseudo Dice: 0.6575000286102295 
2025-03-30 17:43:42.463386:  
2025-03-30 17:43:42.463548: Epoch 40 
2025-03-30 17:43:42.463633: Current learning rate: 0.00964 
2025-03-30 17:44:09.153990: train_loss -0.3097 
2025-03-30 17:44:09.154113: val_loss -0.2862 
2025-03-30 17:44:09.154169: Pseudo dice [np.float32(0.7124), np.float32(0.6975)] 
2025-03-30 17:44:09.154231: Epoch time: 26.69 s 
2025-03-30 17:44:09.154306: Yayy! New best EMA pseudo Dice: 0.6622999906539917 
2025-03-30 17:44:10.431123:  
2025-03-30 17:44:10.431213: Epoch 41 
2025-03-30 17:44:10.431297: Current learning rate: 0.00963 
2025-03-30 17:44:37.103794: train_loss -0.3203 
2025-03-30 17:44:37.103917: val_loss -0.2974 
2025-03-30 17:44:37.103973: Pseudo dice [np.float32(0.6838), np.float32(0.7302)] 
2025-03-30 17:44:37.104037: Epoch time: 26.67 s 
2025-03-30 17:44:37.104084: Yayy! New best EMA pseudo Dice: 0.666700005531311 
2025-03-30 17:44:38.362556:  
2025-03-30 17:44:38.362715: Epoch 42 
2025-03-30 17:44:38.362817: Current learning rate: 0.00962 
2025-03-30 17:45:05.051929: train_loss -0.301 
2025-03-30 17:45:05.052056: val_loss -0.3246 
2025-03-30 17:45:05.052128: Pseudo dice [np.float32(0.7043), np.float32(0.714)] 
2025-03-30 17:45:05.052220: Epoch time: 26.69 s 
2025-03-30 17:45:05.052294: Yayy! New best EMA pseudo Dice: 0.6710000038146973 
2025-03-30 17:45:09.941899:  
2025-03-30 17:45:09.942051: Epoch 43 
2025-03-30 17:45:09.942142: Current learning rate: 0.00961 
2025-03-30 17:45:36.640185: train_loss -0.3221 
2025-03-30 17:45:36.640377: val_loss -0.3323 
2025-03-30 17:45:36.640434: Pseudo dice [np.float32(0.7279), np.float32(0.7018)] 
2025-03-30 17:45:36.640496: Epoch time: 26.7 s 
2025-03-30 17:45:36.640544: Yayy! New best EMA pseudo Dice: 0.6754000186920166 
2025-03-30 17:45:37.912131:  
2025-03-30 17:45:37.912246: Epoch 44 
2025-03-30 17:45:37.912329: Current learning rate: 0.0096 
2025-03-30 17:46:04.582974: train_loss -0.2957 
2025-03-30 17:46:04.583110: val_loss -0.3323 
2025-03-30 17:46:04.583206: Pseudo dice [np.float32(0.7181), np.float32(0.7266)] 
2025-03-30 17:46:04.583269: Epoch time: 26.67 s 
2025-03-30 17:46:04.583317: Yayy! New best EMA pseudo Dice: 0.6801000237464905 
2025-03-30 17:46:05.883557:  
2025-03-30 17:46:05.883633: Epoch 45 
2025-03-30 17:46:05.883698: Current learning rate: 0.00959 
2025-03-30 17:46:32.555192: train_loss -0.3197 
2025-03-30 17:46:32.555324: val_loss -0.3735 
2025-03-30 17:46:32.555381: Pseudo dice [np.float32(0.732), np.float32(0.7414)] 
2025-03-30 17:46:32.555442: Epoch time: 26.67 s 
2025-03-30 17:46:32.555490: Yayy! New best EMA pseudo Dice: 0.685699999332428 
2025-03-30 17:46:33.848729:  
2025-03-30 17:46:33.848886: Epoch 46 
2025-03-30 17:46:33.848960: Current learning rate: 0.00959 
2025-03-30 17:47:00.560079: train_loss -0.3407 
2025-03-30 17:47:00.560222: val_loss -0.3419 
2025-03-30 17:47:00.560278: Pseudo dice [np.float32(0.7075), np.float32(0.7222)] 
2025-03-30 17:47:00.560338: Epoch time: 26.71 s 
2025-03-30 17:47:00.560397: Yayy! New best EMA pseudo Dice: 0.6886000037193298 
2025-03-30 17:47:01.797565:  
2025-03-30 17:47:01.797641: Epoch 47 
2025-03-30 17:47:01.797704: Current learning rate: 0.00958 
2025-03-30 17:47:28.450367: train_loss -0.3107 
2025-03-30 17:47:28.450502: val_loss -0.3644 
2025-03-30 17:47:28.450558: Pseudo dice [np.float32(0.7171), np.float32(0.7415)] 
2025-03-30 17:47:28.450619: Epoch time: 26.65 s 
2025-03-30 17:47:28.450667: Yayy! New best EMA pseudo Dice: 0.6927000284194946 
2025-03-30 17:47:29.692106:  
2025-03-30 17:47:29.692189: Epoch 48 
2025-03-30 17:47:29.692269: Current learning rate: 0.00957 
2025-03-30 17:47:56.360716: train_loss -0.3392 
2025-03-30 17:47:56.360848: val_loss -0.3267 
2025-03-30 17:47:56.360914: Pseudo dice [np.float32(0.7008), np.float32(0.7385)] 
2025-03-30 17:47:56.360991: Epoch time: 26.67 s 
2025-03-30 17:47:56.361039: Yayy! New best EMA pseudo Dice: 0.6953999996185303 
2025-03-30 17:47:57.599445:  
2025-03-30 17:47:57.599578: Epoch 49 
2025-03-30 17:47:57.599658: Current learning rate: 0.00956 
2025-03-30 17:48:24.304224: train_loss -0.3479 
2025-03-30 17:48:24.304357: val_loss -0.3566 
2025-03-30 17:48:24.304412: Pseudo dice [np.float32(0.7393), np.float32(0.7365)] 
2025-03-30 17:48:24.304474: Epoch time: 26.71 s 
2025-03-30 17:48:24.689009: Yayy! New best EMA pseudo Dice: 0.6995999813079834 
2025-03-30 17:48:28.038257:  
2025-03-30 17:48:28.038437: Epoch 50 
2025-03-30 17:48:28.038517: Current learning rate: 0.00955 
2025-03-30 17:48:54.720963: train_loss -0.3207 
2025-03-30 17:48:54.721097: val_loss -0.3403 
2025-03-30 17:48:54.721154: Pseudo dice [np.float32(0.7343), np.float32(0.7308)] 
2025-03-30 17:48:54.721216: Epoch time: 26.68 s 
2025-03-30 17:48:54.721266: Yayy! New best EMA pseudo Dice: 0.7028999924659729 
2025-03-30 17:48:56.094857:  
2025-03-30 17:48:56.094965: Epoch 51 
2025-03-30 17:48:56.095068: Current learning rate: 0.00954 
2025-03-30 17:49:24.067643: train_loss -0.3308 
2025-03-30 17:49:24.067790: val_loss -0.355 
2025-03-30 17:49:24.067847: Pseudo dice [np.float32(0.7267), np.float32(0.6988)] 
2025-03-30 17:49:24.067908: Epoch time: 27.97 s 
2025-03-30 17:49:24.067955: Yayy! New best EMA pseudo Dice: 0.7038999795913696 
2025-03-30 17:49:25.332458:  
2025-03-30 17:49:25.332619: Epoch 52 
2025-03-30 17:49:25.332701: Current learning rate: 0.00953 
2025-03-30 17:49:52.034250: train_loss -0.3397 
2025-03-30 17:49:52.034376: val_loss -0.3448 
2025-03-30 17:49:52.034433: Pseudo dice [np.float32(0.7466), np.float32(0.736)] 
2025-03-30 17:49:52.034495: Epoch time: 26.7 s 
2025-03-30 17:49:52.034543: Yayy! New best EMA pseudo Dice: 0.7077000141143799 
2025-03-30 17:49:53.288738:  
2025-03-30 17:49:53.288825: Epoch 53 
2025-03-30 17:49:53.288903: Current learning rate: 0.00952 
2025-03-30 17:50:19.918570: train_loss -0.3596 
2025-03-30 17:50:19.918692: val_loss -0.3773 
2025-03-30 17:50:19.918747: Pseudo dice [np.float32(0.7258), np.float32(0.7569)] 
2025-03-30 17:50:19.918816: Epoch time: 26.63 s 
2025-03-30 17:50:19.918864: Yayy! New best EMA pseudo Dice: 0.7110000252723694 
2025-03-30 17:50:21.180048:  
2025-03-30 17:50:21.180202: Epoch 54 
2025-03-30 17:50:21.180283: Current learning rate: 0.00951 
2025-03-30 17:50:47.875928: train_loss -0.3918 
2025-03-30 17:50:47.876136: val_loss -0.3761 
2025-03-30 17:50:47.876193: Pseudo dice [np.float32(0.7252), np.float32(0.7405)] 
2025-03-30 17:50:47.876253: Epoch time: 26.7 s 
2025-03-30 17:50:47.876301: Yayy! New best EMA pseudo Dice: 0.7131999731063843 
2025-03-30 17:50:49.142807:  
2025-03-30 17:50:49.142971: Epoch 55 
2025-03-30 17:50:49.143041: Current learning rate: 0.0095 
2025-03-30 17:51:15.833684: train_loss -0.405 
2025-03-30 17:51:15.833882: val_loss -0.3845 
2025-03-30 17:51:15.833940: Pseudo dice [np.float32(0.7419), np.float32(0.7312)] 
2025-03-30 17:51:15.834010: Epoch time: 26.69 s 
2025-03-30 17:51:15.834059: Yayy! New best EMA pseudo Dice: 0.715499997138977 
2025-03-30 17:51:17.095196:  
2025-03-30 17:51:17.095278: Epoch 56 
2025-03-30 17:51:17.095402: Current learning rate: 0.00949 
2025-03-30 17:51:43.788113: train_loss -0.4014 
2025-03-30 17:51:43.788270: val_loss -0.4074 
2025-03-30 17:51:43.788328: Pseudo dice [np.float32(0.7585), np.float32(0.7546)] 
2025-03-30 17:51:43.788390: Epoch time: 26.69 s 
2025-03-30 17:51:43.788439: Yayy! New best EMA pseudo Dice: 0.7196999788284302 
2025-03-30 17:51:45.075059:  
2025-03-30 17:51:45.075202: Epoch 57 
2025-03-30 17:51:45.075284: Current learning rate: 0.00949 
2025-03-30 17:52:11.829639: train_loss -0.407 
2025-03-30 17:52:11.829901: val_loss -0.4386 
2025-03-30 17:52:11.830010: Pseudo dice [np.float32(0.7558), np.float32(0.7656)] 
2025-03-30 17:52:11.830116: Epoch time: 26.76 s 
2025-03-30 17:52:11.830185: Yayy! New best EMA pseudo Dice: 0.723800003528595 
2025-03-30 17:52:13.718793:  
2025-03-30 17:52:13.718900: Epoch 58 
2025-03-30 17:52:13.718987: Current learning rate: 0.00948 
2025-03-30 17:52:40.468375: train_loss -0.427 
2025-03-30 17:52:40.468508: val_loss -0.4012 
2025-03-30 17:52:40.468561: Pseudo dice [np.float32(0.7258), np.float32(0.7526)] 
2025-03-30 17:52:40.468621: Epoch time: 26.75 s 
2025-03-30 17:52:40.468667: Yayy! New best EMA pseudo Dice: 0.7253000140190125 
2025-03-30 17:52:41.741360:  
2025-03-30 17:52:41.741524: Epoch 59 
2025-03-30 17:52:41.741607: Current learning rate: 0.00947 
2025-03-30 17:53:08.445233: train_loss -0.4051 
2025-03-30 17:53:08.445357: val_loss -0.4118 
2025-03-30 17:53:08.445413: Pseudo dice [np.float32(0.7647), np.float32(0.7384)] 
2025-03-30 17:53:08.445473: Epoch time: 26.7 s 
2025-03-30 17:53:08.445521: Yayy! New best EMA pseudo Dice: 0.7279000282287598 
2025-03-30 17:53:09.739917:  
2025-03-30 17:53:09.740025: Epoch 60 
2025-03-30 17:53:09.740124: Current learning rate: 0.00946 
2025-03-30 17:53:36.431306: train_loss -0.4407 
2025-03-30 17:53:36.431478: val_loss -0.439 
2025-03-30 17:53:36.431535: Pseudo dice [np.float32(0.7651), np.float32(0.7583)] 
2025-03-30 17:53:36.431602: Epoch time: 26.69 s 
2025-03-30 17:53:36.431652: Yayy! New best EMA pseudo Dice: 0.7312999963760376 
2025-03-30 17:53:37.678334:  
2025-03-30 17:53:37.678527: Epoch 61 
2025-03-30 17:53:37.678610: Current learning rate: 0.00945 
2025-03-30 17:54:04.389045: train_loss -0.4234 
2025-03-30 17:54:04.389197: val_loss -0.4398 
2025-03-30 17:54:04.389253: Pseudo dice [np.float32(0.7571), np.float32(0.7645)] 
2025-03-30 17:54:04.389316: Epoch time: 26.71 s 
2025-03-30 17:54:04.389365: Yayy! New best EMA pseudo Dice: 0.7343000173568726 
2025-03-30 17:54:05.646969:  
2025-03-30 17:54:05.647085: Epoch 62 
2025-03-30 17:54:05.647187: Current learning rate: 0.00944 
2025-03-30 17:54:32.358416: train_loss -0.3941 
2025-03-30 17:54:32.358659: val_loss -0.3701 
2025-03-30 17:54:32.358717: Pseudo dice [np.float32(0.7339), np.float32(0.74)] 
2025-03-30 17:54:32.358793: Epoch time: 26.71 s 
2025-03-30 17:54:32.358849: Yayy! New best EMA pseudo Dice: 0.734499990940094 
2025-03-30 17:54:33.617329:  
2025-03-30 17:54:33.617450: Epoch 63 
2025-03-30 17:54:33.617522: Current learning rate: 0.00943 
2025-03-30 17:55:00.270157: train_loss -0.4107 
2025-03-30 17:55:00.270364: val_loss -0.4454 
2025-03-30 17:55:00.270421: Pseudo dice [np.float32(0.7901), np.float32(0.7759)] 
2025-03-30 17:55:00.270482: Epoch time: 26.65 s 
2025-03-30 17:55:00.270531: Yayy! New best EMA pseudo Dice: 0.7394000291824341 
2025-03-30 17:55:02.362141:  
2025-03-30 17:55:02.362260: Epoch 64 
2025-03-30 17:55:02.362339: Current learning rate: 0.00942 
2025-03-30 17:55:29.013870: train_loss -0.4271 
2025-03-30 17:55:29.014002: val_loss -0.4538 
2025-03-30 17:55:29.014059: Pseudo dice [np.float32(0.7788), np.float32(0.775)] 
2025-03-30 17:55:29.014121: Epoch time: 26.65 s 
2025-03-30 17:55:29.014171: Yayy! New best EMA pseudo Dice: 0.7430999875068665 
2025-03-30 17:55:30.273282:  
2025-03-30 17:55:30.273424: Epoch 65 
2025-03-30 17:55:30.273508: Current learning rate: 0.00941 
2025-03-30 17:55:56.919995: train_loss -0.4421 
2025-03-30 17:55:56.920236: val_loss -0.467 
2025-03-30 17:55:56.920295: Pseudo dice [np.float32(0.7847), np.float32(0.7767)] 
2025-03-30 17:55:56.920358: Epoch time: 26.65 s 
2025-03-30 17:55:56.920407: Yayy! New best EMA pseudo Dice: 0.7469000220298767 
2025-03-30 17:55:58.185711:  
2025-03-30 17:55:58.185817: Epoch 66 
2025-03-30 17:55:58.185898: Current learning rate: 0.0094 
2025-03-30 17:56:24.892607: train_loss -0.4378 
2025-03-30 17:56:24.892735: val_loss -0.3959 
2025-03-30 17:56:24.892811: Pseudo dice [np.float32(0.7418), np.float32(0.7412)] 
2025-03-30 17:56:24.892874: Epoch time: 26.71 s 
2025-03-30 17:56:25.626903:  
2025-03-30 17:56:25.627011: Epoch 67 
2025-03-30 17:56:25.627093: Current learning rate: 0.00939 
2025-03-30 17:56:52.326876: train_loss -0.4143 
2025-03-30 17:56:52.327135: val_loss -0.4272 
2025-03-30 17:56:52.327193: Pseudo dice [np.float32(0.7806), np.float32(0.7514)] 
2025-03-30 17:56:52.327263: Epoch time: 26.7 s 
2025-03-30 17:56:52.327310: Yayy! New best EMA pseudo Dice: 0.7483000159263611 
2025-03-30 17:56:53.550004:  
2025-03-30 17:56:53.550083: Epoch 68 
2025-03-30 17:56:53.550158: Current learning rate: 0.00939 
2025-03-30 17:57:20.321526: train_loss -0.4439 
2025-03-30 17:57:20.321648: val_loss -0.4522 
2025-03-30 17:57:20.321704: Pseudo dice [np.float32(0.7778), np.float32(0.7606)] 
2025-03-30 17:57:20.321801: Epoch time: 26.77 s 
2025-03-30 17:57:20.321878: Yayy! New best EMA pseudo Dice: 0.7504000067710876 
2025-03-30 17:57:23.960139:  
2025-03-30 17:57:23.960222: Epoch 69 
2025-03-30 17:57:23.960302: Current learning rate: 0.00938 
2025-03-30 17:57:50.681720: train_loss -0.4549 
2025-03-30 17:57:50.682017: val_loss -0.4613 
2025-03-30 17:57:50.682076: Pseudo dice [np.float32(0.7837), np.float32(0.7761)] 
2025-03-30 17:57:50.682144: Epoch time: 26.72 s 
2025-03-30 17:57:50.682194: Yayy! New best EMA pseudo Dice: 0.7534000277519226 
2025-03-30 17:57:51.910021:  
2025-03-30 17:57:51.910124: Epoch 70 
2025-03-30 17:57:51.910203: Current learning rate: 0.00937 
2025-03-30 17:58:18.603675: train_loss -0.4445 
2025-03-30 17:58:18.603959: val_loss -0.4292 
2025-03-30 17:58:18.604019: Pseudo dice [np.float32(0.772), np.float32(0.7632)] 
2025-03-30 17:58:18.604083: Epoch time: 26.69 s 
2025-03-30 17:58:18.604151: Yayy! New best EMA pseudo Dice: 0.754800021648407 
2025-03-30 17:58:19.836019:  
2025-03-30 17:58:19.836162: Epoch 71 
2025-03-30 17:58:19.836235: Current learning rate: 0.00936 
2025-03-30 17:58:46.551166: train_loss -0.4486 
2025-03-30 17:58:46.551308: val_loss -0.4811 
2025-03-30 17:58:46.551364: Pseudo dice [np.float32(0.7918), np.float32(0.7689)] 
2025-03-30 17:58:46.551425: Epoch time: 26.72 s 
2025-03-30 17:58:46.551472: Yayy! New best EMA pseudo Dice: 0.7573000192642212 
2025-03-30 17:58:47.811962:  
2025-03-30 17:58:47.812043: Epoch 72 
2025-03-30 17:58:47.812118: Current learning rate: 0.00935 
2025-03-30 17:59:14.513924: train_loss -0.4448 
2025-03-30 17:59:14.514172: val_loss -0.5246 
2025-03-30 17:59:14.514230: Pseudo dice [np.float32(0.8054), np.float32(0.8051)] 
2025-03-30 17:59:14.514292: Epoch time: 26.7 s 
2025-03-30 17:59:14.514339: Yayy! New best EMA pseudo Dice: 0.7620999813079834 
2025-03-30 17:59:15.778706:  
2025-03-30 17:59:15.778812: Epoch 73 
2025-03-30 17:59:15.778883: Current learning rate: 0.00934 
2025-03-30 17:59:42.477474: train_loss -0.4591 
2025-03-30 17:59:42.477700: val_loss -0.4669 
2025-03-30 17:59:42.477767: Pseudo dice [np.float32(0.773), np.float32(0.7841)] 
2025-03-30 17:59:42.477853: Epoch time: 26.7 s 
2025-03-30 17:59:42.477903: Yayy! New best EMA pseudo Dice: 0.7638000249862671 
2025-03-30 17:59:43.753463:  
2025-03-30 17:59:43.753613: Epoch 74 
2025-03-30 17:59:43.753710: Current learning rate: 0.00933 
2025-03-30 18:00:10.452413: train_loss -0.4568 
2025-03-30 18:00:10.452641: val_loss -0.5173 
2025-03-30 18:00:10.452699: Pseudo dice [np.float32(0.8038), np.float32(0.811)] 
2025-03-30 18:00:10.452773: Epoch time: 26.7 s 
2025-03-30 18:00:10.452872: Yayy! New best EMA pseudo Dice: 0.7681000232696533 
2025-03-30 18:00:11.739366:  
2025-03-30 18:00:11.739483: Epoch 75 
2025-03-30 18:00:11.739581: Current learning rate: 0.00932 
2025-03-30 18:00:38.435627: train_loss -0.488 
2025-03-30 18:00:38.435905: val_loss -0.4904 
2025-03-30 18:00:38.436004: Pseudo dice [np.float32(0.812), np.float32(0.7901)] 
2025-03-30 18:00:38.436068: Epoch time: 26.7 s 
2025-03-30 18:00:38.436116: Yayy! New best EMA pseudo Dice: 0.771399974822998 
2025-03-30 18:00:39.705906:  
2025-03-30 18:00:39.706007: Epoch 76 
2025-03-30 18:00:39.706083: Current learning rate: 0.00931 
2025-03-30 18:01:06.400351: train_loss -0.4422 
2025-03-30 18:01:06.400489: val_loss -0.4535 
2025-03-30 18:01:06.400545: Pseudo dice [np.float32(0.7776), np.float32(0.7617)] 
2025-03-30 18:01:06.400608: Epoch time: 26.7 s 
2025-03-30 18:01:07.725794:  
2025-03-30 18:01:07.725945: Epoch 77 
2025-03-30 18:01:07.726024: Current learning rate: 0.0093 
2025-03-30 18:01:34.453615: train_loss -0.4647 
2025-03-30 18:01:34.453864: val_loss -0.5286 
2025-03-30 18:01:34.453924: Pseudo dice [np.float32(0.8115), np.float32(0.7849)] 
2025-03-30 18:01:34.453984: Epoch time: 26.73 s 
2025-03-30 18:01:34.454030: Yayy! New best EMA pseudo Dice: 0.7738999724388123 
2025-03-30 18:01:35.706789:  
2025-03-30 18:01:35.706873: Epoch 78 
2025-03-30 18:01:35.706950: Current learning rate: 0.0093 
2025-03-30 18:02:02.445811: train_loss -0.4602 
2025-03-30 18:02:02.445964: val_loss -0.5062 
2025-03-30 18:02:02.446017: Pseudo dice [np.float32(0.7951), np.float32(0.7991)] 
2025-03-30 18:02:02.446078: Epoch time: 26.74 s 
2025-03-30 18:02:02.446123: Yayy! New best EMA pseudo Dice: 0.7763000130653381 
2025-03-30 18:02:03.743871:  
2025-03-30 18:02:03.743983: Epoch 79 
2025-03-30 18:02:03.744063: Current learning rate: 0.00929 
2025-03-30 18:02:30.395115: train_loss -0.4773 
2025-03-30 18:02:30.395247: val_loss -0.4787 
2025-03-30 18:02:30.395302: Pseudo dice [np.float32(0.7873), np.float32(0.7917)] 
2025-03-30 18:02:30.395370: Epoch time: 26.65 s 
2025-03-30 18:02:30.395455: Yayy! New best EMA pseudo Dice: 0.7775999903678894 
2025-03-30 18:02:31.680372:  
2025-03-30 18:02:31.680504: Epoch 80 
2025-03-30 18:02:31.680593: Current learning rate: 0.00928 
2025-03-30 18:02:58.356899: train_loss -0.4491 
2025-03-30 18:02:58.357030: val_loss -0.5283 
2025-03-30 18:02:58.357087: Pseudo dice [np.float32(0.8151), np.float32(0.7996)] 
2025-03-30 18:02:58.357151: Epoch time: 26.68 s 
2025-03-30 18:02:58.357200: Yayy! New best EMA pseudo Dice: 0.7806000113487244 
2025-03-30 18:02:59.658979:  
2025-03-30 18:02:59.659148: Epoch 81 
2025-03-30 18:02:59.659222: Current learning rate: 0.00927 
2025-03-30 18:03:26.353001: train_loss -0.488 
2025-03-30 18:03:26.353136: val_loss -0.5263 
2025-03-30 18:03:26.353254: Pseudo dice [np.float32(0.7994), np.float32(0.7949)] 
2025-03-30 18:03:26.353319: Epoch time: 26.7 s 
2025-03-30 18:03:26.353369: Yayy! New best EMA pseudo Dice: 0.7821999788284302 
2025-03-30 18:03:27.685382:  
2025-03-30 18:03:27.685497: Epoch 82 
2025-03-30 18:03:27.685579: Current learning rate: 0.00926 
2025-03-30 18:03:54.368869: train_loss -0.4836 
2025-03-30 18:03:54.369202: val_loss -0.41 
2025-03-30 18:03:54.369264: Pseudo dice [np.float32(0.7641), np.float32(0.7565)] 
2025-03-30 18:03:54.369327: Epoch time: 26.68 s 
2025-03-30 18:03:55.106255:  
2025-03-30 18:03:55.106434: Epoch 83 
2025-03-30 18:03:55.106517: Current learning rate: 0.00925 
2025-03-30 18:04:21.761432: train_loss -0.4847 
2025-03-30 18:04:21.761561: val_loss -0.5137 
2025-03-30 18:04:21.761617: Pseudo dice [np.float32(0.8085), np.float32(0.7948)] 
2025-03-30 18:04:21.761680: Epoch time: 26.66 s 
2025-03-30 18:04:22.488570:  
2025-03-30 18:04:22.488666: Epoch 84 
2025-03-30 18:04:22.488755: Current learning rate: 0.00924 
2025-03-30 18:04:49.212133: train_loss -0.4937 
2025-03-30 18:04:49.212422: val_loss -0.5115 
2025-03-30 18:04:49.212481: Pseudo dice [np.float32(0.7903), np.float32(0.8058)] 
2025-03-30 18:04:49.212543: Epoch time: 26.72 s 
2025-03-30 18:04:49.212592: Yayy! New best EMA pseudo Dice: 0.7838000059127808 
2025-03-30 18:04:50.471224:  
2025-03-30 18:04:50.471326: Epoch 85 
2025-03-30 18:04:50.471401: Current learning rate: 0.00923 
2025-03-30 18:05:17.192508: train_loss -0.5111 
2025-03-30 18:05:17.192641: val_loss -0.535 
2025-03-30 18:05:17.192780: Pseudo dice [np.float32(0.8247), np.float32(0.8142)] 
2025-03-30 18:05:17.192905: Epoch time: 26.72 s 
2025-03-30 18:05:17.192956: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2025-03-30 18:05:20.789893:  
2025-03-30 18:05:20.790098: Epoch 86 
2025-03-30 18:05:20.790185: Current learning rate: 0.00922 
2025-03-30 18:05:47.468918: train_loss -0.5028 
2025-03-30 18:05:47.469153: val_loss -0.5995 
2025-03-30 18:05:47.469218: Pseudo dice [np.float32(0.8458), np.float32(0.8457)] 
2025-03-30 18:05:47.469287: Epoch time: 26.68 s 
2025-03-30 18:05:47.469375: Yayy! New best EMA pseudo Dice: 0.7932000160217285 
2025-03-30 18:05:48.740677:  
2025-03-30 18:05:48.740865: Epoch 87 
2025-03-30 18:05:48.740950: Current learning rate: 0.00921 
2025-03-30 18:06:15.535937: train_loss -0.5185 
2025-03-30 18:06:15.536068: val_loss -0.5597 
2025-03-30 18:06:15.536123: Pseudo dice [np.float32(0.8206), np.float32(0.8277)] 
2025-03-30 18:06:15.536184: Epoch time: 26.8 s 
2025-03-30 18:06:15.536232: Yayy! New best EMA pseudo Dice: 0.7962999939918518 
2025-03-30 18:06:16.775548:  
2025-03-30 18:06:16.775712: Epoch 88 
2025-03-30 18:06:16.775793: Current learning rate: 0.0092 
2025-03-30 18:06:43.595206: train_loss -0.4961 
2025-03-30 18:06:43.595330: val_loss -0.5171 
2025-03-30 18:06:43.595385: Pseudo dice [np.float32(0.8092), np.float32(0.8005)] 
2025-03-30 18:06:43.595444: Epoch time: 26.82 s 
2025-03-30 18:06:43.595492: Yayy! New best EMA pseudo Dice: 0.7971000075340271 
2025-03-30 18:06:44.848140:  
2025-03-30 18:06:44.848226: Epoch 89 
2025-03-30 18:06:44.848302: Current learning rate: 0.0092 
2025-03-30 18:07:11.630337: train_loss -0.5065 
2025-03-30 18:07:11.630471: val_loss -0.5343 
2025-03-30 18:07:11.630527: Pseudo dice [np.float32(0.801), np.float32(0.811)] 
2025-03-30 18:07:11.630589: Epoch time: 26.78 s 
2025-03-30 18:07:11.630637: Yayy! New best EMA pseudo Dice: 0.7979999780654907 
2025-03-30 18:07:12.881487:  
2025-03-30 18:07:12.881658: Epoch 90 
2025-03-30 18:07:12.881741: Current learning rate: 0.00919 
2025-03-30 18:07:39.693172: train_loss -0.5122 
2025-03-30 18:07:39.693335: val_loss -0.5146 
2025-03-30 18:07:39.693406: Pseudo dice [np.float32(0.8036), np.float32(0.7992)] 
2025-03-30 18:07:39.693470: Epoch time: 26.81 s 
2025-03-30 18:07:39.693519: Yayy! New best EMA pseudo Dice: 0.7983999848365784 
2025-03-30 18:07:41.697584:  
2025-03-30 18:07:41.697673: Epoch 91 
2025-03-30 18:07:41.697772: Current learning rate: 0.00918 
2025-03-30 18:08:08.539073: train_loss -0.5224 
2025-03-30 18:08:08.539215: val_loss -0.5521 
2025-03-30 18:08:08.539272: Pseudo dice [np.float32(0.8264), np.float32(0.8128)] 
2025-03-30 18:08:08.539331: Epoch time: 26.84 s 
2025-03-30 18:08:08.539378: Yayy! New best EMA pseudo Dice: 0.8004999756813049 
2025-03-30 18:08:09.748133:  
2025-03-30 18:08:09.748283: Epoch 92 
2025-03-30 18:08:09.748351: Current learning rate: 0.00917 
2025-03-30 18:08:36.690753: train_loss -0.5189 
2025-03-30 18:08:36.690965: val_loss -0.553 
2025-03-30 18:08:36.691040: Pseudo dice [np.float32(0.8284), np.float32(0.8031)] 
2025-03-30 18:08:36.691123: Epoch time: 26.94 s 
2025-03-30 18:08:36.691172: Yayy! New best EMA pseudo Dice: 0.8019999861717224 
2025-03-30 18:08:39.923084:  
2025-03-30 18:08:39.923234: Epoch 93 
2025-03-30 18:08:39.923322: Current learning rate: 0.00916 
2025-03-30 18:09:06.752343: train_loss -0.5273 
2025-03-30 18:09:06.752574: val_loss -0.5118 
2025-03-30 18:09:06.752633: Pseudo dice [np.float32(0.8149), np.float32(0.7964)] 
2025-03-30 18:09:06.752694: Epoch time: 26.83 s 
2025-03-30 18:09:06.752742: Yayy! New best EMA pseudo Dice: 0.8023999929428101 
2025-03-30 18:09:07.990473:  
2025-03-30 18:09:07.990571: Epoch 94 
2025-03-30 18:09:07.990667: Current learning rate: 0.00915 
2025-03-30 18:09:34.718073: train_loss -0.5321 
2025-03-30 18:09:34.718193: val_loss -0.5451 
2025-03-30 18:09:34.718248: Pseudo dice [np.float32(0.8208), np.float32(0.8126)] 
2025-03-30 18:09:34.718309: Epoch time: 26.73 s 
2025-03-30 18:09:34.718356: Yayy! New best EMA pseudo Dice: 0.8037999868392944 
2025-03-30 18:09:35.948825:  
2025-03-30 18:09:35.948987: Epoch 95 
2025-03-30 18:09:35.949068: Current learning rate: 0.00914 
2025-03-30 18:10:03.200836: train_loss -0.5435 
2025-03-30 18:10:03.200999: val_loss -0.4956 
2025-03-30 18:10:03.201064: Pseudo dice [np.float32(0.8031), np.float32(0.7794)] 
2025-03-30 18:10:03.201134: Epoch time: 27.25 s 
2025-03-30 18:10:03.950913:  
2025-03-30 18:10:03.951076: Epoch 96 
2025-03-30 18:10:03.951162: Current learning rate: 0.00913 
2025-03-30 18:10:32.138942: train_loss -0.5168 
2025-03-30 18:10:32.139282: val_loss -0.4887 
2025-03-30 18:10:32.139342: Pseudo dice [np.float32(0.7944), np.float32(0.7967)] 
2025-03-30 18:10:32.139425: Epoch time: 28.19 s 
2025-03-30 18:10:32.917830:  
2025-03-30 18:10:32.917918: Epoch 97 
2025-03-30 18:10:32.918002: Current learning rate: 0.00912 
2025-03-30 18:11:03.476082: train_loss -0.4942 
2025-03-30 18:11:03.476279: val_loss -0.5542 
2025-03-30 18:11:03.476375: Pseudo dice [np.float32(0.83), np.float32(0.8145)] 
2025-03-30 18:11:03.476439: Epoch time: 30.56 s 
2025-03-30 18:11:03.476489: Yayy! New best EMA pseudo Dice: 0.8039000034332275 
2025-03-30 18:11:04.877621:  
2025-03-30 18:11:04.877715: Epoch 98 
2025-03-30 18:11:04.877816: Current learning rate: 0.00911 
2025-03-30 18:11:31.679346: train_loss -0.5239 
2025-03-30 18:11:31.679500: val_loss -0.5223 
2025-03-30 18:11:31.679557: Pseudo dice [np.float32(0.8069), np.float32(0.8056)] 
2025-03-30 18:11:31.679618: Epoch time: 26.8 s 
2025-03-30 18:11:31.679665: Yayy! New best EMA pseudo Dice: 0.804099977016449 
2025-03-30 18:11:32.976856:  
2025-03-30 18:11:32.977028: Epoch 99 
2025-03-30 18:11:32.977108: Current learning rate: 0.0091 
2025-03-30 18:11:59.848074: train_loss -0.5155 
2025-03-30 18:11:59.848202: val_loss -0.5409 
2025-03-30 18:11:59.848262: Pseudo dice [np.float32(0.8388), np.float32(0.7979)] 
2025-03-30 18:11:59.848323: Epoch time: 26.87 s 
2025-03-30 18:12:00.347697: Yayy! New best EMA pseudo Dice: 0.8055999875068665 
2025-03-30 18:12:04.033285:  
2025-03-30 18:12:04.033369: Epoch 100 
2025-03-30 18:12:04.033449: Current learning rate: 0.0091 
2025-03-30 18:12:31.093509: train_loss -0.5541 
2025-03-30 18:12:31.093650: val_loss -0.4792 
2025-03-30 18:12:31.093708: Pseudo dice [np.float32(0.7975), np.float32(0.761)] 
2025-03-30 18:12:31.093780: Epoch time: 27.06 s 
2025-03-30 18:12:31.838763:  
2025-03-30 18:12:31.838871: Epoch 101 
2025-03-30 18:12:31.838951: Current learning rate: 0.00909 
2025-03-30 18:12:58.587039: train_loss -0.5341 
2025-03-30 18:12:58.587186: val_loss -0.555 
2025-03-30 18:12:58.587243: Pseudo dice [np.float32(0.8168), np.float32(0.8116)] 
2025-03-30 18:12:58.587304: Epoch time: 26.75 s 
2025-03-30 18:12:59.326675:  
2025-03-30 18:12:59.326842: Epoch 102 
2025-03-30 18:12:59.326921: Current learning rate: 0.00908 
2025-03-30 18:13:26.295646: train_loss -0.5437 
2025-03-30 18:13:26.295779: val_loss -0.5498 
2025-03-30 18:13:26.295842: Pseudo dice [np.float32(0.8135), np.float32(0.8094)] 
2025-03-30 18:13:26.295902: Epoch time: 26.97 s 
2025-03-30 18:13:27.040083:  
2025-03-30 18:13:27.040182: Epoch 103 
2025-03-30 18:13:27.040261: Current learning rate: 0.00907 
2025-03-30 18:13:53.927677: train_loss -0.5591 
2025-03-30 18:13:53.927825: val_loss -0.54 
2025-03-30 18:13:53.927882: Pseudo dice [np.float32(0.8165), np.float32(0.7943)] 
2025-03-30 18:13:53.927943: Epoch time: 26.89 s 
2025-03-30 18:13:54.669708:  
2025-03-30 18:13:54.669855: Epoch 104 
2025-03-30 18:13:54.669919: Current learning rate: 0.00906 
2025-03-30 18:14:21.657465: train_loss -0.5698 
2025-03-30 18:14:21.657618: val_loss -0.5843 
2025-03-30 18:14:21.657675: Pseudo dice [np.float32(0.8341), np.float32(0.8307)] 
2025-03-30 18:14:21.657737: Epoch time: 26.99 s 
2025-03-30 18:14:21.657794: Yayy! New best EMA pseudo Dice: 0.8076000213623047 
2025-03-30 18:14:22.965084:  
2025-03-30 18:14:22.965190: Epoch 105 
2025-03-30 18:14:22.965291: Current learning rate: 0.00905 
2025-03-30 18:14:49.845221: train_loss -0.5612 
2025-03-30 18:14:49.845347: val_loss -0.5297 
2025-03-30 18:14:49.845433: Pseudo dice [np.float32(0.8077), np.float32(0.7941)] 
2025-03-30 18:14:49.845498: Epoch time: 26.88 s 
2025-03-30 18:14:50.588293:  
2025-03-30 18:14:50.588378: Epoch 106 
2025-03-30 18:14:50.588458: Current learning rate: 0.00904 
2025-03-30 18:15:17.333712: train_loss -0.5503 
2025-03-30 18:15:17.333863: val_loss -0.5376 
2025-03-30 18:15:17.333920: Pseudo dice [np.float32(0.8097), np.float32(0.8041)] 
2025-03-30 18:15:17.333983: Epoch time: 26.75 s 
2025-03-30 18:15:18.086328:  
2025-03-30 18:15:18.086426: Epoch 107 
2025-03-30 18:15:18.086523: Current learning rate: 0.00903 
2025-03-30 18:15:44.789052: train_loss -0.5546 
2025-03-30 18:15:44.789196: val_loss -0.5681 
2025-03-30 18:15:44.789252: Pseudo dice [np.float32(0.8304), np.float32(0.8129)] 
2025-03-30 18:15:44.789326: Epoch time: 26.7 s 
2025-03-30 18:15:44.789374: Yayy! New best EMA pseudo Dice: 0.8083999752998352 
2025-03-30 18:15:46.183240:  
2025-03-30 18:15:46.183365: Epoch 108 
2025-03-30 18:15:46.183453: Current learning rate: 0.00902 
2025-03-30 18:16:13.030772: train_loss -0.5771 
2025-03-30 18:16:13.030890: val_loss -0.5642 
2025-03-30 18:16:13.030946: Pseudo dice [np.float32(0.8327), np.float32(0.8192)] 
2025-03-30 18:16:13.031012: Epoch time: 26.85 s 
2025-03-30 18:16:13.031061: Yayy! New best EMA pseudo Dice: 0.8101999759674072 
2025-03-30 18:16:14.340340:  
2025-03-30 18:16:14.340531: Epoch 109 
2025-03-30 18:16:14.340608: Current learning rate: 0.00901 
2025-03-30 18:16:41.487462: train_loss -0.5646 
2025-03-30 18:16:41.487603: val_loss -0.5198 
2025-03-30 18:16:41.487693: Pseudo dice [np.float32(0.8147), np.float32(0.7811)] 
2025-03-30 18:16:41.487756: Epoch time: 27.15 s 
2025-03-30 18:16:42.236253:  
2025-03-30 18:16:42.236334: Epoch 110 
2025-03-30 18:16:42.236410: Current learning rate: 0.009 
2025-03-30 18:17:09.407571: train_loss -0.5614 
2025-03-30 18:17:09.407699: val_loss -0.5537 
2025-03-30 18:17:09.407755: Pseudo dice [np.float32(0.8296), np.float32(0.8102)] 
2025-03-30 18:17:09.407838: Epoch time: 27.17 s 
2025-03-30 18:17:10.153152:  
2025-03-30 18:17:10.153250: Epoch 111 
2025-03-30 18:17:10.153338: Current learning rate: 0.009 
2025-03-30 18:17:37.151254: train_loss -0.5679 
2025-03-30 18:17:37.151408: val_loss -0.6108 
2025-03-30 18:17:37.151468: Pseudo dice [np.float32(0.8478), np.float32(0.8447)] 
2025-03-30 18:17:37.151530: Epoch time: 27.0 s 
2025-03-30 18:17:37.151578: Yayy! New best EMA pseudo Dice: 0.8137000203132629 
2025-03-30 18:17:38.485657:  
2025-03-30 18:17:38.485745: Epoch 112 
2025-03-30 18:17:38.485863: Current learning rate: 0.00899 
2025-03-30 18:18:05.666879: train_loss -0.5701 
2025-03-30 18:18:05.667025: val_loss -0.5592 
2025-03-30 18:18:05.667088: Pseudo dice [np.float32(0.8172), np.float32(0.8103)] 
2025-03-30 18:18:05.667156: Epoch time: 27.18 s 
2025-03-30 18:18:05.667249: Yayy! New best EMA pseudo Dice: 0.8137000203132629 
2025-03-30 18:18:06.967570:  
2025-03-30 18:18:06.967675: Epoch 113 
2025-03-30 18:18:06.967810: Current learning rate: 0.00898 
2025-03-30 18:18:34.876575: train_loss -0.533 
2025-03-30 18:18:34.876703: val_loss -0.5534 
2025-03-30 18:18:34.876767: Pseudo dice [np.float32(0.8168), np.float32(0.8088)] 
2025-03-30 18:18:34.876832: Epoch time: 27.91 s 
2025-03-30 18:18:35.626159:  
2025-03-30 18:18:35.626312: Epoch 114 
2025-03-30 18:18:35.626395: Current learning rate: 0.00897 
2025-03-30 18:19:03.314977: train_loss -0.5164 
2025-03-30 18:19:03.315206: val_loss -0.5552 
2025-03-30 18:19:03.315264: Pseudo dice [np.float32(0.8253), np.float32(0.8181)] 
2025-03-30 18:19:03.315325: Epoch time: 27.69 s 
2025-03-30 18:19:03.315374: Yayy! New best EMA pseudo Dice: 0.8144000172615051 
2025-03-30 18:19:04.566268:  
2025-03-30 18:19:04.566365: Epoch 115 
2025-03-30 18:19:04.566448: Current learning rate: 0.00896 
2025-03-30 18:19:31.705992: train_loss -0.563 
2025-03-30 18:19:31.706170: val_loss -0.5403 
2025-03-30 18:19:31.706228: Pseudo dice [np.float32(0.8155), np.float32(0.8044)] 
2025-03-30 18:19:31.706290: Epoch time: 27.14 s 
2025-03-30 18:19:32.451385:  
2025-03-30 18:19:32.451564: Epoch 116 
2025-03-30 18:19:32.451647: Current learning rate: 0.00895 
2025-03-30 18:19:59.846026: train_loss -0.5552 
2025-03-30 18:19:59.846282: val_loss -0.5426 
2025-03-30 18:19:59.846340: Pseudo dice [np.float32(0.8191), np.float32(0.7924)] 
2025-03-30 18:19:59.846399: Epoch time: 27.4 s 
2025-03-30 18:20:00.585619:  
2025-03-30 18:20:00.585731: Epoch 117 
2025-03-30 18:20:00.585816: Current learning rate: 0.00894 
2025-03-30 18:20:27.803796: train_loss -0.5545 
2025-03-30 18:20:27.804041: val_loss -0.5512 
2025-03-30 18:20:27.804098: Pseudo dice [np.float32(0.8265), np.float32(0.8237)] 
2025-03-30 18:20:27.804161: Epoch time: 27.22 s 
2025-03-30 18:20:29.184840:  
2025-03-30 18:20:29.184969: Epoch 118 
2025-03-30 18:20:29.185068: Current learning rate: 0.00893 
2025-03-30 18:20:56.625268: train_loss -0.5576 
2025-03-30 18:20:56.625419: val_loss -0.605 
2025-03-30 18:20:56.625475: Pseudo dice [np.float32(0.8539), np.float32(0.8387)] 
2025-03-30 18:20:56.625536: Epoch time: 27.44 s 
2025-03-30 18:20:56.625584: Yayy! New best EMA pseudo Dice: 0.8174999952316284 
2025-03-30 18:20:57.866696:  
2025-03-30 18:20:57.866827: Epoch 119 
2025-03-30 18:20:57.866909: Current learning rate: 0.00892 
2025-03-30 18:21:24.912787: train_loss -0.5828 
2025-03-30 18:21:24.912919: val_loss -0.5952 
2025-03-30 18:21:24.913044: Pseudo dice [np.float32(0.8492), np.float32(0.8461)] 
2025-03-30 18:21:24.913138: Epoch time: 27.05 s 
2025-03-30 18:21:24.913188: Yayy! New best EMA pseudo Dice: 0.8205000162124634 
2025-03-30 18:21:26.205958:  
2025-03-30 18:21:26.206083: Epoch 120 
2025-03-30 18:21:26.206161: Current learning rate: 0.00891 
2025-03-30 18:21:53.201795: train_loss -0.5788 
2025-03-30 18:21:53.201929: val_loss -0.5448 
2025-03-30 18:21:53.201994: Pseudo dice [np.float32(0.8207), np.float32(0.8128)] 
2025-03-30 18:21:53.202058: Epoch time: 27.0 s 
2025-03-30 18:21:53.950729:  
2025-03-30 18:21:53.950878: Epoch 121 
2025-03-30 18:21:53.950961: Current learning rate: 0.0089 
2025-03-30 18:22:21.349751: train_loss -0.5698 
2025-03-30 18:22:21.349991: val_loss -0.5802 
2025-03-30 18:22:21.350049: Pseudo dice [np.float32(0.8319), np.float32(0.822)] 
2025-03-30 18:22:21.350111: Epoch time: 27.4 s 
2025-03-30 18:22:21.350160: Yayy! New best EMA pseudo Dice: 0.8208000063896179 
2025-03-30 18:22:22.644835:  
2025-03-30 18:22:22.644935: Epoch 122 
2025-03-30 18:22:22.645027: Current learning rate: 0.00889 
2025-03-30 18:22:49.836976: train_loss -0.5924 
2025-03-30 18:22:49.837107: val_loss -0.5684 
2025-03-30 18:22:49.837164: Pseudo dice [np.float32(0.8495), np.float32(0.7953)] 
2025-03-30 18:22:49.837226: Epoch time: 27.19 s 
2025-03-30 18:22:49.837276: Yayy! New best EMA pseudo Dice: 0.8209999799728394 
2025-03-30 18:22:51.116061:  
2025-03-30 18:22:51.116143: Epoch 123 
2025-03-30 18:22:51.116219: Current learning rate: 0.00889 
2025-03-30 18:23:17.771225: train_loss -0.5842 
2025-03-30 18:23:17.771399: val_loss -0.5876 
2025-03-30 18:23:17.771457: Pseudo dice [np.float32(0.8385), np.float32(0.828)] 
2025-03-30 18:23:17.771521: Epoch time: 26.66 s 
2025-03-30 18:23:17.771569: Yayy! New best EMA pseudo Dice: 0.8222000002861023 
2025-03-30 18:23:19.188982:  
2025-03-30 18:23:19.189144: Epoch 124 
2025-03-30 18:23:19.189212: Current learning rate: 0.00888 
2025-03-30 18:23:45.899192: train_loss -0.5708 
2025-03-30 18:23:45.899333: val_loss -0.6082 
2025-03-30 18:23:45.899413: Pseudo dice [np.float32(0.8602), np.float32(0.8386)] 
2025-03-30 18:23:45.899477: Epoch time: 26.71 s 
2025-03-30 18:23:45.899525: Yayy! New best EMA pseudo Dice: 0.8248999714851379 
2025-03-30 18:23:47.188823:  
2025-03-30 18:23:47.188940: Epoch 125 
2025-03-30 18:23:47.189012: Current learning rate: 0.00887 
2025-03-30 18:24:14.665183: train_loss -0.5884 
2025-03-30 18:24:14.665323: val_loss -0.5863 
2025-03-30 18:24:14.665429: Pseudo dice [np.float32(0.8338), np.float32(0.8324)] 
2025-03-30 18:24:14.665517: Epoch time: 27.48 s 
2025-03-30 18:24:14.665580: Yayy! New best EMA pseudo Dice: 0.8256999850273132 
2025-03-30 18:24:15.924517:  
2025-03-30 18:24:15.924616: Epoch 126 
2025-03-30 18:24:15.924681: Current learning rate: 0.00886 
2025-03-30 18:24:42.648659: train_loss -0.6078 
2025-03-30 18:24:42.648813: val_loss -0.5674 
2025-03-30 18:24:42.648871: Pseudo dice [np.float32(0.8153), np.float32(0.8304)] 
2025-03-30 18:24:42.648933: Epoch time: 26.73 s 
2025-03-30 18:24:43.388383:  
2025-03-30 18:24:43.388521: Epoch 127 
2025-03-30 18:24:43.388620: Current learning rate: 0.00885 
2025-03-30 18:25:10.066099: train_loss -0.5852 
2025-03-30 18:25:10.066272: val_loss -0.5438 
2025-03-30 18:25:10.066328: Pseudo dice [np.float32(0.8163), np.float32(0.8145)] 
2025-03-30 18:25:10.066390: Epoch time: 26.68 s 
2025-03-30 18:25:10.825601:  
2025-03-30 18:25:10.825749: Epoch 128 
2025-03-30 18:25:10.825852: Current learning rate: 0.00884 
2025-03-30 18:25:37.497987: train_loss -0.5647 
2025-03-30 18:25:37.498106: val_loss -0.5555 
2025-03-30 18:25:37.498161: Pseudo dice [np.float32(0.841), np.float32(0.8092)] 
2025-03-30 18:25:37.498222: Epoch time: 26.67 s 
2025-03-30 18:25:38.242938:  
2025-03-30 18:25:38.243022: Epoch 129 
2025-03-30 18:25:38.243121: Current learning rate: 0.00883 
2025-03-30 18:26:04.954601: train_loss -0.5909 
2025-03-30 18:26:04.954723: val_loss -0.5283 
2025-03-30 18:26:04.954786: Pseudo dice [np.float32(0.8086), np.float32(0.8076)] 
2025-03-30 18:26:04.954894: Epoch time: 26.71 s 
2025-03-30 18:26:05.704493:  
2025-03-30 18:26:05.704629: Epoch 130 
2025-03-30 18:26:05.704702: Current learning rate: 0.00882 
2025-03-30 18:26:32.405912: train_loss -0.5776 
2025-03-30 18:26:32.406046: val_loss -0.5702 
2025-03-30 18:26:32.406102: Pseudo dice [np.float32(0.8264), np.float32(0.8226)] 
2025-03-30 18:26:32.406165: Epoch time: 26.7 s 
2025-03-30 18:26:33.152509:  
2025-03-30 18:26:33.152615: Epoch 131 
2025-03-30 18:26:33.152695: Current learning rate: 0.00881 
2025-03-30 18:26:59.890169: train_loss -0.5899 
2025-03-30 18:26:59.890309: val_loss -0.6138 
2025-03-30 18:26:59.890365: Pseudo dice [np.float32(0.8528), np.float32(0.8427)] 
2025-03-30 18:26:59.890427: Epoch time: 26.74 s 
2025-03-30 18:27:00.639111:  
2025-03-30 18:27:00.639254: Epoch 132 
2025-03-30 18:27:00.639327: Current learning rate: 0.0088 
2025-03-30 18:27:27.376627: train_loss -0.5688 
2025-03-30 18:27:27.376779: val_loss -0.562 
2025-03-30 18:27:27.376837: Pseudo dice [np.float32(0.8305), np.float32(0.831)] 
2025-03-30 18:27:27.376898: Epoch time: 26.74 s 
2025-03-30 18:27:27.376945: Yayy! New best EMA pseudo Dice: 0.8259999752044678 
2025-03-30 18:27:28.674495:  
2025-03-30 18:27:28.674593: Epoch 133 
2025-03-30 18:27:28.674669: Current learning rate: 0.00879 
2025-03-30 18:27:55.412697: train_loss -0.5576 
2025-03-30 18:27:55.412839: val_loss -0.5902 
2025-03-30 18:27:55.412894: Pseudo dice [np.float32(0.8161), np.float32(0.8433)] 
2025-03-30 18:27:55.412954: Epoch time: 26.74 s 
2025-03-30 18:27:55.413001: Yayy! New best EMA pseudo Dice: 0.8263999819755554 
2025-03-30 18:27:56.676307:  
2025-03-30 18:27:56.676458: Epoch 134 
2025-03-30 18:27:56.676540: Current learning rate: 0.00879 
2025-03-30 18:28:23.379744: train_loss -0.5817 
2025-03-30 18:28:23.379890: val_loss -0.6029 
2025-03-30 18:28:23.379946: Pseudo dice [np.float32(0.8446), np.float32(0.8284)] 
2025-03-30 18:28:23.380007: Epoch time: 26.7 s 
2025-03-30 18:28:23.380055: Yayy! New best EMA pseudo Dice: 0.8274000287055969 
2025-03-30 18:28:24.649698:  
2025-03-30 18:28:24.649812: Epoch 135 
2025-03-30 18:28:24.649881: Current learning rate: 0.00878 
2025-03-30 18:28:51.338322: train_loss -0.6008 
2025-03-30 18:28:51.338459: val_loss -0.6011 
2025-03-30 18:28:51.338555: Pseudo dice [np.float32(0.8484), np.float32(0.836)] 
2025-03-30 18:28:51.338619: Epoch time: 26.69 s 
2025-03-30 18:28:51.338666: Yayy! New best EMA pseudo Dice: 0.8288999795913696 
2025-03-30 18:28:52.602657:  
2025-03-30 18:28:52.602817: Epoch 136 
2025-03-30 18:28:52.602891: Current learning rate: 0.00877 
2025-03-30 18:29:19.289068: train_loss -0.5921 
2025-03-30 18:29:19.289232: val_loss -0.6124 
2025-03-30 18:29:19.289301: Pseudo dice [np.float32(0.8522), np.float32(0.83)] 
2025-03-30 18:29:19.289376: Epoch time: 26.69 s 
2025-03-30 18:29:19.289434: Yayy! New best EMA pseudo Dice: 0.8300999999046326 
2025-03-30 18:29:20.699518:  
2025-03-30 18:29:20.699699: Epoch 137 
2025-03-30 18:29:20.699788: Current learning rate: 0.00876 
2025-03-30 18:29:47.377306: train_loss -0.6019 
2025-03-30 18:29:47.377460: val_loss -0.5942 
2025-03-30 18:29:47.377517: Pseudo dice [np.float32(0.8369), np.float32(0.8447)] 
2025-03-30 18:29:47.377579: Epoch time: 26.68 s 
2025-03-30 18:29:47.377627: Yayy! New best EMA pseudo Dice: 0.8312000036239624 
2025-03-30 18:29:49.247941:  
2025-03-30 18:29:49.248121: Epoch 138 
2025-03-30 18:29:49.248207: Current learning rate: 0.00875 
2025-03-30 18:30:15.933817: train_loss -0.5765 
2025-03-30 18:30:15.934017: val_loss -0.6131 
2025-03-30 18:30:15.934075: Pseudo dice [np.float32(0.8441), np.float32(0.8438)] 
2025-03-30 18:30:15.934138: Epoch time: 26.69 s 
2025-03-30 18:30:15.934214: Yayy! New best EMA pseudo Dice: 0.8324000239372253 
2025-03-30 18:30:17.216155:  
2025-03-30 18:30:17.216276: Epoch 139 
2025-03-30 18:30:17.216355: Current learning rate: 0.00874 
2025-03-30 18:30:43.930295: train_loss -0.5983 
2025-03-30 18:30:43.930438: val_loss -0.5753 
2025-03-30 18:30:43.930492: Pseudo dice [np.float32(0.8249), np.float32(0.8225)] 
2025-03-30 18:30:43.930550: Epoch time: 26.72 s 
2025-03-30 18:30:44.681622:  
2025-03-30 18:30:44.681731: Epoch 140 
2025-03-30 18:30:44.681825: Current learning rate: 0.00873 
2025-03-30 18:31:11.364220: train_loss -0.6023 
2025-03-30 18:31:11.364371: val_loss -0.6205 
2025-03-30 18:31:11.364427: Pseudo dice [np.float32(0.8527), np.float32(0.8449)] 
2025-03-30 18:31:11.364489: Epoch time: 26.68 s 
2025-03-30 18:31:11.364537: Yayy! New best EMA pseudo Dice: 0.833299994468689 
2025-03-30 18:31:12.662035:  
2025-03-30 18:31:12.662195: Epoch 141 
2025-03-30 18:31:12.662271: Current learning rate: 0.00872 
2025-03-30 18:31:39.390993: train_loss -0.5988 
2025-03-30 18:31:39.391185: val_loss -0.6115 
2025-03-30 18:31:39.391242: Pseudo dice [np.float32(0.8548), np.float32(0.8296)] 
2025-03-30 18:31:39.391303: Epoch time: 26.73 s 
2025-03-30 18:31:39.391351: Yayy! New best EMA pseudo Dice: 0.8342000246047974 
2025-03-30 18:31:40.681750:  
2025-03-30 18:31:40.681918: Epoch 142 
2025-03-30 18:31:40.681993: Current learning rate: 0.00871 
2025-03-30 18:32:07.359847: train_loss -0.6143 
2025-03-30 18:32:07.360074: val_loss -0.6149 
2025-03-30 18:32:07.360141: Pseudo dice [np.float32(0.8506), np.float32(0.8457)] 
2025-03-30 18:32:07.360216: Epoch time: 26.68 s 
2025-03-30 18:32:07.360273: Yayy! New best EMA pseudo Dice: 0.8356000185012817 
2025-03-30 18:32:08.679479:  
2025-03-30 18:32:08.679585: Epoch 143 
2025-03-30 18:32:08.679665: Current learning rate: 0.0087 
2025-03-30 18:32:35.362951: train_loss -0.6069 
2025-03-30 18:32:35.363106: val_loss -0.6388 
2025-03-30 18:32:35.363161: Pseudo dice [np.float32(0.8606), np.float32(0.849)] 
2025-03-30 18:32:35.363222: Epoch time: 26.68 s 
2025-03-30 18:32:35.363270: Yayy! New best EMA pseudo Dice: 0.8374999761581421 
2025-03-30 18:32:36.665301:  
2025-03-30 18:32:36.665444: Epoch 144 
2025-03-30 18:32:36.665525: Current learning rate: 0.00869 
2025-03-30 18:33:03.386121: train_loss -0.6117 
2025-03-30 18:33:03.386277: val_loss -0.6068 
2025-03-30 18:33:03.386335: Pseudo dice [np.float32(0.8447), np.float32(0.8235)] 
2025-03-30 18:33:03.386395: Epoch time: 26.72 s 
2025-03-30 18:33:04.132753:  
2025-03-30 18:33:04.132843: Epoch 145 
2025-03-30 18:33:04.132920: Current learning rate: 0.00868 
2025-03-30 18:33:30.830721: train_loss -0.5982 
2025-03-30 18:33:30.830863: val_loss -0.6119 
2025-03-30 18:33:30.830919: Pseudo dice [np.float32(0.856), np.float32(0.8473)] 
2025-03-30 18:33:30.830980: Epoch time: 26.7 s 
2025-03-30 18:33:30.831028: Yayy! New best EMA pseudo Dice: 0.8385999798774719 
2025-03-30 18:33:32.123206:  
2025-03-30 18:33:32.123320: Epoch 146 
2025-03-30 18:33:32.123403: Current learning rate: 0.00868 
2025-03-30 18:33:58.853895: train_loss -0.6015 
2025-03-30 18:33:58.854046: val_loss -0.5833 
2025-03-30 18:33:58.854108: Pseudo dice [np.float32(0.8398), np.float32(0.8167)] 
2025-03-30 18:33:58.854202: Epoch time: 26.73 s 
2025-03-30 18:33:59.600128:  
2025-03-30 18:33:59.600210: Epoch 147 
2025-03-30 18:33:59.600289: Current learning rate: 0.00867 
2025-03-30 18:34:26.334497: train_loss -0.5756 
2025-03-30 18:34:26.334638: val_loss -0.5976 
2025-03-30 18:34:26.334694: Pseudo dice [np.float32(0.8543), np.float32(0.8188)] 
2025-03-30 18:34:26.334757: Epoch time: 26.74 s 
2025-03-30 18:34:27.085618:  
2025-03-30 18:34:27.085728: Epoch 148 
2025-03-30 18:34:27.085822: Current learning rate: 0.00866 
2025-03-30 18:34:53.737064: train_loss -0.6064 
2025-03-30 18:34:53.737181: val_loss -0.6156 
2025-03-30 18:34:53.737279: Pseudo dice [np.float32(0.8526), np.float32(0.8314)] 
2025-03-30 18:34:53.737350: Epoch time: 26.65 s 
2025-03-30 18:34:54.488601:  
2025-03-30 18:34:54.488747: Epoch 149 
2025-03-30 18:34:54.488852: Current learning rate: 0.00865 
2025-03-30 18:35:21.133041: train_loss -0.6154 
2025-03-30 18:35:21.133186: val_loss -0.5976 
2025-03-30 18:35:21.133242: Pseudo dice [np.float32(0.8391), np.float32(0.8377)] 
2025-03-30 18:35:21.133303: Epoch time: 26.65 s 
2025-03-30 18:35:25.637007:  
2025-03-30 18:35:25.637112: Epoch 150 
2025-03-30 18:35:25.637214: Current learning rate: 0.00864 
2025-03-30 18:35:52.434011: train_loss -0.624 
2025-03-30 18:35:52.434171: val_loss -0.633 
2025-03-30 18:35:52.434228: Pseudo dice [np.float32(0.8636), np.float32(0.8531)] 
2025-03-30 18:35:52.434292: Epoch time: 26.8 s 
2025-03-30 18:35:52.434341: Yayy! New best EMA pseudo Dice: 0.8399999737739563 
2025-03-30 18:35:53.724914:  
2025-03-30 18:35:53.725074: Epoch 151 
2025-03-30 18:35:53.725156: Current learning rate: 0.00863 
2025-03-30 18:36:20.381543: train_loss -0.6243 
2025-03-30 18:36:20.381666: val_loss -0.6452 
2025-03-30 18:36:20.381721: Pseudo dice [np.float32(0.8651), np.float32(0.8567)] 
2025-03-30 18:36:20.381792: Epoch time: 26.66 s 
2025-03-30 18:36:20.381844: Yayy! New best EMA pseudo Dice: 0.8421000242233276 
2025-03-30 18:36:21.639186:  
2025-03-30 18:36:21.639344: Epoch 152 
2025-03-30 18:36:21.639422: Current learning rate: 0.00862 
2025-03-30 18:36:48.337257: train_loss -0.5906 
2025-03-30 18:36:48.337603: val_loss -0.638 
2025-03-30 18:36:48.337661: Pseudo dice [np.float32(0.852), np.float32(0.8663)] 
2025-03-30 18:36:48.337727: Epoch time: 26.7 s 
2025-03-30 18:36:48.337788: Yayy! New best EMA pseudo Dice: 0.8438000082969666 
2025-03-30 18:36:49.587405:  
2025-03-30 18:36:49.587519: Epoch 153 
2025-03-30 18:36:49.587608: Current learning rate: 0.00861 
2025-03-30 18:37:16.293820: train_loss -0.6068 
2025-03-30 18:37:16.293947: val_loss -0.6142 
2025-03-30 18:37:16.294003: Pseudo dice [np.float32(0.846), np.float32(0.8445)] 
2025-03-30 18:37:16.294065: Epoch time: 26.71 s 
2025-03-30 18:37:16.294112: Yayy! New best EMA pseudo Dice: 0.843999981880188 
2025-03-30 18:37:17.559394:  
2025-03-30 18:37:17.559498: Epoch 154 
2025-03-30 18:37:17.559565: Current learning rate: 0.0086 
2025-03-30 18:37:44.516631: train_loss -0.6257 
2025-03-30 18:37:44.516852: val_loss -0.627 
2025-03-30 18:37:44.516912: Pseudo dice [np.float32(0.8577), np.float32(0.8402)] 
2025-03-30 18:37:44.516973: Epoch time: 26.96 s 
2025-03-30 18:37:44.517021: Yayy! New best EMA pseudo Dice: 0.8445000052452087 
2025-03-30 18:37:45.819541:  
2025-03-30 18:37:45.819696: Epoch 155 
2025-03-30 18:37:45.819785: Current learning rate: 0.00859 
2025-03-30 18:38:14.477443: train_loss -0.6072 
2025-03-30 18:38:14.477607: val_loss -0.5618 
2025-03-30 18:38:14.477666: Pseudo dice [np.float32(0.816), np.float32(0.81)] 
2025-03-30 18:38:14.477727: Epoch time: 28.66 s 
2025-03-30 18:38:15.239918:  
2025-03-30 18:38:15.240066: Epoch 156 
2025-03-30 18:38:15.240152: Current learning rate: 0.00858 
2025-03-30 18:38:42.061051: train_loss -0.6079 
2025-03-30 18:38:42.061207: val_loss -0.6376 
2025-03-30 18:38:42.061263: Pseudo dice [np.float32(0.8568), np.float32(0.8419)] 
2025-03-30 18:38:42.061326: Epoch time: 26.82 s 
2025-03-30 18:38:43.494700:  
2025-03-30 18:38:43.494814: Epoch 157 
2025-03-30 18:38:43.494893: Current learning rate: 0.00858 
2025-03-30 18:39:10.405929: train_loss -0.6333 
2025-03-30 18:39:10.406106: val_loss -0.5981 
2025-03-30 18:39:10.406162: Pseudo dice [np.float32(0.8388), np.float32(0.8457)] 
2025-03-30 18:39:10.406229: Epoch time: 26.91 s 
2025-03-30 18:39:11.188490:  
2025-03-30 18:39:11.188637: Epoch 158 
2025-03-30 18:39:11.188718: Current learning rate: 0.00857 
2025-03-30 18:39:37.951334: train_loss -0.6247 
2025-03-30 18:39:37.951480: val_loss -0.6367 
2025-03-30 18:39:37.951535: Pseudo dice [np.float32(0.8647), np.float32(0.8589)] 
2025-03-30 18:39:37.951599: Epoch time: 26.76 s 
2025-03-30 18:39:38.705775:  
2025-03-30 18:39:38.705876: Epoch 159 
2025-03-30 18:39:38.705980: Current learning rate: 0.00856 
2025-03-30 18:40:05.452696: train_loss -0.6062 
2025-03-30 18:40:05.452835: val_loss -0.6119 
2025-03-30 18:40:05.452893: Pseudo dice [np.float32(0.8448), np.float32(0.8411)] 
2025-03-30 18:40:05.452953: Epoch time: 26.75 s 
2025-03-30 18:40:06.209177:  
2025-03-30 18:40:06.209287: Epoch 160 
2025-03-30 18:40:06.209380: Current learning rate: 0.00855 
2025-03-30 18:40:32.954181: train_loss -0.582 
2025-03-30 18:40:32.954408: val_loss -0.616 
2025-03-30 18:40:32.954464: Pseudo dice [np.float32(0.8517), np.float32(0.8446)] 
2025-03-30 18:40:32.954525: Epoch time: 26.75 s 
2025-03-30 18:40:33.706614:  
2025-03-30 18:40:33.706778: Epoch 161 
2025-03-30 18:40:33.706859: Current learning rate: 0.00854 
2025-03-30 18:41:00.391203: train_loss -0.6066 
2025-03-30 18:41:00.391356: val_loss -0.6102 
2025-03-30 18:41:00.391475: Pseudo dice [np.float32(0.8559), np.float32(0.8353)] 
2025-03-30 18:41:00.391540: Epoch time: 26.69 s 
2025-03-30 18:41:00.391639: Yayy! New best EMA pseudo Dice: 0.8445000052452087 
2025-03-30 18:41:01.690886:  
2025-03-30 18:41:01.691000: Epoch 162 
2025-03-30 18:41:01.691089: Current learning rate: 0.00853 
2025-03-30 18:41:28.558178: train_loss -0.6027 
2025-03-30 18:41:28.558306: val_loss -0.5821 
2025-03-30 18:41:28.558362: Pseudo dice [np.float32(0.8413), np.float32(0.8264)] 
2025-03-30 18:41:28.558423: Epoch time: 26.87 s 
2025-03-30 18:41:29.313181:  
2025-03-30 18:41:29.313281: Epoch 163 
2025-03-30 18:41:29.313347: Current learning rate: 0.00852 
2025-03-30 18:41:56.104755: train_loss -0.6152 
2025-03-30 18:41:56.104901: val_loss -0.5807 
2025-03-30 18:41:56.104957: Pseudo dice [np.float32(0.844), np.float32(0.8272)] 
2025-03-30 18:41:56.105061: Epoch time: 26.79 s 
2025-03-30 18:41:56.868987:  
2025-03-30 18:41:56.869076: Epoch 164 
2025-03-30 18:41:56.869223: Current learning rate: 0.00851 
2025-03-30 18:42:23.593671: train_loss -0.6082 
2025-03-30 18:42:23.593845: val_loss -0.6116 
2025-03-30 18:42:23.593903: Pseudo dice [np.float32(0.8556), np.float32(0.8343)] 
2025-03-30 18:42:23.593986: Epoch time: 26.73 s 
2025-03-30 18:42:24.348192:  
2025-03-30 18:42:24.348299: Epoch 165 
2025-03-30 18:42:24.348394: Current learning rate: 0.0085 
2025-03-30 18:42:51.088242: train_loss -0.6035 
2025-03-30 18:42:51.088424: val_loss -0.5875 
2025-03-30 18:42:51.088482: Pseudo dice [np.float32(0.8367), np.float32(0.8357)] 
2025-03-30 18:42:51.088545: Epoch time: 26.74 s 
2025-03-30 18:42:51.834813:  
2025-03-30 18:42:51.834921: Epoch 166 
2025-03-30 18:42:51.835034: Current learning rate: 0.00849 
2025-03-30 18:43:18.641221: train_loss -0.6132 
2025-03-30 18:43:18.641361: val_loss -0.6365 
2025-03-30 18:43:18.641418: Pseudo dice [np.float32(0.8643), np.float32(0.8448)] 
2025-03-30 18:43:18.641479: Epoch time: 26.81 s 
2025-03-30 18:43:19.389674:  
2025-03-30 18:43:19.389776: Epoch 167 
2025-03-30 18:43:19.389860: Current learning rate: 0.00848 
2025-03-30 18:43:46.187260: train_loss -0.599 
2025-03-30 18:43:46.187429: val_loss -0.6106 
2025-03-30 18:43:46.187487: Pseudo dice [np.float32(0.8528), np.float32(0.8429)] 
2025-03-30 18:43:46.187549: Epoch time: 26.8 s 
2025-03-30 18:43:46.949013:  
2025-03-30 18:43:46.949123: Epoch 168 
2025-03-30 18:43:46.949205: Current learning rate: 0.00847 
2025-03-30 18:44:13.705781: train_loss -0.6314 
2025-03-30 18:44:13.705918: val_loss -0.6281 
2025-03-30 18:44:13.706001: Pseudo dice [np.float32(0.8499), np.float32(0.8355)] 
2025-03-30 18:44:13.706064: Epoch time: 26.76 s 
2025-03-30 18:44:14.465855:  
2025-03-30 18:44:14.465971: Epoch 169 
2025-03-30 18:44:14.466054: Current learning rate: 0.00847 
2025-03-30 18:44:41.155883: train_loss -0.6323 
2025-03-30 18:44:41.156035: val_loss -0.6486 
2025-03-30 18:44:41.156093: Pseudo dice [np.float32(0.8573), np.float32(0.8578)] 
2025-03-30 18:44:41.156154: Epoch time: 26.69 s 
2025-03-30 18:44:41.156203: Yayy! New best EMA pseudo Dice: 0.8450999855995178 
2025-03-30 18:44:42.458520:  
2025-03-30 18:44:42.458638: Epoch 170 
2025-03-30 18:44:42.458724: Current learning rate: 0.00846 
2025-03-30 18:45:09.242236: train_loss -0.6258 
2025-03-30 18:45:09.242389: val_loss -0.6247 
2025-03-30 18:45:09.242442: Pseudo dice [np.float32(0.8547), np.float32(0.8445)] 
2025-03-30 18:45:09.242519: Epoch time: 26.78 s 
2025-03-30 18:45:09.242565: Yayy! New best EMA pseudo Dice: 0.8456000089645386 
2025-03-30 18:45:10.544125:  
2025-03-30 18:45:10.544206: Epoch 171 
2025-03-30 18:45:10.544286: Current learning rate: 0.00845 
2025-03-30 18:45:37.274891: train_loss -0.6174 
2025-03-30 18:45:37.275162: val_loss -0.5988 
2025-03-30 18:45:37.275222: Pseudo dice [np.float32(0.8447), np.float32(0.846)] 
2025-03-30 18:45:37.275285: Epoch time: 26.73 s 
2025-03-30 18:45:38.027331:  
2025-03-30 18:45:38.027483: Epoch 172 
2025-03-30 18:45:38.027571: Current learning rate: 0.00844 
2025-03-30 18:46:04.729441: train_loss -0.611 
2025-03-30 18:46:04.729692: val_loss -0.6184 
2025-03-30 18:46:04.729751: Pseudo dice [np.float32(0.8574), np.float32(0.8425)] 
2025-03-30 18:46:04.729824: Epoch time: 26.7 s 
2025-03-30 18:46:04.729874: Yayy! New best EMA pseudo Dice: 0.8460000157356262 
2025-03-30 18:46:06.026012:  
2025-03-30 18:46:06.026133: Epoch 173 
2025-03-30 18:46:06.026207: Current learning rate: 0.00843 
2025-03-30 18:46:32.761178: train_loss -0.6389 
2025-03-30 18:46:32.761327: val_loss -0.6201 
2025-03-30 18:46:32.761383: Pseudo dice [np.float32(0.8563), np.float32(0.8442)] 
2025-03-30 18:46:32.761449: Epoch time: 26.74 s 
2025-03-30 18:46:32.761532: Yayy! New best EMA pseudo Dice: 0.8464000225067139 
2025-03-30 18:46:34.042218:  
2025-03-30 18:46:34.042336: Epoch 174 
2025-03-30 18:46:34.042422: Current learning rate: 0.00842 
2025-03-30 18:47:00.697152: train_loss -0.6112 
2025-03-30 18:47:00.697438: val_loss -0.5732 
2025-03-30 18:47:00.697496: Pseudo dice [np.float32(0.8248), np.float32(0.8079)] 
2025-03-30 18:47:00.697556: Epoch time: 26.66 s 
2025-03-30 18:47:01.471298:  
2025-03-30 18:47:01.471404: Epoch 175 
2025-03-30 18:47:01.471503: Current learning rate: 0.00841 
2025-03-30 18:47:28.138619: train_loss -0.6234 
2025-03-30 18:47:28.138846: val_loss -0.6505 
2025-03-30 18:47:28.138907: Pseudo dice [np.float32(0.8689), np.float32(0.8464)] 
2025-03-30 18:47:28.138974: Epoch time: 26.67 s 
2025-03-30 18:47:28.915643:  
2025-03-30 18:47:28.915793: Epoch 176 
2025-03-30 18:47:28.915888: Current learning rate: 0.0084 
2025-03-30 18:47:55.663355: train_loss -0.6346 
2025-03-30 18:47:55.663531: val_loss -0.6198 
2025-03-30 18:47:55.663601: Pseudo dice [np.float32(0.8516), np.float32(0.8372)] 
2025-03-30 18:47:55.663665: Epoch time: 26.75 s 
2025-03-30 18:47:57.031446:  
2025-03-30 18:47:57.031589: Epoch 177 
2025-03-30 18:47:57.031667: Current learning rate: 0.00839 
2025-03-30 18:48:23.938316: train_loss -0.6306 
2025-03-30 18:48:23.938477: val_loss -0.6285 
2025-03-30 18:48:23.938534: Pseudo dice [np.float32(0.8664), np.float32(0.8399)] 
2025-03-30 18:48:23.938596: Epoch time: 26.91 s 
2025-03-30 18:48:24.692984:  
2025-03-30 18:48:24.693079: Epoch 178 
2025-03-30 18:48:24.693161: Current learning rate: 0.00838 
2025-03-30 18:48:51.513060: train_loss -0.6424 
2025-03-30 18:48:51.513204: val_loss -0.6627 
2025-03-30 18:48:51.513261: Pseudo dice [np.float32(0.8758), np.float32(0.8597)] 
2025-03-30 18:48:51.513322: Epoch time: 26.82 s 
2025-03-30 18:48:51.513432: Yayy! New best EMA pseudo Dice: 0.8478000164031982 
2025-03-30 18:48:52.773959:  
2025-03-30 18:48:52.774094: Epoch 179 
2025-03-30 18:48:52.774166: Current learning rate: 0.00837 
2025-03-30 18:49:19.522746: train_loss -0.649 
2025-03-30 18:49:19.522898: val_loss -0.676 
2025-03-30 18:49:19.522954: Pseudo dice [np.float32(0.8815), np.float32(0.8591)] 
2025-03-30 18:49:19.523030: Epoch time: 26.75 s 
2025-03-30 18:49:19.523098: Yayy! New best EMA pseudo Dice: 0.8500999808311462 
2025-03-30 18:49:22.560175:  
2025-03-30 18:49:22.560316: Epoch 180 
2025-03-30 18:49:22.560403: Current learning rate: 0.00836 
2025-03-30 18:49:49.243258: train_loss -0.6351 
2025-03-30 18:49:49.243395: val_loss -0.6336 
2025-03-30 18:49:49.243451: Pseudo dice [np.float32(0.8578), np.float32(0.8469)] 
2025-03-30 18:49:49.243521: Epoch time: 26.68 s 
2025-03-30 18:49:49.243568: Yayy! New best EMA pseudo Dice: 0.8503000140190125 
2025-03-30 18:49:50.558731:  
2025-03-30 18:49:50.558913: Epoch 181 
2025-03-30 18:49:50.558995: Current learning rate: 0.00836 
2025-03-30 18:50:18.600043: train_loss -0.6395 
2025-03-30 18:50:18.600191: val_loss -0.6431 
2025-03-30 18:50:18.600248: Pseudo dice [np.float32(0.8632), np.float32(0.8498)] 
2025-03-30 18:50:18.600309: Epoch time: 28.04 s 
2025-03-30 18:50:18.600357: Yayy! New best EMA pseudo Dice: 0.8508999943733215 
2025-03-30 18:50:19.887675:  
2025-03-30 18:50:19.887851: Epoch 182 
2025-03-30 18:50:19.887927: Current learning rate: 0.00835 
2025-03-30 18:50:46.559216: train_loss -0.6302 
2025-03-30 18:50:46.559358: val_loss -0.6155 
2025-03-30 18:50:46.559413: Pseudo dice [np.float32(0.8455), np.float32(0.8453)] 
2025-03-30 18:50:46.559474: Epoch time: 26.67 s 
2025-03-30 18:50:47.314132:  
2025-03-30 18:50:47.314282: Epoch 183 
2025-03-30 18:50:47.314356: Current learning rate: 0.00834 
2025-03-30 18:51:13.972900: train_loss -0.6121 
2025-03-30 18:51:13.973018: val_loss -0.6805 
2025-03-30 18:51:13.973073: Pseudo dice [np.float32(0.8754), np.float32(0.8654)] 
2025-03-30 18:51:13.973131: Epoch time: 26.66 s 
2025-03-30 18:51:13.973179: Yayy! New best EMA pseudo Dice: 0.852400004863739 
2025-03-30 18:51:15.241848:  
2025-03-30 18:51:15.241933: Epoch 184 
2025-03-30 18:51:15.242006: Current learning rate: 0.00833 
2025-03-30 18:51:41.915269: train_loss -0.6347 
2025-03-30 18:51:41.915411: val_loss -0.6484 
2025-03-30 18:51:41.915466: Pseudo dice [np.float32(0.8626), np.float32(0.8565)] 
2025-03-30 18:51:41.915526: Epoch time: 26.67 s 
2025-03-30 18:51:41.915573: Yayy! New best EMA pseudo Dice: 0.8531000018119812 
2025-03-30 18:51:43.206118:  
2025-03-30 18:51:43.206202: Epoch 185 
2025-03-30 18:51:43.206277: Current learning rate: 0.00832 
2025-03-30 18:52:09.963318: train_loss -0.6152 
2025-03-30 18:52:09.963454: val_loss -0.6418 
2025-03-30 18:52:09.963508: Pseudo dice [np.float32(0.859), np.float32(0.8604)] 
2025-03-30 18:52:09.963567: Epoch time: 26.76 s 
2025-03-30 18:52:09.963615: Yayy! New best EMA pseudo Dice: 0.8537999987602234 
2025-03-30 18:52:11.254061:  
2025-03-30 18:52:11.254223: Epoch 186 
2025-03-30 18:52:11.254296: Current learning rate: 0.00831 
2025-03-30 18:52:37.911989: train_loss -0.6351 
2025-03-30 18:52:37.912201: val_loss -0.6708 
2025-03-30 18:52:37.912259: Pseudo dice [np.float32(0.8749), np.float32(0.8631)] 
2025-03-30 18:52:37.912321: Epoch time: 26.66 s 
2025-03-30 18:52:37.912369: Yayy! New best EMA pseudo Dice: 0.8553000092506409 
2025-03-30 18:52:39.345091:  
2025-03-30 18:52:39.345185: Epoch 187 
2025-03-30 18:52:39.345266: Current learning rate: 0.0083 
2025-03-30 18:53:06.448428: train_loss -0.6285 
2025-03-30 18:53:06.448583: val_loss -0.6262 
2025-03-30 18:53:06.448701: Pseudo dice [np.float32(0.8707), np.float32(0.8385)] 
2025-03-30 18:53:06.448810: Epoch time: 27.1 s 
2025-03-30 18:53:07.216337:  
2025-03-30 18:53:07.216491: Epoch 188 
2025-03-30 18:53:07.216586: Current learning rate: 0.00829 
2025-03-30 18:53:34.261388: train_loss -0.6401 
2025-03-30 18:53:34.261674: val_loss -0.6355 
2025-03-30 18:53:34.261733: Pseudo dice [np.float32(0.8579), np.float32(0.8458)] 
2025-03-30 18:53:34.261808: Epoch time: 27.05 s 
2025-03-30 18:53:35.027870:  
2025-03-30 18:53:35.028013: Epoch 189 
2025-03-30 18:53:35.028109: Current learning rate: 0.00828 
2025-03-30 18:54:01.953151: train_loss -0.6242 
2025-03-30 18:54:01.953440: val_loss -0.6129 
2025-03-30 18:54:01.953499: Pseudo dice [np.float32(0.8557), np.float32(0.8271)] 
2025-03-30 18:54:01.953561: Epoch time: 26.93 s 
2025-03-30 18:54:02.710464:  
2025-03-30 18:54:02.710623: Epoch 190 
2025-03-30 18:54:02.710697: Current learning rate: 0.00827 
2025-03-30 18:54:29.759578: train_loss -0.6365 
2025-03-30 18:54:29.759715: val_loss -0.6252 
2025-03-30 18:54:29.759780: Pseudo dice [np.float32(0.8473), np.float32(0.8406)] 
2025-03-30 18:54:29.759854: Epoch time: 27.05 s 
2025-03-30 18:54:30.524619:  
2025-03-30 18:54:30.524717: Epoch 191 
2025-03-30 18:54:30.524816: Current learning rate: 0.00826 
2025-03-30 18:54:57.246705: train_loss -0.6268 
2025-03-30 18:54:57.247007: val_loss -0.643 
2025-03-30 18:54:57.247067: Pseudo dice [np.float32(0.8695), np.float32(0.8491)] 
2025-03-30 18:54:57.247128: Epoch time: 26.72 s 
2025-03-30 18:54:58.010338:  
2025-03-30 18:54:58.010477: Epoch 192 
2025-03-30 18:54:58.010551: Current learning rate: 0.00825 
2025-03-30 18:55:24.665339: train_loss -0.6552 
2025-03-30 18:55:24.665602: val_loss -0.6153 
2025-03-30 18:55:24.665661: Pseudo dice [np.float32(0.8601), np.float32(0.8319)] 
2025-03-30 18:55:24.665723: Epoch time: 26.66 s 
2025-03-30 18:55:25.433601:  
2025-03-30 18:55:25.433754: Epoch 193 
2025-03-30 18:55:25.433842: Current learning rate: 0.00824 
2025-03-30 18:55:52.116174: train_loss -0.6468 
2025-03-30 18:55:52.116433: val_loss -0.6145 
2025-03-30 18:55:52.116491: Pseudo dice [np.float32(0.8429), np.float32(0.8426)] 
2025-03-30 18:55:52.116553: Epoch time: 26.68 s 
2025-03-30 18:55:52.881597:  
2025-03-30 18:55:52.881709: Epoch 194 
2025-03-30 18:55:52.881800: Current learning rate: 0.00824 
2025-03-30 18:56:19.691822: train_loss -0.6343 
2025-03-30 18:56:19.691967: val_loss -0.6635 
2025-03-30 18:56:19.692023: Pseudo dice [np.float32(0.8688), np.float32(0.8615)] 
2025-03-30 18:56:19.692088: Epoch time: 26.81 s 
2025-03-30 18:56:20.454408:  
2025-03-30 18:56:20.454548: Epoch 195 
2025-03-30 18:56:20.454619: Current learning rate: 0.00823 
2025-03-30 18:56:47.304015: train_loss -0.6372 
2025-03-30 18:56:47.304180: val_loss -0.6463 
2025-03-30 18:56:47.304236: Pseudo dice [np.float32(0.8722), np.float32(0.8711)] 
2025-03-30 18:56:47.304344: Epoch time: 26.85 s 
2025-03-30 18:56:48.666121:  
2025-03-30 18:56:48.666299: Epoch 196 
2025-03-30 18:56:48.666377: Current learning rate: 0.00822 
2025-03-30 18:57:15.408159: train_loss -0.6492 
2025-03-30 18:57:15.408304: val_loss -0.6512 
2025-03-30 18:57:15.408396: Pseudo dice [np.float32(0.8605), np.float32(0.8593)] 
2025-03-30 18:57:15.408461: Epoch time: 26.74 s 
2025-03-30 18:57:16.164668:  
2025-03-30 18:57:16.164795: Epoch 197 
2025-03-30 18:57:16.164882: Current learning rate: 0.00821 
2025-03-30 18:57:42.894918: train_loss -0.6496 
2025-03-30 18:57:42.895051: val_loss -0.6529 
2025-03-30 18:57:42.895107: Pseudo dice [np.float32(0.8735), np.float32(0.8514)] 
2025-03-30 18:57:42.895169: Epoch time: 26.73 s 
2025-03-30 18:57:42.895217: Yayy! New best EMA pseudo Dice: 0.8560000061988831 
2025-03-30 18:57:44.150055:  
2025-03-30 18:57:44.150144: Epoch 198 
2025-03-30 18:57:44.150221: Current learning rate: 0.0082 
2025-03-30 18:58:10.798305: train_loss -0.6462 
2025-03-30 18:58:10.798428: val_loss -0.6676 
2025-03-30 18:58:10.798513: Pseudo dice [np.float32(0.8789), np.float32(0.8581)] 
2025-03-30 18:58:10.798577: Epoch time: 26.65 s 
2025-03-30 18:58:10.798625: Yayy! New best EMA pseudo Dice: 0.8572999835014343 
2025-03-30 18:58:12.095302:  
2025-03-30 18:58:12.095470: Epoch 199 
2025-03-30 18:58:12.095551: Current learning rate: 0.00819 
2025-03-30 18:58:39.423195: train_loss -0.6345 
2025-03-30 18:58:39.423375: val_loss -0.6097 
2025-03-30 18:58:39.423431: Pseudo dice [np.float32(0.8603), np.float32(0.8389)] 
2025-03-30 18:58:39.423495: Epoch time: 27.33 s 
2025-03-30 18:58:40.689665:  
2025-03-30 18:58:40.689794: Epoch 200 
2025-03-30 18:58:40.689887: Current learning rate: 0.00818 
2025-03-30 18:59:07.326043: train_loss -0.6336 
2025-03-30 18:59:07.326200: val_loss -0.6567 
2025-03-30 18:59:07.326255: Pseudo dice [np.float32(0.868), np.float32(0.8587)] 
2025-03-30 18:59:07.326319: Epoch time: 26.64 s 
2025-03-30 18:59:08.088664:  
2025-03-30 18:59:08.088764: Epoch 201 
2025-03-30 18:59:08.088836: Current learning rate: 0.00817 
2025-03-30 18:59:34.760696: train_loss -0.6551 
2025-03-30 18:59:34.760890: val_loss -0.6478 
2025-03-30 18:59:34.760947: Pseudo dice [np.float32(0.8654), np.float32(0.8664)] 
2025-03-30 18:59:34.761010: Epoch time: 26.67 s 
2025-03-30 18:59:34.761058: Yayy! New best EMA pseudo Dice: 0.8579999804496765 
2025-03-30 18:59:39.185691:  
2025-03-30 18:59:39.185803: Epoch 202 
2025-03-30 18:59:39.185876: Current learning rate: 0.00816 
2025-03-30 19:00:05.865405: train_loss -0.6422 
2025-03-30 19:00:05.865566: val_loss -0.6605 
2025-03-30 19:00:05.865626: Pseudo dice [np.float32(0.8787), np.float32(0.8602)] 
2025-03-30 19:00:05.865690: Epoch time: 26.68 s 
2025-03-30 19:00:05.865740: Yayy! New best EMA pseudo Dice: 0.8592000007629395 
2025-03-30 19:00:07.292704:  
2025-03-30 19:00:07.292834: Epoch 203 
2025-03-30 19:00:07.292911: Current learning rate: 0.00815 
2025-03-30 19:00:33.964509: train_loss -0.6539 
2025-03-30 19:00:33.964632: val_loss -0.6256 
2025-03-30 19:00:33.964687: Pseudo dice [np.float32(0.8474), np.float32(0.8524)] 
2025-03-30 19:00:33.964749: Epoch time: 26.67 s 
2025-03-30 19:00:34.745435:  
2025-03-30 19:00:34.745545: Epoch 204 
2025-03-30 19:00:34.745620: Current learning rate: 0.00814 
2025-03-30 19:01:01.426083: train_loss -0.6483 
2025-03-30 19:01:01.426215: val_loss -0.6531 
2025-03-30 19:01:01.426271: Pseudo dice [np.float32(0.8624), np.float32(0.8529)] 
2025-03-30 19:01:01.426332: Epoch time: 26.68 s 
2025-03-30 19:01:02.191777:  
2025-03-30 19:01:02.191877: Epoch 205 
2025-03-30 19:01:02.191955: Current learning rate: 0.00813 
2025-03-30 19:01:28.862668: train_loss -0.6475 
2025-03-30 19:01:28.862812: val_loss -0.6226 
2025-03-30 19:01:28.862871: Pseudo dice [np.float32(0.8502), np.float32(0.8411)] 
2025-03-30 19:01:28.862933: Epoch time: 26.67 s 
2025-03-30 19:01:29.604504:  
2025-03-30 19:01:29.604611: Epoch 206 
2025-03-30 19:01:29.604733: Current learning rate: 0.00813 
2025-03-30 19:01:56.321829: train_loss -0.6533 
2025-03-30 19:01:56.321957: val_loss -0.6621 
2025-03-30 19:01:56.322012: Pseudo dice [np.float32(0.8789), np.float32(0.8557)] 
2025-03-30 19:01:56.322072: Epoch time: 26.72 s 
2025-03-30 19:01:57.066336:  
2025-03-30 19:01:57.066415: Epoch 207 
2025-03-30 19:01:57.066490: Current learning rate: 0.00812 
2025-03-30 19:02:23.752960: train_loss -0.6631 
2025-03-30 19:02:23.753087: val_loss -0.6992 
2025-03-30 19:02:23.753142: Pseudo dice [np.float32(0.8908), np.float32(0.8696)] 
2025-03-30 19:02:23.753204: Epoch time: 26.69 s 
2025-03-30 19:02:23.753253: Yayy! New best EMA pseudo Dice: 0.8601999878883362 
2025-03-30 19:02:25.055372:  
2025-03-30 19:02:25.055474: Epoch 208 
2025-03-30 19:02:25.055606: Current learning rate: 0.00811 
2025-03-30 19:02:51.819744: train_loss -0.6748 
2025-03-30 19:02:51.819882: val_loss -0.6755 
2025-03-30 19:02:51.819937: Pseudo dice [np.float32(0.8779), np.float32(0.8638)] 
2025-03-30 19:02:51.820014: Epoch time: 26.77 s 
2025-03-30 19:02:51.820063: Yayy! New best EMA pseudo Dice: 0.861299991607666 
2025-03-30 19:02:53.107671:  
2025-03-30 19:02:53.107768: Epoch 209 
2025-03-30 19:02:53.107874: Current learning rate: 0.0081 
2025-03-30 19:03:19.788900: train_loss -0.6855 
2025-03-30 19:03:19.789137: val_loss -0.6327 
2025-03-30 19:03:19.789212: Pseudo dice [np.float32(0.8623), np.float32(0.8475)] 
2025-03-30 19:03:19.789300: Epoch time: 26.68 s 
2025-03-30 19:03:20.534926:  
2025-03-30 19:03:20.535038: Epoch 210 
2025-03-30 19:03:20.535130: Current learning rate: 0.00809 
2025-03-30 19:03:47.211305: train_loss -0.6625 
2025-03-30 19:03:47.211431: val_loss -0.6706 
2025-03-30 19:03:47.211487: Pseudo dice [np.float32(0.8781), np.float32(0.8681)] 
2025-03-30 19:03:47.211546: Epoch time: 26.68 s 
2025-03-30 19:03:47.211595: Yayy! New best EMA pseudo Dice: 0.8618999719619751 
2025-03-30 19:03:48.640747:  
2025-03-30 19:03:48.640829: Epoch 211 
2025-03-30 19:03:48.640936: Current learning rate: 0.00808 
2025-03-30 19:04:15.355289: train_loss -0.6761 
2025-03-30 19:04:15.355455: val_loss -0.6917 
2025-03-30 19:04:15.355511: Pseudo dice [np.float32(0.8914), np.float32(0.8764)] 
2025-03-30 19:04:15.355597: Epoch time: 26.72 s 
2025-03-30 19:04:15.355671: Yayy! New best EMA pseudo Dice: 0.8640999794006348 
2025-03-30 19:04:16.813371:  
2025-03-30 19:04:16.813476: Epoch 212 
2025-03-30 19:04:16.813543: Current learning rate: 0.00807 
2025-03-30 19:04:43.535466: train_loss -0.6712 
2025-03-30 19:04:43.535632: val_loss -0.6572 
2025-03-30 19:04:43.535696: Pseudo dice [np.float32(0.8722), np.float32(0.8705)] 
2025-03-30 19:04:43.535776: Epoch time: 26.72 s 
2025-03-30 19:04:43.535835: Yayy! New best EMA pseudo Dice: 0.864799976348877 
2025-03-30 19:04:45.057385:  
2025-03-30 19:04:45.057463: Epoch 213 
2025-03-30 19:04:45.057531: Current learning rate: 0.00806 
2025-03-30 19:05:11.693384: train_loss -0.7012 
2025-03-30 19:05:11.693593: val_loss -0.6707 
2025-03-30 19:05:11.693679: Pseudo dice [np.float32(0.8788), np.float32(0.8616)] 
2025-03-30 19:05:11.693743: Epoch time: 26.64 s 
2025-03-30 19:05:11.693800: Yayy! New best EMA pseudo Dice: 0.8652999997138977 
2025-03-30 19:05:14.318156:  
2025-03-30 19:05:14.318291: Epoch 214 
2025-03-30 19:05:14.318377: Current learning rate: 0.00805 
2025-03-30 19:05:40.998375: train_loss -0.6922 
2025-03-30 19:05:40.998501: val_loss -0.6649 
2025-03-30 19:05:40.998556: Pseudo dice [np.float32(0.8739), np.float32(0.867)] 
2025-03-30 19:05:40.998614: Epoch time: 26.68 s 
2025-03-30 19:05:40.998661: Yayy! New best EMA pseudo Dice: 0.8658999800682068 
2025-03-30 19:05:42.267842:  
2025-03-30 19:05:42.267944: Epoch 215 
2025-03-30 19:05:42.268023: Current learning rate: 0.00804 
2025-03-30 19:06:08.985807: train_loss -0.6539 
2025-03-30 19:06:08.985930: val_loss -0.6995 
2025-03-30 19:06:08.985985: Pseudo dice [np.float32(0.8937), np.float32(0.8725)] 
2025-03-30 19:06:08.986050: Epoch time: 26.72 s 
2025-03-30 19:06:08.986156: Yayy! New best EMA pseudo Dice: 0.8676000237464905 
2025-03-30 19:06:10.251341:  
2025-03-30 19:06:10.251441: Epoch 216 
2025-03-30 19:06:10.251519: Current learning rate: 0.00803 
2025-03-30 19:06:37.007373: train_loss -0.6825 
2025-03-30 19:06:37.007509: val_loss -0.6967 
2025-03-30 19:06:37.007567: Pseudo dice [np.float32(0.8911), np.float32(0.8707)] 
2025-03-30 19:06:37.007629: Epoch time: 26.76 s 
2025-03-30 19:06:37.007678: Yayy! New best EMA pseudo Dice: 0.8689000010490417 
2025-03-30 19:06:38.271410:  
2025-03-30 19:06:38.271574: Epoch 217 
2025-03-30 19:06:38.271647: Current learning rate: 0.00802 
2025-03-30 19:07:05.003623: train_loss -0.6791 
2025-03-30 19:07:05.003789: val_loss -0.632 
2025-03-30 19:07:05.003847: Pseudo dice [np.float32(0.8475), np.float32(0.8484)] 
2025-03-30 19:07:05.003909: Epoch time: 26.73 s 
2025-03-30 19:07:05.752887:  
2025-03-30 19:07:05.752978: Epoch 218 
2025-03-30 19:07:05.753055: Current learning rate: 0.00801 
2025-03-30 19:07:32.462701: train_loss -0.6673 
2025-03-30 19:07:32.462854: val_loss -0.6655 
2025-03-30 19:07:32.462910: Pseudo dice [np.float32(0.8774), np.float32(0.8609)] 
2025-03-30 19:07:32.462972: Epoch time: 26.71 s 
2025-03-30 19:07:33.217606:  
2025-03-30 19:07:33.217719: Epoch 219 
2025-03-30 19:07:33.217807: Current learning rate: 0.00801 
2025-03-30 19:07:59.883376: train_loss -0.6688 
2025-03-30 19:07:59.883520: val_loss -0.6572 
2025-03-30 19:07:59.883575: Pseudo dice [np.float32(0.8783), np.float32(0.8446)] 
2025-03-30 19:07:59.883633: Epoch time: 26.67 s 
2025-03-30 19:08:00.630611:  
2025-03-30 19:08:00.630775: Epoch 220 
2025-03-30 19:08:00.630858: Current learning rate: 0.008 
2025-03-30 19:08:27.350847: train_loss -0.6606 
2025-03-30 19:08:27.350980: val_loss -0.6619 
2025-03-30 19:08:27.351036: Pseudo dice [np.float32(0.8629), np.float32(0.8559)] 
2025-03-30 19:08:27.351100: Epoch time: 26.72 s 
2025-03-30 19:08:28.101599:  
2025-03-30 19:08:28.101743: Epoch 221 
2025-03-30 19:08:28.101851: Current learning rate: 0.00799 
2025-03-30 19:08:54.851463: train_loss -0.6684 
2025-03-30 19:08:54.851640: val_loss -0.6491 
2025-03-30 19:08:54.851697: Pseudo dice [np.float32(0.8563), np.float32(0.8626)] 
2025-03-30 19:08:54.851767: Epoch time: 26.75 s 
2025-03-30 19:08:55.592223:  
2025-03-30 19:08:55.592325: Epoch 222 
2025-03-30 19:08:55.592402: Current learning rate: 0.00798 
2025-03-30 19:09:22.292796: train_loss -0.6715 
2025-03-30 19:09:22.292955: val_loss -0.6658 
2025-03-30 19:09:22.293011: Pseudo dice [np.float32(0.8695), np.float32(0.8642)] 
2025-03-30 19:09:22.293090: Epoch time: 26.7 s 
2025-03-30 19:09:23.036294:  
2025-03-30 19:09:23.036381: Epoch 223 
2025-03-30 19:09:23.036456: Current learning rate: 0.00797 
2025-03-30 19:09:49.788300: train_loss -0.6871 
2025-03-30 19:09:49.788446: val_loss -0.6462 
2025-03-30 19:09:49.788504: Pseudo dice [np.float32(0.8617), np.float32(0.8598)] 
2025-03-30 19:09:49.788564: Epoch time: 26.75 s 
2025-03-30 19:09:50.529137:  
2025-03-30 19:09:50.529296: Epoch 224 
2025-03-30 19:09:50.529377: Current learning rate: 0.00796 
2025-03-30 19:10:17.196140: train_loss -0.6864 
2025-03-30 19:10:17.196268: val_loss -0.6568 
2025-03-30 19:10:17.196324: Pseudo dice [np.float32(0.8773), np.float32(0.858)] 
2025-03-30 19:10:17.196385: Epoch time: 26.67 s 
2025-03-30 19:10:17.943551:  
2025-03-30 19:10:17.943674: Epoch 225 
2025-03-30 19:10:17.943757: Current learning rate: 0.00795 
2025-03-30 19:10:44.682063: train_loss -0.6908 
2025-03-30 19:10:44.682228: val_loss -0.6644 
2025-03-30 19:10:44.682285: Pseudo dice [np.float32(0.8706), np.float32(0.8646)] 
2025-03-30 19:10:44.682345: Epoch time: 26.74 s 
2025-03-30 19:10:45.419214:  
2025-03-30 19:10:45.419376: Epoch 226 
2025-03-30 19:10:45.419461: Current learning rate: 0.00794 
2025-03-30 19:11:12.123101: train_loss -0.6806 
2025-03-30 19:11:12.123287: val_loss -0.6553 
2025-03-30 19:11:12.123344: Pseudo dice [np.float32(0.8689), np.float32(0.8527)] 
2025-03-30 19:11:12.123404: Epoch time: 26.7 s 
2025-03-30 19:11:12.854185:  
2025-03-30 19:11:12.854278: Epoch 227 
2025-03-30 19:11:12.854349: Current learning rate: 0.00793 
2025-03-30 19:11:39.586122: train_loss -0.6604 
2025-03-30 19:11:39.586270: val_loss -0.6507 
2025-03-30 19:11:39.586369: Pseudo dice [np.float32(0.873), np.float32(0.8508)] 
2025-03-30 19:11:39.586433: Epoch time: 26.73 s 
2025-03-30 19:11:40.320650:  
2025-03-30 19:11:40.320775: Epoch 228 
2025-03-30 19:11:40.320858: Current learning rate: 0.00792 
2025-03-30 19:12:07.065721: train_loss -0.6943 
2025-03-30 19:12:07.065846: val_loss -0.7092 
2025-03-30 19:12:07.065902: Pseudo dice [np.float32(0.8905), np.float32(0.8749)] 
2025-03-30 19:12:07.065961: Epoch time: 26.75 s 
2025-03-30 19:12:07.801330:  
2025-03-30 19:12:07.801441: Epoch 229 
2025-03-30 19:12:07.801524: Current learning rate: 0.00791 
2025-03-30 19:12:34.576469: train_loss -0.6825 
2025-03-30 19:12:34.576739: val_loss -0.6962 
2025-03-30 19:12:34.576807: Pseudo dice [np.float32(0.8791), np.float32(0.8837)] 
2025-03-30 19:12:34.576869: Epoch time: 26.78 s 
2025-03-30 19:12:35.308093:  
2025-03-30 19:12:35.308259: Epoch 230 
2025-03-30 19:12:35.308379: Current learning rate: 0.0079 
2025-03-30 19:13:02.023668: train_loss -0.6816 
2025-03-30 19:13:02.023934: val_loss -0.6291 
2025-03-30 19:13:02.024020: Pseudo dice [np.float32(0.8552), np.float32(0.8457)] 
2025-03-30 19:13:02.024095: Epoch time: 26.72 s 
2025-03-30 19:13:02.762707:  
2025-03-30 19:13:02.762869: Epoch 231 
2025-03-30 19:13:02.762939: Current learning rate: 0.00789 
2025-03-30 19:13:29.483324: train_loss -0.6401 
2025-03-30 19:13:29.483597: val_loss -0.654 
2025-03-30 19:13:29.483656: Pseudo dice [np.float32(0.8661), np.float32(0.8495)] 
2025-03-30 19:13:29.483718: Epoch time: 26.72 s 
2025-03-30 19:13:30.219915:  
2025-03-30 19:13:30.220071: Epoch 232 
2025-03-30 19:13:30.220185: Current learning rate: 0.00789 
2025-03-30 19:13:56.937407: train_loss -0.6654 
2025-03-30 19:13:56.937577: val_loss -0.6019 
2025-03-30 19:13:56.937633: Pseudo dice [np.float32(0.8518), np.float32(0.83)] 
2025-03-30 19:13:56.937696: Epoch time: 26.72 s 
2025-03-30 19:13:57.680016:  
2025-03-30 19:13:57.680106: Epoch 233 
2025-03-30 19:13:57.680186: Current learning rate: 0.00788 
2025-03-30 19:14:24.421057: train_loss -0.6655 
2025-03-30 19:14:24.421227: val_loss -0.6882 
2025-03-30 19:14:24.421283: Pseudo dice [np.float32(0.8834), np.float32(0.8683)] 
2025-03-30 19:14:24.421345: Epoch time: 26.74 s 
2025-03-30 19:14:25.226968:  
2025-03-30 19:14:25.227066: Epoch 234 
2025-03-30 19:14:25.227145: Current learning rate: 0.00787 
2025-03-30 19:14:51.999229: train_loss -0.6787 
2025-03-30 19:14:51.999400: val_loss -0.6843 
2025-03-30 19:14:51.999455: Pseudo dice [np.float32(0.8719), np.float32(0.8628)] 
2025-03-30 19:14:51.999518: Epoch time: 26.77 s 
2025-03-30 19:14:53.365186:  
2025-03-30 19:14:53.365299: Epoch 235 
2025-03-30 19:14:53.365383: Current learning rate: 0.00786 
2025-03-30 19:15:20.106549: train_loss -0.689 
2025-03-30 19:15:20.106716: val_loss -0.608 
2025-03-30 19:15:20.106825: Pseudo dice [np.float32(0.8491), np.float32(0.8346)] 
2025-03-30 19:15:20.106916: Epoch time: 26.74 s 
2025-03-30 19:15:20.838840:  
2025-03-30 19:15:20.838948: Epoch 236 
2025-03-30 19:15:20.839056: Current learning rate: 0.00785 
2025-03-30 19:15:47.567726: train_loss -0.6645 
2025-03-30 19:15:47.567919: val_loss -0.6426 
2025-03-30 19:15:47.567992: Pseudo dice [np.float32(0.8742), np.float32(0.8364)] 
2025-03-30 19:15:47.568079: Epoch time: 26.73 s 
2025-03-30 19:15:48.306467:  
2025-03-30 19:15:48.306646: Epoch 237 
2025-03-30 19:15:48.306725: Current learning rate: 0.00784 
2025-03-30 19:16:15.027376: train_loss -0.6762 
2025-03-30 19:16:15.027511: val_loss -0.6832 
2025-03-30 19:16:15.027566: Pseudo dice [np.float32(0.8986), np.float32(0.8603)] 
2025-03-30 19:16:15.027627: Epoch time: 26.72 s 
2025-03-30 19:16:15.757539:  
2025-03-30 19:16:15.757645: Epoch 238 
2025-03-30 19:16:15.757725: Current learning rate: 0.00783 
2025-03-30 19:16:42.480185: train_loss -0.666 
2025-03-30 19:16:42.480326: val_loss -0.6774 
2025-03-30 19:16:42.480382: Pseudo dice [np.float32(0.8754), np.float32(0.8798)] 
2025-03-30 19:16:42.480445: Epoch time: 26.72 s 
2025-03-30 19:16:43.225552:  
2025-03-30 19:16:43.225683: Epoch 239 
2025-03-30 19:16:43.225770: Current learning rate: 0.00782 
2025-03-30 19:17:10.026724: train_loss -0.6733 
2025-03-30 19:17:10.026870: val_loss -0.6691 
2025-03-30 19:17:10.026928: Pseudo dice [np.float32(0.8684), np.float32(0.8626)] 
2025-03-30 19:17:10.026991: Epoch time: 26.8 s 
2025-03-30 19:17:10.773028:  
2025-03-30 19:17:10.773140: Epoch 240 
2025-03-30 19:17:10.773218: Current learning rate: 0.00781 
2025-03-30 19:17:37.506916: train_loss -0.6832 
2025-03-30 19:17:37.507065: val_loss -0.6968 
2025-03-30 19:17:37.507120: Pseudo dice [np.float32(0.8859), np.float32(0.8694)] 
2025-03-30 19:17:37.507181: Epoch time: 26.73 s 
2025-03-30 19:17:38.255798:  
2025-03-30 19:17:38.255886: Epoch 241 
2025-03-30 19:17:38.255965: Current learning rate: 0.0078 
2025-03-30 19:18:04.969917: train_loss -0.694 
2025-03-30 19:18:04.970047: val_loss -0.6844 
2025-03-30 19:18:04.970102: Pseudo dice [np.float32(0.8901), np.float32(0.8708)] 
2025-03-30 19:18:04.970164: Epoch time: 26.72 s 
2025-03-30 19:18:05.712935:  
2025-03-30 19:18:05.713056: Epoch 242 
2025-03-30 19:18:05.713158: Current learning rate: 0.00779 
2025-03-30 19:18:32.434232: train_loss -0.6794 
2025-03-30 19:18:32.434361: val_loss -0.6502 
2025-03-30 19:18:32.434417: Pseudo dice [np.float32(0.8622), np.float32(0.8492)] 
2025-03-30 19:18:32.434477: Epoch time: 26.72 s 
2025-03-30 19:18:33.176694:  
2025-03-30 19:18:33.176877: Epoch 243 
2025-03-30 19:18:33.176961: Current learning rate: 0.00778 
2025-03-30 19:18:59.878888: train_loss -0.661 
2025-03-30 19:18:59.879023: val_loss -0.6565 
2025-03-30 19:18:59.879078: Pseudo dice [np.float32(0.8729), np.float32(0.8602)] 
2025-03-30 19:18:59.879139: Epoch time: 26.7 s 
2025-03-30 19:19:00.617879:  
2025-03-30 19:19:00.618030: Epoch 244 
2025-03-30 19:19:00.618116: Current learning rate: 0.00777 
2025-03-30 19:19:27.326294: train_loss -0.6746 
2025-03-30 19:19:27.326444: val_loss -0.6465 
2025-03-30 19:19:27.326500: Pseudo dice [np.float32(0.8652), np.float32(0.8563)] 
2025-03-30 19:19:27.326561: Epoch time: 26.71 s 
2025-03-30 19:19:28.062741:  
2025-03-30 19:19:28.062918: Epoch 245 
2025-03-30 19:19:28.063000: Current learning rate: 0.00777 
2025-03-30 19:19:54.804868: train_loss -0.6613 
2025-03-30 19:19:54.805002: val_loss -0.6264 
2025-03-30 19:19:54.805057: Pseudo dice [np.float32(0.857), np.float32(0.8445)] 
2025-03-30 19:19:54.805118: Epoch time: 26.74 s 
2025-03-30 19:19:55.550180:  
2025-03-30 19:19:55.550316: Epoch 246 
2025-03-30 19:19:55.550390: Current learning rate: 0.00776 
2025-03-30 19:20:22.242053: train_loss -0.646 
2025-03-30 19:20:22.242256: val_loss -0.5488 
2025-03-30 19:20:22.242314: Pseudo dice [np.float32(0.805), np.float32(0.8167)] 
2025-03-30 19:20:22.242377: Epoch time: 26.69 s 
2025-03-30 19:20:22.984938:  
2025-03-30 19:20:22.985082: Epoch 247 
2025-03-30 19:20:22.985170: Current learning rate: 0.00775 
2025-03-30 19:20:49.689025: train_loss -0.6349 
2025-03-30 19:20:49.689155: val_loss -0.6686 
2025-03-30 19:20:49.689209: Pseudo dice [np.float32(0.8706), np.float32(0.867)] 
2025-03-30 19:20:49.689286: Epoch time: 26.71 s 
2025-03-30 19:20:50.428219:  
2025-03-30 19:20:50.428364: Epoch 248 
2025-03-30 19:20:50.428450: Current learning rate: 0.00774 
2025-03-30 19:21:17.152882: train_loss -0.6628 
2025-03-30 19:21:17.153039: val_loss -0.6861 
2025-03-30 19:21:17.153097: Pseudo dice [np.float32(0.8864), np.float32(0.8771)] 
2025-03-30 19:21:17.153158: Epoch time: 26.73 s 
2025-03-30 19:21:17.894276:  
2025-03-30 19:21:17.894433: Epoch 249 
2025-03-30 19:21:17.894505: Current learning rate: 0.00773 
2025-03-30 19:21:44.598697: train_loss -0.6801 
2025-03-30 19:21:44.598869: val_loss -0.6456 
2025-03-30 19:21:44.598926: Pseudo dice [np.float32(0.8679), np.float32(0.8493)] 
2025-03-30 19:21:44.598988: Epoch time: 26.71 s 
2025-03-30 19:21:45.892653:  
2025-03-30 19:21:45.892773: Epoch 250 
2025-03-30 19:21:45.892858: Current learning rate: 0.00772 
2025-03-30 19:22:12.672585: train_loss -0.6854 
2025-03-30 19:22:12.672713: val_loss -0.6553 
2025-03-30 19:22:12.672783: Pseudo dice [np.float32(0.8582), np.float32(0.8516)] 
2025-03-30 19:22:12.672853: Epoch time: 26.78 s 
2025-03-30 19:22:13.415726:  
2025-03-30 19:22:13.415883: Epoch 251 
2025-03-30 19:22:13.415959: Current learning rate: 0.00771 
2025-03-30 19:22:40.358109: train_loss -0.685 
2025-03-30 19:22:40.358282: val_loss -0.6923 
2025-03-30 19:22:40.358339: Pseudo dice [np.float32(0.8774), np.float32(0.8837)] 
2025-03-30 19:22:40.358399: Epoch time: 26.94 s 
2025-03-30 19:22:41.099566:  
2025-03-30 19:22:41.099712: Epoch 252 
2025-03-30 19:22:41.099830: Current learning rate: 0.0077 
2025-03-30 19:23:07.871703: train_loss -0.696 
2025-03-30 19:23:07.871857: val_loss -0.6905 
2025-03-30 19:23:07.871943: Pseudo dice [np.float32(0.8762), np.float32(0.8654)] 
2025-03-30 19:23:07.872007: Epoch time: 26.77 s 
2025-03-30 19:23:08.618443:  
2025-03-30 19:23:08.618578: Epoch 253 
2025-03-30 19:23:08.618649: Current learning rate: 0.00769 
2025-03-30 19:23:35.446693: train_loss -0.7039 
2025-03-30 19:23:35.446850: val_loss -0.6918 
2025-03-30 19:23:35.446907: Pseudo dice [np.float32(0.886), np.float32(0.8732)] 
2025-03-30 19:23:35.446968: Epoch time: 26.83 s 
2025-03-30 19:23:36.191394:  
2025-03-30 19:23:36.191501: Epoch 254 
2025-03-30 19:23:36.191581: Current learning rate: 0.00768 
2025-03-30 19:24:02.960458: train_loss -0.7045 
2025-03-30 19:24:02.960693: val_loss -0.6748 
2025-03-30 19:24:02.960752: Pseudo dice [np.float32(0.8772), np.float32(0.8635)] 
2025-03-30 19:24:02.960854: Epoch time: 26.77 s 
2025-03-30 19:24:03.698542:  
2025-03-30 19:24:03.698659: Epoch 255 
2025-03-30 19:24:03.698789: Current learning rate: 0.00767 
2025-03-30 19:24:30.519218: train_loss -0.6838 
2025-03-30 19:24:30.519449: val_loss -0.6962 
2025-03-30 19:24:30.519555: Pseudo dice [np.float32(0.8839), np.float32(0.8728)] 
2025-03-30 19:24:30.519620: Epoch time: 26.82 s 
2025-03-30 19:24:31.896692:  
2025-03-30 19:24:31.896864: Epoch 256 
2025-03-30 19:24:31.896958: Current learning rate: 0.00766 
2025-03-30 19:24:58.957028: train_loss -0.6956 
2025-03-30 19:24:58.957269: val_loss -0.6836 
2025-03-30 19:24:58.957368: Pseudo dice [np.float32(0.8733), np.float32(0.8789)] 
2025-03-30 19:24:58.957433: Epoch time: 27.06 s 
2025-03-30 19:24:59.700845:  
2025-03-30 19:24:59.701003: Epoch 257 
2025-03-30 19:24:59.701079: Current learning rate: 0.00765 
2025-03-30 19:25:26.589221: train_loss -0.6906 
2025-03-30 19:25:26.589352: val_loss -0.6589 
2025-03-30 19:25:26.589418: Pseudo dice [np.float32(0.8687), np.float32(0.8621)] 
2025-03-30 19:25:26.589518: Epoch time: 26.89 s 
2025-03-30 19:25:27.332714:  
2025-03-30 19:25:27.332876: Epoch 258 
2025-03-30 19:25:27.332952: Current learning rate: 0.00764 
2025-03-30 19:25:54.070584: train_loss -0.6921 
2025-03-30 19:25:54.070754: val_loss -0.7089 
2025-03-30 19:25:54.070819: Pseudo dice [np.float32(0.893), np.float32(0.8779)] 
2025-03-30 19:25:54.070880: Epoch time: 26.74 s 
2025-03-30 19:25:54.070929: Yayy! New best EMA pseudo Dice: 0.8694999814033508 
2025-03-30 19:25:55.306131:  
2025-03-30 19:25:55.306273: Epoch 259 
2025-03-30 19:25:55.306357: Current learning rate: 0.00764 
2025-03-30 19:26:21.988837: train_loss -0.6872 
2025-03-30 19:26:21.988973: val_loss -0.6953 
2025-03-30 19:26:21.989050: Pseudo dice [np.float32(0.8846), np.float32(0.8748)] 
2025-03-30 19:26:21.989113: Epoch time: 26.68 s 
2025-03-30 19:26:21.989174: Yayy! New best EMA pseudo Dice: 0.8705999851226807 
2025-03-30 19:26:23.274074:  
2025-03-30 19:26:23.274178: Epoch 260 
2025-03-30 19:26:23.274239: Current learning rate: 0.00763 
2025-03-30 19:26:49.887174: train_loss -0.6985 
2025-03-30 19:26:49.887319: val_loss -0.7202 
2025-03-30 19:26:49.887376: Pseudo dice [np.float32(0.8959), np.float32(0.8883)] 
2025-03-30 19:26:49.887436: Epoch time: 26.61 s 
2025-03-30 19:26:49.887484: Yayy! New best EMA pseudo Dice: 0.8726999759674072 
2025-03-30 19:26:51.172794:  
2025-03-30 19:26:51.172992: Epoch 261 
2025-03-30 19:26:51.173060: Current learning rate: 0.00762 
2025-03-30 19:27:17.824519: train_loss -0.6858 
2025-03-30 19:27:17.824672: val_loss -0.6796 
2025-03-30 19:27:17.824790: Pseudo dice [np.float32(0.8791), np.float32(0.8732)] 
2025-03-30 19:27:17.824858: Epoch time: 26.65 s 
2025-03-30 19:27:17.824907: Yayy! New best EMA pseudo Dice: 0.8730999827384949 
2025-03-30 19:27:19.126535:  
2025-03-30 19:27:19.126736: Epoch 262 
2025-03-30 19:27:19.126828: Current learning rate: 0.00761 
2025-03-30 19:27:46.330225: train_loss -0.6818 
2025-03-30 19:27:46.330357: val_loss -0.6174 
2025-03-30 19:27:46.330414: Pseudo dice [np.float32(0.853), np.float32(0.8429)] 
2025-03-30 19:27:46.330510: Epoch time: 27.2 s 
2025-03-30 19:27:47.098469:  
2025-03-30 19:27:47.098632: Epoch 263 
2025-03-30 19:27:47.098720: Current learning rate: 0.0076 
2025-03-30 19:28:14.626983: train_loss -0.6695 
2025-03-30 19:28:14.627269: val_loss -0.6793 
2025-03-30 19:28:14.627328: Pseudo dice [np.float32(0.8775), np.float32(0.8611)] 
2025-03-30 19:28:14.627390: Epoch time: 27.53 s 
2025-03-30 19:28:15.392947:  
2025-03-30 19:28:15.393123: Epoch 264 
2025-03-30 19:28:15.393205: Current learning rate: 0.00759 
2025-03-30 19:28:42.575952: train_loss -0.6705 
2025-03-30 19:28:42.576189: val_loss -0.7084 
2025-03-30 19:28:42.576247: Pseudo dice [np.float32(0.8917), np.float32(0.8824)] 
2025-03-30 19:28:42.576310: Epoch time: 27.18 s 
2025-03-30 19:28:43.341571:  
2025-03-30 19:28:43.341731: Epoch 265 
2025-03-30 19:28:43.341824: Current learning rate: 0.00758 
2025-03-30 19:29:10.537264: train_loss -0.693 
2025-03-30 19:29:10.537395: val_loss -0.6425 
2025-03-30 19:29:10.537451: Pseudo dice [np.float32(0.8656), np.float32(0.8386)] 
2025-03-30 19:29:10.537513: Epoch time: 27.2 s 
2025-03-30 19:29:11.278837:  
2025-03-30 19:29:11.278979: Epoch 266 
2025-03-30 19:29:11.279065: Current learning rate: 0.00757 
2025-03-30 19:29:38.218536: train_loss -0.6792 
2025-03-30 19:29:38.218670: val_loss -0.6795 
2025-03-30 19:29:38.218724: Pseudo dice [np.float32(0.8735), np.float32(0.8689)] 
2025-03-30 19:29:38.218806: Epoch time: 26.94 s 
2025-03-30 19:29:38.961154:  
2025-03-30 19:29:38.961320: Epoch 267 
2025-03-30 19:29:38.961398: Current learning rate: 0.00756 
2025-03-30 19:30:06.216168: train_loss -0.7064 
2025-03-30 19:30:06.216298: val_loss -0.6435 
2025-03-30 19:30:06.216353: Pseudo dice [np.float32(0.8607), np.float32(0.8531)] 
2025-03-30 19:30:06.216411: Epoch time: 27.26 s 
2025-03-30 19:30:06.963528:  
2025-03-30 19:30:06.963683: Epoch 268 
2025-03-30 19:30:06.963789: Current learning rate: 0.00755 
2025-03-30 19:30:33.802807: train_loss -0.7092 
2025-03-30 19:30:33.802940: val_loss -0.6787 
2025-03-30 19:30:33.802996: Pseudo dice [np.float32(0.8743), np.float32(0.8679)] 
2025-03-30 19:30:33.803057: Epoch time: 26.84 s 
2025-03-30 19:30:34.550051:  
2025-03-30 19:30:34.550147: Epoch 269 
2025-03-30 19:30:34.550228: Current learning rate: 0.00754 
2025-03-30 19:31:01.409655: train_loss -0.6998 
2025-03-30 19:31:01.409819: val_loss -0.7123 
2025-03-30 19:31:01.409879: Pseudo dice [np.float32(0.8934), np.float32(0.8799)] 
2025-03-30 19:31:01.409961: Epoch time: 26.86 s 
2025-03-30 19:31:02.149552:  
2025-03-30 19:31:02.149687: Epoch 270 
2025-03-30 19:31:02.149771: Current learning rate: 0.00753 
2025-03-30 19:31:29.298862: train_loss -0.7012 
2025-03-30 19:31:29.299002: val_loss -0.7021 
2025-03-30 19:31:29.299072: Pseudo dice [np.float32(0.8743), np.float32(0.8777)] 
2025-03-30 19:31:29.299146: Epoch time: 27.15 s 
2025-03-30 19:31:30.049292:  
2025-03-30 19:31:30.049448: Epoch 271 
2025-03-30 19:31:30.049528: Current learning rate: 0.00752 
2025-03-30 19:31:57.353330: train_loss -0.7015 
2025-03-30 19:31:57.353463: val_loss -0.6991 
2025-03-30 19:31:57.353518: Pseudo dice [np.float32(0.8896), np.float32(0.8763)] 
2025-03-30 19:31:57.353578: Epoch time: 27.31 s 
2025-03-30 19:31:58.110879:  
2025-03-30 19:31:58.111031: Epoch 272 
2025-03-30 19:31:58.111125: Current learning rate: 0.00751 
2025-03-30 19:32:25.661463: train_loss -0.7041 
2025-03-30 19:32:25.661678: val_loss -0.6839 
2025-03-30 19:32:25.661772: Pseudo dice [np.float32(0.8872), np.float32(0.8693)] 
2025-03-30 19:32:25.661851: Epoch time: 27.55 s 
2025-03-30 19:32:25.661901: Yayy! New best EMA pseudo Dice: 0.8730999827384949 
2025-03-30 19:32:26.928653:  
2025-03-30 19:32:26.928815: Epoch 273 
2025-03-30 19:32:26.928900: Current learning rate: 0.00751 
2025-03-30 19:32:53.847880: train_loss -0.6976 
2025-03-30 19:32:53.848040: val_loss -0.6923 
2025-03-30 19:32:53.848112: Pseudo dice [np.float32(0.8833), np.float32(0.8793)] 
2025-03-30 19:32:53.848193: Epoch time: 26.92 s 
2025-03-30 19:32:53.848274: Yayy! New best EMA pseudo Dice: 0.8738999962806702 
2025-03-30 19:32:55.171976:  
2025-03-30 19:32:55.172074: Epoch 274 
2025-03-30 19:32:55.172153: Current learning rate: 0.0075 
2025-03-30 19:33:22.135774: train_loss -0.6832 
2025-03-30 19:33:22.135927: val_loss -0.6759 
2025-03-30 19:33:22.135984: Pseudo dice [np.float32(0.8751), np.float32(0.862)] 
2025-03-30 19:33:22.136043: Epoch time: 26.96 s 
2025-03-30 19:33:22.886142:  
2025-03-30 19:33:22.886292: Epoch 275 
2025-03-30 19:33:22.886374: Current learning rate: 0.00749 
2025-03-30 19:33:49.634580: train_loss -0.6704 
2025-03-30 19:33:49.634739: val_loss -0.6553 
2025-03-30 19:33:49.634810: Pseudo dice [np.float32(0.8644), np.float32(0.8547)] 
2025-03-30 19:33:49.634909: Epoch time: 26.75 s 
2025-03-30 19:33:56.271588:  
2025-03-30 19:33:56.271719: Epoch 276 
2025-03-30 19:33:56.271849: Current learning rate: 0.00748 
2025-03-30 19:34:23.044853: train_loss -0.6617 
2025-03-30 19:34:23.045025: val_loss -0.6926 
2025-03-30 19:34:23.045080: Pseudo dice [np.float32(0.8925), np.float32(0.8744)] 
2025-03-30 19:34:23.045146: Epoch time: 26.77 s 
2025-03-30 19:34:23.793723:  
2025-03-30 19:34:23.793899: Epoch 277 
2025-03-30 19:34:23.793984: Current learning rate: 0.00747 
2025-03-30 19:34:50.523706: train_loss -0.6975 
2025-03-30 19:34:50.523873: val_loss -0.7145 
2025-03-30 19:34:50.523932: Pseudo dice [np.float32(0.8987), np.float32(0.8785)] 
2025-03-30 19:34:50.523994: Epoch time: 26.73 s 
2025-03-30 19:34:50.524042: Yayy! New best EMA pseudo Dice: 0.8747000098228455 
2025-03-30 19:34:51.873764:  
2025-03-30 19:34:51.873935: Epoch 278 
2025-03-30 19:34:51.874020: Current learning rate: 0.00746 
2025-03-30 19:35:18.554864: train_loss -0.7021 
2025-03-30 19:35:18.555011: val_loss -0.6818 
2025-03-30 19:35:18.555067: Pseudo dice [np.float32(0.89), np.float32(0.863)] 
2025-03-30 19:35:18.555127: Epoch time: 26.68 s 
2025-03-30 19:35:18.555175: Yayy! New best EMA pseudo Dice: 0.8748999834060669 
2025-03-30 19:35:19.939055:  
2025-03-30 19:35:19.939225: Epoch 279 
2025-03-30 19:35:19.939307: Current learning rate: 0.00745 
2025-03-30 19:35:46.649323: train_loss -0.7001 
2025-03-30 19:35:46.649467: val_loss -0.698 
2025-03-30 19:35:46.649519: Pseudo dice [np.float32(0.883), np.float32(0.8853)] 
2025-03-30 19:35:46.649577: Epoch time: 26.71 s 
2025-03-30 19:35:46.649623: Yayy! New best EMA pseudo Dice: 0.8758000135421753 
2025-03-30 19:35:47.976615:  
2025-03-30 19:35:47.976784: Epoch 280 
2025-03-30 19:35:47.976868: Current learning rate: 0.00744 
2025-03-30 19:36:14.656162: train_loss -0.692 
2025-03-30 19:36:14.656319: val_loss -0.6797 
2025-03-30 19:36:14.656376: Pseudo dice [np.float32(0.8846), np.float32(0.868)] 
2025-03-30 19:36:14.656438: Epoch time: 26.68 s 
2025-03-30 19:36:14.656486: Yayy! New best EMA pseudo Dice: 0.8758000135421753 
2025-03-30 19:36:16.046798:  
2025-03-30 19:36:16.046917: Epoch 281 
2025-03-30 19:36:16.046997: Current learning rate: 0.00743 
2025-03-30 19:36:42.742055: train_loss -0.7008 
2025-03-30 19:36:42.742205: val_loss -0.6306 
2025-03-30 19:36:42.742262: Pseudo dice [np.float32(0.8623), np.float32(0.8367)] 
2025-03-30 19:36:42.742323: Epoch time: 26.7 s 
2025-03-30 19:36:43.491727:  
2025-03-30 19:36:43.491944: Epoch 282 
2025-03-30 19:36:43.492028: Current learning rate: 0.00742 
2025-03-30 19:37:10.205406: train_loss -0.6811 
2025-03-30 19:37:10.205541: val_loss -0.7146 
2025-03-30 19:37:10.205596: Pseudo dice [np.float32(0.8918), np.float32(0.8823)] 
2025-03-30 19:37:10.205658: Epoch time: 26.72 s 
2025-03-30 19:37:10.958592:  
2025-03-30 19:37:10.958716: Epoch 283 
2025-03-30 19:37:10.958807: Current learning rate: 0.00741 
2025-03-30 19:37:37.694370: train_loss -0.6647 
2025-03-30 19:37:37.694500: val_loss -0.679 
2025-03-30 19:37:37.694582: Pseudo dice [np.float32(0.8709), np.float32(0.873)] 
2025-03-30 19:37:37.694675: Epoch time: 26.74 s 
2025-03-30 19:37:38.443160:  
2025-03-30 19:37:38.443288: Epoch 284 
2025-03-30 19:37:38.443371: Current learning rate: 0.0074 
2025-03-30 19:38:05.229522: train_loss -0.6675 
2025-03-30 19:38:05.229717: val_loss -0.6614 
2025-03-30 19:38:05.229781: Pseudo dice [np.float32(0.8701), np.float32(0.8601)] 
2025-03-30 19:38:05.229846: Epoch time: 26.79 s 
2025-03-30 19:38:05.992085:  
2025-03-30 19:38:05.992186: Epoch 285 
2025-03-30 19:38:05.992279: Current learning rate: 0.00739 
2025-03-30 19:38:32.703716: train_loss -0.7019 
2025-03-30 19:38:32.703900: val_loss -0.6785 
2025-03-30 19:38:32.703976: Pseudo dice [np.float32(0.8805), np.float32(0.8627)] 
2025-03-30 19:38:32.704038: Epoch time: 26.71 s 
2025-03-30 19:38:33.461149:  
2025-03-30 19:38:33.461307: Epoch 286 
2025-03-30 19:38:33.461390: Current learning rate: 0.00738 
2025-03-30 19:39:00.207001: train_loss -0.7156 
2025-03-30 19:39:00.207126: val_loss -0.698 
2025-03-30 19:39:00.207181: Pseudo dice [np.float32(0.8964), np.float32(0.8722)] 
2025-03-30 19:39:00.207241: Epoch time: 26.75 s 
2025-03-30 19:39:00.959151:  
2025-03-30 19:39:00.959302: Epoch 287 
2025-03-30 19:39:00.959387: Current learning rate: 0.00738 
2025-03-30 19:39:27.681252: train_loss -0.7183 
2025-03-30 19:39:27.681379: val_loss -0.6841 
2025-03-30 19:39:27.681434: Pseudo dice [np.float32(0.867), np.float32(0.8708)] 
2025-03-30 19:39:27.681496: Epoch time: 26.72 s 
2025-03-30 19:39:28.453111:  
2025-03-30 19:39:28.453218: Epoch 288 
2025-03-30 19:39:28.453296: Current learning rate: 0.00737 
2025-03-30 19:39:55.167841: train_loss -0.7088 
2025-03-30 19:39:55.168005: val_loss -0.7063 
2025-03-30 19:39:55.168061: Pseudo dice [np.float32(0.8911), np.float32(0.8771)] 
2025-03-30 19:39:55.168123: Epoch time: 26.72 s 
2025-03-30 19:39:55.913675:  
2025-03-30 19:39:55.913799: Epoch 289 
2025-03-30 19:39:55.913880: Current learning rate: 0.00736 
2025-03-30 19:40:22.680563: train_loss -0.6998 
2025-03-30 19:40:22.680699: val_loss -0.6893 
2025-03-30 19:40:22.680754: Pseudo dice [np.float32(0.8805), np.float32(0.8691)] 
2025-03-30 19:40:22.680840: Epoch time: 26.77 s 
2025-03-30 19:40:23.442030:  
2025-03-30 19:40:23.442213: Epoch 290 
2025-03-30 19:40:23.442289: Current learning rate: 0.00735 
2025-03-30 19:40:50.174954: train_loss -0.7075 
2025-03-30 19:40:50.175117: val_loss -0.634 
2025-03-30 19:40:50.175173: Pseudo dice [np.float32(0.8547), np.float32(0.8517)] 
2025-03-30 19:40:50.175235: Epoch time: 26.73 s 
2025-03-30 19:40:50.930891:  
2025-03-30 19:40:50.930978: Epoch 291 
2025-03-30 19:40:50.931060: Current learning rate: 0.00734 
2025-03-30 19:41:17.703225: train_loss -0.7082 
2025-03-30 19:41:17.703428: val_loss -0.7118 
2025-03-30 19:41:17.703485: Pseudo dice [np.float32(0.8931), np.float32(0.8802)] 
2025-03-30 19:41:17.703547: Epoch time: 26.77 s 
2025-03-30 19:41:18.456106:  
2025-03-30 19:41:18.456249: Epoch 292 
2025-03-30 19:41:18.456338: Current learning rate: 0.00733 
2025-03-30 19:41:45.218246: train_loss -0.6968 
2025-03-30 19:41:45.218388: val_loss -0.6811 
2025-03-30 19:41:45.218443: Pseudo dice [np.float32(0.8884), np.float32(0.8632)] 
2025-03-30 19:41:45.218507: Epoch time: 26.76 s 
2025-03-30 19:41:45.986679:  
2025-03-30 19:41:45.986799: Epoch 293 
2025-03-30 19:41:45.986884: Current learning rate: 0.00732 
2025-03-30 19:42:12.779345: train_loss -0.6877 
2025-03-30 19:42:12.779484: val_loss -0.7091 
2025-03-30 19:42:12.779542: Pseudo dice [np.float32(0.8936), np.float32(0.8779)] 
2025-03-30 19:42:12.779605: Epoch time: 26.79 s 
2025-03-30 19:42:13.537056:  
2025-03-30 19:42:13.537211: Epoch 294 
2025-03-30 19:42:13.537294: Current learning rate: 0.00731 
2025-03-30 19:42:40.299083: train_loss -0.6911 
2025-03-30 19:42:40.299370: val_loss -0.6501 
2025-03-30 19:42:40.299428: Pseudo dice [np.float32(0.8764), np.float32(0.8502)] 
2025-03-30 19:42:40.299491: Epoch time: 26.76 s 
2025-03-30 19:42:41.057523:  
2025-03-30 19:42:41.057686: Epoch 295 
2025-03-30 19:42:41.057776: Current learning rate: 0.0073 
2025-03-30 19:43:07.808617: train_loss -0.6833 
2025-03-30 19:43:07.808745: val_loss -0.6809 
2025-03-30 19:43:07.808849: Pseudo dice [np.float32(0.8776), np.float32(0.8648)] 
2025-03-30 19:43:07.808918: Epoch time: 26.75 s 
2025-03-30 19:43:09.152049:  
2025-03-30 19:43:09.152223: Epoch 296 
2025-03-30 19:43:09.152327: Current learning rate: 0.00729 
2025-03-30 19:43:35.886525: train_loss -0.706 
2025-03-30 19:43:35.886729: val_loss -0.6896 
2025-03-30 19:43:35.886794: Pseudo dice [np.float32(0.8826), np.float32(0.8736)] 
2025-03-30 19:43:35.886859: Epoch time: 26.74 s 
2025-03-30 19:43:36.669451:  
2025-03-30 19:43:36.669655: Epoch 297 
2025-03-30 19:43:36.669735: Current learning rate: 0.00728 
2025-03-30 19:44:03.400964: train_loss -0.7007 
2025-03-30 19:44:03.401167: val_loss -0.7098 
2025-03-30 19:44:03.401225: Pseudo dice [np.float32(0.8929), np.float32(0.889)] 
2025-03-30 19:44:03.401285: Epoch time: 26.73 s 
2025-03-30 19:44:03.401334: Yayy! New best EMA pseudo Dice: 0.8759999871253967 
2025-03-30 19:44:04.699368:  
2025-03-30 19:44:04.699531: Epoch 298 
2025-03-30 19:44:04.699638: Current learning rate: 0.00727 
2025-03-30 19:44:31.437787: train_loss -0.7231 
2025-03-30 19:44:31.437925: val_loss -0.715 
2025-03-30 19:44:31.437989: Pseudo dice [np.float32(0.8893), np.float32(0.8811)] 
2025-03-30 19:44:31.438056: Epoch time: 26.74 s 
2025-03-30 19:44:31.438111: Yayy! New best EMA pseudo Dice: 0.8769000172615051 
2025-03-30 19:44:32.754623:  
2025-03-30 19:44:32.754786: Epoch 299 
2025-03-30 19:44:32.754883: Current learning rate: 0.00726 
2025-03-30 19:44:59.438005: train_loss -0.7023 
2025-03-30 19:44:59.438130: val_loss -0.6783 
2025-03-30 19:44:59.438184: Pseudo dice [np.float32(0.8753), np.float32(0.8612)] 
2025-03-30 19:44:59.438243: Epoch time: 26.68 s 
2025-03-30 19:45:00.714095:  
2025-03-30 19:45:00.714209: Epoch 300 
2025-03-30 19:45:00.714289: Current learning rate: 0.00725 
2025-03-30 19:45:27.473276: train_loss -0.662 
2025-03-30 19:45:27.473409: val_loss -0.7063 
2025-03-30 19:45:27.473465: Pseudo dice [np.float32(0.8963), np.float32(0.8754)] 
2025-03-30 19:45:27.473525: Epoch time: 26.76 s 
2025-03-30 19:45:27.473572: Yayy! New best EMA pseudo Dice: 0.8769999742507935 
2025-03-30 19:45:28.798356:  
2025-03-30 19:45:28.798553: Epoch 301 
2025-03-30 19:45:28.798633: Current learning rate: 0.00724 
2025-03-30 19:45:55.944296: train_loss -0.6685 
2025-03-30 19:45:55.944497: val_loss -0.6697 
2025-03-30 19:45:55.944553: Pseudo dice [np.float32(0.8696), np.float32(0.8588)] 
2025-03-30 19:45:55.944616: Epoch time: 27.15 s 
2025-03-30 19:45:56.721259:  
2025-03-30 19:45:56.721435: Epoch 302 
2025-03-30 19:45:56.721537: Current learning rate: 0.00724 
2025-03-30 19:46:23.723895: train_loss -0.6907 
2025-03-30 19:46:23.724028: val_loss -0.5724 
2025-03-30 19:46:23.724084: Pseudo dice [np.float32(0.8278), np.float32(0.8199)] 
2025-03-30 19:46:23.724146: Epoch time: 27.0 s 
2025-03-30 19:46:24.503094:  
2025-03-30 19:46:24.503258: Epoch 303 
2025-03-30 19:46:24.503339: Current learning rate: 0.00723 
2025-03-30 19:46:51.741575: train_loss -0.6886 
2025-03-30 19:46:51.741711: val_loss -0.6861 
2025-03-30 19:46:51.741775: Pseudo dice [np.float32(0.8759), np.float32(0.8771)] 
2025-03-30 19:46:51.741839: Epoch time: 27.24 s 
2025-03-30 19:46:52.513932:  
2025-03-30 19:46:52.514125: Epoch 304 
2025-03-30 19:46:52.514216: Current learning rate: 0.00722 
2025-03-30 19:47:19.741020: train_loss -0.6838 
2025-03-30 19:47:19.741178: val_loss -0.7154 
2025-03-30 19:47:19.741233: Pseudo dice [np.float32(0.8999), np.float32(0.8759)] 
2025-03-30 19:47:19.741296: Epoch time: 27.23 s 
2025-03-30 19:47:20.540953:  
2025-03-30 19:47:20.541132: Epoch 305 
2025-03-30 19:47:20.541213: Current learning rate: 0.00721 
2025-03-30 19:47:47.394991: train_loss -0.7047 
2025-03-30 19:47:47.395174: val_loss -0.7106 
2025-03-30 19:47:47.395230: Pseudo dice [np.float32(0.8959), np.float32(0.8833)] 
2025-03-30 19:47:47.395294: Epoch time: 26.86 s 
2025-03-30 19:47:48.167752:  
2025-03-30 19:47:48.167922: Epoch 306 
2025-03-30 19:47:48.168016: Current learning rate: 0.0072 
2025-03-30 19:48:14.990041: train_loss -0.6921 
2025-03-30 19:48:14.990165: val_loss -0.6474 
2025-03-30 19:48:14.990220: Pseudo dice [np.float32(0.8718), np.float32(0.8491)] 
2025-03-30 19:48:14.990281: Epoch time: 26.82 s 
2025-03-30 19:48:15.764174:  
2025-03-30 19:48:15.764350: Epoch 307 
2025-03-30 19:48:15.764432: Current learning rate: 0.00719 
2025-03-30 19:48:42.615930: train_loss -0.6446 
2025-03-30 19:48:42.616058: val_loss -0.6644 
2025-03-30 19:48:42.616112: Pseudo dice [np.float32(0.8737), np.float32(0.8651)] 
2025-03-30 19:48:42.616173: Epoch time: 26.85 s 
2025-03-30 19:48:43.384461:  
2025-03-30 19:48:43.384619: Epoch 308 
2025-03-30 19:48:43.384708: Current learning rate: 0.00718 
2025-03-30 19:49:10.246093: train_loss -0.6963 
2025-03-30 19:49:10.246220: val_loss -0.7061 
2025-03-30 19:49:10.246276: Pseudo dice [np.float32(0.889), np.float32(0.8817)] 
2025-03-30 19:49:10.246338: Epoch time: 26.86 s 
2025-03-30 19:49:11.018656:  
2025-03-30 19:49:11.018828: Epoch 309 
2025-03-30 19:49:11.018907: Current learning rate: 0.00717 
2025-03-30 19:49:37.839447: train_loss -0.6758 
2025-03-30 19:49:37.839616: val_loss -0.6601 
2025-03-30 19:49:37.839673: Pseudo dice [np.float32(0.8649), np.float32(0.8674)] 
2025-03-30 19:49:37.839735: Epoch time: 26.82 s 
2025-03-30 19:49:38.615521:  
2025-03-30 19:49:38.615685: Epoch 310 
2025-03-30 19:49:38.615786: Current learning rate: 0.00716 
2025-03-30 19:50:05.433677: train_loss -0.6905 
2025-03-30 19:50:05.433926: val_loss -0.6873 
2025-03-30 19:50:05.433986: Pseudo dice [np.float32(0.8738), np.float32(0.8818)] 
2025-03-30 19:50:05.434047: Epoch time: 26.82 s 
2025-03-30 19:50:06.212146:  
2025-03-30 19:50:06.212343: Epoch 311 
2025-03-30 19:50:06.212433: Current learning rate: 0.00715 
2025-03-30 19:50:33.132697: train_loss -0.7106 
2025-03-30 19:50:33.132827: val_loss -0.6428 
2025-03-30 19:50:33.132883: Pseudo dice [np.float32(0.8637), np.float32(0.8389)] 
2025-03-30 19:50:33.132941: Epoch time: 26.92 s 
2025-03-30 19:50:33.895951:  
2025-03-30 19:50:33.896113: Epoch 312 
2025-03-30 19:50:33.896193: Current learning rate: 0.00714 
2025-03-30 19:51:00.749552: train_loss -0.6891 
2025-03-30 19:51:00.749791: val_loss -0.6685 
2025-03-30 19:51:00.749861: Pseudo dice [np.float32(0.8611), np.float32(0.8653)] 
2025-03-30 19:51:00.749922: Epoch time: 26.85 s 
2025-03-30 19:51:01.522122:  
2025-03-30 19:51:01.522296: Epoch 313 
2025-03-30 19:51:01.522380: Current learning rate: 0.00713 
2025-03-30 19:51:28.385614: train_loss -0.7081 
2025-03-30 19:51:28.385879: val_loss -0.6959 
2025-03-30 19:51:28.385961: Pseudo dice [np.float32(0.8823), np.float32(0.867)] 
2025-03-30 19:51:28.386042: Epoch time: 26.86 s 
2025-03-30 19:51:29.161447:  
2025-03-30 19:51:29.161619: Epoch 314 
2025-03-30 19:51:29.161695: Current learning rate: 0.00712 
2025-03-30 19:51:56.031568: train_loss -0.7273 
2025-03-30 19:51:56.031718: val_loss -0.6954 
2025-03-30 19:51:56.031807: Pseudo dice [np.float32(0.8813), np.float32(0.88)] 
2025-03-30 19:51:56.031875: Epoch time: 26.87 s 
2025-03-30 19:51:56.806928:  
2025-03-30 19:51:56.807094: Epoch 315 
2025-03-30 19:51:56.807189: Current learning rate: 0.00711 
2025-03-30 19:52:23.628908: train_loss -0.7147 
2025-03-30 19:52:23.629059: val_loss -0.7001 
2025-03-30 19:52:23.629117: Pseudo dice [np.float32(0.8795), np.float32(0.874)] 
2025-03-30 19:52:23.629180: Epoch time: 26.82 s 
2025-03-30 19:52:25.040693:  
2025-03-30 19:52:25.040914: Epoch 316 
2025-03-30 19:52:25.041005: Current learning rate: 0.0071 
2025-03-30 19:52:51.829748: train_loss -0.7031 
2025-03-30 19:52:51.829923: val_loss -0.6734 
2025-03-30 19:52:51.829979: Pseudo dice [np.float32(0.8798), np.float32(0.8662)] 
2025-03-30 19:52:51.830079: Epoch time: 26.79 s 
2025-03-30 19:52:52.610447:  
2025-03-30 19:52:52.610647: Epoch 317 
2025-03-30 19:52:52.610729: Current learning rate: 0.0071 
2025-03-30 19:53:19.405981: train_loss -0.6769 
2025-03-30 19:53:19.406134: val_loss -0.7234 
2025-03-30 19:53:19.406189: Pseudo dice [np.float32(0.9005), np.float32(0.8741)] 
2025-03-30 19:53:19.406253: Epoch time: 26.8 s 
2025-03-30 19:53:20.185073:  
2025-03-30 19:53:20.185266: Epoch 318 
2025-03-30 19:53:20.185347: Current learning rate: 0.00709 
2025-03-30 19:53:46.967042: train_loss -0.7087 
2025-03-30 19:53:46.967179: val_loss -0.6985 
2025-03-30 19:53:46.967234: Pseudo dice [np.float32(0.882), np.float32(0.8782)] 
2025-03-30 19:53:46.967294: Epoch time: 26.78 s 
2025-03-30 19:53:47.742504:  
2025-03-30 19:53:47.742688: Epoch 319 
2025-03-30 19:53:47.742778: Current learning rate: 0.00708 
2025-03-30 19:54:14.568512: train_loss -0.695 
2025-03-30 19:54:14.568638: val_loss -0.6713 
2025-03-30 19:54:14.568693: Pseudo dice [np.float32(0.8768), np.float32(0.8495)] 
2025-03-30 19:54:14.568754: Epoch time: 26.83 s 
2025-03-30 19:54:15.341390:  
2025-03-30 19:54:15.341571: Epoch 320 
2025-03-30 19:54:15.341655: Current learning rate: 0.00707 
2025-03-30 19:54:42.110043: train_loss -0.7205 
2025-03-30 19:54:42.110195: val_loss -0.719 
2025-03-30 19:54:42.110252: Pseudo dice [np.float32(0.893), np.float32(0.8933)] 
2025-03-30 19:54:42.110315: Epoch time: 26.77 s 
2025-03-30 19:54:42.894663:  
2025-03-30 19:54:42.894848: Epoch 321 
2025-03-30 19:54:42.894931: Current learning rate: 0.00706 
2025-03-30 19:55:09.768280: train_loss -0.7192 
2025-03-30 19:55:09.768439: val_loss -0.7174 
2025-03-30 19:55:09.768495: Pseudo dice [np.float32(0.8973), np.float32(0.8754)] 
2025-03-30 19:55:09.768559: Epoch time: 26.87 s 
2025-03-30 19:55:10.550459:  
2025-03-30 19:55:10.550656: Epoch 322 
2025-03-30 19:55:10.550766: Current learning rate: 0.00705 
2025-03-30 19:55:37.454822: train_loss -0.6875 
2025-03-30 19:55:37.455062: val_loss -0.5998 
2025-03-30 19:55:37.455120: Pseudo dice [np.float32(0.8567), np.float32(0.8198)] 
2025-03-30 19:55:37.455183: Epoch time: 26.91 s 
2025-03-30 19:55:38.228353:  
2025-03-30 19:55:38.228527: Epoch 323 
2025-03-30 19:55:38.228617: Current learning rate: 0.00704 
2025-03-30 19:56:05.037101: train_loss -0.6996 
2025-03-30 19:56:05.037302: val_loss -0.6674 
2025-03-30 19:56:05.037365: Pseudo dice [np.float32(0.8869), np.float32(0.8565)] 
2025-03-30 19:56:05.037434: Epoch time: 26.81 s 
2025-03-30 19:56:05.803194:  
2025-03-30 19:56:05.803355: Epoch 324 
2025-03-30 19:56:05.803437: Current learning rate: 0.00703 
2025-03-30 19:56:32.628105: train_loss -0.6878 
2025-03-30 19:56:32.628254: val_loss -0.6918 
2025-03-30 19:56:32.628309: Pseudo dice [np.float32(0.8894), np.float32(0.8669)] 
2025-03-30 19:56:32.628373: Epoch time: 26.83 s 
2025-03-30 19:56:33.400460:  
2025-03-30 19:56:33.400664: Epoch 325 
2025-03-30 19:56:33.400743: Current learning rate: 0.00702 
2025-03-30 19:57:00.225844: train_loss -0.7286 
2025-03-30 19:57:00.225987: val_loss -0.7144 
2025-03-30 19:57:00.226085: Pseudo dice [np.float32(0.8914), np.float32(0.8865)] 
2025-03-30 19:57:00.226187: Epoch time: 26.83 s 
2025-03-30 19:57:00.997254:  
2025-03-30 19:57:00.997410: Epoch 326 
2025-03-30 19:57:00.997483: Current learning rate: 0.00701 
2025-03-30 19:57:27.835163: train_loss -0.7016 
2025-03-30 19:57:27.835296: val_loss -0.6834 
2025-03-30 19:57:27.835352: Pseudo dice [np.float32(0.8675), np.float32(0.8656)] 
2025-03-30 19:57:27.835416: Epoch time: 26.84 s 
2025-03-30 19:57:28.608911:  
2025-03-30 19:57:28.609073: Epoch 327 
2025-03-30 19:57:28.609152: Current learning rate: 0.007 
2025-03-30 19:57:55.446905: train_loss -0.6771 
2025-03-30 19:57:55.447030: val_loss -0.6797 
2025-03-30 19:57:55.447084: Pseudo dice [np.float32(0.8688), np.float32(0.8709)] 
2025-03-30 19:57:55.447182: Epoch time: 26.84 s 
2025-03-30 19:57:56.217540:  
2025-03-30 19:57:56.217691: Epoch 328 
2025-03-30 19:57:56.217782: Current learning rate: 0.00699 
2025-03-30 19:58:23.060818: train_loss -0.6726 
2025-03-30 19:58:23.060946: val_loss -0.6735 
2025-03-30 19:58:23.061002: Pseudo dice [np.float32(0.8742), np.float32(0.8668)] 
2025-03-30 19:58:23.061064: Epoch time: 26.84 s 
2025-03-30 19:58:23.838933:  
2025-03-30 19:58:23.839079: Epoch 329 
2025-03-30 19:58:23.839158: Current learning rate: 0.00698 
2025-03-30 19:58:50.655541: train_loss -0.7109 
2025-03-30 19:58:50.655691: val_loss -0.6711 
2025-03-30 19:58:50.655746: Pseudo dice [np.float32(0.8761), np.float32(0.8628)] 
2025-03-30 19:58:50.655826: Epoch time: 26.82 s 
2025-03-30 19:58:51.424787:  
2025-03-30 19:58:51.424959: Epoch 330 
2025-03-30 19:58:51.425042: Current learning rate: 0.00697 
2025-03-30 19:59:18.234210: train_loss -0.6846 
2025-03-30 19:59:18.234448: val_loss -0.6528 
2025-03-30 19:59:18.234507: Pseudo dice [np.float32(0.8624), np.float32(0.8495)] 
2025-03-30 19:59:18.234568: Epoch time: 26.81 s 
2025-03-30 19:59:19.003695:  
2025-03-30 19:59:19.003842: Epoch 331 
2025-03-30 19:59:19.003963: Current learning rate: 0.00696 
2025-03-30 19:59:45.853732: train_loss -0.6883 
2025-03-30 19:59:45.854072: val_loss -0.7194 
2025-03-30 19:59:45.854141: Pseudo dice [np.float32(0.9052), np.float32(0.8898)] 
2025-03-30 19:59:45.854205: Epoch time: 26.85 s 
2025-03-30 19:59:46.622460:  
2025-03-30 19:59:46.622640: Epoch 332 
2025-03-30 19:59:46.622722: Current learning rate: 0.00696 
2025-03-30 20:00:13.445140: train_loss -0.7257 
2025-03-30 20:00:13.445390: val_loss -0.7205 
2025-03-30 20:00:13.445449: Pseudo dice [np.float32(0.8952), np.float32(0.8882)] 
2025-03-30 20:00:13.445509: Epoch time: 26.82 s 
2025-03-30 20:00:14.218486:  
2025-03-30 20:00:14.218647: Epoch 333 
2025-03-30 20:00:14.218730: Current learning rate: 0.00695 
2025-03-30 20:00:41.192617: train_loss -0.7118 
2025-03-30 20:00:41.192873: val_loss -0.7135 
2025-03-30 20:00:41.192933: Pseudo dice [np.float32(0.8862), np.float32(0.8879)] 
2025-03-30 20:00:41.192996: Epoch time: 26.98 s 
2025-03-30 20:00:41.968694:  
2025-03-30 20:00:41.968838: Epoch 334 
2025-03-30 20:00:41.968922: Current learning rate: 0.00694 
2025-03-30 20:01:08.776815: train_loss -0.7083 
2025-03-30 20:01:08.776991: val_loss -0.7228 
2025-03-30 20:01:08.777050: Pseudo dice [np.float32(0.8994), np.float32(0.8888)] 
2025-03-30 20:01:08.777111: Epoch time: 26.81 s 
2025-03-30 20:01:08.777161: Yayy! New best EMA pseudo Dice: 0.8784999847412109 
2025-03-30 20:01:10.055509:  
2025-03-30 20:01:10.055680: Epoch 335 
2025-03-30 20:01:10.055775: Current learning rate: 0.00693 
2025-03-30 20:01:37.294394: train_loss -0.7229 
2025-03-30 20:01:37.294521: val_loss -0.7338 
2025-03-30 20:01:37.294574: Pseudo dice [np.float32(0.9063), np.float32(0.8902)] 
2025-03-30 20:01:37.294665: Epoch time: 27.24 s 
2025-03-30 20:01:37.294712: Yayy! New best EMA pseudo Dice: 0.8804000020027161 
2025-03-30 20:01:40.863694:  
2025-03-30 20:01:40.863883: Epoch 336 
2025-03-30 20:01:40.863985: Current learning rate: 0.00692 
2025-03-30 20:02:07.586391: train_loss -0.7152 
2025-03-30 20:02:07.586580: val_loss -0.742 
2025-03-30 20:02:07.586636: Pseudo dice [np.float32(0.9123), np.float32(0.8962)] 
2025-03-30 20:02:07.586700: Epoch time: 26.72 s 
2025-03-30 20:02:07.586750: Yayy! New best EMA pseudo Dice: 0.8827999830245972 
2025-03-30 20:02:08.917285:  
2025-03-30 20:02:08.917445: Epoch 337 
2025-03-30 20:02:08.917530: Current learning rate: 0.00691 
2025-03-30 20:02:36.458151: train_loss -0.6876 
2025-03-30 20:02:36.458295: val_loss -0.7166 
2025-03-30 20:02:36.458355: Pseudo dice [np.float32(0.889), np.float32(0.8794)] 
2025-03-30 20:02:36.458419: Epoch time: 27.54 s 
2025-03-30 20:02:36.458467: Yayy! New best EMA pseudo Dice: 0.8828999996185303 
2025-03-30 20:02:37.770338:  
2025-03-30 20:02:37.770539: Epoch 338 
2025-03-30 20:02:37.770625: Current learning rate: 0.0069 
2025-03-30 20:03:04.412448: train_loss -0.7186 
2025-03-30 20:03:04.412580: val_loss -0.712 
2025-03-30 20:03:04.412637: Pseudo dice [np.float32(0.8948), np.float32(0.8764)] 
2025-03-30 20:03:04.412699: Epoch time: 26.64 s 
2025-03-30 20:03:04.412749: Yayy! New best EMA pseudo Dice: 0.8831999897956848 
2025-03-30 20:03:05.725460:  
2025-03-30 20:03:05.725639: Epoch 339 
2025-03-30 20:03:05.725721: Current learning rate: 0.00689 
2025-03-30 20:03:32.384743: train_loss -0.733 
2025-03-30 20:03:32.384900: val_loss -0.7016 
2025-03-30 20:03:32.384956: Pseudo dice [np.float32(0.8914), np.float32(0.8754)] 
2025-03-30 20:03:32.385018: Epoch time: 26.66 s 
2025-03-30 20:03:32.385066: Yayy! New best EMA pseudo Dice: 0.8831999897956848 
2025-03-30 20:03:33.699479:  
2025-03-30 20:03:33.699643: Epoch 340 
2025-03-30 20:03:33.699713: Current learning rate: 0.00688 
2025-03-30 20:04:00.402960: train_loss -0.7466 
2025-03-30 20:04:00.403094: val_loss -0.721 
2025-03-30 20:04:00.403149: Pseudo dice [np.float32(0.9006), np.float32(0.8836)] 
2025-03-30 20:04:00.403210: Epoch time: 26.7 s 
2025-03-30 20:04:00.403257: Yayy! New best EMA pseudo Dice: 0.8841000199317932 
2025-03-30 20:04:04.075410:  
2025-03-30 20:04:04.075607: Epoch 341 
2025-03-30 20:04:04.075689: Current learning rate: 0.00687 
2025-03-30 20:04:30.772880: train_loss -0.7346 
2025-03-30 20:04:30.773010: val_loss -0.7094 
2025-03-30 20:04:30.773065: Pseudo dice [np.float32(0.8912), np.float32(0.8731)] 
2025-03-30 20:04:30.773125: Epoch time: 26.7 s 
2025-03-30 20:04:31.560144:  
2025-03-30 20:04:31.560319: Epoch 342 
2025-03-30 20:04:31.560401: Current learning rate: 0.00686 
2025-03-30 20:04:58.232884: train_loss -0.7307 
2025-03-30 20:04:58.233011: val_loss -0.6912 
2025-03-30 20:04:58.233066: Pseudo dice [np.float32(0.8888), np.float32(0.8682)] 
2025-03-30 20:04:58.233133: Epoch time: 26.67 s 
2025-03-30 20:04:59.019744:  
2025-03-30 20:04:59.019924: Epoch 343 
2025-03-30 20:04:59.020006: Current learning rate: 0.00685 
2025-03-30 20:05:25.688659: train_loss -0.7291 
2025-03-30 20:05:25.688830: val_loss -0.7027 
2025-03-30 20:05:25.688887: Pseudo dice [np.float32(0.8783), np.float32(0.8843)] 
2025-03-30 20:05:25.688992: Epoch time: 26.67 s 
2025-03-30 20:05:26.474180:  
2025-03-30 20:05:26.474346: Epoch 344 
2025-03-30 20:05:26.474429: Current learning rate: 0.00684 
2025-03-30 20:05:53.158238: train_loss -0.7203 
2025-03-30 20:05:53.158385: val_loss -0.6759 
2025-03-30 20:05:53.158440: Pseudo dice [np.float32(0.8721), np.float32(0.8566)] 
2025-03-30 20:05:53.158505: Epoch time: 26.69 s 
2025-03-30 20:05:53.939492:  
2025-03-30 20:05:53.939638: Epoch 345 
2025-03-30 20:05:53.939750: Current learning rate: 0.00683 
2025-03-30 20:06:20.661952: train_loss -0.7182 
2025-03-30 20:06:20.662077: val_loss -0.7018 
2025-03-30 20:06:20.662163: Pseudo dice [np.float32(0.8824), np.float32(0.8747)] 
2025-03-30 20:06:20.662273: Epoch time: 26.72 s 
2025-03-30 20:06:21.442155:  
2025-03-30 20:06:21.442320: Epoch 346 
2025-03-30 20:06:21.442387: Current learning rate: 0.00682 
2025-03-30 20:06:48.138697: train_loss -0.7348 
2025-03-30 20:06:48.138834: val_loss -0.7076 
2025-03-30 20:06:48.138891: Pseudo dice [np.float32(0.8912), np.float32(0.8804)] 
2025-03-30 20:06:48.138952: Epoch time: 26.7 s 
2025-03-30 20:06:48.924417:  
2025-03-30 20:06:48.924558: Epoch 347 
2025-03-30 20:06:48.924640: Current learning rate: 0.00681 
2025-03-30 20:07:15.635780: train_loss -0.7078 
2025-03-30 20:07:15.635943: val_loss -0.6898 
2025-03-30 20:07:15.636023: Pseudo dice [np.float32(0.8846), np.float32(0.8689)] 
2025-03-30 20:07:15.636086: Epoch time: 26.71 s 
2025-03-30 20:07:16.422767:  
2025-03-30 20:07:16.422931: Epoch 348 
2025-03-30 20:07:16.423012: Current learning rate: 0.0068 
2025-03-30 20:07:43.157897: train_loss -0.708 
2025-03-30 20:07:43.158083: val_loss -0.6873 
2025-03-30 20:07:43.158147: Pseudo dice [np.float32(0.8726), np.float32(0.8697)] 
2025-03-30 20:07:43.158215: Epoch time: 26.74 s 
2025-03-30 20:07:43.944085:  
2025-03-30 20:07:43.944237: Epoch 349 
2025-03-30 20:07:43.944317: Current learning rate: 0.0068 
2025-03-30 20:08:10.692141: train_loss -0.6936 
2025-03-30 20:08:10.692278: val_loss -0.7123 
2025-03-30 20:08:10.692364: Pseudo dice [np.float32(0.8885), np.float32(0.8781)] 
2025-03-30 20:08:10.692426: Epoch time: 26.75 s 
2025-03-30 20:08:11.976144:  
2025-03-30 20:08:11.976318: Epoch 350 
2025-03-30 20:08:11.976398: Current learning rate: 0.00679 
2025-03-30 20:08:38.786319: train_loss -0.7248 
2025-03-30 20:08:38.786462: val_loss -0.685 
2025-03-30 20:08:38.786518: Pseudo dice [np.float32(0.8866), np.float32(0.862)] 
2025-03-30 20:08:38.786580: Epoch time: 26.81 s 
2025-03-30 20:08:39.575570:  
2025-03-30 20:08:39.575733: Epoch 351 
2025-03-30 20:08:39.575834: Current learning rate: 0.00678 
2025-03-30 20:09:06.330174: train_loss -0.7221 
2025-03-30 20:09:06.330437: val_loss -0.7148 
2025-03-30 20:09:06.330499: Pseudo dice [np.float32(0.9), np.float32(0.8765)] 
2025-03-30 20:09:06.330562: Epoch time: 26.76 s 
2025-03-30 20:09:07.117858:  
2025-03-30 20:09:07.117995: Epoch 352 
2025-03-30 20:09:07.118076: Current learning rate: 0.00677 
2025-03-30 20:09:33.866746: train_loss -0.7008 
2025-03-30 20:09:33.866996: val_loss -0.7013 
2025-03-30 20:09:33.867057: Pseudo dice [np.float32(0.8843), np.float32(0.8729)] 
2025-03-30 20:09:33.867124: Epoch time: 26.75 s 
2025-03-30 20:09:34.642813:  
2025-03-30 20:09:34.642977: Epoch 353 
2025-03-30 20:09:34.643087: Current learning rate: 0.00676 
2025-03-30 20:10:01.379403: train_loss -0.7155 
2025-03-30 20:10:01.379834: val_loss -0.7268 
2025-03-30 20:10:01.379894: Pseudo dice [np.float32(0.8973), np.float32(0.8852)] 
2025-03-30 20:10:01.379981: Epoch time: 26.74 s 
2025-03-30 20:10:02.717696:  
2025-03-30 20:10:02.717914: Epoch 354 
2025-03-30 20:10:02.718001: Current learning rate: 0.00675 
2025-03-30 20:10:29.496104: train_loss -0.7187 
2025-03-30 20:10:29.496328: val_loss -0.6769 
2025-03-30 20:10:29.496386: Pseudo dice [np.float32(0.8799), np.float32(0.8706)] 
2025-03-30 20:10:29.496448: Epoch time: 26.78 s 
2025-03-30 20:10:30.274816:  
2025-03-30 20:10:30.275005: Epoch 355 
2025-03-30 20:10:30.275081: Current learning rate: 0.00674 
2025-03-30 20:10:56.982126: train_loss -0.6839 
2025-03-30 20:10:56.982283: val_loss -0.7068 
2025-03-30 20:10:56.982355: Pseudo dice [np.float32(0.8892), np.float32(0.8736)] 
2025-03-30 20:10:56.982419: Epoch time: 26.71 s 
2025-03-30 20:10:57.761887:  
2025-03-30 20:10:57.762063: Epoch 356 
2025-03-30 20:10:57.762142: Current learning rate: 0.00673 
2025-03-30 20:11:24.480077: train_loss -0.7155 
2025-03-30 20:11:24.480375: val_loss -0.695 
2025-03-30 20:11:24.480433: Pseudo dice [np.float32(0.8923), np.float32(0.8735)] 
2025-03-30 20:11:24.480494: Epoch time: 26.72 s 
2025-03-30 20:11:25.259851:  
2025-03-30 20:11:25.260030: Epoch 357 
2025-03-30 20:11:25.260109: Current learning rate: 0.00672 
2025-03-30 20:11:51.983504: train_loss -0.7201 
2025-03-30 20:11:51.983651: val_loss -0.7045 
2025-03-30 20:11:51.983706: Pseudo dice [np.float32(0.8951), np.float32(0.8767)] 
2025-03-30 20:11:51.983779: Epoch time: 26.72 s 
2025-03-30 20:11:52.762345:  
2025-03-30 20:11:52.762516: Epoch 358 
2025-03-30 20:11:52.762585: Current learning rate: 0.00671 
2025-03-30 20:12:19.452308: train_loss -0.7001 
2025-03-30 20:12:19.452434: val_loss -0.6954 
2025-03-30 20:12:19.452489: Pseudo dice [np.float32(0.8723), np.float32(0.8865)] 
2025-03-30 20:12:19.452549: Epoch time: 26.69 s 
2025-03-30 20:12:20.231891:  
2025-03-30 20:12:20.232055: Epoch 359 
2025-03-30 20:12:20.232153: Current learning rate: 0.0067 
2025-03-30 20:12:46.958905: train_loss -0.7135 
2025-03-30 20:12:46.959066: val_loss -0.6915 
2025-03-30 20:12:46.959121: Pseudo dice [np.float32(0.8859), np.float32(0.8707)] 
2025-03-30 20:12:46.959181: Epoch time: 26.73 s 
2025-03-30 20:12:47.736509:  
2025-03-30 20:12:47.736705: Epoch 360 
2025-03-30 20:12:47.736796: Current learning rate: 0.00669 
2025-03-30 20:13:14.493290: train_loss -0.7117 
2025-03-30 20:13:14.493446: val_loss -0.6662 
2025-03-30 20:13:14.493501: Pseudo dice [np.float32(0.8762), np.float32(0.8618)] 
2025-03-30 20:13:14.493562: Epoch time: 26.76 s 
2025-03-30 20:13:15.275120:  
2025-03-30 20:13:15.275287: Epoch 361 
2025-03-30 20:13:15.275368: Current learning rate: 0.00668 
2025-03-30 20:13:42.015853: train_loss -0.7288 
2025-03-30 20:13:42.016110: val_loss -0.7312 
2025-03-30 20:13:42.016168: Pseudo dice [np.float32(0.8955), np.float32(0.8883)] 
2025-03-30 20:13:42.016234: Epoch time: 26.74 s 
2025-03-30 20:13:42.803053:  
2025-03-30 20:13:42.803222: Epoch 362 
2025-03-30 20:13:42.803303: Current learning rate: 0.00667 
2025-03-30 20:14:09.549958: train_loss -0.7318 
2025-03-30 20:14:09.550106: val_loss -0.7363 
2025-03-30 20:14:09.550162: Pseudo dice [np.float32(0.9055), np.float32(0.8973)] 
2025-03-30 20:14:09.550226: Epoch time: 26.75 s 
2025-03-30 20:14:10.327771:  
2025-03-30 20:14:10.327917: Epoch 363 
2025-03-30 20:14:10.328007: Current learning rate: 0.00666 
2025-03-30 20:14:37.382480: train_loss -0.7369 
2025-03-30 20:14:37.382723: val_loss -0.7324 
2025-03-30 20:14:37.382803: Pseudo dice [np.float32(0.9034), np.float32(0.8874)] 
2025-03-30 20:14:37.382874: Epoch time: 27.06 s 
2025-03-30 20:14:37.382930: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2025-03-30 20:14:38.706286:  
2025-03-30 20:14:38.706503: Epoch 364 
2025-03-30 20:14:38.706586: Current learning rate: 0.00665 
2025-03-30 20:15:06.012903: train_loss -0.7279 
2025-03-30 20:15:06.013063: val_loss -0.693 
2025-03-30 20:15:06.013119: Pseudo dice [np.float32(0.8802), np.float32(0.877)] 
2025-03-30 20:15:06.013180: Epoch time: 27.31 s 
2025-03-30 20:15:06.795558:  
2025-03-30 20:15:06.795719: Epoch 365 
2025-03-30 20:15:06.795806: Current learning rate: 0.00665 
2025-03-30 20:15:34.111227: train_loss -0.7258 
2025-03-30 20:15:34.111586: val_loss -0.7352 
2025-03-30 20:15:34.111645: Pseudo dice [np.float32(0.9028), np.float32(0.8871)] 
2025-03-30 20:15:34.111709: Epoch time: 27.32 s 
2025-03-30 20:15:34.111766: Yayy! New best EMA pseudo Dice: 0.8848999738693237 
2025-03-30 20:15:35.445684:  
2025-03-30 20:15:35.445909: Epoch 366 
2025-03-30 20:15:35.446010: Current learning rate: 0.00664 
2025-03-30 20:16:02.398728: train_loss -0.7499 
2025-03-30 20:16:02.398869: val_loss -0.7005 
2025-03-30 20:16:02.398931: Pseudo dice [np.float32(0.8845), np.float32(0.8621)] 
2025-03-30 20:16:02.398998: Epoch time: 26.95 s 
2025-03-30 20:16:03.190770:  
2025-03-30 20:16:03.190940: Epoch 367 
2025-03-30 20:16:03.191019: Current learning rate: 0.00663 
2025-03-30 20:16:30.358665: train_loss -0.7312 
2025-03-30 20:16:30.358810: val_loss -0.7382 
2025-03-30 20:16:30.358904: Pseudo dice [np.float32(0.9033), np.float32(0.8808)] 
2025-03-30 20:16:30.358971: Epoch time: 27.17 s 
2025-03-30 20:16:31.151287:  
2025-03-30 20:16:31.151452: Epoch 368 
2025-03-30 20:16:31.151535: Current learning rate: 0.00662 
2025-03-30 20:16:58.053289: train_loss -0.7338 
2025-03-30 20:16:58.053437: val_loss -0.6936 
2025-03-30 20:16:58.053499: Pseudo dice [np.float32(0.8841), np.float32(0.8731)] 
2025-03-30 20:16:58.053564: Epoch time: 26.9 s 
2025-03-30 20:16:58.842093:  
2025-03-30 20:16:58.842250: Epoch 369 
2025-03-30 20:16:58.842335: Current learning rate: 0.00661 
2025-03-30 20:17:25.689941: train_loss -0.7291 
2025-03-30 20:17:25.690119: val_loss -0.6993 
2025-03-30 20:17:25.690175: Pseudo dice [np.float32(0.8881), np.float32(0.8716)] 
2025-03-30 20:17:25.690260: Epoch time: 26.85 s 
2025-03-30 20:17:26.475241:  
2025-03-30 20:17:26.475435: Epoch 370 
2025-03-30 20:17:26.475534: Current learning rate: 0.0066 
2025-03-30 20:17:53.351327: train_loss -0.7141 
2025-03-30 20:17:53.351480: val_loss -0.7202 
2025-03-30 20:17:53.351549: Pseudo dice [np.float32(0.8904), np.float32(0.8929)] 
2025-03-30 20:17:53.351611: Epoch time: 26.88 s 
2025-03-30 20:17:54.139712:  
2025-03-30 20:17:54.139868: Epoch 371 
2025-03-30 20:17:54.139960: Current learning rate: 0.00659 
2025-03-30 20:18:21.220345: train_loss -0.7203 
2025-03-30 20:18:21.220510: val_loss -0.7184 
2025-03-30 20:18:21.220566: Pseudo dice [np.float32(0.901), np.float32(0.8915)] 
2025-03-30 20:18:21.220626: Epoch time: 27.08 s 
2025-03-30 20:18:21.220674: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2025-03-30 20:18:22.551472:  
2025-03-30 20:18:22.551623: Epoch 372 
2025-03-30 20:18:22.551702: Current learning rate: 0.00658 
2025-03-30 20:18:49.555020: train_loss -0.7276 
2025-03-30 20:18:49.555143: val_loss -0.6973 
2025-03-30 20:18:49.555197: Pseudo dice [np.float32(0.8869), np.float32(0.8762)] 
2025-03-30 20:18:49.555258: Epoch time: 27.0 s 
2025-03-30 20:18:50.937978:  
2025-03-30 20:18:50.938152: Epoch 373 
2025-03-30 20:18:50.938248: Current learning rate: 0.00657 
2025-03-30 20:19:17.671330: train_loss -0.7187 
2025-03-30 20:19:17.671457: val_loss -0.74 
2025-03-30 20:19:17.671512: Pseudo dice [np.float32(0.9124), np.float32(0.892)] 
2025-03-30 20:19:17.671573: Epoch time: 26.73 s 
2025-03-30 20:19:17.671621: Yayy! New best EMA pseudo Dice: 0.8867999911308289 
2025-03-30 20:19:19.015747:  
2025-03-30 20:19:19.015937: Epoch 374 
2025-03-30 20:19:19.016017: Current learning rate: 0.00656 
2025-03-30 20:19:45.733394: train_loss -0.7216 
2025-03-30 20:19:45.733553: val_loss -0.678 
2025-03-30 20:19:45.733612: Pseudo dice [np.float32(0.8794), np.float32(0.867)] 
2025-03-30 20:19:45.733675: Epoch time: 26.72 s 
2025-03-30 20:19:46.522037:  
2025-03-30 20:19:46.522252: Epoch 375 
2025-03-30 20:19:46.522334: Current learning rate: 0.00655 
2025-03-30 20:20:13.195876: train_loss -0.7018 
2025-03-30 20:20:13.196003: val_loss -0.702 
2025-03-30 20:20:13.196062: Pseudo dice [np.float32(0.8828), np.float32(0.8865)] 
2025-03-30 20:20:13.196123: Epoch time: 26.67 s 
2025-03-30 20:20:13.981240:  
2025-03-30 20:20:13.981447: Epoch 376 
2025-03-30 20:20:13.981528: Current learning rate: 0.00654 
2025-03-30 20:20:40.689935: train_loss -0.7205 
2025-03-30 20:20:40.690163: val_loss -0.7064 
2025-03-30 20:20:40.690222: Pseudo dice [np.float32(0.8877), np.float32(0.8812)] 
2025-03-30 20:20:40.690317: Epoch time: 26.71 s 
2025-03-30 20:20:41.479040:  
2025-03-30 20:20:41.479220: Epoch 377 
2025-03-30 20:20:41.479300: Current learning rate: 0.00653 
2025-03-30 20:21:08.208833: train_loss -0.7152 
2025-03-30 20:21:08.208999: val_loss -0.7149 
2025-03-30 20:21:08.209054: Pseudo dice [np.float32(0.902), np.float32(0.8642)] 
2025-03-30 20:21:08.209116: Epoch time: 26.73 s 
2025-03-30 20:21:08.992858:  
2025-03-30 20:21:08.993030: Epoch 378 
2025-03-30 20:21:08.993109: Current learning rate: 0.00652 
2025-03-30 20:21:35.754081: train_loss -0.7087 
2025-03-30 20:21:35.754207: val_loss -0.6755 
2025-03-30 20:21:35.754263: Pseudo dice [np.float32(0.869), np.float32(0.8635)] 
2025-03-30 20:21:35.754325: Epoch time: 26.76 s 
2025-03-30 20:21:36.542937:  
2025-03-30 20:21:36.543100: Epoch 379 
2025-03-30 20:21:36.543180: Current learning rate: 0.00651 
2025-03-30 20:22:03.279209: train_loss -0.7102 
2025-03-30 20:22:03.279374: val_loss -0.6935 
2025-03-30 20:22:03.279480: Pseudo dice [np.float32(0.8823), np.float32(0.8693)] 
2025-03-30 20:22:03.279541: Epoch time: 26.74 s 
2025-03-30 20:22:04.065972:  
2025-03-30 20:22:04.066141: Epoch 380 
2025-03-30 20:22:04.066233: Current learning rate: 0.0065 
2025-03-30 20:22:30.822183: train_loss -0.7041 
2025-03-30 20:22:30.822428: val_loss -0.6792 
2025-03-30 20:22:30.822487: Pseudo dice [np.float32(0.8752), np.float32(0.8684)] 
2025-03-30 20:22:30.822548: Epoch time: 26.76 s 
2025-03-30 20:22:31.612919:  
2025-03-30 20:22:31.613069: Epoch 381 
2025-03-30 20:22:31.613139: Current learning rate: 0.00649 
2025-03-30 20:22:58.363185: train_loss -0.7279 
2025-03-30 20:22:58.363436: val_loss -0.7302 
2025-03-30 20:22:58.363494: Pseudo dice [np.float32(0.8955), np.float32(0.8984)] 
2025-03-30 20:22:58.363557: Epoch time: 26.75 s 
2025-03-30 20:22:59.161627:  
2025-03-30 20:22:59.161822: Epoch 382 
2025-03-30 20:22:59.161914: Current learning rate: 0.00648 
2025-03-30 20:23:25.878198: train_loss -0.7448 
2025-03-30 20:23:25.878417: val_loss -0.6995 
2025-03-30 20:23:25.878476: Pseudo dice [np.float32(0.8906), np.float32(0.8802)] 
2025-03-30 20:23:25.878538: Epoch time: 26.72 s 
2025-03-30 20:23:26.673225:  
2025-03-30 20:23:26.673371: Epoch 383 
2025-03-30 20:23:26.673449: Current learning rate: 0.00648 
2025-03-30 20:23:53.407043: train_loss -0.7109 
2025-03-30 20:23:53.407297: val_loss -0.6678 
2025-03-30 20:23:53.407361: Pseudo dice [np.float32(0.8654), np.float32(0.8599)] 
2025-03-30 20:23:53.407424: Epoch time: 26.73 s 
2025-03-30 20:23:54.261160:  
2025-03-30 20:23:54.261325: Epoch 384 
2025-03-30 20:23:54.261416: Current learning rate: 0.00647 
2025-03-30 20:24:20.939111: train_loss -0.7093 
2025-03-30 20:24:20.939369: val_loss -0.7234 
2025-03-30 20:24:20.939428: Pseudo dice [np.float32(0.8931), np.float32(0.8833)] 
2025-03-30 20:24:20.939495: Epoch time: 26.68 s 
2025-03-30 20:24:21.732165:  
2025-03-30 20:24:21.732337: Epoch 385 
2025-03-30 20:24:21.732419: Current learning rate: 0.00646 
2025-03-30 20:24:48.447543: train_loss -0.6871 
2025-03-30 20:24:48.447848: val_loss -0.6986 
2025-03-30 20:24:48.447908: Pseudo dice [np.float32(0.8904), np.float32(0.88)] 
2025-03-30 20:24:48.447972: Epoch time: 26.72 s 
2025-03-30 20:24:49.239283:  
2025-03-30 20:24:49.239432: Epoch 386 
2025-03-30 20:24:49.239513: Current learning rate: 0.00645 
2025-03-30 20:25:15.914826: train_loss -0.7151 
2025-03-30 20:25:15.915166: val_loss -0.6926 
2025-03-30 20:25:15.915224: Pseudo dice [np.float32(0.8676), np.float32(0.876)] 
2025-03-30 20:25:15.915330: Epoch time: 26.68 s 
2025-03-30 20:25:16.713524:  
2025-03-30 20:25:16.713685: Epoch 387 
2025-03-30 20:25:16.713771: Current learning rate: 0.00644 
2025-03-30 20:25:43.456795: train_loss -0.7217 
2025-03-30 20:25:43.457026: val_loss -0.7131 
2025-03-30 20:25:43.457084: Pseudo dice [np.float32(0.8808), np.float32(0.8862)] 
2025-03-30 20:25:43.457146: Epoch time: 26.74 s 
2025-03-30 20:25:44.251091:  
2025-03-30 20:25:44.251273: Epoch 388 
2025-03-30 20:25:44.251358: Current learning rate: 0.00643 
2025-03-30 20:26:10.989256: train_loss -0.7231 
2025-03-30 20:26:10.989382: val_loss -0.729 
2025-03-30 20:26:10.989438: Pseudo dice [np.float32(0.8942), np.float32(0.8993)] 
2025-03-30 20:26:10.989501: Epoch time: 26.74 s 
2025-03-30 20:26:11.782895:  
2025-03-30 20:26:11.783045: Epoch 389 
2025-03-30 20:26:11.783132: Current learning rate: 0.00642 
2025-03-30 20:26:38.471136: train_loss -0.7043 
2025-03-30 20:26:38.471312: val_loss -0.6774 
2025-03-30 20:26:38.471388: Pseudo dice [np.float32(0.8785), np.float32(0.8688)] 
2025-03-30 20:26:38.471450: Epoch time: 26.69 s 
2025-03-30 20:26:39.259140:  
2025-03-30 20:26:39.259298: Epoch 390 
2025-03-30 20:26:39.259381: Current learning rate: 0.00641 
2025-03-30 20:27:05.983326: train_loss -0.7324 
2025-03-30 20:27:05.983459: val_loss -0.7008 
2025-03-30 20:27:05.983515: Pseudo dice [np.float32(0.8841), np.float32(0.8795)] 
2025-03-30 20:27:05.983577: Epoch time: 26.73 s 
2025-03-30 20:27:06.777020:  
2025-03-30 20:27:06.777173: Epoch 391 
2025-03-30 20:27:06.777265: Current learning rate: 0.0064 
2025-03-30 20:27:33.523506: train_loss -0.7234 
2025-03-30 20:27:33.523646: val_loss -0.7037 
2025-03-30 20:27:33.523702: Pseudo dice [np.float32(0.8858), np.float32(0.8748)] 
2025-03-30 20:27:33.523773: Epoch time: 26.75 s 
2025-03-30 20:27:34.910783:  
2025-03-30 20:27:34.910966: Epoch 392 
2025-03-30 20:27:34.911061: Current learning rate: 0.00639 
2025-03-30 20:28:01.623905: train_loss -0.7314 
2025-03-30 20:28:01.624058: val_loss -0.7204 
2025-03-30 20:28:01.624113: Pseudo dice [np.float32(0.8889), np.float32(0.883)] 
2025-03-30 20:28:01.624176: Epoch time: 26.71 s 
2025-03-30 20:28:02.416329:  
2025-03-30 20:28:02.416523: Epoch 393 
2025-03-30 20:28:02.416603: Current learning rate: 0.00638 
2025-03-30 20:28:29.129616: train_loss -0.7419 
2025-03-30 20:28:29.129755: val_loss -0.7014 
2025-03-30 20:28:29.129822: Pseudo dice [np.float32(0.8839), np.float32(0.8789)] 
2025-03-30 20:28:29.129883: Epoch time: 26.71 s 
2025-03-30 20:28:29.918974:  
2025-03-30 20:28:29.919173: Epoch 394 
2025-03-30 20:28:29.919251: Current learning rate: 0.00637 
2025-03-30 20:28:56.598307: train_loss -0.7441 
2025-03-30 20:28:56.598433: val_loss -0.7289 
2025-03-30 20:28:56.598490: Pseudo dice [np.float32(0.8945), np.float32(0.8841)] 
2025-03-30 20:28:56.598551: Epoch time: 26.68 s 
2025-03-30 20:28:57.393411:  
2025-03-30 20:28:57.393607: Epoch 395 
2025-03-30 20:28:57.393700: Current learning rate: 0.00636 
2025-03-30 20:29:24.111094: train_loss -0.7576 
2025-03-30 20:29:24.111239: val_loss -0.7048 
2025-03-30 20:29:24.111295: Pseudo dice [np.float32(0.894), np.float32(0.8691)] 
2025-03-30 20:29:24.111360: Epoch time: 26.72 s 
2025-03-30 20:29:24.899956:  
2025-03-30 20:29:24.900141: Epoch 396 
2025-03-30 20:29:24.900227: Current learning rate: 0.00635 
2025-03-30 20:29:51.641266: train_loss -0.7341 
2025-03-30 20:29:51.641422: val_loss -0.6924 
2025-03-30 20:29:51.641479: Pseudo dice [np.float32(0.8853), np.float32(0.871)] 
2025-03-30 20:29:51.641541: Epoch time: 26.74 s 
2025-03-30 20:29:52.435942:  
2025-03-30 20:29:52.436112: Epoch 397 
2025-03-30 20:29:52.436191: Current learning rate: 0.00634 
2025-03-30 20:30:19.176156: train_loss -0.7325 
2025-03-30 20:30:19.176291: val_loss -0.7314 
2025-03-30 20:30:19.176347: Pseudo dice [np.float32(0.9023), np.float32(0.8798)] 
2025-03-30 20:30:19.176407: Epoch time: 26.74 s 
2025-03-30 20:30:19.972606:  
2025-03-30 20:30:19.972785: Epoch 398 
2025-03-30 20:30:19.972884: Current learning rate: 0.00633 
2025-03-30 20:30:46.696432: train_loss -0.7576 
2025-03-30 20:30:46.696574: val_loss -0.7543 
2025-03-30 20:30:46.696631: Pseudo dice [np.float32(0.9126), np.float32(0.903)] 
2025-03-30 20:30:46.696692: Epoch time: 26.72 s 
2025-03-30 20:30:47.492857:  
2025-03-30 20:30:47.493020: Epoch 399 
2025-03-30 20:30:47.493100: Current learning rate: 0.00632 
2025-03-30 20:31:14.224884: train_loss -0.7021 
2025-03-30 20:31:14.225024: val_loss -0.7119 
2025-03-30 20:31:14.225117: Pseudo dice [np.float32(0.8857), np.float32(0.8767)] 
2025-03-30 20:31:14.225209: Epoch time: 26.73 s 
2025-03-30 20:31:15.615136:  
2025-03-30 20:31:15.615284: Epoch 400 
2025-03-30 20:31:15.615388: Current learning rate: 0.00631 
2025-03-30 20:31:42.452599: train_loss -0.7268 
2025-03-30 20:31:42.452718: val_loss -0.7175 
2025-03-30 20:31:42.452783: Pseudo dice [np.float32(0.8987), np.float32(0.8799)] 
2025-03-30 20:31:42.452848: Epoch time: 26.84 s 
2025-03-30 20:31:43.235591:  
2025-03-30 20:31:43.235755: Epoch 401 
2025-03-30 20:31:43.235844: Current learning rate: 0.0063 
2025-03-30 20:32:10.001832: train_loss -0.734 
2025-03-30 20:32:10.002093: val_loss -0.728 
2025-03-30 20:32:10.002151: Pseudo dice [np.float32(0.9033), np.float32(0.8921)] 
2025-03-30 20:32:10.002216: Epoch time: 26.77 s 
2025-03-30 20:32:10.948240:  
2025-03-30 20:32:10.948410: Epoch 402 
2025-03-30 20:32:10.948498: Current learning rate: 0.0063 
2025-03-30 20:32:37.583887: train_loss -0.7388 
2025-03-30 20:32:37.584159: val_loss -0.7036 
2025-03-30 20:32:37.584217: Pseudo dice [np.float32(0.8846), np.float32(0.8744)] 
2025-03-30 20:32:37.584303: Epoch time: 26.64 s 
2025-03-30 20:32:38.374461:  
2025-03-30 20:32:38.374605: Epoch 403 
2025-03-30 20:32:38.374690: Current learning rate: 0.00629 
2025-03-30 20:33:05.078200: train_loss -0.6935 
2025-03-30 20:33:05.078433: val_loss -0.6875 
2025-03-30 20:33:05.078541: Pseudo dice [np.float32(0.8855), np.float32(0.857)] 
2025-03-30 20:33:05.078604: Epoch time: 26.7 s 
2025-03-30 20:33:06.040014:  
2025-03-30 20:33:06.040201: Epoch 404 
2025-03-30 20:33:06.040282: Current learning rate: 0.00628 
2025-03-30 20:33:32.731699: train_loss -0.6948 
2025-03-30 20:33:32.732041: val_loss -0.7298 
2025-03-30 20:33:32.732100: Pseudo dice [np.float32(0.9053), np.float32(0.8799)] 
2025-03-30 20:33:32.732163: Epoch time: 26.69 s 
2025-03-30 20:33:33.858738:  
2025-03-30 20:33:33.858907: Epoch 405 
2025-03-30 20:33:33.858988: Current learning rate: 0.00627 
2025-03-30 20:34:00.599421: train_loss -0.7261 
2025-03-30 20:34:00.599692: val_loss -0.7176 
2025-03-30 20:34:00.599751: Pseudo dice [np.float32(0.8958), np.float32(0.8859)] 
2025-03-30 20:34:00.599834: Epoch time: 26.74 s 
2025-03-30 20:34:01.392266:  
2025-03-30 20:34:01.392414: Epoch 406 
2025-03-30 20:34:01.392489: Current learning rate: 0.00626 
2025-03-30 20:34:28.137905: train_loss -0.7295 
2025-03-30 20:34:28.138156: val_loss -0.6955 
2025-03-30 20:34:28.138214: Pseudo dice [np.float32(0.8861), np.float32(0.8679)] 
2025-03-30 20:34:28.138275: Epoch time: 26.75 s 
2025-03-30 20:34:28.931984:  
2025-03-30 20:34:28.932125: Epoch 407 
2025-03-30 20:34:28.932218: Current learning rate: 0.00625 
2025-03-30 20:34:55.636419: train_loss -0.7434 
2025-03-30 20:34:55.636666: val_loss -0.742 
2025-03-30 20:34:55.636725: Pseudo dice [np.float32(0.897), np.float32(0.8938)] 
2025-03-30 20:34:55.636798: Epoch time: 26.71 s 
2025-03-30 20:34:56.426224:  
2025-03-30 20:34:56.426353: Epoch 408 
2025-03-30 20:34:56.426465: Current learning rate: 0.00624 
2025-03-30 20:35:23.131169: train_loss -0.7385 
2025-03-30 20:35:23.131454: val_loss -0.6834 
2025-03-30 20:35:23.131514: Pseudo dice [np.float32(0.8798), np.float32(0.8659)] 
2025-03-30 20:35:23.131578: Epoch time: 26.71 s 
2025-03-30 20:35:23.925831:  
2025-03-30 20:35:23.925984: Epoch 409 
2025-03-30 20:35:23.926063: Current learning rate: 0.00623 
2025-03-30 20:35:50.619508: train_loss -0.7266 
2025-03-30 20:35:50.619778: val_loss -0.7256 
2025-03-30 20:35:50.619840: Pseudo dice [np.float32(0.891), np.float32(0.8952)] 
2025-03-30 20:35:50.619922: Epoch time: 26.69 s 
2025-03-30 20:35:51.412923:  
2025-03-30 20:35:51.413070: Epoch 410 
2025-03-30 20:35:51.413150: Current learning rate: 0.00622 
2025-03-30 20:36:18.209116: train_loss -0.74 
2025-03-30 20:36:18.209310: val_loss -0.7298 
2025-03-30 20:36:18.209367: Pseudo dice [np.float32(0.9032), np.float32(0.8914)] 
2025-03-30 20:36:18.209428: Epoch time: 26.8 s 
2025-03-30 20:36:19.558915:  
2025-03-30 20:36:19.559100: Epoch 411 
2025-03-30 20:36:19.559189: Current learning rate: 0.00621 
2025-03-30 20:36:46.314886: train_loss -0.7414 
2025-03-30 20:36:46.315104: val_loss -0.742 
2025-03-30 20:36:46.315209: Pseudo dice [np.float32(0.9082), np.float32(0.8934)] 
2025-03-30 20:36:46.315275: Epoch time: 26.76 s 
2025-03-30 20:36:46.315324: Yayy! New best EMA pseudo Dice: 0.8881999850273132 
2025-03-30 20:36:47.576454:  
2025-03-30 20:36:47.576634: Epoch 412 
2025-03-30 20:36:47.576734: Current learning rate: 0.0062 
2025-03-30 20:37:14.315270: train_loss -0.7603 
2025-03-30 20:37:14.315419: val_loss -0.7192 
2025-03-30 20:37:14.315479: Pseudo dice [np.float32(0.8853), np.float32(0.8832)] 
2025-03-30 20:37:14.315542: Epoch time: 26.74 s 
2025-03-30 20:37:15.085607:  
2025-03-30 20:37:15.085810: Epoch 413 
2025-03-30 20:37:15.085891: Current learning rate: 0.00619 
2025-03-30 20:37:41.962993: train_loss -0.7668 
2025-03-30 20:37:41.963140: val_loss -0.7467 
2025-03-30 20:37:41.963195: Pseudo dice [np.float32(0.9048), np.float32(0.8994)] 
2025-03-30 20:37:41.963261: Epoch time: 26.88 s 
2025-03-30 20:37:41.963310: Yayy! New best EMA pseudo Dice: 0.88919997215271 
2025-03-30 20:37:43.279793:  
2025-03-30 20:37:43.279926: Epoch 414 
2025-03-30 20:37:43.280014: Current learning rate: 0.00618 
2025-03-30 20:38:10.011919: train_loss -0.7639 
2025-03-30 20:38:10.012038: val_loss -0.7413 
2025-03-30 20:38:10.012091: Pseudo dice [np.float32(0.9009), np.float32(0.8979)] 
2025-03-30 20:38:10.012147: Epoch time: 26.73 s 
2025-03-30 20:38:10.012192: Yayy! New best EMA pseudo Dice: 0.8902000188827515 
2025-03-30 20:38:13.302255:  
2025-03-30 20:38:13.302423: Epoch 415 
2025-03-30 20:38:13.302503: Current learning rate: 0.00617 
2025-03-30 20:38:39.999216: train_loss -0.7514 
2025-03-30 20:38:39.999339: val_loss -0.7205 
2025-03-30 20:38:39.999393: Pseudo dice [np.float32(0.8922), np.float32(0.8783)] 
2025-03-30 20:38:39.999452: Epoch time: 26.7 s 
2025-03-30 20:38:40.765779:  
2025-03-30 20:38:40.765916: Epoch 416 
2025-03-30 20:38:40.766018: Current learning rate: 0.00616 
2025-03-30 20:39:07.457704: train_loss -0.7417 
2025-03-30 20:39:07.457876: val_loss -0.734 
2025-03-30 20:39:07.457933: Pseudo dice [np.float32(0.9031), np.float32(0.8882)] 
2025-03-30 20:39:07.457995: Epoch time: 26.69 s 
2025-03-30 20:39:07.458043: Yayy! New best EMA pseudo Dice: 0.8902999758720398 
2025-03-30 20:39:08.776654:  
2025-03-30 20:39:08.776842: Epoch 417 
2025-03-30 20:39:08.776929: Current learning rate: 0.00615 
2025-03-30 20:39:35.516854: train_loss -0.7249 
2025-03-30 20:39:35.517003: val_loss -0.7142 
2025-03-30 20:39:35.517060: Pseudo dice [np.float32(0.895), np.float32(0.8858)] 
2025-03-30 20:39:35.517127: Epoch time: 26.74 s 
2025-03-30 20:39:35.517176: Yayy! New best EMA pseudo Dice: 0.8902999758720398 
2025-03-30 20:39:36.858352:  
2025-03-30 20:39:36.858525: Epoch 418 
2025-03-30 20:39:36.858602: Current learning rate: 0.00614 
2025-03-30 20:40:03.604874: train_loss -0.7335 
2025-03-30 20:40:03.605046: val_loss -0.7349 
2025-03-30 20:40:03.605104: Pseudo dice [np.float32(0.9034), np.float32(0.8888)] 
2025-03-30 20:40:03.605164: Epoch time: 26.75 s 
2025-03-30 20:40:03.605213: Yayy! New best EMA pseudo Dice: 0.8909000158309937 
2025-03-30 20:40:04.935434:  
2025-03-30 20:40:04.935591: Epoch 419 
2025-03-30 20:40:04.935690: Current learning rate: 0.00613 
2025-03-30 20:40:31.639239: train_loss -0.7555 
2025-03-30 20:40:31.639374: val_loss -0.7074 
2025-03-30 20:40:31.639429: Pseudo dice [np.float32(0.8907), np.float32(0.8817)] 
2025-03-30 20:40:31.639493: Epoch time: 26.7 s 
2025-03-30 20:40:32.567510:  
2025-03-30 20:40:32.567667: Epoch 420 
2025-03-30 20:40:32.567780: Current learning rate: 0.00612 
2025-03-30 20:40:59.304134: train_loss -0.741 
2025-03-30 20:40:59.304306: val_loss -0.7325 
2025-03-30 20:40:59.304363: Pseudo dice [np.float32(0.9004), np.float32(0.8951)] 
2025-03-30 20:40:59.304428: Epoch time: 26.74 s 
2025-03-30 20:40:59.304477: Yayy! New best EMA pseudo Dice: 0.8912000060081482 
2025-03-30 20:41:00.643028:  
2025-03-30 20:41:00.643189: Epoch 421 
2025-03-30 20:41:00.643284: Current learning rate: 0.00612 
2025-03-30 20:41:27.451836: train_loss -0.7358 
2025-03-30 20:41:27.451976: val_loss -0.6963 
2025-03-30 20:41:27.452040: Pseudo dice [np.float32(0.8908), np.float32(0.8723)] 
2025-03-30 20:41:27.452107: Epoch time: 26.81 s 
2025-03-30 20:41:28.216964:  
2025-03-30 20:41:28.217121: Epoch 422 
2025-03-30 20:41:28.217212: Current learning rate: 0.00611 
2025-03-30 20:41:54.967323: train_loss -0.727 
2025-03-30 20:41:54.967549: val_loss -0.687 
2025-03-30 20:41:54.967608: Pseudo dice [np.float32(0.8798), np.float32(0.8721)] 
2025-03-30 20:41:54.967671: Epoch time: 26.75 s 
2025-03-30 20:41:55.741331:  
2025-03-30 20:41:55.741487: Epoch 423 
2025-03-30 20:41:55.741567: Current learning rate: 0.0061 
2025-03-30 20:42:22.460076: train_loss -0.7129 
2025-03-30 20:42:22.460326: val_loss -0.714 
2025-03-30 20:42:22.460385: Pseudo dice [np.float32(0.8925), np.float32(0.8911)] 
2025-03-30 20:42:22.460446: Epoch time: 26.72 s 
2025-03-30 20:42:23.243174:  
2025-03-30 20:42:23.243329: Epoch 424 
2025-03-30 20:42:23.243409: Current learning rate: 0.00609 
2025-03-30 20:42:49.966996: train_loss -0.7454 
2025-03-30 20:42:49.967280: val_loss -0.7141 
2025-03-30 20:42:49.967337: Pseudo dice [np.float32(0.8889), np.float32(0.8809)] 
2025-03-30 20:42:49.967398: Epoch time: 26.72 s 
2025-03-30 20:42:50.738621:  
2025-03-30 20:42:50.738790: Epoch 425 
2025-03-30 20:42:50.738892: Current learning rate: 0.00608 
2025-03-30 20:43:17.463056: train_loss -0.7462 
2025-03-30 20:43:17.463308: val_loss -0.6812 
2025-03-30 20:43:17.463368: Pseudo dice [np.float32(0.8711), np.float32(0.8623)] 
2025-03-30 20:43:17.463430: Epoch time: 26.73 s 
2025-03-30 20:43:18.236348:  
2025-03-30 20:43:18.236507: Epoch 426 
2025-03-30 20:43:18.236615: Current learning rate: 0.00607 
2025-03-30 20:43:44.954787: train_loss -0.7517 
2025-03-30 20:43:44.955069: val_loss -0.7206 
2025-03-30 20:43:44.955135: Pseudo dice [np.float32(0.8947), np.float32(0.8948)] 
2025-03-30 20:43:44.955205: Epoch time: 26.72 s 
2025-03-30 20:43:45.721805:  
2025-03-30 20:43:45.721955: Epoch 427 
2025-03-30 20:43:45.722036: Current learning rate: 0.00606 
2025-03-30 20:44:12.445039: train_loss -0.7535 
2025-03-30 20:44:12.445276: val_loss -0.7423 
2025-03-30 20:44:12.445335: Pseudo dice [np.float32(0.9058), np.float32(0.8956)] 
2025-03-30 20:44:12.445396: Epoch time: 26.72 s 
2025-03-30 20:44:13.221099:  
2025-03-30 20:44:13.221259: Epoch 428 
2025-03-30 20:44:13.221338: Current learning rate: 0.00605 
2025-03-30 20:44:39.997031: train_loss -0.7395 
2025-03-30 20:44:39.997226: val_loss -0.7134 
2025-03-30 20:44:39.997283: Pseudo dice [np.float32(0.896), np.float32(0.8823)] 
2025-03-30 20:44:39.997343: Epoch time: 26.78 s 
2025-03-30 20:44:40.770521:  
2025-03-30 20:44:40.770679: Epoch 429 
2025-03-30 20:44:40.770781: Current learning rate: 0.00604 
2025-03-30 20:45:07.540865: train_loss -0.746 
2025-03-30 20:45:07.540994: val_loss -0.7214 
2025-03-30 20:45:07.541050: Pseudo dice [np.float32(0.8926), np.float32(0.8815)] 
2025-03-30 20:45:07.541111: Epoch time: 26.77 s 
2025-03-30 20:45:08.312149:  
2025-03-30 20:45:08.312307: Epoch 430 
2025-03-30 20:45:08.312387: Current learning rate: 0.00603 
2025-03-30 20:45:35.065263: train_loss -0.7245 
2025-03-30 20:45:35.065408: val_loss -0.6951 
2025-03-30 20:45:35.065465: Pseudo dice [np.float32(0.8907), np.float32(0.873)] 
2025-03-30 20:45:35.065526: Epoch time: 26.75 s 
2025-03-30 20:45:36.454487:  
2025-03-30 20:45:36.454681: Epoch 431 
2025-03-30 20:45:36.454778: Current learning rate: 0.00602 
2025-03-30 20:46:03.270903: train_loss -0.7157 
2025-03-30 20:46:03.271042: val_loss -0.7501 
2025-03-30 20:46:03.271096: Pseudo dice [np.float32(0.911), np.float32(0.8938)] 
2025-03-30 20:46:03.271158: Epoch time: 26.82 s 
2025-03-30 20:46:04.043173:  
2025-03-30 20:46:04.043359: Epoch 432 
2025-03-30 20:46:04.043449: Current learning rate: 0.00601 
2025-03-30 20:46:30.859356: train_loss -0.7352 
2025-03-30 20:46:30.859497: val_loss -0.6877 
2025-03-30 20:46:30.859554: Pseudo dice [np.float32(0.8766), np.float32(0.8577)] 
2025-03-30 20:46:30.859616: Epoch time: 26.82 s 
2025-03-30 20:46:31.640300:  
2025-03-30 20:46:31.640479: Epoch 433 
2025-03-30 20:46:31.640564: Current learning rate: 0.006 
2025-03-30 20:46:58.350842: train_loss -0.7433 
2025-03-30 20:46:58.350995: val_loss -0.7352 
2025-03-30 20:46:58.351052: Pseudo dice [np.float32(0.8969), np.float32(0.8907)] 
2025-03-30 20:46:58.351112: Epoch time: 26.71 s 
2025-03-30 20:46:59.125240:  
2025-03-30 20:46:59.125405: Epoch 434 
2025-03-30 20:46:59.125501: Current learning rate: 0.00599 
2025-03-30 20:47:25.818024: train_loss -0.7567 
2025-03-30 20:47:25.818189: val_loss -0.725 
2025-03-30 20:47:25.818258: Pseudo dice [np.float32(0.8976), np.float32(0.8881)] 
2025-03-30 20:47:25.818325: Epoch time: 26.69 s 
2025-03-30 20:47:26.779709:  
2025-03-30 20:47:26.779917: Epoch 435 
2025-03-30 20:47:26.780004: Current learning rate: 0.00598 
2025-03-30 20:47:53.499778: train_loss -0.7432 
2025-03-30 20:47:53.499946: val_loss -0.715 
2025-03-30 20:47:53.500026: Pseudo dice [np.float32(0.8953), np.float32(0.8798)] 
2025-03-30 20:47:53.500089: Epoch time: 26.72 s 
2025-03-30 20:47:54.269834:  
2025-03-30 20:47:54.270011: Epoch 436 
2025-03-30 20:47:54.270099: Current learning rate: 0.00597 
2025-03-30 20:48:20.884561: train_loss -0.7466 
2025-03-30 20:48:20.884698: val_loss -0.7033 
2025-03-30 20:48:20.884757: Pseudo dice [np.float32(0.8899), np.float32(0.8798)] 
2025-03-30 20:48:20.884830: Epoch time: 26.62 s 
2025-03-30 20:48:21.662988:  
2025-03-30 20:48:21.663136: Epoch 437 
2025-03-30 20:48:21.663237: Current learning rate: 0.00596 
2025-03-30 20:48:48.358743: train_loss -0.749 
2025-03-30 20:48:48.358937: val_loss -0.7235 
2025-03-30 20:48:48.358993: Pseudo dice [np.float32(0.8999), np.float32(0.8855)] 
2025-03-30 20:48:48.359057: Epoch time: 26.7 s 
2025-03-30 20:48:49.133510:  
2025-03-30 20:48:49.133683: Epoch 438 
2025-03-30 20:48:49.133770: Current learning rate: 0.00595 
2025-03-30 20:49:15.825557: train_loss -0.7549 
2025-03-30 20:49:15.825716: val_loss -0.7319 
2025-03-30 20:49:15.825781: Pseudo dice [np.float32(0.9013), np.float32(0.8903)] 
2025-03-30 20:49:15.825845: Epoch time: 26.69 s 
2025-03-30 20:49:16.597908:  
2025-03-30 20:49:16.598074: Epoch 439 
2025-03-30 20:49:16.598155: Current learning rate: 0.00594 
2025-03-30 20:49:43.291957: train_loss -0.7395 
2025-03-30 20:49:43.292089: val_loss -0.707 
2025-03-30 20:49:43.292145: Pseudo dice [np.float32(0.8882), np.float32(0.8741)] 
2025-03-30 20:49:43.292208: Epoch time: 26.7 s 
2025-03-30 20:49:44.062141:  
2025-03-30 20:49:44.062309: Epoch 440 
2025-03-30 20:49:44.062389: Current learning rate: 0.00593 
2025-03-30 20:50:10.754735: train_loss -0.7247 
2025-03-30 20:50:10.754879: val_loss -0.7107 
2025-03-30 20:50:10.754936: Pseudo dice [np.float32(0.8879), np.float32(0.886)] 
2025-03-30 20:50:10.754998: Epoch time: 26.69 s 
2025-03-30 20:50:11.532975:  
2025-03-30 20:50:11.533140: Epoch 441 
2025-03-30 20:50:11.533222: Current learning rate: 0.00592 
2025-03-30 20:50:38.273544: train_loss -0.7413 
2025-03-30 20:50:38.273696: val_loss -0.7286 
2025-03-30 20:50:38.273753: Pseudo dice [np.float32(0.9028), np.float32(0.8882)] 
2025-03-30 20:50:38.273842: Epoch time: 26.74 s 
2025-03-30 20:50:39.047485:  
2025-03-30 20:50:39.047648: Epoch 442 
2025-03-30 20:50:39.047733: Current learning rate: 0.00592 
2025-03-30 20:51:05.758308: train_loss -0.7443 
2025-03-30 20:51:05.758465: val_loss -0.7313 
2025-03-30 20:51:05.758521: Pseudo dice [np.float32(0.894), np.float32(0.8907)] 
2025-03-30 20:51:05.758583: Epoch time: 26.71 s 
2025-03-30 20:51:06.531689:  
2025-03-30 20:51:06.531853: Epoch 443 
2025-03-30 20:51:06.531939: Current learning rate: 0.00591 
2025-03-30 20:51:33.267754: train_loss -0.7339 
2025-03-30 20:51:33.267899: val_loss -0.708 
2025-03-30 20:51:33.267962: Pseudo dice [np.float32(0.8944), np.float32(0.8683)] 
2025-03-30 20:51:33.268042: Epoch time: 26.74 s 
2025-03-30 20:51:34.035554:  
2025-03-30 20:51:34.035706: Epoch 444 
2025-03-30 20:51:34.035813: Current learning rate: 0.0059 
2025-03-30 20:52:00.763610: train_loss -0.7712 
2025-03-30 20:52:00.763778: val_loss -0.7251 
2025-03-30 20:52:00.763837: Pseudo dice [np.float32(0.8897), np.float32(0.8855)] 
2025-03-30 20:52:00.763900: Epoch time: 26.73 s 
2025-03-30 20:52:01.526460:  
2025-03-30 20:52:01.526619: Epoch 445 
2025-03-30 20:52:01.526695: Current learning rate: 0.00589 
2025-03-30 20:52:28.248465: train_loss -0.764 
2025-03-30 20:52:28.248623: val_loss -0.7106 
2025-03-30 20:52:28.248680: Pseudo dice [np.float32(0.8961), np.float32(0.8831)] 
2025-03-30 20:52:28.248739: Epoch time: 26.72 s 
2025-03-30 20:52:29.018542:  
2025-03-30 20:52:29.018701: Epoch 446 
2025-03-30 20:52:29.018804: Current learning rate: 0.00588 
2025-03-30 20:52:55.717372: train_loss -0.7563 
2025-03-30 20:52:55.717501: val_loss -0.6947 
2025-03-30 20:52:55.717556: Pseudo dice [np.float32(0.8865), np.float32(0.89)] 
2025-03-30 20:52:55.717638: Epoch time: 26.7 s 
2025-03-30 20:52:56.478767:  
2025-03-30 20:52:56.478911: Epoch 447 
2025-03-30 20:52:56.478990: Current learning rate: 0.00587 
2025-03-30 20:53:23.252754: train_loss -0.7424 
2025-03-30 20:53:23.252901: val_loss -0.7349 
2025-03-30 20:53:23.252966: Pseudo dice [np.float32(0.9042), np.float32(0.8938)] 
2025-03-30 20:53:23.253025: Epoch time: 26.78 s 
2025-03-30 20:53:24.012626:  
2025-03-30 20:53:24.012776: Epoch 448 
2025-03-30 20:53:24.012857: Current learning rate: 0.00586 
2025-03-30 20:53:50.713767: train_loss -0.75 
2025-03-30 20:53:50.713904: val_loss -0.7453 
2025-03-30 20:53:50.713962: Pseudo dice [np.float32(0.9063), np.float32(0.8995)] 
2025-03-30 20:53:50.714040: Epoch time: 26.7 s 
2025-03-30 20:53:51.476582:  
2025-03-30 20:53:51.476727: Epoch 449 
2025-03-30 20:53:51.476813: Current learning rate: 0.00585 
2025-03-30 20:54:18.200590: train_loss -0.7314 
2025-03-30 20:54:18.200828: val_loss -0.6801 
2025-03-30 20:54:18.200887: Pseudo dice [np.float32(0.8705), np.float32(0.8521)] 
2025-03-30 20:54:18.200949: Epoch time: 26.73 s 
2025-03-30 20:54:19.458351:  
2025-03-30 20:54:19.458513: Epoch 450 
2025-03-30 20:54:19.458608: Current learning rate: 0.00584 
2025-03-30 20:54:46.125803: train_loss -0.747 
2025-03-30 20:54:46.126087: val_loss -0.7358 
2025-03-30 20:54:46.126149: Pseudo dice [np.float32(0.904), np.float32(0.893)] 
2025-03-30 20:54:46.126248: Epoch time: 26.67 s 
2025-03-30 20:54:47.461243:  
2025-03-30 20:54:47.461409: Epoch 451 
2025-03-30 20:54:47.461505: Current learning rate: 0.00583 
2025-03-30 20:55:14.199397: train_loss -0.7462 
2025-03-30 20:55:14.199653: val_loss -0.7322 
2025-03-30 20:55:14.199711: Pseudo dice [np.float32(0.8985), np.float32(0.8945)] 
2025-03-30 20:55:14.199784: Epoch time: 26.74 s 
2025-03-30 20:55:14.962198:  
2025-03-30 20:55:14.962361: Epoch 452 
2025-03-30 20:55:14.962468: Current learning rate: 0.00582 
2025-03-30 20:55:41.701988: train_loss -0.7505 
2025-03-30 20:55:41.702123: val_loss -0.7387 
2025-03-30 20:55:41.702179: Pseudo dice [np.float32(0.9061), np.float32(0.8921)] 
2025-03-30 20:55:41.702239: Epoch time: 26.74 s 
2025-03-30 20:55:42.466013:  
2025-03-30 20:55:42.466185: Epoch 453 
2025-03-30 20:55:42.466273: Current learning rate: 0.00581 
2025-03-30 20:56:09.342525: train_loss -0.7599 
2025-03-30 20:56:09.342654: val_loss -0.7328 
2025-03-30 20:56:09.342710: Pseudo dice [np.float32(0.8964), np.float32(0.8955)] 
2025-03-30 20:56:09.342783: Epoch time: 26.88 s 
2025-03-30 20:56:09.342836: Yayy! New best EMA pseudo Dice: 0.8912000060081482 
2025-03-30 20:56:10.630242:  
2025-03-30 20:56:10.630410: Epoch 454 
2025-03-30 20:56:10.630481: Current learning rate: 0.0058 
2025-03-30 20:56:37.295734: train_loss -0.7571 
2025-03-30 20:56:37.295927: val_loss -0.7326 
2025-03-30 20:56:37.295985: Pseudo dice [np.float32(0.8937), np.float32(0.8947)] 
2025-03-30 20:56:37.296056: Epoch time: 26.67 s 
2025-03-30 20:56:37.296106: Yayy! New best EMA pseudo Dice: 0.8914999961853027 
2025-03-30 20:56:38.604154:  
2025-03-30 20:56:38.604325: Epoch 455 
2025-03-30 20:56:38.604403: Current learning rate: 0.00579 
2025-03-30 20:57:05.321614: train_loss -0.7537 
2025-03-30 20:57:05.321753: val_loss -0.7371 
2025-03-30 20:57:05.321866: Pseudo dice [np.float32(0.8956), np.float32(0.8962)] 
2025-03-30 20:57:05.321930: Epoch time: 26.72 s 
2025-03-30 20:57:05.321978: Yayy! New best EMA pseudo Dice: 0.8919000029563904 
2025-03-30 20:57:06.635552:  
2025-03-30 20:57:06.635698: Epoch 456 
2025-03-30 20:57:06.635786: Current learning rate: 0.00578 
2025-03-30 20:57:33.362399: train_loss -0.7727 
2025-03-30 20:57:33.362518: val_loss -0.7495 
2025-03-30 20:57:33.362574: Pseudo dice [np.float32(0.9058), np.float32(0.8945)] 
2025-03-30 20:57:33.362634: Epoch time: 26.73 s 
2025-03-30 20:57:33.362682: Yayy! New best EMA pseudo Dice: 0.8927000164985657 
2025-03-30 20:57:34.678401:  
2025-03-30 20:57:34.678585: Epoch 457 
2025-03-30 20:57:34.678670: Current learning rate: 0.00577 
2025-03-30 20:58:01.346210: train_loss -0.7507 
2025-03-30 20:58:01.346346: val_loss -0.7221 
2025-03-30 20:58:01.346402: Pseudo dice [np.float32(0.8952), np.float32(0.8841)] 
2025-03-30 20:58:01.346467: Epoch time: 26.67 s 
2025-03-30 20:58:02.112344:  
2025-03-30 20:58:02.112509: Epoch 458 
2025-03-30 20:58:02.112598: Current learning rate: 0.00576 
2025-03-30 20:58:28.788168: train_loss -0.7536 
2025-03-30 20:58:28.788310: val_loss -0.7394 
2025-03-30 20:58:28.788386: Pseudo dice [np.float32(0.8921), np.float32(0.9025)] 
2025-03-30 20:58:28.788450: Epoch time: 26.68 s 
2025-03-30 20:58:28.788498: Yayy! New best EMA pseudo Dice: 0.8928999900817871 
2025-03-30 20:58:30.105052:  
2025-03-30 20:58:30.105221: Epoch 459 
2025-03-30 20:58:30.105302: Current learning rate: 0.00575 
2025-03-30 20:58:56.836813: train_loss -0.7602 
2025-03-30 20:58:56.836936: val_loss -0.7123 
2025-03-30 20:58:56.836992: Pseudo dice [np.float32(0.8869), np.float32(0.8842)] 
2025-03-30 20:58:56.837053: Epoch time: 26.73 s 
2025-03-30 20:58:57.603340:  
2025-03-30 20:58:57.603492: Epoch 460 
2025-03-30 20:58:57.603575: Current learning rate: 0.00574 
2025-03-30 20:59:24.454709: train_loss -0.7185 
2025-03-30 20:59:24.454966: val_loss -0.7175 
2025-03-30 20:59:24.455029: Pseudo dice [np.float32(0.8913), np.float32(0.8903)] 
2025-03-30 20:59:24.455089: Epoch time: 26.85 s 
2025-03-30 20:59:25.225124:  
2025-03-30 20:59:25.225304: Epoch 461 
2025-03-30 20:59:25.225383: Current learning rate: 0.00573 
2025-03-30 20:59:52.078254: train_loss -0.7459 
2025-03-30 20:59:52.078531: val_loss -0.754 
2025-03-30 20:59:52.078637: Pseudo dice [np.float32(0.9087), np.float32(0.9011)] 
2025-03-30 20:59:52.078778: Epoch time: 26.85 s 
2025-03-30 20:59:52.078832: Yayy! New best EMA pseudo Dice: 0.8932999968528748 
2025-03-30 20:59:53.406452:  
2025-03-30 20:59:53.406637: Epoch 462 
2025-03-30 20:59:53.406708: Current learning rate: 0.00572 
2025-03-30 21:00:20.241042: train_loss -0.7406 
2025-03-30 21:00:20.241200: val_loss -0.7363 
2025-03-30 21:00:20.241257: Pseudo dice [np.float32(0.9046), np.float32(0.8947)] 
2025-03-30 21:00:20.241320: Epoch time: 26.84 s 
2025-03-30 21:00:20.241368: Yayy! New best EMA pseudo Dice: 0.8939999938011169 
2025-03-30 21:00:21.631975:  
2025-03-30 21:00:21.632158: Epoch 463 
2025-03-30 21:00:21.632245: Current learning rate: 0.00571 
2025-03-30 21:00:48.427020: train_loss -0.7235 
2025-03-30 21:00:48.427170: val_loss -0.6933 
2025-03-30 21:00:48.427225: Pseudo dice [np.float32(0.8812), np.float32(0.8713)] 
2025-03-30 21:00:48.427290: Epoch time: 26.8 s 
2025-03-30 21:00:49.185926:  
2025-03-30 21:00:49.186076: Epoch 464 
2025-03-30 21:00:49.186145: Current learning rate: 0.0057 
2025-03-30 21:01:15.923964: train_loss -0.74 
2025-03-30 21:01:15.924176: val_loss -0.7433 
2025-03-30 21:01:15.924233: Pseudo dice [np.float32(0.9103), np.float32(0.8894)] 
2025-03-30 21:01:15.924294: Epoch time: 26.74 s 
2025-03-30 21:01:16.689158:  
2025-03-30 21:01:16.689313: Epoch 465 
2025-03-30 21:01:16.689395: Current learning rate: 0.0057 
2025-03-30 21:01:43.447150: train_loss -0.7454 
2025-03-30 21:01:43.447319: val_loss -0.7393 
2025-03-30 21:01:43.447390: Pseudo dice [np.float32(0.8955), np.float32(0.8992)] 
2025-03-30 21:01:43.447451: Epoch time: 26.76 s 
2025-03-30 21:01:44.212629:  
2025-03-30 21:01:44.212800: Epoch 466 
2025-03-30 21:01:44.212884: Current learning rate: 0.00569 
2025-03-30 21:02:10.980516: train_loss -0.7619 
2025-03-30 21:02:10.980642: val_loss -0.7533 
2025-03-30 21:02:10.980718: Pseudo dice [np.float32(0.9117), np.float32(0.8986)] 
2025-03-30 21:02:10.980809: Epoch time: 26.77 s 
2025-03-30 21:02:10.980858: Yayy! New best EMA pseudo Dice: 0.894599974155426 
2025-03-30 21:02:12.296166:  
2025-03-30 21:02:12.296325: Epoch 467 
2025-03-30 21:02:12.296424: Current learning rate: 0.00568 
2025-03-30 21:02:38.988782: train_loss -0.7801 
2025-03-30 21:02:38.988933: val_loss -0.7354 
2025-03-30 21:02:38.988987: Pseudo dice [np.float32(0.9006), np.float32(0.8865)] 
2025-03-30 21:02:38.989071: Epoch time: 26.69 s 
2025-03-30 21:02:39.758541:  
2025-03-30 21:02:39.758717: Epoch 468 
2025-03-30 21:02:39.758808: Current learning rate: 0.00567 
2025-03-30 21:03:06.515595: train_loss -0.7729 
2025-03-30 21:03:06.515749: val_loss -0.7541 
2025-03-30 21:03:06.515814: Pseudo dice [np.float32(0.9008), np.float32(0.8972)] 
2025-03-30 21:03:06.515874: Epoch time: 26.76 s 
2025-03-30 21:03:06.515933: Yayy! New best EMA pseudo Dice: 0.8949000239372253 
2025-03-30 21:03:07.836667:  
2025-03-30 21:03:07.836846: Epoch 469 
2025-03-30 21:03:07.836928: Current learning rate: 0.00566 
2025-03-30 21:03:34.627707: train_loss -0.7644 
2025-03-30 21:03:34.627861: val_loss -0.7308 
2025-03-30 21:03:34.627935: Pseudo dice [np.float32(0.8979), np.float32(0.8848)] 
2025-03-30 21:03:34.628034: Epoch time: 26.79 s 
2025-03-30 21:03:35.388476:  
2025-03-30 21:03:35.388643: Epoch 470 
2025-03-30 21:03:35.388729: Current learning rate: 0.00565 
2025-03-30 21:04:02.048117: train_loss -0.7729 
2025-03-30 21:04:02.048364: val_loss -0.7368 
2025-03-30 21:04:02.048453: Pseudo dice [np.float32(0.9058), np.float32(0.8853)] 
2025-03-30 21:04:02.048516: Epoch time: 26.66 s 
2025-03-30 21:04:03.401380:  
2025-03-30 21:04:03.401578: Epoch 471 
2025-03-30 21:04:03.401665: Current learning rate: 0.00564 
2025-03-30 21:04:30.163182: train_loss -0.7533 
2025-03-30 21:04:30.163513: val_loss -0.7363 
2025-03-30 21:04:30.163571: Pseudo dice [np.float32(0.8976), np.float32(0.8925)] 
2025-03-30 21:04:30.163633: Epoch time: 26.76 s 
2025-03-30 21:04:30.927942:  
2025-03-30 21:04:30.928132: Epoch 472 
2025-03-30 21:04:30.928223: Current learning rate: 0.00563 
2025-03-30 21:04:57.677001: train_loss -0.7354 
2025-03-30 21:04:57.677171: val_loss -0.7044 
2025-03-30 21:04:57.677233: Pseudo dice [np.float32(0.8869), np.float32(0.8794)] 
2025-03-30 21:04:57.677296: Epoch time: 26.75 s 
2025-03-30 21:04:58.435492:  
2025-03-30 21:04:58.435663: Epoch 473 
2025-03-30 21:04:58.435740: Current learning rate: 0.00562 
2025-03-30 21:05:25.161733: train_loss -0.7438 
2025-03-30 21:05:25.161877: val_loss -0.7621 
2025-03-30 21:05:25.161933: Pseudo dice [np.float32(0.901), np.float32(0.9068)] 
2025-03-30 21:05:25.161994: Epoch time: 26.73 s 
2025-03-30 21:05:25.927821:  
2025-03-30 21:05:25.927993: Epoch 474 
2025-03-30 21:05:25.928074: Current learning rate: 0.00561 
2025-03-30 21:05:52.669459: train_loss -0.7546 
2025-03-30 21:05:52.669599: val_loss -0.7159 
2025-03-30 21:05:52.669654: Pseudo dice [np.float32(0.876), np.float32(0.885)] 
2025-03-30 21:05:52.669718: Epoch time: 26.74 s 
2025-03-30 21:05:53.430971:  
2025-03-30 21:05:53.431135: Epoch 475 
2025-03-30 21:05:53.431215: Current learning rate: 0.0056 
2025-03-30 21:06:20.121816: train_loss -0.7592 
2025-03-30 21:06:20.121988: val_loss -0.7477 
2025-03-30 21:06:20.122044: Pseudo dice [np.float32(0.899), np.float32(0.9005)] 
2025-03-30 21:06:20.122105: Epoch time: 26.69 s 
2025-03-30 21:06:20.882685:  
2025-03-30 21:06:20.882859: Epoch 476 
2025-03-30 21:06:20.882955: Current learning rate: 0.00559 
2025-03-30 21:06:47.604743: train_loss -0.7582 
2025-03-30 21:06:47.604883: val_loss -0.7547 
2025-03-30 21:06:47.604938: Pseudo dice [np.float32(0.9083), np.float32(0.9015)] 
2025-03-30 21:06:47.604997: Epoch time: 26.72 s 
2025-03-30 21:06:47.605045: Yayy! New best EMA pseudo Dice: 0.8949000239372253 
2025-03-30 21:06:48.897060:  
2025-03-30 21:06:48.897245: Epoch 477 
2025-03-30 21:06:48.897332: Current learning rate: 0.00558 
2025-03-30 21:07:15.640021: train_loss -0.75 
2025-03-30 21:07:15.640173: val_loss -0.6927 
2025-03-30 21:07:15.640229: Pseudo dice [np.float32(0.8851), np.float32(0.8656)] 
2025-03-30 21:07:15.640292: Epoch time: 26.74 s 
2025-03-30 21:07:16.409159:  
2025-03-30 21:07:16.409316: Epoch 478 
2025-03-30 21:07:16.409406: Current learning rate: 0.00557 
2025-03-30 21:07:43.149568: train_loss -0.7615 
2025-03-30 21:07:43.149807: val_loss -0.6999 
2025-03-30 21:07:43.149868: Pseudo dice [np.float32(0.8862), np.float32(0.8673)] 
2025-03-30 21:07:43.149930: Epoch time: 26.74 s 
2025-03-30 21:07:43.924484:  
2025-03-30 21:07:43.924647: Epoch 479 
2025-03-30 21:07:43.924726: Current learning rate: 0.00556 
2025-03-30 21:08:10.644069: train_loss -0.7541 
2025-03-30 21:08:10.644445: val_loss -0.7418 
2025-03-30 21:08:10.644503: Pseudo dice [np.float32(0.9029), np.float32(0.8882)] 
2025-03-30 21:08:10.644564: Epoch time: 26.72 s 
2025-03-30 21:08:11.412722:  
2025-03-30 21:08:11.412884: Epoch 480 
2025-03-30 21:08:11.412972: Current learning rate: 0.00555 
2025-03-30 21:08:38.140928: train_loss -0.7567 
2025-03-30 21:08:38.141077: val_loss -0.7308 
2025-03-30 21:08:38.141135: Pseudo dice [np.float32(0.8966), np.float32(0.8877)] 
2025-03-30 21:08:38.141197: Epoch time: 26.73 s 
2025-03-30 21:08:38.909311:  
2025-03-30 21:08:38.909458: Epoch 481 
2025-03-30 21:08:38.909542: Current learning rate: 0.00554 
2025-03-30 21:09:05.647077: train_loss -0.7607 
2025-03-30 21:09:05.647259: val_loss -0.7468 
2025-03-30 21:09:05.647345: Pseudo dice [np.float32(0.9023), np.float32(0.8988)] 
2025-03-30 21:09:05.647408: Epoch time: 26.74 s 
2025-03-30 21:09:06.422025:  
2025-03-30 21:09:06.422177: Epoch 482 
2025-03-30 21:09:06.422270: Current learning rate: 0.00553 
2025-03-30 21:09:33.169406: train_loss -0.7698 
2025-03-30 21:09:33.169546: val_loss -0.773 
2025-03-30 21:09:33.169600: Pseudo dice [np.float32(0.9148), np.float32(0.8997)] 
2025-03-30 21:09:33.169662: Epoch time: 26.75 s 
2025-03-30 21:09:33.942383:  
2025-03-30 21:09:33.942549: Epoch 483 
2025-03-30 21:09:33.942636: Current learning rate: 0.00552 
2025-03-30 21:10:00.684607: train_loss -0.7591 
2025-03-30 21:10:00.684746: val_loss -0.7192 
2025-03-30 21:10:00.684818: Pseudo dice [np.float32(0.9011), np.float32(0.8857)] 
2025-03-30 21:10:00.684887: Epoch time: 26.74 s 
2025-03-30 21:10:01.458491:  
2025-03-30 21:10:01.458675: Epoch 484 
2025-03-30 21:10:01.458756: Current learning rate: 0.00551 
2025-03-30 21:10:28.206497: train_loss -0.7697 
2025-03-30 21:10:28.206647: val_loss -0.7647 
2025-03-30 21:10:28.206734: Pseudo dice [np.float32(0.9108), np.float32(0.9043)] 
2025-03-30 21:10:28.206809: Epoch time: 26.75 s 
2025-03-30 21:10:28.206858: Yayy! New best EMA pseudo Dice: 0.8953999876976013 
2025-03-30 21:10:29.500793:  
2025-03-30 21:10:29.500950: Epoch 485 
2025-03-30 21:10:29.501025: Current learning rate: 0.0055 
2025-03-30 21:10:56.203725: train_loss -0.7578 
2025-03-30 21:10:56.203876: val_loss -0.7518 
2025-03-30 21:10:56.203931: Pseudo dice [np.float32(0.9026), np.float32(0.8992)] 
2025-03-30 21:10:56.203992: Epoch time: 26.7 s 
2025-03-30 21:10:56.204040: Yayy! New best EMA pseudo Dice: 0.8960000276565552 
2025-03-30 21:10:59.061984:  
2025-03-30 21:10:59.062176: Epoch 486 
2025-03-30 21:10:59.062262: Current learning rate: 0.00549 
2025-03-30 21:11:25.929888: train_loss -0.7201 
2025-03-30 21:11:25.930079: val_loss -0.742 
2025-03-30 21:11:25.930137: Pseudo dice [np.float32(0.9047), np.float32(0.8993)] 
2025-03-30 21:11:25.930199: Epoch time: 26.87 s 
2025-03-30 21:11:25.930247: Yayy! New best EMA pseudo Dice: 0.8966000080108643 
2025-03-30 21:11:27.324592:  
2025-03-30 21:11:27.324745: Epoch 487 
2025-03-30 21:11:27.324844: Current learning rate: 0.00548 
2025-03-30 21:11:53.987404: train_loss -0.7235 
2025-03-30 21:11:53.987566: val_loss -0.7431 
2025-03-30 21:11:53.987631: Pseudo dice [np.float32(0.9048), np.float32(0.8954)] 
2025-03-30 21:11:53.987700: Epoch time: 26.66 s 
2025-03-30 21:11:53.987801: Yayy! New best EMA pseudo Dice: 0.8968999981880188 
2025-03-30 21:11:55.312001:  
2025-03-30 21:11:55.312158: Epoch 488 
2025-03-30 21:11:55.312245: Current learning rate: 0.00547 
2025-03-30 21:12:21.998517: train_loss -0.7423 
2025-03-30 21:12:21.998675: val_loss -0.7246 
2025-03-30 21:12:21.998730: Pseudo dice [np.float32(0.896), np.float32(0.8901)] 
2025-03-30 21:12:21.998800: Epoch time: 26.69 s 
2025-03-30 21:12:22.770716:  
2025-03-30 21:12:22.770888: Epoch 489 
2025-03-30 21:12:22.770969: Current learning rate: 0.00546 
2025-03-30 21:12:49.457175: train_loss -0.7575 
2025-03-30 21:12:49.457330: val_loss -0.7267 
2025-03-30 21:12:49.457386: Pseudo dice [np.float32(0.899), np.float32(0.8827)] 
2025-03-30 21:12:49.457448: Epoch time: 26.69 s 
2025-03-30 21:12:50.231831:  
2025-03-30 21:12:50.231983: Epoch 490 
2025-03-30 21:12:50.232054: Current learning rate: 0.00546 
2025-03-30 21:13:16.935745: train_loss -0.7549 
2025-03-30 21:13:16.935898: val_loss -0.7393 
2025-03-30 21:13:16.935954: Pseudo dice [np.float32(0.9048), np.float32(0.8859)] 
2025-03-30 21:13:16.936027: Epoch time: 26.71 s 
2025-03-30 21:13:18.286735:  
2025-03-30 21:13:18.286911: Epoch 491 
2025-03-30 21:13:18.286994: Current learning rate: 0.00545 
2025-03-30 21:13:45.005730: train_loss -0.7621 
2025-03-30 21:13:45.005870: val_loss -0.7319 
2025-03-30 21:13:45.005926: Pseudo dice [np.float32(0.9038), np.float32(0.9001)] 
2025-03-30 21:13:45.005989: Epoch time: 26.72 s 
2025-03-30 21:13:45.780620:  
2025-03-30 21:13:45.780795: Epoch 492 
2025-03-30 21:13:45.780868: Current learning rate: 0.00544 
2025-03-30 21:14:12.445022: train_loss -0.7543 
2025-03-30 21:14:12.445143: val_loss -0.7289 
2025-03-30 21:14:12.445198: Pseudo dice [np.float32(0.905), np.float32(0.8833)] 
2025-03-30 21:14:12.445270: Epoch time: 26.67 s 
2025-03-30 21:14:13.216366:  
2025-03-30 21:14:13.216539: Epoch 493 
2025-03-30 21:14:13.216618: Current learning rate: 0.00543 
2025-03-30 21:14:39.846846: train_loss -0.7672 
2025-03-30 21:14:39.846974: val_loss -0.7318 
2025-03-30 21:14:39.847029: Pseudo dice [np.float32(0.8974), np.float32(0.8856)] 
2025-03-30 21:14:39.847091: Epoch time: 26.63 s 
2025-03-30 21:14:40.619976:  
2025-03-30 21:14:40.620166: Epoch 494 
2025-03-30 21:14:40.620253: Current learning rate: 0.00542 
2025-03-30 21:15:07.360311: train_loss -0.7747 
2025-03-30 21:15:07.360462: val_loss -0.7321 
2025-03-30 21:15:07.360546: Pseudo dice [np.float32(0.902), np.float32(0.8847)] 
2025-03-30 21:15:07.360615: Epoch time: 26.74 s 
2025-03-30 21:15:08.129424:  
2025-03-30 21:15:08.129587: Epoch 495 
2025-03-30 21:15:08.129670: Current learning rate: 0.00541 
2025-03-30 21:15:34.782923: train_loss -0.7695 
2025-03-30 21:15:34.783053: val_loss -0.7679 
2025-03-30 21:15:34.783109: Pseudo dice [np.float32(0.9145), np.float32(0.9026)] 
2025-03-30 21:15:34.783168: Epoch time: 26.65 s 
2025-03-30 21:15:35.550591:  
2025-03-30 21:15:35.550772: Epoch 496 
2025-03-30 21:15:35.550854: Current learning rate: 0.0054 
2025-03-30 21:16:02.240970: train_loss -0.7633 
2025-03-30 21:16:02.241112: val_loss -0.7531 
2025-03-30 21:16:02.241168: Pseudo dice [np.float32(0.9118), np.float32(0.9067)] 
2025-03-30 21:16:02.241230: Epoch time: 26.69 s 
2025-03-30 21:16:02.241278: Yayy! New best EMA pseudo Dice: 0.8981000185012817 
2025-03-30 21:16:03.555289:  
2025-03-30 21:16:03.555458: Epoch 497 
2025-03-30 21:16:03.555531: Current learning rate: 0.00539 
2025-03-30 21:16:30.206203: train_loss -0.768 
2025-03-30 21:16:30.206345: val_loss -0.7377 
2025-03-30 21:16:30.206400: Pseudo dice [np.float32(0.8953), np.float32(0.8928)] 
2025-03-30 21:16:30.206461: Epoch time: 26.65 s 
2025-03-30 21:16:30.983740:  
2025-03-30 21:16:30.983898: Epoch 498 
2025-03-30 21:16:30.983979: Current learning rate: 0.00538 
2025-03-30 21:16:57.725574: train_loss -0.7636 
2025-03-30 21:16:57.725737: val_loss -0.7509 
2025-03-30 21:16:57.725802: Pseudo dice [np.float32(0.9044), np.float32(0.9012)] 
2025-03-30 21:16:57.725865: Epoch time: 26.74 s 
2025-03-30 21:16:57.725913: Yayy! New best EMA pseudo Dice: 0.8981999754905701 
2025-03-30 21:16:59.044502:  
2025-03-30 21:16:59.044648: Epoch 499 
2025-03-30 21:16:59.044738: Current learning rate: 0.00537 
2025-03-30 21:17:25.705683: train_loss -0.7568 
2025-03-30 21:17:25.705832: val_loss -0.7067 
2025-03-30 21:17:25.705936: Pseudo dice [np.float32(0.8971), np.float32(0.8847)] 
2025-03-30 21:17:25.705998: Epoch time: 26.66 s 
2025-03-30 21:17:27.001334:  
2025-03-30 21:17:27.001481: Epoch 500 
2025-03-30 21:17:27.001565: Current learning rate: 0.00536 
2025-03-30 21:17:53.868165: train_loss -0.778 
2025-03-30 21:17:53.868326: val_loss -0.7604 
2025-03-30 21:17:53.868385: Pseudo dice [np.float32(0.9115), np.float32(0.902)] 
2025-03-30 21:17:53.868447: Epoch time: 26.87 s 
2025-03-30 21:17:53.868495: Yayy! New best EMA pseudo Dice: 0.8984000086784363 
2025-03-30 21:17:55.183216:  
2025-03-30 21:17:55.183455: Epoch 501 
2025-03-30 21:17:55.183543: Current learning rate: 0.00535 
2025-03-30 21:18:21.911038: train_loss -0.7675 
2025-03-30 21:18:21.911185: val_loss -0.7237 
2025-03-30 21:18:21.911240: Pseudo dice [np.float32(0.9001), np.float32(0.8875)] 
2025-03-30 21:18:21.911312: Epoch time: 26.73 s 
2025-03-30 21:18:22.843943:  
2025-03-30 21:18:22.844105: Epoch 502 
2025-03-30 21:18:22.844187: Current learning rate: 0.00534 
2025-03-30 21:18:49.546633: train_loss -0.7454 
2025-03-30 21:18:49.546814: val_loss -0.7548 
2025-03-30 21:18:49.546872: Pseudo dice [np.float32(0.9133), np.float32(0.8923)] 
2025-03-30 21:18:49.546936: Epoch time: 26.7 s 
2025-03-30 21:18:49.546985: Yayy! New best EMA pseudo Dice: 0.8984000086784363 
2025-03-30 21:18:50.968731:  
2025-03-30 21:18:50.968931: Epoch 503 
2025-03-30 21:18:50.969003: Current learning rate: 0.00533 
2025-03-30 21:19:17.721896: train_loss -0.7584 
2025-03-30 21:19:17.722084: val_loss -0.6941 
2025-03-30 21:19:17.722140: Pseudo dice [np.float32(0.884), np.float32(0.8787)] 
2025-03-30 21:19:17.722208: Epoch time: 26.75 s 
2025-03-30 21:19:18.503222:  
2025-03-30 21:19:18.503399: Epoch 504 
2025-03-30 21:19:18.503481: Current learning rate: 0.00532 
2025-03-30 21:19:45.188969: train_loss -0.7427 
2025-03-30 21:19:45.189118: val_loss -0.7149 
2025-03-30 21:19:45.189176: Pseudo dice [np.float32(0.9002), np.float32(0.8862)] 
2025-03-30 21:19:45.189240: Epoch time: 26.69 s 
2025-03-30 21:19:45.963610:  
2025-03-30 21:19:45.963780: Epoch 505 
2025-03-30 21:19:45.963868: Current learning rate: 0.00531 
2025-03-30 21:20:12.766371: train_loss -0.7559 
2025-03-30 21:20:12.766499: val_loss -0.7571 
2025-03-30 21:20:12.766554: Pseudo dice [np.float32(0.9083), np.float32(0.9046)] 
2025-03-30 21:20:12.766614: Epoch time: 26.8 s 
2025-03-30 21:20:13.541794:  
2025-03-30 21:20:13.541955: Epoch 506 
2025-03-30 21:20:13.542033: Current learning rate: 0.0053 
2025-03-30 21:20:40.309348: train_loss -0.7635 
2025-03-30 21:20:40.309509: val_loss -0.737 
2025-03-30 21:20:40.309566: Pseudo dice [np.float32(0.9015), np.float32(0.8921)] 
2025-03-30 21:20:40.309629: Epoch time: 26.77 s 
2025-03-30 21:20:41.090311:  
2025-03-30 21:20:41.090480: Epoch 507 
2025-03-30 21:20:41.090554: Current learning rate: 0.00529 
2025-03-30 21:21:07.794718: train_loss -0.7375 
2025-03-30 21:21:07.794881: val_loss -0.667 
2025-03-30 21:21:07.794938: Pseudo dice [np.float32(0.8653), np.float32(0.8663)] 
2025-03-30 21:21:07.795001: Epoch time: 26.71 s 
2025-03-30 21:21:08.557360:  
2025-03-30 21:21:08.557506: Epoch 508 
2025-03-30 21:21:08.557598: Current learning rate: 0.00528 
2025-03-30 21:21:35.247041: train_loss -0.7511 
2025-03-30 21:21:35.247225: val_loss -0.7117 
2025-03-30 21:21:35.247281: Pseudo dice [np.float32(0.876), np.float32(0.8883)] 
2025-03-30 21:21:35.247344: Epoch time: 26.69 s 
2025-03-30 21:21:36.018355:  
2025-03-30 21:21:36.018507: Epoch 509 
2025-03-30 21:21:36.018584: Current learning rate: 0.00527 
2025-03-30 21:22:02.723732: train_loss -0.7408 
2025-03-30 21:22:02.723884: val_loss -0.727 
2025-03-30 21:22:02.723940: Pseudo dice [np.float32(0.9032), np.float32(0.8867)] 
2025-03-30 21:22:02.724002: Epoch time: 26.71 s 
2025-03-30 21:22:03.489836:  
2025-03-30 21:22:03.490031: Epoch 510 
2025-03-30 21:22:03.490125: Current learning rate: 0.00526 
2025-03-30 21:22:30.208248: train_loss -0.7533 
2025-03-30 21:22:30.208378: val_loss -0.7312 
2025-03-30 21:22:30.208433: Pseudo dice [np.float32(0.8948), np.float32(0.8903)] 
2025-03-30 21:22:30.208493: Epoch time: 26.72 s 
2025-03-30 21:22:31.568375:  
2025-03-30 21:22:31.568531: Epoch 511 
2025-03-30 21:22:31.568630: Current learning rate: 0.00525 
2025-03-30 21:22:58.288287: train_loss -0.7593 
2025-03-30 21:22:58.288470: val_loss -0.7206 
2025-03-30 21:22:58.288527: Pseudo dice [np.float32(0.8917), np.float32(0.884)] 
2025-03-30 21:22:58.288589: Epoch time: 26.72 s 
2025-03-30 21:22:59.241333:  
2025-03-30 21:22:59.241537: Epoch 512 
2025-03-30 21:22:59.241610: Current learning rate: 0.00524 
2025-03-30 21:23:25.966475: train_loss -0.7454 
2025-03-30 21:23:25.966600: val_loss -0.7686 
2025-03-30 21:23:25.966655: Pseudo dice [np.float32(0.9161), np.float32(0.9096)] 
2025-03-30 21:23:25.966717: Epoch time: 26.73 s 
2025-03-30 21:23:26.731992:  
2025-03-30 21:23:26.732147: Epoch 513 
2025-03-30 21:23:26.732224: Current learning rate: 0.00523 
2025-03-30 21:23:53.441521: train_loss -0.778 
2025-03-30 21:23:53.441678: val_loss -0.7399 
2025-03-30 21:23:53.441748: Pseudo dice [np.float32(0.901), np.float32(0.9004)] 
2025-03-30 21:23:53.441819: Epoch time: 26.71 s 
2025-03-30 21:23:54.208235:  
2025-03-30 21:23:54.208402: Epoch 514 
2025-03-30 21:23:54.208513: Current learning rate: 0.00522 
2025-03-30 21:24:20.886261: train_loss -0.7797 
2025-03-30 21:24:20.886394: val_loss -0.7575 
2025-03-30 21:24:20.886450: Pseudo dice [np.float32(0.9071), np.float32(0.8945)] 
2025-03-30 21:24:20.886534: Epoch time: 26.68 s 
2025-03-30 21:24:21.662238:  
2025-03-30 21:24:21.662393: Epoch 515 
2025-03-30 21:24:21.662463: Current learning rate: 0.00521 
2025-03-30 21:24:48.334542: train_loss -0.7728 
2025-03-30 21:24:48.334681: val_loss -0.7303 
2025-03-30 21:24:48.334737: Pseudo dice [np.float32(0.9031), np.float32(0.8926)] 
2025-03-30 21:24:48.334812: Epoch time: 26.67 s 
2025-03-30 21:24:49.106266:  
2025-03-30 21:24:49.106436: Epoch 516 
2025-03-30 21:24:49.106519: Current learning rate: 0.0052 
2025-03-30 21:25:15.791520: train_loss -0.7521 
2025-03-30 21:25:15.791647: val_loss -0.7649 
2025-03-30 21:25:15.791701: Pseudo dice [np.float32(0.9158), np.float32(0.9078)] 
2025-03-30 21:25:15.791770: Epoch time: 26.69 s 
2025-03-30 21:25:16.574248:  
2025-03-30 21:25:16.574419: Epoch 517 
2025-03-30 21:25:16.574497: Current learning rate: 0.00519 
2025-03-30 21:25:43.269899: train_loss -0.7668 
2025-03-30 21:25:43.270031: val_loss -0.7369 
2025-03-30 21:25:43.270087: Pseudo dice [np.float32(0.9042), np.float32(0.8864)] 
2025-03-30 21:25:43.270149: Epoch time: 26.7 s 
2025-03-30 21:25:44.045279:  
2025-03-30 21:25:44.045437: Epoch 518 
2025-03-30 21:25:44.045516: Current learning rate: 0.00518 
2025-03-30 21:26:10.753856: train_loss -0.7768 
2025-03-30 21:26:10.753994: val_loss -0.7517 
2025-03-30 21:26:10.754050: Pseudo dice [np.float32(0.9097), np.float32(0.8929)] 
2025-03-30 21:26:10.754111: Epoch time: 26.71 s 
2025-03-30 21:26:11.527919:  
2025-03-30 21:26:11.528083: Epoch 519 
2025-03-30 21:26:11.528167: Current learning rate: 0.00518 
2025-03-30 21:26:38.255958: train_loss -0.7768 
2025-03-30 21:26:38.256136: val_loss -0.7454 
2025-03-30 21:26:38.256194: Pseudo dice [np.float32(0.9169), np.float32(0.8861)] 
2025-03-30 21:26:38.256257: Epoch time: 26.73 s 
2025-03-30 21:26:39.028868:  
2025-03-30 21:26:39.029014: Epoch 520 
2025-03-30 21:26:39.029105: Current learning rate: 0.00517 
2025-03-30 21:27:05.719888: train_loss -0.7761 
2025-03-30 21:27:05.720061: val_loss -0.7734 
2025-03-30 21:27:05.720135: Pseudo dice [np.float32(0.9173), np.float32(0.9069)] 
2025-03-30 21:27:05.720222: Epoch time: 26.69 s 
2025-03-30 21:27:05.720285: Yayy! New best EMA pseudo Dice: 0.8995000123977661 
2025-03-30 21:27:07.101258:  
2025-03-30 21:27:07.101398: Epoch 521 
2025-03-30 21:27:07.101486: Current learning rate: 0.00516 
2025-03-30 21:27:33.781978: train_loss -0.7442 
2025-03-30 21:27:33.782117: val_loss -0.7476 
2025-03-30 21:27:33.782173: Pseudo dice [np.float32(0.9041), np.float32(0.8928)] 
2025-03-30 21:27:33.782233: Epoch time: 26.68 s 
2025-03-30 21:27:34.554525:  
2025-03-30 21:27:34.554691: Epoch 522 
2025-03-30 21:27:34.554777: Current learning rate: 0.00515 
2025-03-30 21:28:01.275532: train_loss -0.7599 
2025-03-30 21:28:01.275728: val_loss -0.737 
2025-03-30 21:28:01.275813: Pseudo dice [np.float32(0.9056), np.float32(0.8893)] 
2025-03-30 21:28:01.275899: Epoch time: 26.72 s 
2025-03-30 21:28:02.050897:  
2025-03-30 21:28:02.051052: Epoch 523 
2025-03-30 21:28:02.051152: Current learning rate: 0.00514 
2025-03-30 21:28:28.814801: train_loss -0.7395 
2025-03-30 21:28:28.814927: val_loss -0.7199 
2025-03-30 21:28:28.814982: Pseudo dice [np.float32(0.8886), np.float32(0.8882)] 
2025-03-30 21:28:28.815044: Epoch time: 26.76 s 
2025-03-30 21:28:29.583203:  
2025-03-30 21:28:29.583359: Epoch 524 
2025-03-30 21:28:29.583432: Current learning rate: 0.00513 
2025-03-30 21:28:56.237960: train_loss -0.7521 
2025-03-30 21:28:56.238097: val_loss -0.7083 
2025-03-30 21:28:56.238174: Pseudo dice [np.float32(0.8757), np.float32(0.8798)] 
2025-03-30 21:28:56.238254: Epoch time: 26.66 s 
2025-03-30 21:28:57.006404:  
2025-03-30 21:28:57.006538: Epoch 525 
2025-03-30 21:28:57.006625: Current learning rate: 0.00512 
2025-03-30 21:29:23.729249: train_loss -0.7642 
2025-03-30 21:29:23.729482: val_loss -0.7769 
2025-03-30 21:29:23.729565: Pseudo dice [np.float32(0.9223), np.float32(0.9075)] 
2025-03-30 21:29:23.729640: Epoch time: 26.72 s 
2025-03-30 21:29:24.496587:  
2025-03-30 21:29:24.496750: Epoch 526 
2025-03-30 21:29:24.496836: Current learning rate: 0.00511 
2025-03-30 21:29:51.232563: train_loss -0.7578 
2025-03-30 21:29:51.232799: val_loss -0.7696 
2025-03-30 21:29:51.232859: Pseudo dice [np.float32(0.9137), np.float32(0.9064)] 
2025-03-30 21:29:51.232919: Epoch time: 26.74 s 
2025-03-30 21:29:52.003497:  
2025-03-30 21:29:52.003669: Epoch 527 
2025-03-30 21:29:52.003752: Current learning rate: 0.0051 
2025-03-30 21:30:18.707662: train_loss -0.7648 
2025-03-30 21:30:18.707901: val_loss -0.7162 
2025-03-30 21:30:18.707961: Pseudo dice [np.float32(0.8931), np.float32(0.8899)] 
2025-03-30 21:30:18.708022: Epoch time: 26.71 s 
2025-03-30 21:30:19.474845:  
2025-03-30 21:30:19.474990: Epoch 528 
2025-03-30 21:30:19.475064: Current learning rate: 0.00509 
2025-03-30 21:30:46.201168: train_loss -0.7814 
2025-03-30 21:30:46.201295: val_loss -0.7351 
2025-03-30 21:30:46.201350: Pseudo dice [np.float32(0.904), np.float32(0.8941)] 
2025-03-30 21:30:46.201412: Epoch time: 26.73 s 
2025-03-30 21:30:46.983608:  
2025-03-30 21:30:46.983751: Epoch 529 
2025-03-30 21:30:46.983868: Current learning rate: 0.00508 
2025-03-30 21:31:13.722201: train_loss -0.7659 
2025-03-30 21:31:13.722321: val_loss -0.7453 
2025-03-30 21:31:13.722376: Pseudo dice [np.float32(0.9035), np.float32(0.8924)] 
2025-03-30 21:31:13.722437: Epoch time: 26.74 s 
2025-03-30 21:31:14.501567:  
2025-03-30 21:31:14.501704: Epoch 530 
2025-03-30 21:31:14.501818: Current learning rate: 0.00507 
2025-03-30 21:31:41.210691: train_loss -0.7712 
2025-03-30 21:31:41.210830: val_loss -0.7644 
2025-03-30 21:31:41.210887: Pseudo dice [np.float32(0.9115), np.float32(0.9034)] 
2025-03-30 21:31:41.210950: Epoch time: 26.71 s 
2025-03-30 21:31:42.566538:  
2025-03-30 21:31:42.566704: Epoch 531 
2025-03-30 21:31:42.566803: Current learning rate: 0.00506 
2025-03-30 21:32:09.259094: train_loss -0.772 
2025-03-30 21:32:09.259222: val_loss -0.7638 
2025-03-30 21:32:09.259277: Pseudo dice [np.float32(0.9099), np.float32(0.9006)] 
2025-03-30 21:32:09.259337: Epoch time: 26.69 s 
2025-03-30 21:32:09.259386: Yayy! New best EMA pseudo Dice: 0.8999000191688538 
2025-03-30 21:32:10.547676:  
2025-03-30 21:32:10.547855: Epoch 532 
2025-03-30 21:32:10.547956: Current learning rate: 0.00505 
2025-03-30 21:32:37.243385: train_loss -0.7681 
2025-03-30 21:32:37.243513: val_loss -0.7634 
2025-03-30 21:32:37.243566: Pseudo dice [np.float32(0.915), np.float32(0.897)] 
2025-03-30 21:32:37.243628: Epoch time: 26.7 s 
2025-03-30 21:32:37.243675: Yayy! New best EMA pseudo Dice: 0.9004999995231628 
2025-03-30 21:32:38.575489:  
2025-03-30 21:32:38.575660: Epoch 533 
2025-03-30 21:32:38.575739: Current learning rate: 0.00504 
2025-03-30 21:33:05.236779: train_loss -0.7604 
2025-03-30 21:33:05.236926: val_loss -0.7378 
2025-03-30 21:33:05.236982: Pseudo dice [np.float32(0.9099), np.float32(0.8893)] 
2025-03-30 21:33:05.237042: Epoch time: 26.66 s 
2025-03-30 21:33:06.010489:  
2025-03-30 21:33:06.010651: Epoch 534 
2025-03-30 21:33:06.010726: Current learning rate: 0.00503 
2025-03-30 21:33:32.713269: train_loss -0.7688 
2025-03-30 21:33:32.713401: val_loss -0.7658 
2025-03-30 21:33:32.713456: Pseudo dice [np.float32(0.9131), np.float32(0.9038)] 
2025-03-30 21:33:32.713516: Epoch time: 26.7 s 
2025-03-30 21:33:32.713564: Yayy! New best EMA pseudo Dice: 0.901199996471405 
2025-03-30 21:33:34.033584:  
2025-03-30 21:33:34.033736: Epoch 535 
2025-03-30 21:33:34.033834: Current learning rate: 0.00502 
2025-03-30 21:34:00.700724: train_loss -0.7849 
2025-03-30 21:34:00.700872: val_loss -0.7621 
2025-03-30 21:34:00.700930: Pseudo dice [np.float32(0.9071), np.float32(0.8978)] 
2025-03-30 21:34:00.700990: Epoch time: 26.67 s 
2025-03-30 21:34:00.701038: Yayy! New best EMA pseudo Dice: 0.9014000296592712 
2025-03-30 21:34:02.021367:  
2025-03-30 21:34:02.021541: Epoch 536 
2025-03-30 21:34:02.021615: Current learning rate: 0.00501 
2025-03-30 21:34:28.709768: train_loss -0.7743 
2025-03-30 21:34:28.709896: val_loss -0.7581 
2025-03-30 21:34:28.709990: Pseudo dice [np.float32(0.9103), np.float32(0.9082)] 
2025-03-30 21:34:28.710053: Epoch time: 26.69 s 
2025-03-30 21:34:28.710101: Yayy! New best EMA pseudo Dice: 0.9021000266075134 
2025-03-30 21:34:30.037893:  
2025-03-30 21:34:30.038057: Epoch 537 
2025-03-30 21:34:30.038126: Current learning rate: 0.005 
2025-03-30 21:34:56.695062: train_loss -0.7803 
2025-03-30 21:34:56.695186: val_loss -0.7329 
2025-03-30 21:34:56.695241: Pseudo dice [np.float32(0.9038), np.float32(0.9037)] 
2025-03-30 21:34:56.695299: Epoch time: 26.66 s 
2025-03-30 21:34:56.695346: Yayy! New best EMA pseudo Dice: 0.9023000001907349 
2025-03-30 21:34:58.014087:  
2025-03-30 21:34:58.014256: Epoch 538 
2025-03-30 21:34:58.014328: Current learning rate: 0.00499 
2025-03-30 21:35:24.657655: train_loss -0.7678 
2025-03-30 21:35:24.657788: val_loss -0.7436 
2025-03-30 21:35:24.657847: Pseudo dice [np.float32(0.8973), np.float32(0.8918)] 
2025-03-30 21:35:24.657985: Epoch time: 26.64 s 
2025-03-30 21:35:25.428601:  
2025-03-30 21:35:25.428753: Epoch 539 
2025-03-30 21:35:25.428846: Current learning rate: 0.00498 
2025-03-30 21:35:52.158801: train_loss -0.774 
2025-03-30 21:35:52.158959: val_loss -0.7609 
2025-03-30 21:35:52.159015: Pseudo dice [np.float32(0.9106), np.float32(0.9003)] 
2025-03-30 21:35:52.159075: Epoch time: 26.73 s 
2025-03-30 21:35:52.938139:  
2025-03-30 21:35:52.938298: Epoch 540 
2025-03-30 21:35:52.938388: Current learning rate: 0.00497 
2025-03-30 21:36:19.677191: train_loss -0.7674 
2025-03-30 21:36:19.677323: val_loss -0.764 
2025-03-30 21:36:19.677416: Pseudo dice [np.float32(0.903), np.float32(0.9098)] 
2025-03-30 21:36:19.677480: Epoch time: 26.74 s 
2025-03-30 21:36:19.677528: Yayy! New best EMA pseudo Dice: 0.902400016784668 
2025-03-30 21:36:21.000058:  
2025-03-30 21:36:21.000238: Epoch 541 
2025-03-30 21:36:21.000318: Current learning rate: 0.00496 
2025-03-30 21:36:47.653219: train_loss -0.7927 
2025-03-30 21:36:47.653403: val_loss -0.7274 
2025-03-30 21:36:47.653483: Pseudo dice [np.float32(0.8991), np.float32(0.8801)] 
2025-03-30 21:36:47.653548: Epoch time: 26.65 s 
2025-03-30 21:36:48.429833:  
2025-03-30 21:36:48.429984: Epoch 542 
2025-03-30 21:36:48.430091: Current learning rate: 0.00495 
2025-03-30 21:37:15.277642: train_loss -0.7712 
2025-03-30 21:37:15.277789: val_loss -0.7718 
2025-03-30 21:37:15.277882: Pseudo dice [np.float32(0.9137), np.float32(0.9092)] 
2025-03-30 21:37:15.277946: Epoch time: 26.85 s 
2025-03-30 21:37:16.056399:  
2025-03-30 21:37:16.056556: Epoch 543 
2025-03-30 21:37:16.056639: Current learning rate: 0.00494 
2025-03-30 21:37:42.874329: train_loss -0.7872 
2025-03-30 21:37:42.874521: val_loss -0.7582 
2025-03-30 21:37:42.874606: Pseudo dice [np.float32(0.9061), np.float32(0.9025)] 
2025-03-30 21:37:42.874731: Epoch time: 26.82 s 
2025-03-30 21:37:43.742388:  
2025-03-30 21:37:43.742557: Epoch 544 
2025-03-30 21:37:43.742635: Current learning rate: 0.00493 
2025-03-30 21:38:10.587260: train_loss -0.7742 
2025-03-30 21:38:10.587406: val_loss -0.7674 
2025-03-30 21:38:10.587481: Pseudo dice [np.float32(0.9111), np.float32(0.9098)] 
2025-03-30 21:38:10.587546: Epoch time: 26.85 s 
2025-03-30 21:38:10.587594: Yayy! New best EMA pseudo Dice: 0.9031999707221985 
2025-03-30 21:38:11.921364:  
2025-03-30 21:38:11.921532: Epoch 545 
2025-03-30 21:38:11.921616: Current learning rate: 0.00492 
2025-03-30 21:38:38.738824: train_loss -0.7717 
2025-03-30 21:38:38.739038: val_loss -0.7575 
2025-03-30 21:38:38.739095: Pseudo dice [np.float32(0.9112), np.float32(0.897)] 
2025-03-30 21:38:38.739168: Epoch time: 26.82 s 
2025-03-30 21:38:38.739215: Yayy! New best EMA pseudo Dice: 0.9031999707221985 
2025-03-30 21:38:40.064333:  
2025-03-30 21:38:40.064477: Epoch 546 
2025-03-30 21:38:40.064568: Current learning rate: 0.00491 
2025-03-30 21:39:06.889048: train_loss -0.7765 
2025-03-30 21:39:06.889190: val_loss -0.7423 
2025-03-30 21:39:06.889246: Pseudo dice [np.float32(0.9037), np.float32(0.8978)] 
2025-03-30 21:39:06.889308: Epoch time: 26.83 s 
2025-03-30 21:39:07.843271:  
2025-03-30 21:39:07.843415: Epoch 547 
2025-03-30 21:39:07.843493: Current learning rate: 0.0049 
2025-03-30 21:39:34.582188: train_loss -0.7878 
2025-03-30 21:39:34.582394: val_loss -0.7564 
2025-03-30 21:39:34.582452: Pseudo dice [np.float32(0.9093), np.float32(0.9097)] 
2025-03-30 21:39:34.582520: Epoch time: 26.74 s 
2025-03-30 21:39:34.582569: Yayy! New best EMA pseudo Dice: 0.9036999940872192 
2025-03-30 21:39:35.960723:  
2025-03-30 21:39:35.960880: Epoch 548 
2025-03-30 21:39:35.960948: Current learning rate: 0.00489 
2025-03-30 21:40:02.639428: train_loss -0.7835 
2025-03-30 21:40:02.639571: val_loss -0.7427 
2025-03-30 21:40:02.639627: Pseudo dice [np.float32(0.894), np.float32(0.8942)] 
2025-03-30 21:40:02.639689: Epoch time: 26.68 s 
2025-03-30 21:40:03.408751:  
2025-03-30 21:40:03.408901: Epoch 549 
2025-03-30 21:40:03.408979: Current learning rate: 0.00488 
2025-03-30 21:40:30.121683: train_loss -0.783 
2025-03-30 21:40:30.121929: val_loss -0.7587 
2025-03-30 21:40:30.121988: Pseudo dice [np.float32(0.9084), np.float32(0.9066)] 
2025-03-30 21:40:30.122049: Epoch time: 26.71 s 
2025-03-30 21:40:31.971473:  
2025-03-30 21:40:31.971632: Epoch 550 
2025-03-30 21:40:31.971713: Current learning rate: 0.00487 
2025-03-30 21:40:58.667694: train_loss -0.782 
2025-03-30 21:40:58.667832: val_loss -0.7268 
2025-03-30 21:40:58.667888: Pseudo dice [np.float32(0.8939), np.float32(0.8884)] 
2025-03-30 21:40:58.667952: Epoch time: 26.7 s 
2025-03-30 21:40:59.432895:  
2025-03-30 21:40:59.433075: Epoch 551 
2025-03-30 21:40:59.433161: Current learning rate: 0.00486 
2025-03-30 21:41:26.159217: train_loss -0.7637 
2025-03-30 21:41:26.159342: val_loss -0.7489 
2025-03-30 21:41:26.159398: Pseudo dice [np.float32(0.9032), np.float32(0.8951)] 
2025-03-30 21:41:26.159460: Epoch time: 26.73 s 
2025-03-30 21:41:26.939225:  
2025-03-30 21:41:26.939417: Epoch 552 
2025-03-30 21:41:26.939497: Current learning rate: 0.00485 
2025-03-30 21:41:53.628947: train_loss -0.7702 
2025-03-30 21:41:53.629111: val_loss -0.7318 
2025-03-30 21:41:53.629169: Pseudo dice [np.float32(0.9063), np.float32(0.8917)] 
2025-03-30 21:41:53.629239: Epoch time: 26.69 s 
2025-03-30 21:41:54.396960:  
2025-03-30 21:41:54.397116: Epoch 553 
2025-03-30 21:41:54.397213: Current learning rate: 0.00484 
2025-03-30 21:42:21.073869: train_loss -0.7747 
2025-03-30 21:42:21.074003: val_loss -0.7655 
2025-03-30 21:42:21.074058: Pseudo dice [np.float32(0.9096), np.float32(0.9111)] 
2025-03-30 21:42:21.074120: Epoch time: 26.68 s 
2025-03-30 21:42:21.847169:  
2025-03-30 21:42:21.847340: Epoch 554 
2025-03-30 21:42:21.847425: Current learning rate: 0.00484 
2025-03-30 21:42:48.519009: train_loss -0.7769 
2025-03-30 21:42:48.519204: val_loss -0.7571 
2025-03-30 21:42:48.519262: Pseudo dice [np.float32(0.9133), np.float32(0.9002)] 
2025-03-30 21:42:48.519322: Epoch time: 26.67 s 
2025-03-30 21:42:49.298478:  
2025-03-30 21:42:49.298667: Epoch 555 
2025-03-30 21:42:49.298749: Current learning rate: 0.00483 
2025-03-30 21:43:15.942955: train_loss -0.7805 
2025-03-30 21:43:15.943163: val_loss -0.7494 
2025-03-30 21:43:15.943219: Pseudo dice [np.float32(0.8988), np.float32(0.8979)] 
2025-03-30 21:43:15.943281: Epoch time: 26.65 s 
2025-03-30 21:43:16.715879:  
2025-03-30 21:43:16.716051: Epoch 556 
2025-03-30 21:43:16.716129: Current learning rate: 0.00482 
2025-03-30 21:43:43.403915: train_loss -0.7675 
2025-03-30 21:43:43.404036: val_loss -0.696 
2025-03-30 21:43:43.404093: Pseudo dice [np.float32(0.8808), np.float32(0.8728)] 
2025-03-30 21:43:43.404191: Epoch time: 26.69 s 
2025-03-30 21:43:44.176884:  
2025-03-30 21:43:44.177038: Epoch 557 
2025-03-30 21:43:44.177116: Current learning rate: 0.00481 
2025-03-30 21:44:10.825126: train_loss -0.753 
2025-03-30 21:44:10.825266: val_loss -0.7495 
2025-03-30 21:44:10.825351: Pseudo dice [np.float32(0.9089), np.float32(0.8952)] 
2025-03-30 21:44:10.825414: Epoch time: 26.65 s 
2025-03-30 21:44:11.597821:  
2025-03-30 21:44:11.597975: Epoch 558 
2025-03-30 21:44:11.598065: Current learning rate: 0.0048 
2025-03-30 21:44:38.294343: train_loss -0.7599 
2025-03-30 21:44:38.294485: val_loss -0.7363 
2025-03-30 21:44:38.294549: Pseudo dice [np.float32(0.9041), np.float32(0.8939)] 
2025-03-30 21:44:38.294616: Epoch time: 26.7 s 
2025-03-30 21:44:39.064433:  
2025-03-30 21:44:39.064594: Epoch 559 
2025-03-30 21:44:39.064677: Current learning rate: 0.00479 
2025-03-30 21:45:05.770989: train_loss -0.7621 
2025-03-30 21:45:05.771131: val_loss -0.7356 
2025-03-30 21:45:05.771205: Pseudo dice [np.float32(0.902), np.float32(0.8901)] 
2025-03-30 21:45:05.771267: Epoch time: 26.71 s 
2025-03-30 21:45:06.549211:  
2025-03-30 21:45:06.549371: Epoch 560 
2025-03-30 21:45:06.549452: Current learning rate: 0.00478 
2025-03-30 21:45:33.248877: train_loss -0.7655 
2025-03-30 21:45:33.248997: val_loss -0.7609 
2025-03-30 21:45:33.249053: Pseudo dice [np.float32(0.9128), np.float32(0.9062)] 
2025-03-30 21:45:33.249112: Epoch time: 26.7 s 
2025-03-30 21:45:34.024166:  
2025-03-30 21:45:34.024314: Epoch 561 
2025-03-30 21:45:34.024410: Current learning rate: 0.00477 
2025-03-30 21:46:00.731147: train_loss -0.7531 
2025-03-30 21:46:00.731302: val_loss -0.7627 
2025-03-30 21:46:00.731359: Pseudo dice [np.float32(0.9143), np.float32(0.9032)] 
2025-03-30 21:46:00.731420: Epoch time: 26.71 s 
2025-03-30 21:46:01.504274:  
2025-03-30 21:46:01.504412: Epoch 562 
2025-03-30 21:46:01.504510: Current learning rate: 0.00476 
2025-03-30 21:46:28.200448: train_loss -0.7629 
2025-03-30 21:46:28.200598: val_loss -0.7645 
2025-03-30 21:46:28.200654: Pseudo dice [np.float32(0.9099), np.float32(0.9052)] 
2025-03-30 21:46:28.200715: Epoch time: 26.7 s 
2025-03-30 21:46:28.977449:  
2025-03-30 21:46:28.977612: Epoch 563 
2025-03-30 21:46:28.977685: Current learning rate: 0.00475 
2025-03-30 21:46:55.612156: train_loss -0.7598 
2025-03-30 21:46:55.612310: val_loss -0.7452 
2025-03-30 21:46:55.612366: Pseudo dice [np.float32(0.9144), np.float32(0.8905)] 
2025-03-30 21:46:55.612429: Epoch time: 26.64 s 
2025-03-30 21:46:56.379870:  
2025-03-30 21:46:56.379999: Epoch 564 
2025-03-30 21:46:56.380088: Current learning rate: 0.00474 
2025-03-30 21:47:23.041653: train_loss -0.7334 
2025-03-30 21:47:23.041790: val_loss -0.6901 
2025-03-30 21:47:23.041849: Pseudo dice [np.float32(0.876), np.float32(0.8591)] 
2025-03-30 21:47:23.041909: Epoch time: 26.66 s 
2025-03-30 21:47:23.816146:  
2025-03-30 21:47:23.816309: Epoch 565 
2025-03-30 21:47:23.816389: Current learning rate: 0.00473 
2025-03-30 21:47:50.457015: train_loss -0.7587 
2025-03-30 21:47:50.457131: val_loss -0.7632 
2025-03-30 21:47:50.457186: Pseudo dice [np.float32(0.9166), np.float32(0.9056)] 
2025-03-30 21:47:50.457245: Epoch time: 26.64 s 
2025-03-30 21:47:51.233455:  
2025-03-30 21:47:51.233620: Epoch 566 
2025-03-30 21:47:51.233699: Current learning rate: 0.00472 
2025-03-30 21:48:17.917132: train_loss -0.7849 
2025-03-30 21:48:17.917268: val_loss -0.7308 
2025-03-30 21:48:17.917324: Pseudo dice [np.float32(0.9001), np.float32(0.8875)] 
2025-03-30 21:48:17.917386: Epoch time: 26.68 s 
2025-03-30 21:48:18.690590:  
2025-03-30 21:48:18.690738: Epoch 567 
2025-03-30 21:48:18.690837: Current learning rate: 0.00471 
2025-03-30 21:48:45.327266: train_loss -0.7508 
2025-03-30 21:48:45.327391: val_loss -0.736 
2025-03-30 21:48:45.327446: Pseudo dice [np.float32(0.9045), np.float32(0.8932)] 
2025-03-30 21:48:45.327504: Epoch time: 26.64 s 
2025-03-30 21:48:46.097286:  
2025-03-30 21:48:46.097440: Epoch 568 
2025-03-30 21:48:46.097515: Current learning rate: 0.0047 
2025-03-30 21:49:12.798021: train_loss -0.7581 
2025-03-30 21:49:12.798301: val_loss -0.7507 
2025-03-30 21:49:12.798368: Pseudo dice [np.float32(0.9087), np.float32(0.8922)] 
2025-03-30 21:49:12.798428: Epoch time: 26.7 s 
2025-03-30 21:49:13.570834:  
2025-03-30 21:49:13.571011: Epoch 569 
2025-03-30 21:49:13.571097: Current learning rate: 0.00469 
2025-03-30 21:49:40.274878: train_loss -0.7585 
2025-03-30 21:49:40.275132: val_loss -0.7605 
2025-03-30 21:49:40.275190: Pseudo dice [np.float32(0.9071), np.float32(0.9153)] 
2025-03-30 21:49:40.275252: Epoch time: 26.71 s 
2025-03-30 21:49:41.617273:  
2025-03-30 21:49:41.617459: Epoch 570 
2025-03-30 21:49:41.617545: Current learning rate: 0.00468 
2025-03-30 21:50:08.452193: train_loss -0.744 
2025-03-30 21:50:08.452455: val_loss -0.7143 
2025-03-30 21:50:08.452516: Pseudo dice [np.float32(0.8883), np.float32(0.8729)] 
2025-03-30 21:50:08.452623: Epoch time: 26.84 s 
2025-03-30 21:50:09.227315:  
2025-03-30 21:50:09.227528: Epoch 571 
2025-03-30 21:50:09.227612: Current learning rate: 0.00467 
2025-03-30 21:50:36.005002: train_loss -0.7516 
2025-03-30 21:50:36.005123: val_loss -0.71 
2025-03-30 21:50:36.005177: Pseudo dice [np.float32(0.8874), np.float32(0.8875)] 
2025-03-30 21:50:36.005237: Epoch time: 26.78 s 
2025-03-30 21:50:36.775696:  
2025-03-30 21:50:36.775896: Epoch 572 
2025-03-30 21:50:36.775979: Current learning rate: 0.00466 
2025-03-30 21:51:03.541339: train_loss -0.7648 
2025-03-30 21:51:03.541475: val_loss -0.7323 
2025-03-30 21:51:03.541532: Pseudo dice [np.float32(0.8997), np.float32(0.8899)] 
2025-03-30 21:51:03.541593: Epoch time: 26.77 s 
2025-03-30 21:51:04.321537:  
2025-03-30 21:51:04.321695: Epoch 573 
2025-03-30 21:51:04.321792: Current learning rate: 0.00465 
2025-03-30 21:51:31.207171: train_loss -0.7843 
2025-03-30 21:51:31.207379: val_loss -0.7584 
2025-03-30 21:51:31.207435: Pseudo dice [np.float32(0.9093), np.float32(0.9036)] 
2025-03-30 21:51:31.207495: Epoch time: 26.89 s 
2025-03-30 21:51:31.984791:  
2025-03-30 21:51:31.984964: Epoch 574 
2025-03-30 21:51:31.985044: Current learning rate: 0.00464 
2025-03-30 21:51:58.731369: train_loss -0.7678 
2025-03-30 21:51:58.731500: val_loss -0.7373 
2025-03-30 21:51:58.731555: Pseudo dice [np.float32(0.895), np.float32(0.8992)] 
2025-03-30 21:51:58.731618: Epoch time: 26.75 s 
2025-03-30 21:51:59.510691:  
2025-03-30 21:51:59.510900: Epoch 575 
2025-03-30 21:51:59.510981: Current learning rate: 0.00463 
2025-03-30 21:52:26.243836: train_loss -0.7675 
2025-03-30 21:52:26.243973: val_loss -0.7284 
2025-03-30 21:52:26.244029: Pseudo dice [np.float32(0.9001), np.float32(0.8841)] 
2025-03-30 21:52:26.244093: Epoch time: 26.73 s 
2025-03-30 21:52:27.020989:  
2025-03-30 21:52:27.021171: Epoch 576 
2025-03-30 21:52:27.021250: Current learning rate: 0.00462 
2025-03-30 21:52:53.765550: train_loss -0.7829 
2025-03-30 21:52:53.765727: val_loss -0.7403 
2025-03-30 21:52:53.765797: Pseudo dice [np.float32(0.8987), np.float32(0.8909)] 
2025-03-30 21:52:53.765871: Epoch time: 26.75 s 
2025-03-30 21:52:54.549047:  
2025-03-30 21:52:54.549191: Epoch 577 
2025-03-30 21:52:54.549273: Current learning rate: 0.00461 
2025-03-30 21:53:21.300277: train_loss -0.7768 
2025-03-30 21:53:21.300446: val_loss -0.7382 
2025-03-30 21:53:21.300503: Pseudo dice [np.float32(0.8977), np.float32(0.8942)] 
2025-03-30 21:53:21.300565: Epoch time: 26.75 s 
2025-03-30 21:53:22.076795:  
2025-03-30 21:53:22.076965: Epoch 578 
2025-03-30 21:53:22.077049: Current learning rate: 0.0046 
2025-03-30 21:53:48.803715: train_loss -0.7855 
2025-03-30 21:53:48.803854: val_loss -0.7139 
2025-03-30 21:53:48.803909: Pseudo dice [np.float32(0.8971), np.float32(0.8812)] 
2025-03-30 21:53:48.803968: Epoch time: 26.73 s 
2025-03-30 21:53:49.581021:  
2025-03-30 21:53:49.581174: Epoch 579 
2025-03-30 21:53:49.581260: Current learning rate: 0.00459 
2025-03-30 21:54:16.397678: train_loss -0.7739 
2025-03-30 21:54:16.397829: val_loss -0.7177 
2025-03-30 21:54:16.397887: Pseudo dice [np.float32(0.8921), np.float32(0.8826)] 
2025-03-30 21:54:16.397947: Epoch time: 26.82 s 
2025-03-30 21:54:17.175143:  
2025-03-30 21:54:17.175335: Epoch 580 
2025-03-30 21:54:17.175424: Current learning rate: 0.00458 
2025-03-30 21:54:43.995921: train_loss -0.7647 
2025-03-30 21:54:43.996060: val_loss -0.7539 
2025-03-30 21:54:43.996115: Pseudo dice [np.float32(0.9061), np.float32(0.9011)] 
2025-03-30 21:54:43.996178: Epoch time: 26.82 s 
2025-03-30 21:54:44.773844:  
2025-03-30 21:54:44.774010: Epoch 581 
2025-03-30 21:54:44.774088: Current learning rate: 0.00457 
2025-03-30 21:55:11.567486: train_loss -0.7703 
2025-03-30 21:55:11.567718: val_loss -0.7409 
2025-03-30 21:55:11.567793: Pseudo dice [np.float32(0.9066), np.float32(0.8907)] 
2025-03-30 21:55:11.567861: Epoch time: 26.79 s 
2025-03-30 21:55:12.353873:  
2025-03-30 21:55:12.354031: Epoch 582 
2025-03-30 21:55:12.354148: Current learning rate: 0.00456 
2025-03-30 21:55:39.020522: train_loss -0.757 
2025-03-30 21:55:39.020660: val_loss -0.7597 
2025-03-30 21:55:39.020715: Pseudo dice [np.float32(0.9101), np.float32(0.906)] 
2025-03-30 21:55:39.020790: Epoch time: 26.67 s 
2025-03-30 21:55:39.799025:  
2025-03-30 21:55:39.799195: Epoch 583 
2025-03-30 21:55:39.799272: Current learning rate: 0.00455 
2025-03-30 21:56:06.477620: train_loss -0.774 
2025-03-30 21:56:06.477792: val_loss -0.7465 
2025-03-30 21:56:06.477851: Pseudo dice [np.float32(0.9048), np.float32(0.9072)] 
2025-03-30 21:56:06.477911: Epoch time: 26.68 s 
2025-03-30 21:56:07.259739:  
2025-03-30 21:56:07.259912: Epoch 584 
2025-03-30 21:56:07.259993: Current learning rate: 0.00454 
2025-03-30 21:56:33.986621: train_loss -0.7793 
2025-03-30 21:56:33.986944: val_loss -0.7694 
2025-03-30 21:56:33.987003: Pseudo dice [np.float32(0.9147), np.float32(0.9064)] 
2025-03-30 21:56:33.987095: Epoch time: 26.73 s 
2025-03-30 21:56:34.772297:  
2025-03-30 21:56:34.772454: Epoch 585 
2025-03-30 21:56:34.772533: Current learning rate: 0.00453 
2025-03-30 21:57:01.459118: train_loss -0.7757 
2025-03-30 21:57:01.459381: val_loss -0.78 
2025-03-30 21:57:01.459440: Pseudo dice [np.float32(0.9197), np.float32(0.9066)] 
2025-03-30 21:57:01.459501: Epoch time: 26.69 s 
2025-03-30 21:57:02.244721:  
2025-03-30 21:57:02.244894: Epoch 586 
2025-03-30 21:57:02.244992: Current learning rate: 0.00452 
2025-03-30 21:57:28.948448: train_loss -0.7815 
2025-03-30 21:57:28.948578: val_loss -0.7558 
2025-03-30 21:57:28.948634: Pseudo dice [np.float32(0.9036), np.float32(0.897)] 
2025-03-30 21:57:28.948697: Epoch time: 26.7 s 
2025-03-30 21:57:29.735383:  
2025-03-30 21:57:29.735522: Epoch 587 
2025-03-30 21:57:29.735592: Current learning rate: 0.00451 
2025-03-30 21:57:56.450124: train_loss -0.7976 
2025-03-30 21:57:56.450264: val_loss -0.7482 
2025-03-30 21:57:56.450320: Pseudo dice [np.float32(0.9036), np.float32(0.9029)] 
2025-03-30 21:57:56.450382: Epoch time: 26.72 s 
2025-03-30 21:57:57.226460:  
2025-03-30 21:57:57.226589: Epoch 588 
2025-03-30 21:57:57.226696: Current learning rate: 0.0045 
2025-03-30 21:58:23.944879: train_loss -0.803 
2025-03-30 21:58:23.945037: val_loss -0.7693 
2025-03-30 21:58:23.945094: Pseudo dice [np.float32(0.913), np.float32(0.9069)] 
2025-03-30 21:58:23.945184: Epoch time: 26.72 s 
2025-03-30 21:58:24.725957:  
2025-03-30 21:58:24.726107: Epoch 589 
2025-03-30 21:58:24.726184: Current learning rate: 0.00449 
2025-03-30 21:58:51.468040: train_loss -0.8045 
2025-03-30 21:58:51.468174: val_loss -0.7572 
2025-03-30 21:58:51.468229: Pseudo dice [np.float32(0.9067), np.float32(0.903)] 
2025-03-30 21:58:51.468292: Epoch time: 26.74 s 
2025-03-30 21:58:52.835138:  
2025-03-30 21:58:52.835312: Epoch 590 
2025-03-30 21:58:52.835410: Current learning rate: 0.00448 
2025-03-30 21:59:19.598209: train_loss -0.7974 
2025-03-30 21:59:19.598334: val_loss -0.7757 
2025-03-30 21:59:19.598389: Pseudo dice [np.float32(0.919), np.float32(0.9)] 
2025-03-30 21:59:19.598453: Epoch time: 26.76 s 
2025-03-30 21:59:20.376964:  
2025-03-30 21:59:20.377162: Epoch 591 
2025-03-30 21:59:20.377236: Current learning rate: 0.00447 
2025-03-30 21:59:47.072832: train_loss -0.7767 
2025-03-30 21:59:47.072968: val_loss -0.7323 
2025-03-30 21:59:47.073023: Pseudo dice [np.float32(0.9046), np.float32(0.8887)] 
2025-03-30 21:59:47.073095: Epoch time: 26.7 s 
2025-03-30 21:59:47.852422:  
2025-03-30 21:59:47.852594: Epoch 592 
2025-03-30 21:59:47.852685: Current learning rate: 0.00446 
2025-03-30 22:00:14.541073: train_loss -0.7741 
2025-03-30 22:00:14.541233: val_loss -0.763 
2025-03-30 22:00:14.541289: Pseudo dice [np.float32(0.9118), np.float32(0.9077)] 
2025-03-30 22:00:14.541351: Epoch time: 26.69 s 
2025-03-30 22:00:15.321803:  
2025-03-30 22:00:15.321999: Epoch 593 
2025-03-30 22:00:15.322088: Current learning rate: 0.00445 
2025-03-30 22:00:42.029146: train_loss -0.7638 
2025-03-30 22:00:42.029280: val_loss -0.7461 
2025-03-30 22:00:42.029335: Pseudo dice [np.float32(0.9078), np.float32(0.8953)] 
2025-03-30 22:00:42.029398: Epoch time: 26.71 s 
2025-03-30 22:00:42.811990:  
2025-03-30 22:00:42.812177: Epoch 594 
2025-03-30 22:00:42.812261: Current learning rate: 0.00444 
2025-03-30 22:01:09.520634: train_loss -0.775 
2025-03-30 22:01:09.520780: val_loss -0.7689 
2025-03-30 22:01:09.520840: Pseudo dice [np.float32(0.9166), np.float32(0.9002)] 
2025-03-30 22:01:09.520899: Epoch time: 26.71 s 
2025-03-30 22:01:10.299208:  
2025-03-30 22:01:10.299387: Epoch 595 
2025-03-30 22:01:10.299485: Current learning rate: 0.00443 
2025-03-30 22:01:36.994169: train_loss -0.8035 
2025-03-30 22:01:36.994308: val_loss -0.7212 
2025-03-30 22:01:36.994365: Pseudo dice [np.float32(0.8888), np.float32(0.8975)] 
2025-03-30 22:01:36.994426: Epoch time: 26.7 s 
2025-03-30 22:01:37.776943:  
2025-03-30 22:01:37.777100: Epoch 596 
2025-03-30 22:01:37.777172: Current learning rate: 0.00442 
2025-03-30 22:02:04.512294: train_loss -0.7769 
2025-03-30 22:02:04.512436: val_loss -0.7634 
2025-03-30 22:02:04.512492: Pseudo dice [np.float32(0.9057), np.float32(0.9098)] 
2025-03-30 22:02:04.512555: Epoch time: 26.74 s 
2025-03-30 22:02:05.293147:  
2025-03-30 22:02:05.293319: Epoch 597 
2025-03-30 22:02:05.293407: Current learning rate: 0.00441 
2025-03-30 22:02:31.958675: train_loss -0.7783 
2025-03-30 22:02:31.958809: val_loss -0.7614 
2025-03-30 22:02:31.958865: Pseudo dice [np.float32(0.91), np.float32(0.9115)] 
2025-03-30 22:02:31.958960: Epoch time: 26.67 s 
2025-03-30 22:02:31.959021: Yayy! New best EMA pseudo Dice: 0.9038000106811523 
2025-03-30 22:02:33.289484:  
2025-03-30 22:02:33.289669: Epoch 598 
2025-03-30 22:02:33.289754: Current learning rate: 0.0044 
2025-03-30 22:03:00.044610: train_loss -0.7959 
2025-03-30 22:03:00.044739: val_loss -0.7452 
2025-03-30 22:03:00.044814: Pseudo dice [np.float32(0.9092), np.float32(0.892)] 
2025-03-30 22:03:00.044879: Epoch time: 26.76 s 
2025-03-30 22:03:00.822304:  
2025-03-30 22:03:00.822465: Epoch 599 
2025-03-30 22:03:00.822542: Current learning rate: 0.00439 
2025-03-30 22:03:27.551033: train_loss -0.7949 
2025-03-30 22:03:27.551165: val_loss -0.7673 
2025-03-30 22:03:27.551219: Pseudo dice [np.float32(0.9085), np.float32(0.9081)] 
2025-03-30 22:03:27.551280: Epoch time: 26.73 s 
2025-03-30 22:03:28.054074: Yayy! New best EMA pseudo Dice: 0.9039000272750854 
2025-03-30 22:03:29.461308:  
2025-03-30 22:03:29.461465: Epoch 600 
2025-03-30 22:03:29.461550: Current learning rate: 0.00438 
2025-03-30 22:03:56.174378: train_loss -0.7988 
2025-03-30 22:03:56.174519: val_loss -0.7995 
2025-03-30 22:03:56.174593: Pseudo dice [np.float32(0.9259), np.float32(0.9224)] 
2025-03-30 22:03:56.174658: Epoch time: 26.71 s 
2025-03-30 22:03:56.174707: Yayy! New best EMA pseudo Dice: 0.906000018119812 
2025-03-30 22:03:57.582071:  
2025-03-30 22:03:57.582230: Epoch 601 
2025-03-30 22:03:57.582310: Current learning rate: 0.00437 
2025-03-30 22:04:24.311405: train_loss -0.7984 
2025-03-30 22:04:24.311547: val_loss -0.7598 
2025-03-30 22:04:24.311603: Pseudo dice [np.float32(0.9085), np.float32(0.9042)] 
2025-03-30 22:04:24.311688: Epoch time: 26.73 s 
2025-03-30 22:04:24.311738: Yayy! New best EMA pseudo Dice: 0.906000018119812 
2025-03-30 22:04:25.678320:  
2025-03-30 22:04:25.678509: Epoch 602 
2025-03-30 22:04:25.678615: Current learning rate: 0.00436 
2025-03-30 22:04:52.371600: train_loss -0.7903 
2025-03-30 22:04:52.371864: val_loss -0.7539 
2025-03-30 22:04:52.371919: Pseudo dice [np.float32(0.901), np.float32(0.9)] 
2025-03-30 22:04:52.371979: Epoch time: 26.69 s 
2025-03-30 22:04:53.149279:  
2025-03-30 22:04:53.149449: Epoch 603 
2025-03-30 22:04:53.149530: Current learning rate: 0.00435 
2025-03-30 22:05:19.898463: train_loss -0.7874 
2025-03-30 22:05:19.898599: val_loss -0.7249 
2025-03-30 22:05:19.898655: Pseudo dice [np.float32(0.8908), np.float32(0.8658)] 
2025-03-30 22:05:19.898731: Epoch time: 26.75 s 
2025-03-30 22:05:20.702358:  
2025-03-30 22:05:20.702507: Epoch 604 
2025-03-30 22:05:20.702588: Current learning rate: 0.00434 
2025-03-30 22:05:47.394042: train_loss -0.7932 
2025-03-30 22:05:47.394175: val_loss -0.7801 
2025-03-30 22:05:47.394230: Pseudo dice [np.float32(0.92), np.float32(0.9195)] 
2025-03-30 22:05:47.394289: Epoch time: 26.69 s 
2025-03-30 22:05:48.186209:  
2025-03-30 22:05:48.186366: Epoch 605 
2025-03-30 22:05:48.186459: Current learning rate: 0.00433 
2025-03-30 22:06:14.938704: train_loss -0.7955 
2025-03-30 22:06:14.938858: val_loss -0.7697 
2025-03-30 22:06:14.938946: Pseudo dice [np.float32(0.91), np.float32(0.9098)] 
2025-03-30 22:06:14.939015: Epoch time: 26.75 s 
2025-03-30 22:06:15.725498:  
2025-03-30 22:06:15.725643: Epoch 606 
2025-03-30 22:06:15.725733: Current learning rate: 0.00432 
2025-03-30 22:06:42.442364: train_loss -0.797 
2025-03-30 22:06:42.442504: val_loss -0.7304 
2025-03-30 22:06:42.442560: Pseudo dice [np.float32(0.8955), np.float32(0.8909)] 
2025-03-30 22:06:42.442657: Epoch time: 26.72 s 
2025-03-30 22:06:43.222005:  
2025-03-30 22:06:43.222167: Epoch 607 
2025-03-30 22:06:43.222250: Current learning rate: 0.00431 
2025-03-30 22:07:09.959793: train_loss -0.7468 
2025-03-30 22:07:09.959948: val_loss -0.7264 
2025-03-30 22:07:09.960043: Pseudo dice [np.float32(0.8908), np.float32(0.8996)] 
2025-03-30 22:07:09.960131: Epoch time: 26.74 s 
2025-03-30 22:07:10.738434:  
2025-03-30 22:07:10.738587: Epoch 608 
2025-03-30 22:07:10.738667: Current learning rate: 0.0043 
2025-03-30 22:07:37.534361: train_loss -0.7687 
2025-03-30 22:07:37.534609: val_loss -0.7588 
2025-03-30 22:07:37.534668: Pseudo dice [np.float32(0.9057), np.float32(0.9004)] 
2025-03-30 22:07:37.534729: Epoch time: 26.8 s 
2025-03-30 22:07:38.316453:  
2025-03-30 22:07:38.316612: Epoch 609 
2025-03-30 22:07:38.316693: Current learning rate: 0.00429 
2025-03-30 22:08:05.026865: train_loss -0.7788 
2025-03-30 22:08:05.027112: val_loss -0.7664 
2025-03-30 22:08:05.027177: Pseudo dice [np.float32(0.9144), np.float32(0.9052)] 
2025-03-30 22:08:05.027245: Epoch time: 26.71 s 
2025-03-30 22:08:06.412374:  
2025-03-30 22:08:06.412587: Epoch 610 
2025-03-30 22:08:06.412679: Current learning rate: 0.00429 
2025-03-30 22:08:33.412764: train_loss -0.7779 
2025-03-30 22:08:33.412902: val_loss -0.7622 
2025-03-30 22:08:33.412979: Pseudo dice [np.float32(0.9057), np.float32(0.9118)] 
2025-03-30 22:08:33.413041: Epoch time: 27.0 s 
2025-03-30 22:08:34.187868:  
2025-03-30 22:08:34.188048: Epoch 611 
2025-03-30 22:08:34.188127: Current learning rate: 0.00428 
2025-03-30 22:09:00.857558: train_loss -0.7808 
2025-03-30 22:09:00.857733: val_loss -0.7526 
2025-03-30 22:09:00.857810: Pseudo dice [np.float32(0.9077), np.float32(0.8963)] 
2025-03-30 22:09:00.857874: Epoch time: 26.67 s 
2025-03-30 22:09:01.635668:  
2025-03-30 22:09:01.635860: Epoch 612 
2025-03-30 22:09:01.635942: Current learning rate: 0.00427 
2025-03-30 22:09:28.330893: train_loss -0.7796 
2025-03-30 22:09:28.331047: val_loss -0.7778 
2025-03-30 22:09:28.331112: Pseudo dice [np.float32(0.9161), np.float32(0.9187)] 
2025-03-30 22:09:28.331180: Epoch time: 26.7 s 
2025-03-30 22:09:29.109696:  
2025-03-30 22:09:29.109854: Epoch 613 
2025-03-30 22:09:29.109930: Current learning rate: 0.00426 
2025-03-30 22:09:55.919549: train_loss -0.7887 
2025-03-30 22:09:55.919694: val_loss -0.762 
2025-03-30 22:09:55.919749: Pseudo dice [np.float32(0.9117), np.float32(0.9039)] 
2025-03-30 22:09:55.919818: Epoch time: 26.81 s 
2025-03-30 22:09:56.700047:  
2025-03-30 22:09:56.700240: Epoch 614 
2025-03-30 22:09:56.700314: Current learning rate: 0.00425 
2025-03-30 22:10:23.814180: train_loss -0.7956 
2025-03-30 22:10:23.814371: val_loss -0.7676 
2025-03-30 22:10:23.814446: Pseudo dice [np.float32(0.919), np.float32(0.9076)] 
2025-03-30 22:10:23.814510: Epoch time: 27.12 s 
2025-03-30 22:10:23.814558: Yayy! New best EMA pseudo Dice: 0.9063000082969666 
2025-03-30 22:10:25.103589:  
2025-03-30 22:10:25.103793: Epoch 615 
2025-03-30 22:10:25.103911: Current learning rate: 0.00424 
2025-03-30 22:10:51.910052: train_loss -0.7948 
2025-03-30 22:10:51.910197: val_loss -0.6899 
2025-03-30 22:10:51.910253: Pseudo dice [np.float32(0.8905), np.float32(0.8738)] 
2025-03-30 22:10:51.910316: Epoch time: 26.81 s 
2025-03-30 22:10:52.714181:  
2025-03-30 22:10:52.714360: Epoch 616 
2025-03-30 22:10:52.714437: Current learning rate: 0.00423 
2025-03-30 22:11:19.766878: train_loss -0.7687 
2025-03-30 22:11:19.767023: val_loss -0.7552 
2025-03-30 22:11:19.767086: Pseudo dice [np.float32(0.9016), np.float32(0.9003)] 
2025-03-30 22:11:19.767174: Epoch time: 27.05 s 
2025-03-30 22:11:20.553448:  
2025-03-30 22:11:20.553608: Epoch 617 
2025-03-30 22:11:20.553696: Current learning rate: 0.00422 
2025-03-30 22:11:47.364024: train_loss -0.7747 
2025-03-30 22:11:47.364165: val_loss -0.7793 
2025-03-30 22:11:47.364223: Pseudo dice [np.float32(0.9181), np.float32(0.9145)] 
2025-03-30 22:11:47.364285: Epoch time: 26.81 s 
2025-03-30 22:11:48.147910:  
2025-03-30 22:11:48.148129: Epoch 618 
2025-03-30 22:11:48.148226: Current learning rate: 0.00421 
2025-03-30 22:12:15.057070: train_loss -0.7676 
2025-03-30 22:12:15.057205: val_loss -0.7744 
2025-03-30 22:12:15.057260: Pseudo dice [np.float32(0.912), np.float32(0.9106)] 
2025-03-30 22:12:15.057320: Epoch time: 26.91 s 
2025-03-30 22:12:15.845004:  
2025-03-30 22:12:15.845164: Epoch 619 
2025-03-30 22:12:15.845247: Current learning rate: 0.0042 
2025-03-30 22:12:42.759880: train_loss -0.7716 
2025-03-30 22:12:42.760082: val_loss -0.6985 
2025-03-30 22:12:42.760138: Pseudo dice [np.float32(0.8818), np.float32(0.8753)] 
2025-03-30 22:12:42.760199: Epoch time: 26.92 s 
2025-03-30 22:12:43.538199:  
2025-03-30 22:12:43.538363: Epoch 620 
2025-03-30 22:12:43.538459: Current learning rate: 0.00419 
2025-03-30 22:13:10.267607: train_loss -0.7603 
2025-03-30 22:13:10.267746: val_loss -0.7596 
2025-03-30 22:13:10.267811: Pseudo dice [np.float32(0.9035), np.float32(0.9028)] 
2025-03-30 22:13:10.267901: Epoch time: 26.73 s 
2025-03-30 22:13:11.042196:  
2025-03-30 22:13:11.042363: Epoch 621 
2025-03-30 22:13:11.042454: Current learning rate: 0.00418 
2025-03-30 22:13:37.833635: train_loss -0.7518 
2025-03-30 22:13:37.833788: val_loss -0.7565 
2025-03-30 22:13:37.833848: Pseudo dice [np.float32(0.9103), np.float32(0.8967)] 
2025-03-30 22:13:37.833914: Epoch time: 26.79 s 
2025-03-30 22:13:38.618098:  
2025-03-30 22:13:38.618261: Epoch 622 
2025-03-30 22:13:38.618342: Current learning rate: 0.00417 
2025-03-30 22:14:05.370118: train_loss -0.7746 
2025-03-30 22:14:05.370258: val_loss -0.7587 
2025-03-30 22:14:05.370331: Pseudo dice [np.float32(0.9114), np.float32(0.9089)] 
2025-03-30 22:14:05.370391: Epoch time: 26.75 s 
2025-03-30 22:14:06.153825:  
2025-03-30 22:14:06.153972: Epoch 623 
2025-03-30 22:14:06.154051: Current learning rate: 0.00416 
2025-03-30 22:14:32.894502: train_loss -0.7792 
2025-03-30 22:14:32.894683: val_loss -0.7514 
2025-03-30 22:14:32.894741: Pseudo dice [np.float32(0.9082), np.float32(0.8942)] 
2025-03-30 22:14:32.894824: Epoch time: 26.74 s 
2025-03-30 22:14:33.666859:  
2025-03-30 22:14:33.667005: Epoch 624 
2025-03-30 22:14:33.667086: Current learning rate: 0.00415 
2025-03-30 22:15:00.436954: train_loss -0.7825 
2025-03-30 22:15:00.437092: val_loss -0.7533 
2025-03-30 22:15:00.437149: Pseudo dice [np.float32(0.9079), np.float32(0.8964)] 
2025-03-30 22:15:00.437254: Epoch time: 26.77 s 
2025-03-30 22:15:01.210701:  
2025-03-30 22:15:01.210840: Epoch 625 
2025-03-30 22:15:01.210908: Current learning rate: 0.00414 
2025-03-30 22:15:27.947308: train_loss -0.766 
2025-03-30 22:15:27.947439: val_loss -0.7763 
2025-03-30 22:15:27.947493: Pseudo dice [np.float32(0.9158), np.float32(0.9042)] 
2025-03-30 22:15:27.947574: Epoch time: 26.74 s 
2025-03-30 22:15:28.720365:  
2025-03-30 22:15:28.720521: Epoch 626 
2025-03-30 22:15:28.720598: Current learning rate: 0.00413 
2025-03-30 22:15:55.447638: train_loss -0.7735 
2025-03-30 22:15:55.447779: val_loss -0.7756 
2025-03-30 22:15:55.447838: Pseudo dice [np.float32(0.9186), np.float32(0.91)] 
2025-03-30 22:15:55.447926: Epoch time: 26.73 s 
2025-03-30 22:15:56.232808:  
2025-03-30 22:15:56.232965: Epoch 627 
2025-03-30 22:15:56.233043: Current learning rate: 0.00412 
2025-03-30 22:16:22.899676: train_loss -0.7757 
2025-03-30 22:16:22.899809: val_loss -0.7645 
2025-03-30 22:16:22.899866: Pseudo dice [np.float32(0.9109), np.float32(0.9055)] 
2025-03-30 22:16:22.899926: Epoch time: 26.67 s 
2025-03-30 22:16:23.684922:  
2025-03-30 22:16:23.685074: Epoch 628 
2025-03-30 22:16:23.685157: Current learning rate: 0.00411 
2025-03-30 22:16:50.486106: train_loss -0.7938 
2025-03-30 22:16:50.486336: val_loss -0.7457 
2025-03-30 22:16:50.486394: Pseudo dice [np.float32(0.9031), np.float32(0.8946)] 
2025-03-30 22:16:50.486460: Epoch time: 26.8 s 
2025-03-30 22:16:51.840472:  
2025-03-30 22:16:51.840629: Epoch 629 
2025-03-30 22:16:51.840724: Current learning rate: 0.0041 
2025-03-30 22:17:18.568721: train_loss -0.7952 
2025-03-30 22:17:18.568996: val_loss -0.756 
2025-03-30 22:17:18.569054: Pseudo dice [np.float32(0.906), np.float32(0.8978)] 
2025-03-30 22:17:18.569115: Epoch time: 26.73 s 
2025-03-30 22:17:19.348851:  
2025-03-30 22:17:19.349034: Epoch 630 
2025-03-30 22:17:19.349140: Current learning rate: 0.00409 
2025-03-30 22:17:46.090262: train_loss -0.8047 
2025-03-30 22:17:46.091185: val_loss -0.7713 
2025-03-30 22:17:46.091253: Pseudo dice [np.float32(0.9123), np.float32(0.911)] 
2025-03-30 22:17:46.091317: Epoch time: 26.74 s 
2025-03-30 22:17:46.867289:  
2025-03-30 22:17:46.867481: Epoch 631 
2025-03-30 22:17:46.867566: Current learning rate: 0.00408 
2025-03-30 22:18:13.593623: train_loss -0.7875 
2025-03-30 22:18:13.593866: val_loss -0.7617 
2025-03-30 22:18:13.593949: Pseudo dice [np.float32(0.9103), np.float32(0.9008)] 
2025-03-30 22:18:13.594035: Epoch time: 26.73 s 
2025-03-30 22:18:14.374373:  
2025-03-30 22:18:14.374550: Epoch 632 
2025-03-30 22:18:14.374628: Current learning rate: 0.00407 
2025-03-30 22:18:41.134457: train_loss -0.7737 
2025-03-30 22:18:41.134587: val_loss -0.751 
2025-03-30 22:18:41.134641: Pseudo dice [np.float32(0.9166), np.float32(0.896)] 
2025-03-30 22:18:41.134725: Epoch time: 26.76 s 
2025-03-30 22:18:41.923403:  
2025-03-30 22:18:41.923581: Epoch 633 
2025-03-30 22:18:41.923664: Current learning rate: 0.00406 
2025-03-30 22:19:08.602494: train_loss -0.7798 
2025-03-30 22:19:08.602735: val_loss -0.7484 
2025-03-30 22:19:08.602806: Pseudo dice [np.float32(0.9037), np.float32(0.8968)] 
2025-03-30 22:19:08.602871: Epoch time: 26.68 s 
2025-03-30 22:19:09.388430:  
2025-03-30 22:19:09.388587: Epoch 634 
2025-03-30 22:19:09.388668: Current learning rate: 0.00405 
2025-03-30 22:19:36.070435: train_loss -0.7951 
2025-03-30 22:19:36.070681: val_loss -0.7679 
2025-03-30 22:19:36.070739: Pseudo dice [np.float32(0.9122), np.float32(0.9048)] 
2025-03-30 22:19:36.070811: Epoch time: 26.68 s 
2025-03-30 22:19:36.850933:  
2025-03-30 22:19:36.851109: Epoch 635 
2025-03-30 22:19:36.851191: Current learning rate: 0.00404 
2025-03-30 22:20:03.561687: train_loss -0.7845 
2025-03-30 22:20:03.561953: val_loss -0.7624 
2025-03-30 22:20:03.562015: Pseudo dice [np.float32(0.9097), np.float32(0.9085)] 
2025-03-30 22:20:03.562124: Epoch time: 26.71 s 
2025-03-30 22:20:04.337071:  
2025-03-30 22:20:04.337246: Epoch 636 
2025-03-30 22:20:04.337323: Current learning rate: 0.00403 
2025-03-30 22:20:31.077253: train_loss -0.788 
2025-03-30 22:20:31.077518: val_loss -0.7542 
2025-03-30 22:20:31.077578: Pseudo dice [np.float32(0.9084), np.float32(0.908)] 
2025-03-30 22:20:31.077652: Epoch time: 26.74 s 
2025-03-30 22:20:31.855902:  
2025-03-30 22:20:31.856067: Epoch 637 
2025-03-30 22:20:31.856142: Current learning rate: 0.00402 
2025-03-30 22:20:58.606648: train_loss -0.7845 
2025-03-30 22:20:58.606888: val_loss -0.7725 
2025-03-30 22:20:58.606948: Pseudo dice [np.float32(0.9172), np.float32(0.915)] 
2025-03-30 22:20:58.607054: Epoch time: 26.75 s 
2025-03-30 22:20:58.607104: Yayy! New best EMA pseudo Dice: 0.9067999720573425 
2025-03-30 22:20:59.935589:  
2025-03-30 22:20:59.935749: Epoch 638 
2025-03-30 22:20:59.935832: Current learning rate: 0.00401 
2025-03-30 22:21:26.637730: train_loss -0.7837 
2025-03-30 22:21:26.637969: val_loss -0.7553 
2025-03-30 22:21:26.638027: Pseudo dice [np.float32(0.9175), np.float32(0.8972)] 
2025-03-30 22:21:26.638089: Epoch time: 26.7 s 
2025-03-30 22:21:26.638137: Yayy! New best EMA pseudo Dice: 0.9068999886512756 
2025-03-30 22:21:27.948107:  
2025-03-30 22:21:27.948286: Epoch 639 
2025-03-30 22:21:27.948365: Current learning rate: 0.004 
2025-03-30 22:21:54.612389: train_loss -0.8006 
2025-03-30 22:21:54.612536: val_loss -0.7854 
2025-03-30 22:21:54.612608: Pseudo dice [np.float32(0.9234), np.float32(0.9091)] 
2025-03-30 22:21:54.612671: Epoch time: 26.67 s 
2025-03-30 22:21:54.612720: Yayy! New best EMA pseudo Dice: 0.907800018787384 
2025-03-30 22:21:55.940845:  
2025-03-30 22:21:55.941022: Epoch 640 
2025-03-30 22:21:55.941102: Current learning rate: 0.00399 
2025-03-30 22:22:22.751943: train_loss -0.7877 
2025-03-30 22:22:22.752080: val_loss -0.7539 
2025-03-30 22:22:22.752160: Pseudo dice [np.float32(0.9098), np.float32(0.8986)] 
2025-03-30 22:22:22.752225: Epoch time: 26.81 s 
2025-03-30 22:22:23.551983:  
2025-03-30 22:22:23.552148: Epoch 641 
2025-03-30 22:22:23.552227: Current learning rate: 0.00398 
2025-03-30 22:22:50.274243: train_loss -0.7881 
2025-03-30 22:22:50.274405: val_loss -0.7593 
2025-03-30 22:22:50.274462: Pseudo dice [np.float32(0.8997), np.float32(0.9102)] 
2025-03-30 22:22:50.274528: Epoch time: 26.72 s 
2025-03-30 22:22:51.063905:  
2025-03-30 22:22:51.064028: Epoch 642 
2025-03-30 22:22:51.064123: Current learning rate: 0.00397 
2025-03-30 22:23:17.811870: train_loss -0.7876 
2025-03-30 22:23:17.812049: val_loss -0.7675 
2025-03-30 22:23:17.812105: Pseudo dice [np.float32(0.911), np.float32(0.9145)] 
2025-03-30 22:23:17.812209: Epoch time: 26.75 s 
2025-03-30 22:23:18.589720:  
2025-03-30 22:23:18.589873: Epoch 643 
2025-03-30 22:23:18.589952: Current learning rate: 0.00396 
2025-03-30 22:23:45.293422: train_loss -0.7958 
2025-03-30 22:23:45.293557: val_loss -0.7279 
2025-03-30 22:23:45.293612: Pseudo dice [np.float32(0.9014), np.float32(0.8934)] 
2025-03-30 22:23:45.293671: Epoch time: 26.7 s 
2025-03-30 22:23:46.073638:  
2025-03-30 22:23:46.073806: Epoch 644 
2025-03-30 22:23:46.073883: Current learning rate: 0.00395 
2025-03-30 22:24:12.827438: train_loss -0.7892 
2025-03-30 22:24:12.827582: val_loss -0.7722 
2025-03-30 22:24:12.827663: Pseudo dice [np.float32(0.9121), np.float32(0.9119)] 
2025-03-30 22:24:12.827730: Epoch time: 26.75 s 
2025-03-30 22:24:13.624000:  
2025-03-30 22:24:13.624153: Epoch 645 
2025-03-30 22:24:13.624228: Current learning rate: 0.00394 
2025-03-30 22:24:40.335190: train_loss -0.794 
2025-03-30 22:24:40.335369: val_loss -0.7575 
2025-03-30 22:24:40.335445: Pseudo dice [np.float32(0.9106), np.float32(0.9045)] 
2025-03-30 22:24:40.335514: Epoch time: 26.71 s 
2025-03-30 22:24:41.128700:  
2025-03-30 22:24:41.128882: Epoch 646 
2025-03-30 22:24:41.128967: Current learning rate: 0.00393 
2025-03-30 22:25:07.880487: train_loss -0.7939 
2025-03-30 22:25:07.880612: val_loss -0.7819 
2025-03-30 22:25:07.880668: Pseudo dice [np.float32(0.9234), np.float32(0.912)] 
2025-03-30 22:25:07.880728: Epoch time: 26.75 s 
2025-03-30 22:25:07.880789: Yayy! New best EMA pseudo Dice: 0.90829998254776 
2025-03-30 22:25:09.377600:  
2025-03-30 22:25:09.377770: Epoch 647 
2025-03-30 22:25:09.377853: Current learning rate: 0.00392 
2025-03-30 22:25:36.130208: train_loss -0.7893 
2025-03-30 22:25:36.130362: val_loss -0.7414 
2025-03-30 22:25:36.130419: Pseudo dice [np.float32(0.8983), np.float32(0.897)] 
2025-03-30 22:25:36.130493: Epoch time: 26.75 s 
2025-03-30 22:25:37.525962:  
2025-03-30 22:25:37.526171: Epoch 648 
2025-03-30 22:25:37.526283: Current learning rate: 0.00391 
2025-03-30 22:26:04.280069: train_loss -0.7966 
2025-03-30 22:26:04.280236: val_loss -0.7788 
2025-03-30 22:26:04.280292: Pseudo dice [np.float32(0.9146), np.float32(0.9119)] 
2025-03-30 22:26:04.280354: Epoch time: 26.76 s 
2025-03-30 22:26:05.057369:  
2025-03-30 22:26:05.057554: Epoch 649 
2025-03-30 22:26:05.057626: Current learning rate: 0.0039 
2025-03-30 22:26:31.808291: train_loss -0.7895 
2025-03-30 22:26:31.808460: val_loss -0.7704 
2025-03-30 22:26:31.808518: Pseudo dice [np.float32(0.9161), np.float32(0.903)] 
2025-03-30 22:26:31.808580: Epoch time: 26.75 s 
2025-03-30 22:26:33.092052:  
2025-03-30 22:26:33.092228: Epoch 650 
2025-03-30 22:26:33.092305: Current learning rate: 0.00389 
2025-03-30 22:26:59.747141: train_loss -0.8022 
2025-03-30 22:26:59.747284: val_loss -0.8065 
2025-03-30 22:26:59.747348: Pseudo dice [np.float32(0.9268), np.float32(0.9259)] 
2025-03-30 22:26:59.747411: Epoch time: 26.66 s 
2025-03-30 22:26:59.747495: Yayy! New best EMA pseudo Dice: 0.9099000096321106 
2025-03-30 22:27:01.084980:  
2025-03-30 22:27:01.085181: Epoch 651 
2025-03-30 22:27:01.085259: Current learning rate: 0.00388 
2025-03-30 22:27:27.755215: train_loss -0.7924 
2025-03-30 22:27:27.755371: val_loss -0.7778 
2025-03-30 22:27:27.755514: Pseudo dice [np.float32(0.9196), np.float32(0.8999)] 
2025-03-30 22:27:27.755577: Epoch time: 26.67 s 
2025-03-30 22:27:28.530550:  
2025-03-30 22:27:28.530734: Epoch 652 
2025-03-30 22:27:28.530822: Current learning rate: 0.00387 
2025-03-30 22:27:55.230190: train_loss -0.7913 
2025-03-30 22:27:55.230310: val_loss -0.7517 
2025-03-30 22:27:55.230366: Pseudo dice [np.float32(0.908), np.float32(0.9001)] 
2025-03-30 22:27:55.230426: Epoch time: 26.7 s 
2025-03-30 22:27:56.008331:  
2025-03-30 22:27:56.008492: Epoch 653 
2025-03-30 22:27:56.008583: Current learning rate: 0.00386 
2025-03-30 22:28:22.731665: train_loss -0.7902 
2025-03-30 22:28:22.731800: val_loss -0.7614 
2025-03-30 22:28:22.731857: Pseudo dice [np.float32(0.915), np.float32(0.9022)] 
2025-03-30 22:28:22.731919: Epoch time: 26.72 s 
2025-03-30 22:28:23.518855:  
2025-03-30 22:28:23.519056: Epoch 654 
2025-03-30 22:28:23.519140: Current learning rate: 0.00385 
2025-03-30 22:28:50.247738: train_loss -0.7971 
2025-03-30 22:28:50.247999: val_loss -0.7608 
2025-03-30 22:28:50.248057: Pseudo dice [np.float32(0.9077), np.float32(0.9042)] 
2025-03-30 22:28:50.248121: Epoch time: 26.73 s 
2025-03-30 22:28:51.028690:  
2025-03-30 22:28:51.028882: Epoch 655 
2025-03-30 22:28:51.028965: Current learning rate: 0.00384 
2025-03-30 22:29:17.757232: train_loss -0.7974 
2025-03-30 22:29:17.757461: val_loss -0.7583 
2025-03-30 22:29:17.757531: Pseudo dice [np.float32(0.9158), np.float32(0.8927)] 
2025-03-30 22:29:17.757609: Epoch time: 26.73 s 
2025-03-30 22:29:18.540469:  
2025-03-30 22:29:18.540611: Epoch 656 
2025-03-30 22:29:18.540691: Current learning rate: 0.00383 
2025-03-30 22:29:45.273186: train_loss -0.7988 
2025-03-30 22:29:45.273931: val_loss -0.7735 
2025-03-30 22:29:45.273992: Pseudo dice [np.float32(0.9159), np.float32(0.9061)] 
2025-03-30 22:29:45.274055: Epoch time: 26.73 s 
2025-03-30 22:29:46.056301:  
2025-03-30 22:29:46.056470: Epoch 657 
2025-03-30 22:29:46.056550: Current learning rate: 0.00382 
2025-03-30 22:30:12.771460: train_loss -0.809 
2025-03-30 22:30:12.771721: val_loss -0.7824 
2025-03-30 22:30:12.771799: Pseudo dice [np.float32(0.9262), np.float32(0.9096)] 
2025-03-30 22:30:12.771867: Epoch time: 26.72 s 
2025-03-30 22:30:13.557873:  
2025-03-30 22:30:13.558055: Epoch 658 
2025-03-30 22:30:13.558161: Current learning rate: 0.00381 
2025-03-30 22:30:40.282603: train_loss -0.7788 
2025-03-30 22:30:40.282867: val_loss -0.7626 
2025-03-30 22:30:40.282927: Pseudo dice [np.float32(0.9165), np.float32(0.8977)] 
2025-03-30 22:30:40.282988: Epoch time: 26.73 s 
2025-03-30 22:30:41.064810:  
2025-03-30 22:30:41.064963: Epoch 659 
2025-03-30 22:30:41.065043: Current learning rate: 0.0038 
2025-03-30 22:31:07.778090: train_loss -0.7837 
2025-03-30 22:31:07.778246: val_loss -0.7292 
2025-03-30 22:31:07.778302: Pseudo dice [np.float32(0.8919), np.float32(0.8867)] 
2025-03-30 22:31:07.778364: Epoch time: 26.71 s 
2025-03-30 22:31:08.559875:  
2025-03-30 22:31:08.560022: Epoch 660 
2025-03-30 22:31:08.560112: Current learning rate: 0.00379 
2025-03-30 22:31:35.284729: train_loss -0.7751 
2025-03-30 22:31:35.284871: val_loss -0.7708 
2025-03-30 22:31:35.284965: Pseudo dice [np.float32(0.9065), np.float32(0.9122)] 
2025-03-30 22:31:35.285029: Epoch time: 26.73 s 
2025-03-30 22:31:36.072190:  
2025-03-30 22:31:36.072348: Epoch 661 
2025-03-30 22:31:36.072438: Current learning rate: 0.00378 
2025-03-30 22:32:02.838079: train_loss -0.796 
2025-03-30 22:32:02.838211: val_loss -0.7899 
2025-03-30 22:32:02.838266: Pseudo dice [np.float32(0.9266), np.float32(0.9142)] 
2025-03-30 22:32:02.838329: Epoch time: 26.77 s 
2025-03-30 22:32:03.616804:  
2025-03-30 22:32:03.616940: Epoch 662 
2025-03-30 22:32:03.617037: Current learning rate: 0.00377 
2025-03-30 22:32:30.356391: train_loss -0.7964 
2025-03-30 22:32:30.356522: val_loss -0.7677 
2025-03-30 22:32:30.356585: Pseudo dice [np.float32(0.9128), np.float32(0.9102)] 
2025-03-30 22:32:30.356652: Epoch time: 26.74 s 
2025-03-30 22:32:31.135904:  
2025-03-30 22:32:31.136074: Epoch 663 
2025-03-30 22:32:31.136157: Current learning rate: 0.00376 
2025-03-30 22:32:57.906754: train_loss -0.7868 
2025-03-30 22:32:57.907022: val_loss -0.7581 
2025-03-30 22:32:57.907080: Pseudo dice [np.float32(0.9083), np.float32(0.8955)] 
2025-03-30 22:32:57.907141: Epoch time: 26.77 s 
2025-03-30 22:32:58.690010:  
2025-03-30 22:32:58.690151: Epoch 664 
2025-03-30 22:32:58.690231: Current learning rate: 0.00375 
2025-03-30 22:33:25.389910: train_loss -0.7922 
2025-03-30 22:33:25.390055: val_loss -0.778 
2025-03-30 22:33:25.390116: Pseudo dice [np.float32(0.9158), np.float32(0.9074)] 
2025-03-30 22:33:25.390177: Epoch time: 26.7 s 
2025-03-30 22:33:26.169173:  
2025-03-30 22:33:26.169345: Epoch 665 
2025-03-30 22:33:26.169431: Current learning rate: 0.00374 
2025-03-30 22:33:52.891856: train_loss -0.8008 
2025-03-30 22:33:52.891981: val_loss -0.7723 
2025-03-30 22:33:52.892036: Pseudo dice [np.float32(0.9097), np.float32(0.9045)] 
2025-03-30 22:33:52.892099: Epoch time: 26.72 s 
2025-03-30 22:33:53.669798:  
2025-03-30 22:33:53.669987: Epoch 666 
2025-03-30 22:33:53.670072: Current learning rate: 0.00373 
2025-03-30 22:34:20.500268: train_loss -0.8004 
2025-03-30 22:34:20.500407: val_loss -0.7635 
2025-03-30 22:34:20.500463: Pseudo dice [np.float32(0.909), np.float32(0.9075)] 
2025-03-30 22:34:20.500522: Epoch time: 26.83 s 
2025-03-30 22:34:21.276840:  
2025-03-30 22:34:21.277021: Epoch 667 
2025-03-30 22:34:21.277103: Current learning rate: 0.00372 
2025-03-30 22:34:48.140685: train_loss -0.8025 
2025-03-30 22:34:48.140845: val_loss -0.7865 
2025-03-30 22:34:48.140902: Pseudo dice [np.float32(0.9197), np.float32(0.9199)] 
2025-03-30 22:34:48.140965: Epoch time: 26.86 s 
2025-03-30 22:34:49.512460:  
2025-03-30 22:34:49.512635: Epoch 668 
2025-03-30 22:34:49.512720: Current learning rate: 0.00371 
2025-03-30 22:35:16.246953: train_loss -0.8057 
2025-03-30 22:35:16.247118: val_loss -0.766 
2025-03-30 22:35:16.247175: Pseudo dice [np.float32(0.9119), np.float32(0.9053)] 
2025-03-30 22:35:16.247283: Epoch time: 26.74 s 
2025-03-30 22:35:17.026164:  
2025-03-30 22:35:17.026368: Epoch 669 
2025-03-30 22:35:17.026451: Current learning rate: 0.0037 
2025-03-30 22:35:43.783895: train_loss -0.8212 
2025-03-30 22:35:43.784087: val_loss -0.7821 
2025-03-30 22:35:43.784146: Pseudo dice [np.float32(0.9238), np.float32(0.9154)] 
2025-03-30 22:35:43.784216: Epoch time: 26.76 s 
2025-03-30 22:35:43.784266: Yayy! New best EMA pseudo Dice: 0.9106000065803528 
2025-03-30 22:35:45.083704:  
2025-03-30 22:35:45.083901: Epoch 670 
2025-03-30 22:35:45.083982: Current learning rate: 0.00369 
2025-03-30 22:36:11.811837: train_loss -0.8208 
2025-03-30 22:36:11.811991: val_loss -0.77 
2025-03-30 22:36:11.812045: Pseudo dice [np.float32(0.9152), np.float32(0.9129)] 
2025-03-30 22:36:11.812105: Epoch time: 26.73 s 
2025-03-30 22:36:11.812150: Yayy! New best EMA pseudo Dice: 0.9108999967575073 
2025-03-30 22:36:15.044632:  
2025-03-30 22:36:15.044827: Epoch 671 
2025-03-30 22:36:15.044907: Current learning rate: 0.00368 
2025-03-30 22:36:41.783816: train_loss -0.8154 
2025-03-30 22:36:41.783936: val_loss -0.7583 
2025-03-30 22:36:41.783989: Pseudo dice [np.float32(0.9086), np.float32(0.9035)] 
2025-03-30 22:36:41.784045: Epoch time: 26.74 s 
2025-03-30 22:36:42.568631:  
2025-03-30 22:36:42.568789: Epoch 672 
2025-03-30 22:36:42.568870: Current learning rate: 0.00367 
2025-03-30 22:37:09.314599: train_loss -0.8108 
2025-03-30 22:37:09.314728: val_loss -0.7531 
2025-03-30 22:37:09.314802: Pseudo dice [np.float32(0.9049), np.float32(0.9035)] 
2025-03-30 22:37:09.314868: Epoch time: 26.75 s 
2025-03-30 22:37:10.097794:  
2025-03-30 22:37:10.097969: Epoch 673 
2025-03-30 22:37:10.098049: Current learning rate: 0.00366 
2025-03-30 22:37:36.807255: train_loss -0.7937 
2025-03-30 22:37:36.807466: val_loss -0.7533 
2025-03-30 22:37:36.807523: Pseudo dice [np.float32(0.9146), np.float32(0.89)] 
2025-03-30 22:37:36.807585: Epoch time: 26.71 s 
2025-03-30 22:37:37.603092:  
2025-03-30 22:37:37.603241: Epoch 674 
2025-03-30 22:37:37.603343: Current learning rate: 0.00365 
2025-03-30 22:38:04.330638: train_loss -0.7972 
2025-03-30 22:38:04.330806: val_loss -0.8041 
2025-03-30 22:38:04.330864: Pseudo dice [np.float32(0.9283), np.float32(0.918)] 
2025-03-30 22:38:04.330926: Epoch time: 26.73 s 
2025-03-30 22:38:05.117308:  
2025-03-30 22:38:05.117474: Epoch 675 
2025-03-30 22:38:05.117558: Current learning rate: 0.00364 
2025-03-30 22:38:31.824723: train_loss -0.8065 
2025-03-30 22:38:31.824858: val_loss -0.7743 
2025-03-30 22:38:31.824914: Pseudo dice [np.float32(0.9146), np.float32(0.911)] 
2025-03-30 22:38:31.824975: Epoch time: 26.71 s 
2025-03-30 22:38:32.614392:  
2025-03-30 22:38:32.614538: Epoch 676 
2025-03-30 22:38:32.614629: Current learning rate: 0.00363 
2025-03-30 22:38:59.342143: train_loss -0.8098 
2025-03-30 22:38:59.342312: val_loss -0.7578 
2025-03-30 22:38:59.342367: Pseudo dice [np.float32(0.9058), np.float32(0.8989)] 
2025-03-30 22:38:59.342429: Epoch time: 26.73 s 
2025-03-30 22:39:00.131844:  
2025-03-30 22:39:00.131990: Epoch 677 
2025-03-30 22:39:00.132078: Current learning rate: 0.00362 
2025-03-30 22:39:26.838097: train_loss -0.8049 
2025-03-30 22:39:26.838226: val_loss -0.7588 
2025-03-30 22:39:26.838310: Pseudo dice [np.float32(0.9052), np.float32(0.9076)] 
2025-03-30 22:39:26.838373: Epoch time: 26.71 s 
2025-03-30 22:39:27.618538:  
2025-03-30 22:39:27.618708: Epoch 678 
2025-03-30 22:39:27.618800: Current learning rate: 0.00361 
2025-03-30 22:39:54.371186: train_loss -0.8017 
2025-03-30 22:39:54.371314: val_loss -0.7684 
2025-03-30 22:39:54.371369: Pseudo dice [np.float32(0.9093), np.float32(0.908)] 
2025-03-30 22:39:54.371432: Epoch time: 26.75 s 
2025-03-30 22:39:55.152472:  
2025-03-30 22:39:55.152636: Epoch 679 
2025-03-30 22:39:55.152718: Current learning rate: 0.0036 
2025-03-30 22:40:21.880286: train_loss -0.8083 
2025-03-30 22:40:21.880431: val_loss -0.7886 
2025-03-30 22:40:21.880486: Pseudo dice [np.float32(0.9271), np.float32(0.9143)] 
2025-03-30 22:40:21.880548: Epoch time: 26.73 s 
2025-03-30 22:40:22.663660:  
2025-03-30 22:40:22.663833: Epoch 680 
2025-03-30 22:40:22.663915: Current learning rate: 0.00359 
2025-03-30 22:40:49.370675: train_loss -0.8184 
2025-03-30 22:40:49.370847: val_loss -0.768 
2025-03-30 22:40:49.370940: Pseudo dice [np.float32(0.9125), np.float32(0.91)] 
2025-03-30 22:40:49.371023: Epoch time: 26.71 s 
2025-03-30 22:40:50.155394:  
2025-03-30 22:40:50.155550: Epoch 681 
2025-03-30 22:40:50.155629: Current learning rate: 0.00358 
2025-03-30 22:41:16.892816: train_loss -0.8095 
2025-03-30 22:41:16.892961: val_loss -0.7853 
2025-03-30 22:41:16.893040: Pseudo dice [np.float32(0.9166), np.float32(0.916)] 
2025-03-30 22:41:16.893116: Epoch time: 26.74 s 
2025-03-30 22:41:16.893162: Yayy! New best EMA pseudo Dice: 0.9111999869346619 
2025-03-30 22:41:18.227545:  
2025-03-30 22:41:18.227680: Epoch 682 
2025-03-30 22:41:18.227785: Current learning rate: 0.00357 
2025-03-30 22:41:44.965998: train_loss -0.8063 
2025-03-30 22:41:44.966131: val_loss -0.7422 
2025-03-30 22:41:44.966197: Pseudo dice [np.float32(0.9134), np.float32(0.8958)] 
2025-03-30 22:41:44.966265: Epoch time: 26.74 s 
2025-03-30 22:41:45.761477:  
2025-03-30 22:41:45.761626: Epoch 683 
2025-03-30 22:41:45.761720: Current learning rate: 0.00356 
2025-03-30 22:42:12.535466: train_loss -0.8165 
2025-03-30 22:42:12.535641: val_loss -0.729 
2025-03-30 22:42:12.535698: Pseudo dice [np.float32(0.9014), np.float32(0.8897)] 
2025-03-30 22:42:12.535769: Epoch time: 26.78 s 
2025-03-30 22:42:13.317156:  
2025-03-30 22:42:13.317295: Epoch 684 
2025-03-30 22:42:13.317369: Current learning rate: 0.00355 
2025-03-30 22:42:40.074816: train_loss -0.8087 
2025-03-30 22:42:40.075058: val_loss -0.7672 
2025-03-30 22:42:40.075115: Pseudo dice [np.float32(0.9148), np.float32(0.9142)] 
2025-03-30 22:42:40.075176: Epoch time: 26.76 s 
2025-03-30 22:42:40.858063:  
2025-03-30 22:42:40.858250: Epoch 685 
2025-03-30 22:42:40.858332: Current learning rate: 0.00354 
2025-03-30 22:43:07.557320: train_loss -0.7977 
2025-03-30 22:43:07.557511: val_loss -0.7838 
2025-03-30 22:43:07.557569: Pseudo dice [np.float32(0.9226), np.float32(0.9113)] 
2025-03-30 22:43:07.557632: Epoch time: 26.7 s 
2025-03-30 22:43:08.341412:  
2025-03-30 22:43:08.341571: Epoch 686 
2025-03-30 22:43:08.341651: Current learning rate: 0.00353 
2025-03-30 22:43:35.077145: train_loss -0.7988 
2025-03-30 22:43:35.077296: val_loss -0.7419 
2025-03-30 22:43:35.077353: Pseudo dice [np.float32(0.8989), np.float32(0.8989)] 
2025-03-30 22:43:35.077415: Epoch time: 26.74 s 
2025-03-30 22:43:36.447964:  
2025-03-30 22:43:36.448161: Epoch 687 
2025-03-30 22:43:36.448253: Current learning rate: 0.00352 
2025-03-30 22:44:03.184032: train_loss -0.7921 
2025-03-30 22:44:03.184244: val_loss -0.7841 
2025-03-30 22:44:03.184302: Pseudo dice [np.float32(0.9252), np.float32(0.9109)] 
2025-03-30 22:44:03.184365: Epoch time: 26.74 s 
2025-03-30 22:44:03.966971:  
2025-03-30 22:44:03.967170: Epoch 688 
2025-03-30 22:44:03.967250: Current learning rate: 0.00351 
2025-03-30 22:44:30.713862: train_loss -0.8014 
2025-03-30 22:44:30.713981: val_loss -0.7575 
2025-03-30 22:44:30.714036: Pseudo dice [np.float32(0.9131), np.float32(0.9023)] 
2025-03-30 22:44:30.714097: Epoch time: 26.75 s 
2025-03-30 22:44:31.499800:  
2025-03-30 22:44:31.499995: Epoch 689 
2025-03-30 22:44:31.500079: Current learning rate: 0.0035 
2025-03-30 22:44:58.209622: train_loss -0.8092 
2025-03-30 22:44:58.209767: val_loss -0.7868 
2025-03-30 22:44:58.209833: Pseudo dice [np.float32(0.921), np.float32(0.9095)] 
2025-03-30 22:44:58.209902: Epoch time: 26.71 s 
2025-03-30 22:44:59.001879:  
2025-03-30 22:44:59.002073: Epoch 690 
2025-03-30 22:44:59.002157: Current learning rate: 0.00349 
2025-03-30 22:45:25.700030: train_loss -0.8127 
2025-03-30 22:45:25.700166: val_loss -0.7721 
2025-03-30 22:45:25.700222: Pseudo dice [np.float32(0.9174), np.float32(0.9047)] 
2025-03-30 22:45:25.700284: Epoch time: 26.7 s 
2025-03-30 22:45:26.484488:  
2025-03-30 22:45:26.484648: Epoch 691 
2025-03-30 22:45:26.484736: Current learning rate: 0.00348 
2025-03-30 22:45:53.157685: train_loss -0.8141 
2025-03-30 22:45:53.157818: val_loss -0.7773 
2025-03-30 22:45:53.157875: Pseudo dice [np.float32(0.9191), np.float32(0.9104)] 
2025-03-30 22:45:53.157935: Epoch time: 26.67 s 
2025-03-30 22:45:53.951510:  
2025-03-30 22:45:53.951700: Epoch 692 
2025-03-30 22:45:53.951794: Current learning rate: 0.00346 
2025-03-30 22:46:20.698004: train_loss -0.8209 
2025-03-30 22:46:20.698169: val_loss -0.7884 
2025-03-30 22:46:20.698226: Pseudo dice [np.float32(0.9248), np.float32(0.9102)] 
2025-03-30 22:46:20.698286: Epoch time: 26.75 s 
2025-03-30 22:46:20.698334: Yayy! New best EMA pseudo Dice: 0.9114999771118164 
2025-03-30 22:46:21.998586:  
2025-03-30 22:46:21.998753: Epoch 693 
2025-03-30 22:46:21.998839: Current learning rate: 0.00345 
2025-03-30 22:46:48.742874: train_loss -0.7998 
2025-03-30 22:46:48.743021: val_loss -0.7509 
2025-03-30 22:46:48.743074: Pseudo dice [np.float32(0.9048), np.float32(0.8988)] 
2025-03-30 22:46:48.743133: Epoch time: 26.75 s 
2025-03-30 22:46:49.528950:  
2025-03-30 22:46:49.529121: Epoch 694 
2025-03-30 22:46:49.529197: Current learning rate: 0.00344 
2025-03-30 22:47:16.228884: train_loss -0.8169 
2025-03-30 22:47:16.229032: val_loss -0.7915 
2025-03-30 22:47:16.229088: Pseudo dice [np.float32(0.9229), np.float32(0.9176)] 
2025-03-30 22:47:16.229149: Epoch time: 26.7 s 
2025-03-30 22:47:17.016422:  
2025-03-30 22:47:17.016602: Epoch 695 
2025-03-30 22:47:17.016688: Current learning rate: 0.00343 
2025-03-30 22:47:43.742546: train_loss -0.8182 
2025-03-30 22:47:43.742782: val_loss -0.7911 
2025-03-30 22:47:43.742841: Pseudo dice [np.float32(0.9209), np.float32(0.917)] 
2025-03-30 22:47:43.742902: Epoch time: 26.73 s 
2025-03-30 22:47:43.742950: Yayy! New best EMA pseudo Dice: 0.9122999906539917 
2025-03-30 22:47:45.087611:  
2025-03-30 22:47:45.087817: Epoch 696 
2025-03-30 22:47:45.087934: Current learning rate: 0.00342 
2025-03-30 22:48:11.794699: train_loss -0.8145 
2025-03-30 22:48:11.794857: val_loss -0.7686 
2025-03-30 22:48:11.794913: Pseudo dice [np.float32(0.9159), np.float32(0.9084)] 
2025-03-30 22:48:11.794975: Epoch time: 26.71 s 
2025-03-30 22:48:12.578186:  
2025-03-30 22:48:12.578351: Epoch 697 
2025-03-30 22:48:12.578431: Current learning rate: 0.00341 
2025-03-30 22:48:39.297635: train_loss -0.8174 
2025-03-30 22:48:39.297795: val_loss -0.803 
2025-03-30 22:48:39.297858: Pseudo dice [np.float32(0.927), np.float32(0.9246)] 
2025-03-30 22:48:39.297921: Epoch time: 26.72 s 
2025-03-30 22:48:39.297969: Yayy! New best EMA pseudo Dice: 0.9136000275611877 
2025-03-30 22:48:40.642189:  
2025-03-30 22:48:40.642383: Epoch 698 
2025-03-30 22:48:40.642461: Current learning rate: 0.0034 
2025-03-30 22:49:07.294188: train_loss -0.8193 
2025-03-30 22:49:07.294338: val_loss -0.7659 
2025-03-30 22:49:07.294400: Pseudo dice [np.float32(0.9168), np.float32(0.9001)] 
2025-03-30 22:49:07.294470: Epoch time: 26.65 s 
2025-03-30 22:49:08.074661:  
2025-03-30 22:49:08.074854: Epoch 699 
2025-03-30 22:49:08.074939: Current learning rate: 0.00339 
2025-03-30 22:49:34.848038: train_loss -0.8038 
2025-03-30 22:49:34.848210: val_loss -0.7291 
2025-03-30 22:49:34.848268: Pseudo dice [np.float32(0.8917), np.float32(0.89)] 
2025-03-30 22:49:34.848327: Epoch time: 26.77 s 
2025-03-30 22:49:36.163417:  
2025-03-30 22:49:36.163596: Epoch 700 
2025-03-30 22:49:36.163678: Current learning rate: 0.00338 
2025-03-30 22:50:02.926598: train_loss -0.8077 
2025-03-30 22:50:02.926787: val_loss -0.7197 
2025-03-30 22:50:02.926865: Pseudo dice [np.float32(0.8862), np.float32(0.8913)] 
2025-03-30 22:50:02.926956: Epoch time: 26.76 s 
2025-03-30 22:50:03.710675:  
2025-03-30 22:50:03.710868: Epoch 701 
2025-03-30 22:50:03.710948: Current learning rate: 0.00337 
2025-03-30 22:50:30.476726: train_loss -0.8097 
2025-03-30 22:50:30.476884: val_loss -0.7692 
2025-03-30 22:50:30.476941: Pseudo dice [np.float32(0.9099), np.float32(0.9006)] 
2025-03-30 22:50:30.477001: Epoch time: 26.77 s 
2025-03-30 22:50:31.256501:  
2025-03-30 22:50:31.256678: Epoch 702 
2025-03-30 22:50:31.256770: Current learning rate: 0.00336 
2025-03-30 22:50:57.990537: train_loss -0.7984 
2025-03-30 22:50:57.990672: val_loss -0.7759 
2025-03-30 22:50:57.990766: Pseudo dice [np.float32(0.9154), np.float32(0.9131)] 
2025-03-30 22:50:57.990831: Epoch time: 26.74 s 
2025-03-30 22:50:58.776107:  
2025-03-30 22:50:58.776284: Epoch 703 
2025-03-30 22:50:58.776365: Current learning rate: 0.00335 
2025-03-30 22:51:25.501577: train_loss -0.7984 
2025-03-30 22:51:25.501708: val_loss -0.7979 
2025-03-30 22:51:25.501771: Pseudo dice [np.float32(0.9252), np.float32(0.9173)] 
2025-03-30 22:51:25.501870: Epoch time: 26.73 s 
2025-03-30 22:51:26.279989:  
2025-03-30 22:51:26.280151: Epoch 704 
2025-03-30 22:51:26.280227: Current learning rate: 0.00334 
2025-03-30 22:51:53.009716: train_loss -0.8014 
2025-03-30 22:51:53.009873: val_loss -0.7896 
2025-03-30 22:51:53.009931: Pseudo dice [np.float32(0.9244), np.float32(0.9099)] 
2025-03-30 22:51:53.009992: Epoch time: 26.73 s 
2025-03-30 22:51:54.345008:  
2025-03-30 22:51:54.345194: Epoch 705 
2025-03-30 22:51:54.345279: Current learning rate: 0.00333 
2025-03-30 22:52:21.102870: train_loss -0.8121 
2025-03-30 22:52:21.102994: val_loss -0.7945 
2025-03-30 22:52:21.103098: Pseudo dice [np.float32(0.9223), np.float32(0.9195)] 
2025-03-30 22:52:21.103161: Epoch time: 26.76 s 
2025-03-30 22:52:21.883827:  
2025-03-30 22:52:21.884005: Epoch 706 
2025-03-30 22:52:21.884084: Current learning rate: 0.00332 
2025-03-30 22:52:48.583441: train_loss -0.8149 
2025-03-30 22:52:48.583595: val_loss -0.7727 
2025-03-30 22:52:48.583651: Pseudo dice [np.float32(0.9151), np.float32(0.9109)] 
2025-03-30 22:52:48.583713: Epoch time: 26.7 s 
2025-03-30 22:52:49.362142:  
2025-03-30 22:52:49.362343: Epoch 707 
2025-03-30 22:52:49.362416: Current learning rate: 0.00331 
2025-03-30 22:53:16.390236: train_loss -0.8072 
2025-03-30 22:53:16.390410: val_loss -0.7862 
2025-03-30 22:53:16.390466: Pseudo dice [np.float32(0.9245), np.float32(0.9115)] 
2025-03-30 22:53:16.390528: Epoch time: 27.03 s 
2025-03-30 22:53:17.179003:  
2025-03-30 22:53:17.179199: Epoch 708 
2025-03-30 22:53:17.179286: Current learning rate: 0.0033 
2025-03-30 22:53:44.221400: train_loss -0.8103 
2025-03-30 22:53:44.221773: val_loss -0.7726 
2025-03-30 22:53:44.221838: Pseudo dice [np.float32(0.9144), np.float32(0.9085)] 
2025-03-30 22:53:44.221909: Epoch time: 27.04 s 
2025-03-30 22:53:45.025215:  
2025-03-30 22:53:45.025436: Epoch 709 
2025-03-30 22:53:45.025519: Current learning rate: 0.00329 
2025-03-30 22:54:11.929595: train_loss -0.807 
2025-03-30 22:54:11.929890: val_loss -0.7522 
2025-03-30 22:54:11.929950: Pseudo dice [np.float32(0.914), np.float32(0.9063)] 
2025-03-30 22:54:11.930019: Epoch time: 26.91 s 
2025-03-30 22:54:12.720275:  
2025-03-30 22:54:12.720451: Epoch 710 
2025-03-30 22:54:12.720531: Current learning rate: 0.00328 
2025-03-30 22:54:39.453113: train_loss -0.808 
2025-03-30 22:54:39.453241: val_loss -0.7699 
2025-03-30 22:54:39.453332: Pseudo dice [np.float32(0.9135), np.float32(0.9125)] 
2025-03-30 22:54:39.453395: Epoch time: 26.73 s 
2025-03-30 22:54:40.248147:  
2025-03-30 22:54:40.248331: Epoch 711 
2025-03-30 22:54:40.248413: Current learning rate: 0.00327 
2025-03-30 22:55:07.039397: train_loss -0.8115 
2025-03-30 22:55:07.039690: val_loss -0.8029 
2025-03-30 22:55:07.039749: Pseudo dice [np.float32(0.9312), np.float32(0.9257)] 
2025-03-30 22:55:07.039837: Epoch time: 26.79 s 
2025-03-30 22:55:07.039890: Yayy! New best EMA pseudo Dice: 0.9139000177383423 
2025-03-30 22:55:08.378349:  
2025-03-30 22:55:08.378505: Epoch 712 
2025-03-30 22:55:08.378592: Current learning rate: 0.00326 
2025-03-30 22:55:35.059874: train_loss -0.8162 
2025-03-30 22:55:35.060024: val_loss -0.7958 
2025-03-30 22:55:35.060081: Pseudo dice [np.float32(0.9299), np.float32(0.9139)] 
2025-03-30 22:55:35.060143: Epoch time: 26.68 s 
2025-03-30 22:55:35.060214: Yayy! New best EMA pseudo Dice: 0.9146999716758728 
2025-03-30 22:55:36.402457:  
2025-03-30 22:55:36.402629: Epoch 713 
2025-03-30 22:55:36.402733: Current learning rate: 0.00325 
2025-03-30 22:56:03.135395: train_loss -0.8101 
2025-03-30 22:56:03.135675: val_loss -0.7508 
2025-03-30 22:56:03.135740: Pseudo dice [np.float32(0.9127), np.float32(0.901)] 
2025-03-30 22:56:03.135819: Epoch time: 26.73 s 
2025-03-30 22:56:03.921629:  
2025-03-30 22:56:03.921798: Epoch 714 
2025-03-30 22:56:03.921912: Current learning rate: 0.00324 
2025-03-30 22:56:30.676702: train_loss -0.7947 
2025-03-30 22:56:30.676859: val_loss -0.6944 
2025-03-30 22:56:30.676915: Pseudo dice [np.float32(0.8717), np.float32(0.8788)] 
2025-03-30 22:56:30.676979: Epoch time: 26.76 s 
2025-03-30 22:56:31.465517:  
2025-03-30 22:56:31.465691: Epoch 715 
2025-03-30 22:56:31.465792: Current learning rate: 0.00323 
2025-03-30 22:56:58.185804: train_loss -0.7848 
2025-03-30 22:56:58.185957: val_loss -0.7788 
2025-03-30 22:56:58.186014: Pseudo dice [np.float32(0.9216), np.float32(0.908)] 
2025-03-30 22:56:58.186077: Epoch time: 26.72 s 
2025-03-30 22:56:58.978290:  
2025-03-30 22:56:58.978449: Epoch 716 
2025-03-30 22:56:58.978531: Current learning rate: 0.00322 
2025-03-30 22:57:25.733831: train_loss -0.7916 
2025-03-30 22:57:25.733973: val_loss -0.7778 
2025-03-30 22:57:25.734029: Pseudo dice [np.float32(0.9154), np.float32(0.9158)] 
2025-03-30 22:57:25.734089: Epoch time: 26.76 s 
2025-03-30 22:57:26.520678:  
2025-03-30 22:57:26.520854: Epoch 717 
2025-03-30 22:57:26.520936: Current learning rate: 0.00321 
2025-03-30 22:57:53.223665: train_loss -0.8017 
2025-03-30 22:57:53.223826: val_loss -0.7844 
2025-03-30 22:57:53.223882: Pseudo dice [np.float32(0.9214), np.float32(0.9083)] 
2025-03-30 22:57:53.223945: Epoch time: 26.7 s 
2025-03-30 22:57:54.018081:  
2025-03-30 22:57:54.018227: Epoch 718 
2025-03-30 22:57:54.018326: Current learning rate: 0.0032 
2025-03-30 22:58:20.775306: train_loss -0.8112 
2025-03-30 22:58:20.775529: val_loss -0.77 
2025-03-30 22:58:20.775589: Pseudo dice [np.float32(0.9113), np.float32(0.9028)] 
2025-03-30 22:58:20.775668: Epoch time: 26.76 s 
2025-03-30 22:58:21.565948:  
2025-03-30 22:58:21.566126: Epoch 719 
2025-03-30 22:58:21.566209: Current learning rate: 0.00319 
2025-03-30 22:58:48.309477: train_loss -0.7925 
2025-03-30 22:58:48.309619: val_loss -0.7474 
2025-03-30 22:58:48.309675: Pseudo dice [np.float32(0.9045), np.float32(0.8961)] 
2025-03-30 22:58:48.309738: Epoch time: 26.74 s 
2025-03-30 22:58:49.098132:  
2025-03-30 22:58:49.098283: Epoch 720 
2025-03-30 22:58:49.098369: Current learning rate: 0.00318 
2025-03-30 22:59:15.818747: train_loss -0.8038 
2025-03-30 22:59:15.818873: val_loss -0.7563 
2025-03-30 22:59:15.818929: Pseudo dice [np.float32(0.9126), np.float32(0.8982)] 
2025-03-30 22:59:15.818992: Epoch time: 26.72 s 
2025-03-30 22:59:16.614695:  
2025-03-30 22:59:16.614843: Epoch 721 
2025-03-30 22:59:16.614923: Current learning rate: 0.00317 
2025-03-30 22:59:43.380422: train_loss -0.8055 
2025-03-30 22:59:43.380586: val_loss -0.7797 
2025-03-30 22:59:43.380643: Pseudo dice [np.float32(0.9254), np.float32(0.9055)] 
2025-03-30 22:59:43.380703: Epoch time: 26.77 s 
2025-03-30 22:59:44.168497:  
2025-03-30 22:59:44.168665: Epoch 722 
2025-03-30 22:59:44.168769: Current learning rate: 0.00316 
2025-03-30 23:00:10.918158: train_loss -0.7961 
2025-03-30 23:00:10.918284: val_loss -0.7796 
2025-03-30 23:00:10.918339: Pseudo dice [np.float32(0.9208), np.float32(0.9064)] 
2025-03-30 23:00:10.918404: Epoch time: 26.75 s 
2025-03-30 23:00:11.709089:  
2025-03-30 23:00:11.709226: Epoch 723 
2025-03-30 23:00:11.709316: Current learning rate: 0.00315 
2025-03-30 23:00:38.417279: train_loss -0.7993 
2025-03-30 23:00:38.417425: val_loss -0.7643 
2025-03-30 23:00:38.417482: Pseudo dice [np.float32(0.9164), np.float32(0.9025)] 
2025-03-30 23:00:38.417544: Epoch time: 26.71 s 
2025-03-30 23:00:39.805721:  
2025-03-30 23:00:39.805913: Epoch 724 
2025-03-30 23:00:39.806002: Current learning rate: 0.00314 
2025-03-30 23:01:06.560788: train_loss -0.789 
2025-03-30 23:01:06.560935: val_loss -0.7251 
2025-03-30 23:01:06.560990: Pseudo dice [np.float32(0.8991), np.float32(0.8727)] 
2025-03-30 23:01:06.561098: Epoch time: 26.76 s 
2025-03-30 23:01:07.343929:  
2025-03-30 23:01:07.344096: Epoch 725 
2025-03-30 23:01:07.344189: Current learning rate: 0.00313 
2025-03-30 23:01:34.126528: train_loss -0.7998 
2025-03-30 23:01:34.126658: val_loss -0.7872 
2025-03-30 23:01:34.126714: Pseudo dice [np.float32(0.9248), np.float32(0.9087)] 
2025-03-30 23:01:34.126782: Epoch time: 26.78 s 
2025-03-30 23:01:34.914878:  
2025-03-30 23:01:34.915078: Epoch 726 
2025-03-30 23:01:34.915159: Current learning rate: 0.00312 
2025-03-30 23:02:01.633562: train_loss -0.8143 
2025-03-30 23:02:01.633715: val_loss -0.7457 
2025-03-30 23:02:01.633778: Pseudo dice [np.float32(0.9026), np.float32(0.8942)] 
2025-03-30 23:02:01.633853: Epoch time: 26.72 s 
2025-03-30 23:02:02.427840:  
2025-03-30 23:02:02.428051: Epoch 727 
2025-03-30 23:02:02.428150: Current learning rate: 0.00311 
2025-03-30 23:02:29.173564: train_loss -0.8218 
2025-03-30 23:02:29.173719: val_loss -0.7926 
2025-03-30 23:02:29.173822: Pseudo dice [np.float32(0.9199), np.float32(0.913)] 
2025-03-30 23:02:29.173885: Epoch time: 26.75 s 
2025-03-30 23:02:29.959285:  
2025-03-30 23:02:29.959461: Epoch 728 
2025-03-30 23:02:29.959562: Current learning rate: 0.0031 
2025-03-30 23:02:56.651558: train_loss -0.8115 
2025-03-30 23:02:56.651683: val_loss -0.7727 
2025-03-30 23:02:56.651737: Pseudo dice [np.float32(0.9215), np.float32(0.9023)] 
2025-03-30 23:02:56.651817: Epoch time: 26.69 s 
2025-03-30 23:02:57.437858:  
2025-03-30 23:02:57.438032: Epoch 729 
2025-03-30 23:02:57.438110: Current learning rate: 0.00309 
2025-03-30 23:03:24.220161: train_loss -0.7985 
2025-03-30 23:03:24.220292: val_loss -0.7431 
2025-03-30 23:03:24.220348: Pseudo dice [np.float32(0.8985), np.float32(0.8997)] 
2025-03-30 23:03:24.220409: Epoch time: 26.78 s 
2025-03-30 23:03:25.015196:  
2025-03-30 23:03:25.015379: Epoch 730 
2025-03-30 23:03:25.015462: Current learning rate: 0.00308 
2025-03-30 23:03:51.707169: train_loss -0.813 
2025-03-30 23:03:51.707309: val_loss -0.7707 
2025-03-30 23:03:51.707381: Pseudo dice [np.float32(0.9104), np.float32(0.912)] 
2025-03-30 23:03:51.707442: Epoch time: 26.69 s 
2025-03-30 23:03:52.488431:  
2025-03-30 23:03:52.488596: Epoch 731 
2025-03-30 23:03:52.488672: Current learning rate: 0.00307 
2025-03-30 23:04:19.227496: train_loss -0.8095 
2025-03-30 23:04:19.227628: val_loss -0.7903 
2025-03-30 23:04:19.227710: Pseudo dice [np.float32(0.9181), np.float32(0.9123)] 
2025-03-30 23:04:19.227780: Epoch time: 26.74 s 
2025-03-30 23:04:20.017840:  
2025-03-30 23:04:20.017994: Epoch 732 
2025-03-30 23:04:20.018073: Current learning rate: 0.00306 
2025-03-30 23:04:46.787007: train_loss -0.8026 
2025-03-30 23:04:46.787149: val_loss -0.7235 
2025-03-30 23:04:46.787205: Pseudo dice [np.float32(0.8942), np.float32(0.8933)] 
2025-03-30 23:04:46.787265: Epoch time: 26.77 s 
2025-03-30 23:04:47.577275:  
2025-03-30 23:04:47.577423: Epoch 733 
2025-03-30 23:04:47.577500: Current learning rate: 0.00305 
2025-03-30 23:05:14.284743: train_loss -0.7911 
2025-03-30 23:05:14.284932: val_loss -0.7801 
2025-03-30 23:05:14.284989: Pseudo dice [np.float32(0.9152), np.float32(0.9146)] 
2025-03-30 23:05:14.285049: Epoch time: 26.71 s 
2025-03-30 23:05:15.079766:  
2025-03-30 23:05:15.079916: Epoch 734 
2025-03-30 23:05:15.079987: Current learning rate: 0.00304 
2025-03-30 23:05:41.810695: train_loss -0.8182 
2025-03-30 23:05:41.810849: val_loss -0.7902 
2025-03-30 23:05:41.810906: Pseudo dice [np.float32(0.9268), np.float32(0.9157)] 
2025-03-30 23:05:41.810969: Epoch time: 26.73 s 
2025-03-30 23:05:42.599484:  
2025-03-30 23:05:42.599655: Epoch 735 
2025-03-30 23:05:42.599735: Current learning rate: 0.00303 
2025-03-30 23:06:09.362900: train_loss -0.8239 
2025-03-30 23:06:09.363034: val_loss -0.8036 
2025-03-30 23:06:09.363090: Pseudo dice [np.float32(0.9217), np.float32(0.924)] 
2025-03-30 23:06:09.363152: Epoch time: 26.76 s 
2025-03-30 23:06:10.148391:  
2025-03-30 23:06:10.148541: Epoch 736 
2025-03-30 23:06:10.148617: Current learning rate: 0.00302 
2025-03-30 23:06:36.865988: train_loss -0.8258 
2025-03-30 23:06:36.866115: val_loss -0.7623 
2025-03-30 23:06:36.866170: Pseudo dice [np.float32(0.9097), np.float32(0.8937)] 
2025-03-30 23:06:36.866231: Epoch time: 26.72 s 
2025-03-30 23:06:37.656973:  
2025-03-30 23:06:37.657169: Epoch 737 
2025-03-30 23:06:37.657251: Current learning rate: 0.00301 
2025-03-30 23:07:04.463886: train_loss -0.8178 
2025-03-30 23:07:04.464048: val_loss -0.7975 
2025-03-30 23:07:04.464104: Pseudo dice [np.float32(0.9233), np.float32(0.9178)] 
2025-03-30 23:07:04.464164: Epoch time: 26.81 s 
2025-03-30 23:07:05.251119:  
2025-03-30 23:07:05.251278: Epoch 738 
2025-03-30 23:07:05.251355: Current learning rate: 0.003 
2025-03-30 23:07:32.020070: train_loss -0.8346 
2025-03-30 23:07:32.020358: val_loss -0.8046 
2025-03-30 23:07:32.020429: Pseudo dice [np.float32(0.9313), np.float32(0.9237)] 
2025-03-30 23:07:32.020508: Epoch time: 26.77 s 
2025-03-30 23:07:32.809880:  
2025-03-30 23:07:32.810051: Epoch 739 
2025-03-30 23:07:32.810151: Current learning rate: 0.00299 
2025-03-30 23:07:59.514841: train_loss -0.8366 
2025-03-30 23:07:59.514984: val_loss -0.7897 
2025-03-30 23:07:59.515041: Pseudo dice [np.float32(0.922), np.float32(0.9178)] 
2025-03-30 23:07:59.515099: Epoch time: 26.71 s 
2025-03-30 23:08:00.306703:  
2025-03-30 23:08:00.306909: Epoch 740 
2025-03-30 23:08:00.306994: Current learning rate: 0.00297 
2025-03-30 23:08:27.048733: train_loss -0.8268 
2025-03-30 23:08:27.048914: val_loss -0.766 
2025-03-30 23:08:27.048972: Pseudo dice [np.float32(0.9161), np.float32(0.9024)] 
2025-03-30 23:08:27.049035: Epoch time: 26.74 s 
2025-03-30 23:08:27.834517:  
2025-03-30 23:08:27.834682: Epoch 741 
2025-03-30 23:08:27.834769: Current learning rate: 0.00296 
2025-03-30 23:08:54.639446: train_loss -0.8272 
2025-03-30 23:08:54.639674: val_loss -0.796 
2025-03-30 23:08:54.639731: Pseudo dice [np.float32(0.9262), np.float32(0.9118)] 
2025-03-30 23:08:54.639803: Epoch time: 26.81 s 
2025-03-30 23:08:55.425305:  
2025-03-30 23:08:55.425470: Epoch 742 
2025-03-30 23:08:55.425552: Current learning rate: 0.00295 
2025-03-30 23:09:22.228001: train_loss -0.8169 
2025-03-30 23:09:22.228256: val_loss -0.7734 
2025-03-30 23:09:22.228321: Pseudo dice [np.float32(0.9145), np.float32(0.9096)] 
2025-03-30 23:09:22.228390: Epoch time: 26.8 s 
2025-03-30 23:09:23.596262:  
2025-03-30 23:09:23.596445: Epoch 743 
2025-03-30 23:09:23.596531: Current learning rate: 0.00294 
2025-03-30 23:09:50.344127: train_loss -0.8267 
2025-03-30 23:09:50.344255: val_loss -0.7884 
2025-03-30 23:09:50.344310: Pseudo dice [np.float32(0.9251), np.float32(0.9155)] 
2025-03-30 23:09:50.344370: Epoch time: 26.75 s 
2025-03-30 23:09:51.129427:  
2025-03-30 23:09:51.129633: Epoch 744 
2025-03-30 23:09:51.129717: Current learning rate: 0.00293 
2025-03-30 23:10:17.855861: train_loss -0.8309 
2025-03-30 23:10:17.856071: val_loss -0.7861 
2025-03-30 23:10:17.856128: Pseudo dice [np.float32(0.9171), np.float32(0.9157)] 
2025-03-30 23:10:17.856189: Epoch time: 26.73 s 
2025-03-30 23:10:18.646604:  
2025-03-30 23:10:18.646821: Epoch 745 
2025-03-30 23:10:18.646910: Current learning rate: 0.00292 
2025-03-30 23:10:45.382009: train_loss -0.8253 
2025-03-30 23:10:45.382209: val_loss -0.7843 
2025-03-30 23:10:45.382265: Pseudo dice [np.float32(0.9189), np.float32(0.9184)] 
2025-03-30 23:10:45.382326: Epoch time: 26.74 s 
2025-03-30 23:10:45.382374: Yayy! New best EMA pseudo Dice: 0.9147999882698059 
2025-03-30 23:10:46.689011:  
2025-03-30 23:10:46.689193: Epoch 746 
2025-03-30 23:10:46.689273: Current learning rate: 0.00291 
2025-03-30 23:11:13.447662: train_loss -0.8203 
2025-03-30 23:11:13.447805: val_loss -0.7831 
2025-03-30 23:11:13.447864: Pseudo dice [np.float32(0.913), np.float32(0.9217)] 
2025-03-30 23:11:13.447927: Epoch time: 26.76 s 
2025-03-30 23:11:13.447999: Yayy! New best EMA pseudo Dice: 0.9150000214576721 
2025-03-30 23:11:14.785865:  
2025-03-30 23:11:14.786039: Epoch 747 
2025-03-30 23:11:14.786121: Current learning rate: 0.0029 
2025-03-30 23:11:41.522498: train_loss -0.8061 
2025-03-30 23:11:41.522645: val_loss -0.7736 
2025-03-30 23:11:41.522701: Pseudo dice [np.float32(0.9078), np.float32(0.9125)] 
2025-03-30 23:11:41.522777: Epoch time: 26.74 s 
2025-03-30 23:11:42.317051:  
2025-03-30 23:11:42.317248: Epoch 748 
2025-03-30 23:11:42.317328: Current learning rate: 0.00289 
2025-03-30 23:12:09.064268: train_loss -0.8018 
2025-03-30 23:12:09.064418: val_loss -0.797 
2025-03-30 23:12:09.064496: Pseudo dice [np.float32(0.9269), np.float32(0.9157)] 
2025-03-30 23:12:09.064560: Epoch time: 26.75 s 
2025-03-30 23:12:09.064609: Yayy! New best EMA pseudo Dice: 0.9151999950408936 
2025-03-30 23:12:10.430153:  
2025-03-30 23:12:10.430332: Epoch 749 
2025-03-30 23:12:10.430412: Current learning rate: 0.00288 
2025-03-30 23:12:37.132631: train_loss -0.809 
2025-03-30 23:12:37.132804: val_loss -0.7755 
2025-03-30 23:12:37.132863: Pseudo dice [np.float32(0.9133), np.float32(0.9149)] 
2025-03-30 23:12:37.132930: Epoch time: 26.7 s 
2025-03-30 23:12:38.445549:  
2025-03-30 23:12:38.445731: Epoch 750 
2025-03-30 23:12:38.445835: Current learning rate: 0.00287 
2025-03-30 23:13:05.209998: train_loss -0.8189 
2025-03-30 23:13:05.210121: val_loss -0.805 
2025-03-30 23:13:05.210220: Pseudo dice [np.float32(0.9238), np.float32(0.9203)] 
2025-03-30 23:13:05.210285: Epoch time: 26.77 s 
2025-03-30 23:13:05.210333: Yayy! New best EMA pseudo Dice: 0.9157999753952026 
2025-03-30 23:13:08.770041:  
2025-03-30 23:13:08.770229: Epoch 751 
2025-03-30 23:13:08.770310: Current learning rate: 0.00286 
2025-03-30 23:13:35.481135: train_loss -0.8397 
2025-03-30 23:13:35.481272: val_loss -0.7792 
2025-03-30 23:13:35.481328: Pseudo dice [np.float32(0.9137), np.float32(0.9163)] 
2025-03-30 23:13:35.481391: Epoch time: 26.71 s 
2025-03-30 23:13:36.279154:  
2025-03-30 23:13:36.279309: Epoch 752 
2025-03-30 23:13:36.279402: Current learning rate: 0.00285 
2025-03-30 23:14:03.026422: train_loss -0.8139 
2025-03-30 23:14:03.026562: val_loss -0.7674 
2025-03-30 23:14:03.026636: Pseudo dice [np.float32(0.918), np.float32(0.8994)] 
2025-03-30 23:14:03.026702: Epoch time: 26.75 s 
2025-03-30 23:14:03.816100:  
2025-03-30 23:14:03.816247: Epoch 753 
2025-03-30 23:14:03.816340: Current learning rate: 0.00284 
2025-03-30 23:14:30.573870: train_loss -0.8208 
2025-03-30 23:14:30.573992: val_loss -0.7898 
2025-03-30 23:14:30.574048: Pseudo dice [np.float32(0.9217), np.float32(0.9177)] 
2025-03-30 23:14:30.574109: Epoch time: 26.76 s 
2025-03-30 23:14:31.359295:  
2025-03-30 23:14:31.359459: Epoch 754 
2025-03-30 23:14:31.359541: Current learning rate: 0.00283 
2025-03-30 23:14:58.062108: train_loss -0.8098 
2025-03-30 23:14:58.062294: val_loss -0.7493 
2025-03-30 23:14:58.062353: Pseudo dice [np.float32(0.8946), np.float32(0.909)] 
2025-03-30 23:14:58.062415: Epoch time: 26.7 s 
2025-03-30 23:14:58.850577:  
2025-03-30 23:14:58.850782: Epoch 755 
2025-03-30 23:14:58.850878: Current learning rate: 0.00282 
2025-03-30 23:15:25.595033: train_loss -0.8171 
2025-03-30 23:15:25.595274: val_loss -0.7852 
2025-03-30 23:15:25.595331: Pseudo dice [np.float32(0.9205), np.float32(0.9165)] 
2025-03-30 23:15:25.595395: Epoch time: 26.75 s 
2025-03-30 23:15:26.389193:  
2025-03-30 23:15:26.389352: Epoch 756 
2025-03-30 23:15:26.389435: Current learning rate: 0.00281 
2025-03-30 23:15:53.129997: train_loss -0.8088 
2025-03-30 23:15:53.130141: val_loss -0.7878 
2025-03-30 23:15:53.130197: Pseudo dice [np.float32(0.9188), np.float32(0.914)] 
2025-03-30 23:15:53.130260: Epoch time: 26.74 s 
2025-03-30 23:15:53.913879:  
2025-03-30 23:15:53.914040: Epoch 757 
2025-03-30 23:15:53.914118: Current learning rate: 0.0028 
2025-03-30 23:16:20.668635: train_loss -0.8184 
2025-03-30 23:16:20.668789: val_loss -0.8118 
2025-03-30 23:16:20.668848: Pseudo dice [np.float32(0.9293), np.float32(0.9204)] 
2025-03-30 23:16:20.668909: Epoch time: 26.76 s 
2025-03-30 23:16:21.463476:  
2025-03-30 23:16:21.463641: Epoch 758 
2025-03-30 23:16:21.463724: Current learning rate: 0.00279 
2025-03-30 23:16:48.218202: train_loss -0.812 
2025-03-30 23:16:48.218371: val_loss -0.7797 
2025-03-30 23:16:48.218428: Pseudo dice [np.float32(0.9148), np.float32(0.9126)] 
2025-03-30 23:16:48.218489: Epoch time: 26.76 s 
2025-03-30 23:16:49.004019:  
2025-03-30 23:16:49.004172: Epoch 759 
2025-03-30 23:16:49.004248: Current learning rate: 0.00278 
2025-03-30 23:17:15.759317: train_loss -0.8165 
2025-03-30 23:17:15.759438: val_loss -0.782 
2025-03-30 23:17:15.759493: Pseudo dice [np.float32(0.9183), np.float32(0.9079)] 
2025-03-30 23:17:15.759551: Epoch time: 26.76 s 
2025-03-30 23:17:16.542424:  
2025-03-30 23:17:16.542563: Epoch 760 
2025-03-30 23:17:16.542644: Current learning rate: 0.00277 
2025-03-30 23:17:43.307059: train_loss -0.8133 
2025-03-30 23:17:43.307297: val_loss -0.7627 
2025-03-30 23:17:43.307356: Pseudo dice [np.float32(0.9093), np.float32(0.9081)] 
2025-03-30 23:17:43.307429: Epoch time: 26.77 s 
2025-03-30 23:17:44.650915:  
2025-03-30 23:17:44.651082: Epoch 761 
2025-03-30 23:17:44.651156: Current learning rate: 0.00276 
2025-03-30 23:18:11.402166: train_loss -0.8177 
2025-03-30 23:18:11.402308: val_loss -0.7739 
2025-03-30 23:18:11.402363: Pseudo dice [np.float32(0.9094), np.float32(0.9152)] 
2025-03-30 23:18:11.402424: Epoch time: 26.75 s 
2025-03-30 23:18:12.192894:  
2025-03-30 23:18:12.193073: Epoch 762 
2025-03-30 23:18:12.193168: Current learning rate: 0.00275 
2025-03-30 23:18:38.906833: train_loss -0.8203 
2025-03-30 23:18:38.906974: val_loss -0.7935 
2025-03-30 23:18:38.907029: Pseudo dice [np.float32(0.9203), np.float32(0.9128)] 
2025-03-30 23:18:38.907089: Epoch time: 26.72 s 
2025-03-30 23:18:39.699715:  
2025-03-30 23:18:39.699935: Epoch 763 
2025-03-30 23:18:39.700024: Current learning rate: 0.00274 
2025-03-30 23:19:06.456818: train_loss -0.8204 
2025-03-30 23:19:06.456944: val_loss -0.7768 
2025-03-30 23:19:06.457001: Pseudo dice [np.float32(0.9156), np.float32(0.9123)] 
2025-03-30 23:19:06.457106: Epoch time: 26.76 s 
2025-03-30 23:19:07.249945:  
2025-03-30 23:19:07.250120: Epoch 764 
2025-03-30 23:19:07.250199: Current learning rate: 0.00273 
2025-03-30 23:19:33.937022: train_loss -0.8306 
2025-03-30 23:19:33.937288: val_loss -0.7802 
2025-03-30 23:19:33.937346: Pseudo dice [np.float32(0.9156), np.float32(0.9034)] 
2025-03-30 23:19:33.937408: Epoch time: 26.69 s 
2025-03-30 23:19:34.730993:  
2025-03-30 23:19:34.731160: Epoch 765 
2025-03-30 23:19:34.731244: Current learning rate: 0.00272 
2025-03-30 23:20:01.474341: train_loss -0.8387 
2025-03-30 23:20:01.474512: val_loss -0.7779 
2025-03-30 23:20:01.474574: Pseudo dice [np.float32(0.9142), np.float32(0.9207)] 
2025-03-30 23:20:01.474637: Epoch time: 26.74 s 
2025-03-30 23:20:02.272472:  
2025-03-30 23:20:02.272630: Epoch 766 
2025-03-30 23:20:02.272728: Current learning rate: 0.00271 
2025-03-30 23:20:29.019698: train_loss -0.8303 
2025-03-30 23:20:29.019994: val_loss -0.8142 
2025-03-30 23:20:29.020056: Pseudo dice [np.float32(0.9296), np.float32(0.9216)] 
2025-03-30 23:20:29.020118: Epoch time: 26.75 s 
2025-03-30 23:20:29.811472:  
2025-03-30 23:20:29.811651: Epoch 767 
2025-03-30 23:20:29.811732: Current learning rate: 0.0027 
2025-03-30 23:20:56.537710: train_loss -0.8406 
2025-03-30 23:20:56.537946: val_loss -0.8059 
2025-03-30 23:20:56.538004: Pseudo dice [np.float32(0.9251), np.float32(0.9177)] 
2025-03-30 23:20:56.538067: Epoch time: 26.73 s 
2025-03-30 23:20:56.538116: Yayy! New best EMA pseudo Dice: 0.916100025177002 
2025-03-30 23:20:57.842060:  
2025-03-30 23:20:57.842227: Epoch 768 
2025-03-30 23:20:57.842306: Current learning rate: 0.00268 
2025-03-30 23:21:24.542551: train_loss -0.8292 
2025-03-30 23:21:24.542867: val_loss -0.7963 
2025-03-30 23:21:24.542928: Pseudo dice [np.float32(0.9199), np.float32(0.9213)] 
2025-03-30 23:21:24.542993: Epoch time: 26.7 s 
2025-03-30 23:21:24.543041: Yayy! New best EMA pseudo Dice: 0.9165999889373779 
2025-03-30 23:21:25.903882:  
2025-03-30 23:21:25.904067: Epoch 769 
2025-03-30 23:21:25.904170: Current learning rate: 0.00267 
2025-03-30 23:21:52.636362: train_loss -0.8413 
2025-03-30 23:21:52.636497: val_loss -0.7853 
2025-03-30 23:21:52.636552: Pseudo dice [np.float32(0.9189), np.float32(0.9098)] 
2025-03-30 23:21:52.636613: Epoch time: 26.73 s 
2025-03-30 23:21:53.429327:  
2025-03-30 23:21:53.429472: Epoch 770 
2025-03-30 23:21:53.429565: Current learning rate: 0.00266 
2025-03-30 23:22:20.309215: train_loss -0.8477 
2025-03-30 23:22:20.309390: val_loss -0.8056 
2025-03-30 23:22:20.309446: Pseudo dice [np.float32(0.9248), np.float32(0.928)] 
2025-03-30 23:22:20.309506: Epoch time: 26.88 s 
2025-03-30 23:22:20.309554: Yayy! New best EMA pseudo Dice: 0.9172999858856201 
2025-03-30 23:22:22.340968:  
2025-03-30 23:22:22.341115: Epoch 771 
2025-03-30 23:22:22.341204: Current learning rate: 0.00265 
2025-03-30 23:22:49.103467: train_loss -0.8463 
2025-03-30 23:22:49.103606: val_loss -0.7993 
2025-03-30 23:22:49.103674: Pseudo dice [np.float32(0.9276), np.float32(0.9221)] 
2025-03-30 23:22:49.103734: Epoch time: 26.76 s 
2025-03-30 23:22:49.103790: Yayy! New best EMA pseudo Dice: 0.9180999994277954 
2025-03-30 23:22:50.474442:  
2025-03-30 23:22:50.474612: Epoch 772 
2025-03-30 23:22:50.474693: Current learning rate: 0.00264 
2025-03-30 23:23:17.208285: train_loss -0.8355 
2025-03-30 23:23:17.208422: val_loss -0.7656 
2025-03-30 23:23:17.208499: Pseudo dice [np.float32(0.9114), np.float32(0.911)] 
2025-03-30 23:23:17.208579: Epoch time: 26.73 s 
2025-03-30 23:23:18.185229:  
2025-03-30 23:23:18.185397: Epoch 773 
2025-03-30 23:23:18.185481: Current learning rate: 0.00263 
2025-03-30 23:23:44.905991: train_loss -0.828 
2025-03-30 23:23:44.906123: val_loss -0.7774 
2025-03-30 23:23:44.906178: Pseudo dice [np.float32(0.9183), np.float32(0.9047)] 
2025-03-30 23:23:44.906241: Epoch time: 26.72 s 
2025-03-30 23:23:45.698963:  
2025-03-30 23:23:45.699116: Epoch 774 
2025-03-30 23:23:45.699209: Current learning rate: 0.00262 
2025-03-30 23:24:12.476035: train_loss -0.8279 
2025-03-30 23:24:12.476233: val_loss -0.7913 
2025-03-30 23:24:12.476290: Pseudo dice [np.float32(0.9267), np.float32(0.9115)] 
2025-03-30 23:24:12.476352: Epoch time: 26.78 s 
2025-03-30 23:24:13.271625:  
2025-03-30 23:24:13.271776: Epoch 775 
2025-03-30 23:24:13.271868: Current learning rate: 0.00261 
2025-03-30 23:24:39.969415: train_loss -0.8285 
2025-03-30 23:24:39.969569: val_loss -0.7727 
2025-03-30 23:24:39.969624: Pseudo dice [np.float32(0.919), np.float32(0.9022)] 
2025-03-30 23:24:39.969685: Epoch time: 26.7 s 
2025-03-30 23:24:40.766222:  
2025-03-30 23:24:40.766381: Epoch 776 
2025-03-30 23:24:40.766506: Current learning rate: 0.0026 
2025-03-30 23:25:07.532864: train_loss -0.8163 
2025-03-30 23:25:07.533059: val_loss -0.7658 
2025-03-30 23:25:07.533117: Pseudo dice [np.float32(0.9052), np.float32(0.9131)] 
2025-03-30 23:25:07.533180: Epoch time: 26.77 s 
2025-03-30 23:25:08.332636:  
2025-03-30 23:25:08.332801: Epoch 777 
2025-03-30 23:25:08.332906: Current learning rate: 0.00259 
2025-03-30 23:25:35.053819: train_loss -0.8246 
2025-03-30 23:25:35.053965: val_loss -0.7901 
2025-03-30 23:25:35.054059: Pseudo dice [np.float32(0.9216), np.float32(0.907)] 
2025-03-30 23:25:35.054121: Epoch time: 26.72 s 
2025-03-30 23:25:35.857032:  
2025-03-30 23:25:35.857221: Epoch 778 
2025-03-30 23:25:35.857308: Current learning rate: 0.00258 
2025-03-30 23:26:02.578273: train_loss -0.819 
2025-03-30 23:26:02.578468: val_loss -0.7715 
2025-03-30 23:26:02.578524: Pseudo dice [np.float32(0.9142), np.float32(0.9071)] 
2025-03-30 23:26:02.578590: Epoch time: 26.72 s 
2025-03-30 23:26:03.373680:  
2025-03-30 23:26:03.373859: Epoch 779 
2025-03-30 23:26:03.373949: Current learning rate: 0.00257 
2025-03-30 23:26:30.094947: train_loss -0.8239 
2025-03-30 23:26:30.095094: val_loss -0.7875 
2025-03-30 23:26:30.095157: Pseudo dice [np.float32(0.9191), np.float32(0.9117)] 
2025-03-30 23:26:30.095226: Epoch time: 26.72 s 
2025-03-30 23:26:31.491598:  
2025-03-30 23:26:31.491792: Epoch 780 
2025-03-30 23:26:31.491886: Current learning rate: 0.00256 
2025-03-30 23:26:58.206860: train_loss -0.8301 
2025-03-30 23:26:58.207025: val_loss -0.8097 
2025-03-30 23:26:58.207082: Pseudo dice [np.float32(0.9254), np.float32(0.9211)] 
2025-03-30 23:26:58.207145: Epoch time: 26.72 s 
2025-03-30 23:26:58.999555:  
2025-03-30 23:26:58.999747: Epoch 781 
2025-03-30 23:26:58.999849: Current learning rate: 0.00255 
2025-03-30 23:27:25.758660: train_loss -0.8393 
2025-03-30 23:27:25.758816: val_loss -0.8041 
2025-03-30 23:27:25.758874: Pseudo dice [np.float32(0.9268), np.float32(0.9218)] 
2025-03-30 23:27:25.758946: Epoch time: 26.76 s 
2025-03-30 23:27:26.548736:  
2025-03-30 23:27:26.548926: Epoch 782 
2025-03-30 23:27:26.549007: Current learning rate: 0.00254 
2025-03-30 23:27:53.291405: train_loss -0.8317 
2025-03-30 23:27:53.291538: val_loss -0.796 
2025-03-30 23:27:53.291593: Pseudo dice [np.float32(0.9216), np.float32(0.9199)] 
2025-03-30 23:27:53.291653: Epoch time: 26.74 s 
2025-03-30 23:27:54.085150:  
2025-03-30 23:27:54.085319: Epoch 783 
2025-03-30 23:27:54.085408: Current learning rate: 0.00253 
2025-03-30 23:28:20.846689: train_loss -0.828 
2025-03-30 23:28:20.846844: val_loss -0.7819 
2025-03-30 23:28:20.846902: Pseudo dice [np.float32(0.9188), np.float32(0.913)] 
2025-03-30 23:28:20.846962: Epoch time: 26.76 s 
2025-03-30 23:28:21.646651:  
2025-03-30 23:28:21.646848: Epoch 784 
2025-03-30 23:28:21.646938: Current learning rate: 0.00252 
2025-03-30 23:28:48.375096: train_loss -0.8206 
2025-03-30 23:28:48.375259: val_loss -0.7782 
2025-03-30 23:28:48.375314: Pseudo dice [np.float32(0.9203), np.float32(0.9065)] 
2025-03-30 23:28:48.375373: Epoch time: 26.73 s 
2025-03-30 23:28:49.172947:  
2025-03-30 23:28:49.173113: Epoch 785 
2025-03-30 23:28:49.173195: Current learning rate: 0.00251 
2025-03-30 23:29:15.896585: train_loss -0.8192 
2025-03-30 23:29:15.896729: val_loss -0.7887 
2025-03-30 23:29:15.896799: Pseudo dice [np.float32(0.9159), np.float32(0.9183)] 
2025-03-30 23:29:15.896869: Epoch time: 26.72 s 
2025-03-30 23:29:16.699938:  
2025-03-30 23:29:16.700101: Epoch 786 
2025-03-30 23:29:16.700182: Current learning rate: 0.0025 
2025-03-30 23:29:43.469298: train_loss -0.8197 
2025-03-30 23:29:43.469431: val_loss -0.7717 
2025-03-30 23:29:43.469489: Pseudo dice [np.float32(0.9093), np.float32(0.9173)] 
2025-03-30 23:29:43.469547: Epoch time: 26.77 s 
2025-03-30 23:29:44.261331:  
2025-03-30 23:29:44.261493: Epoch 787 
2025-03-30 23:29:44.261576: Current learning rate: 0.00249 
2025-03-30 23:30:11.031585: train_loss -0.8345 
2025-03-30 23:30:11.031745: val_loss -0.7917 
2025-03-30 23:30:11.031812: Pseudo dice [np.float32(0.9191), np.float32(0.9112)] 
2025-03-30 23:30:11.031873: Epoch time: 26.77 s 
2025-03-30 23:30:11.825828:  
2025-03-30 23:30:11.826001: Epoch 788 
2025-03-30 23:30:11.826083: Current learning rate: 0.00248 
2025-03-30 23:30:38.593278: train_loss -0.8353 
2025-03-30 23:30:38.593431: val_loss -0.8085 
2025-03-30 23:30:38.593497: Pseudo dice [np.float32(0.932), np.float32(0.9253)] 
2025-03-30 23:30:38.593568: Epoch time: 26.77 s 
2025-03-30 23:30:39.391754:  
2025-03-30 23:30:39.391906: Epoch 789 
2025-03-30 23:30:39.392004: Current learning rate: 0.00247 
2025-03-30 23:31:06.102738: train_loss -0.8485 
2025-03-30 23:31:06.102878: val_loss -0.7969 
2025-03-30 23:31:06.102933: Pseudo dice [np.float32(0.9172), np.float32(0.9209)] 
2025-03-30 23:31:06.102993: Epoch time: 26.71 s 
2025-03-30 23:31:06.890592:  
2025-03-30 23:31:06.890757: Epoch 790 
2025-03-30 23:31:06.890860: Current learning rate: 0.00245 
2025-03-30 23:31:33.649147: train_loss -0.8428 
2025-03-30 23:31:33.649277: val_loss -0.8086 
2025-03-30 23:31:33.649349: Pseudo dice [np.float32(0.9264), np.float32(0.926)] 
2025-03-30 23:31:33.649410: Epoch time: 26.76 s 
2025-03-30 23:31:33.649458: Yayy! New best EMA pseudo Dice: 0.9185000061988831 
2025-03-30 23:31:35.010745:  
2025-03-30 23:31:35.010928: Epoch 791 
2025-03-30 23:31:35.011008: Current learning rate: 0.00244 
2025-03-30 23:32:01.790127: train_loss -0.8394 
2025-03-30 23:32:01.790363: val_loss -0.7798 
2025-03-30 23:32:01.790422: Pseudo dice [np.float32(0.919), np.float32(0.9136)] 
2025-03-30 23:32:01.790487: Epoch time: 26.78 s 
2025-03-30 23:32:02.577032:  
2025-03-30 23:32:02.577201: Epoch 792 
2025-03-30 23:32:02.577283: Current learning rate: 0.00243 
2025-03-30 23:32:29.312619: train_loss -0.8372 
2025-03-30 23:32:29.312927: val_loss -0.8151 
2025-03-30 23:32:29.312987: Pseudo dice [np.float32(0.9321), np.float32(0.9293)] 
2025-03-30 23:32:29.313049: Epoch time: 26.74 s 
2025-03-30 23:32:29.313097: Yayy! New best EMA pseudo Dice: 0.9194999933242798 
2025-03-30 23:32:30.664152:  
2025-03-30 23:32:30.664307: Epoch 793 
2025-03-30 23:32:30.664387: Current learning rate: 0.00242 
2025-03-30 23:32:57.407710: train_loss -0.8445 
2025-03-30 23:32:57.407955: val_loss -0.7826 
2025-03-30 23:32:57.408015: Pseudo dice [np.float32(0.9146), np.float32(0.9152)] 
2025-03-30 23:32:57.408078: Epoch time: 26.74 s 
2025-03-30 23:32:58.200687:  
2025-03-30 23:32:58.200859: Epoch 794 
2025-03-30 23:32:58.200939: Current learning rate: 0.00241 
2025-03-30 23:33:24.898313: train_loss -0.8371 
2025-03-30 23:33:24.898514: val_loss -0.7936 
2025-03-30 23:33:24.898571: Pseudo dice [np.float32(0.9245), np.float32(0.9169)] 
2025-03-30 23:33:24.898630: Epoch time: 26.7 s 
2025-03-30 23:33:25.687696:  
2025-03-30 23:33:25.687874: Epoch 795 
2025-03-30 23:33:25.687955: Current learning rate: 0.0024 
2025-03-30 23:33:52.418372: train_loss -0.8364 
2025-03-30 23:33:52.418498: val_loss -0.7875 
2025-03-30 23:33:52.418553: Pseudo dice [np.float32(0.9125), np.float32(0.9173)] 
2025-03-30 23:33:52.418615: Epoch time: 26.73 s 
2025-03-30 23:33:53.211252:  
2025-03-30 23:33:53.211426: Epoch 796 
2025-03-30 23:33:53.211507: Current learning rate: 0.00239 
2025-03-30 23:34:19.966851: train_loss -0.8494 
2025-03-30 23:34:19.967030: val_loss -0.7918 
2025-03-30 23:34:19.967087: Pseudo dice [np.float32(0.9185), np.float32(0.9214)] 
2025-03-30 23:34:19.967151: Epoch time: 26.76 s 
2025-03-30 23:34:20.760011:  
2025-03-30 23:34:20.760163: Epoch 797 
2025-03-30 23:34:20.760245: Current learning rate: 0.00238 
2025-03-30 23:34:47.545205: train_loss -0.8458 
2025-03-30 23:34:47.545396: val_loss -0.7993 
2025-03-30 23:34:47.545452: Pseudo dice [np.float32(0.9273), np.float32(0.9208)] 
2025-03-30 23:34:47.545512: Epoch time: 26.79 s 
2025-03-30 23:34:48.944156:  
2025-03-30 23:34:48.944335: Epoch 798 
2025-03-30 23:34:48.944422: Current learning rate: 0.00237 
2025-03-30 23:35:15.656342: train_loss -0.8422 
2025-03-30 23:35:15.656492: val_loss -0.8043 
2025-03-30 23:35:15.656549: Pseudo dice [np.float32(0.9314), np.float32(0.9138)] 
2025-03-30 23:35:15.656614: Epoch time: 26.71 s 
2025-03-30 23:35:15.656663: Yayy! New best EMA pseudo Dice: 0.919700026512146 
2025-03-30 23:35:16.967598:  
2025-03-30 23:35:16.967800: Epoch 799 
2025-03-30 23:35:16.967871: Current learning rate: 0.00236 
2025-03-30 23:35:43.684669: train_loss -0.8431 
2025-03-30 23:35:43.684813: val_loss -0.7937 
2025-03-30 23:35:43.684871: Pseudo dice [np.float32(0.9207), np.float32(0.9145)] 
2025-03-30 23:35:43.684931: Epoch time: 26.72 s 
2025-03-30 23:35:44.992902:  
2025-03-30 23:35:44.993088: Epoch 800 
2025-03-30 23:35:44.993166: Current learning rate: 0.00235 
2025-03-30 23:36:11.727253: train_loss -0.8422 
2025-03-30 23:36:11.727387: val_loss -0.7896 
2025-03-30 23:36:11.727443: Pseudo dice [np.float32(0.9192), np.float32(0.9235)] 
2025-03-30 23:36:11.727544: Epoch time: 26.74 s 
2025-03-30 23:36:12.530426:  
2025-03-30 23:36:12.530599: Epoch 801 
2025-03-30 23:36:12.530679: Current learning rate: 0.00234 
2025-03-30 23:36:39.355623: train_loss -0.8401 
2025-03-30 23:36:39.355813: val_loss -0.8039 
2025-03-30 23:36:39.355871: Pseudo dice [np.float32(0.9252), np.float32(0.9255)] 
2025-03-30 23:36:39.355932: Epoch time: 26.83 s 
2025-03-30 23:36:39.355981: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2025-03-30 23:36:40.713127:  
2025-03-30 23:36:40.713321: Epoch 802 
2025-03-30 23:36:40.713408: Current learning rate: 0.00233 
2025-03-30 23:37:07.494830: train_loss -0.8277 
2025-03-30 23:37:07.494966: val_loss -0.8135 
2025-03-30 23:37:07.495023: Pseudo dice [np.float32(0.9322), np.float32(0.9268)] 
2025-03-30 23:37:07.495084: Epoch time: 26.78 s 
2025-03-30 23:37:07.495133: Yayy! New best EMA pseudo Dice: 0.9211999773979187 
2025-03-30 23:37:08.854666:  
2025-03-30 23:37:08.854877: Epoch 803 
2025-03-30 23:37:08.854961: Current learning rate: 0.00232 
2025-03-30 23:37:35.624174: train_loss -0.8386 
2025-03-30 23:37:35.624305: val_loss -0.7947 
2025-03-30 23:37:35.624360: Pseudo dice [np.float32(0.9206), np.float32(0.9127)] 
2025-03-30 23:37:35.624421: Epoch time: 26.77 s 
2025-03-30 23:37:36.414682:  
2025-03-30 23:37:36.414837: Epoch 804 
2025-03-30 23:37:36.414916: Current learning rate: 0.00231 
2025-03-30 23:38:03.232262: train_loss -0.8397 
2025-03-30 23:38:03.232390: val_loss -0.7942 
2025-03-30 23:38:03.232469: Pseudo dice [np.float32(0.9244), np.float32(0.9127)] 
2025-03-30 23:38:03.232548: Epoch time: 26.82 s 
2025-03-30 23:38:04.031903:  
2025-03-30 23:38:04.032090: Epoch 805 
2025-03-30 23:38:04.032182: Current learning rate: 0.0023 
2025-03-30 23:38:30.884790: train_loss -0.8389 
2025-03-30 23:38:30.885008: val_loss -0.8166 
2025-03-30 23:38:30.885065: Pseudo dice [np.float32(0.9316), np.float32(0.9242)] 
2025-03-30 23:38:30.885132: Epoch time: 26.85 s 
2025-03-30 23:38:30.885180: Yayy! New best EMA pseudo Dice: 0.9212999939918518 
2025-03-30 23:38:32.246453:  
2025-03-30 23:38:32.246637: Epoch 806 
2025-03-30 23:38:32.246717: Current learning rate: 0.00229 
2025-03-30 23:38:59.047451: train_loss -0.8411 
2025-03-30 23:38:59.047585: val_loss -0.8017 
2025-03-30 23:38:59.047639: Pseudo dice [np.float32(0.9319), np.float32(0.9157)] 
2025-03-30 23:38:59.047700: Epoch time: 26.8 s 
2025-03-30 23:38:59.047748: Yayy! New best EMA pseudo Dice: 0.921500027179718 
2025-03-30 23:39:00.376010:  
2025-03-30 23:39:00.376173: Epoch 807 
2025-03-30 23:39:00.376265: Current learning rate: 0.00228 
2025-03-30 23:39:27.122679: train_loss -0.8457 
2025-03-30 23:39:27.122847: val_loss -0.7926 
2025-03-30 23:39:27.122940: Pseudo dice [np.float32(0.9163), np.float32(0.9135)] 
2025-03-30 23:39:27.123004: Epoch time: 26.75 s 
2025-03-30 23:39:27.914748:  
2025-03-30 23:39:27.914926: Epoch 808 
2025-03-30 23:39:27.915002: Current learning rate: 0.00226 
2025-03-30 23:39:54.654595: train_loss -0.8406 
2025-03-30 23:39:54.654750: val_loss -0.7757 
2025-03-30 23:39:54.654817: Pseudo dice [np.float32(0.9156), np.float32(0.9068)] 
2025-03-30 23:39:54.654880: Epoch time: 26.74 s 
2025-03-30 23:39:55.442534:  
2025-03-30 23:39:55.442711: Epoch 809 
2025-03-30 23:39:55.442801: Current learning rate: 0.00225 
2025-03-30 23:40:22.137808: train_loss -0.8423 
2025-03-30 23:40:22.137938: val_loss -0.7775 
2025-03-30 23:40:22.137994: Pseudo dice [np.float32(0.9132), np.float32(0.9174)] 
2025-03-30 23:40:22.138055: Epoch time: 26.7 s 
2025-03-30 23:40:22.928365:  
2025-03-30 23:40:22.928528: Epoch 810 
2025-03-30 23:40:22.928615: Current learning rate: 0.00224 
2025-03-30 23:40:49.603839: train_loss -0.8418 
2025-03-30 23:40:49.603974: val_loss -0.7886 
2025-03-30 23:40:49.604029: Pseudo dice [np.float32(0.912), np.float32(0.9111)] 
2025-03-30 23:40:49.604091: Epoch time: 26.68 s 
2025-03-30 23:40:50.398731:  
2025-03-30 23:40:50.398886: Epoch 811 
2025-03-30 23:40:50.398990: Current learning rate: 0.00223 
2025-03-30 23:41:17.147728: train_loss -0.8465 
2025-03-30 23:41:17.147873: val_loss -0.7922 
2025-03-30 23:41:17.147928: Pseudo dice [np.float32(0.9296), np.float32(0.9084)] 
2025-03-30 23:41:17.147988: Epoch time: 26.75 s 
2025-03-30 23:41:17.940951:  
2025-03-30 23:41:17.941090: Epoch 812 
2025-03-30 23:41:17.941177: Current learning rate: 0.00222 
2025-03-30 23:41:44.671646: train_loss -0.8439 
2025-03-30 23:41:44.671862: val_loss -0.785 
2025-03-30 23:41:44.671922: Pseudo dice [np.float32(0.9192), np.float32(0.9088)] 
2025-03-30 23:41:44.671984: Epoch time: 26.73 s 
2025-03-30 23:41:45.460944:  
2025-03-30 23:41:45.461105: Epoch 813 
2025-03-30 23:41:45.461198: Current learning rate: 0.00221 
2025-03-30 23:42:12.215705: train_loss -0.8402 
2025-03-30 23:42:12.215856: val_loss -0.7967 
2025-03-30 23:42:12.215912: Pseudo dice [np.float32(0.9201), np.float32(0.9183)] 
2025-03-30 23:42:12.215973: Epoch time: 26.76 s 
2025-03-30 23:42:13.004009:  
2025-03-30 23:42:13.004151: Epoch 814 
2025-03-30 23:42:13.004267: Current learning rate: 0.0022 
2025-03-30 23:42:39.815495: train_loss -0.8455 
2025-03-30 23:42:39.815638: val_loss -0.8056 
2025-03-30 23:42:39.815703: Pseudo dice [np.float32(0.9213), np.float32(0.9214)] 
2025-03-30 23:42:39.815776: Epoch time: 26.81 s 
2025-03-30 23:42:41.182501:  
2025-03-30 23:42:41.182675: Epoch 815 
2025-03-30 23:42:41.182764: Current learning rate: 0.00219 
2025-03-30 23:43:07.910460: train_loss -0.8535 
2025-03-30 23:43:07.910622: val_loss -0.8269 
2025-03-30 23:43:07.910678: Pseudo dice [np.float32(0.9319), np.float32(0.9308)] 
2025-03-30 23:43:07.910738: Epoch time: 26.73 s 
2025-03-30 23:43:08.707748:  
2025-03-30 23:43:08.707954: Epoch 816 
2025-03-30 23:43:08.708045: Current learning rate: 0.00218 
2025-03-30 23:43:35.418846: train_loss -0.8391 
2025-03-30 23:43:35.419011: val_loss -0.8173 
2025-03-30 23:43:35.419104: Pseudo dice [np.float32(0.9328), np.float32(0.9278)] 
2025-03-30 23:43:35.419173: Epoch time: 26.71 s 
2025-03-30 23:43:36.210240:  
2025-03-30 23:43:36.210414: Epoch 817 
2025-03-30 23:43:36.210502: Current learning rate: 0.00217 
2025-03-30 23:44:02.915483: train_loss -0.8468 
2025-03-30 23:44:02.915610: val_loss -0.8137 
2025-03-30 23:44:02.915665: Pseudo dice [np.float32(0.9353), np.float32(0.9246)] 
2025-03-30 23:44:02.915725: Epoch time: 26.71 s 
2025-03-30 23:44:02.915826: Yayy! New best EMA pseudo Dice: 0.9218000173568726 
2025-03-30 23:44:04.231677:  
2025-03-30 23:44:04.231896: Epoch 818 
2025-03-30 23:44:04.232019: Current learning rate: 0.00216 
2025-03-30 23:44:30.939352: train_loss -0.8528 
2025-03-30 23:44:30.939484: val_loss -0.8015 
2025-03-30 23:44:30.939540: Pseudo dice [np.float32(0.9278), np.float32(0.9219)] 
2025-03-30 23:44:30.939603: Epoch time: 26.71 s 
2025-03-30 23:44:30.939651: Yayy! New best EMA pseudo Dice: 0.9221000075340271 
2025-03-30 23:44:32.293372:  
2025-03-30 23:44:32.293540: Epoch 819 
2025-03-30 23:44:32.293635: Current learning rate: 0.00215 
2025-03-30 23:44:59.026033: train_loss -0.8483 
2025-03-30 23:44:59.026170: val_loss -0.8148 
2025-03-30 23:44:59.026233: Pseudo dice [np.float32(0.9325), np.float32(0.9235)] 
2025-03-30 23:44:59.026302: Epoch time: 26.73 s 
2025-03-30 23:44:59.026357: Yayy! New best EMA pseudo Dice: 0.9226999878883362 
2025-03-30 23:45:00.361904:  
2025-03-30 23:45:00.362055: Epoch 820 
2025-03-30 23:45:00.362136: Current learning rate: 0.00214 
2025-03-30 23:45:27.040255: train_loss -0.8513 
2025-03-30 23:45:27.040387: val_loss -0.7837 
2025-03-30 23:45:27.040441: Pseudo dice [np.float32(0.9224), np.float32(0.9104)] 
2025-03-30 23:45:27.040503: Epoch time: 26.68 s 
2025-03-30 23:45:27.814442:  
2025-03-30 23:45:27.814598: Epoch 821 
2025-03-30 23:45:27.814677: Current learning rate: 0.00213 
2025-03-30 23:45:54.597811: train_loss -0.8439 
2025-03-30 23:45:54.597951: val_loss -0.8091 
2025-03-30 23:45:54.598020: Pseudo dice [np.float32(0.9275), np.float32(0.9296)] 
2025-03-30 23:45:54.598081: Epoch time: 26.78 s 
2025-03-30 23:45:54.598129: Yayy! New best EMA pseudo Dice: 0.9226999878883362 
2025-03-30 23:45:55.937669:  
2025-03-30 23:45:55.937858: Epoch 822 
2025-03-30 23:45:55.937934: Current learning rate: 0.00212 
2025-03-30 23:46:22.751009: train_loss -0.8483 
2025-03-30 23:46:22.751151: val_loss -0.7981 
2025-03-30 23:46:22.751207: Pseudo dice [np.float32(0.921), np.float32(0.9182)] 
2025-03-30 23:46:22.751271: Epoch time: 26.81 s 
2025-03-30 23:46:23.527220:  
2025-03-30 23:46:23.527395: Epoch 823 
2025-03-30 23:46:23.527483: Current learning rate: 0.0021 
2025-03-30 23:46:50.316914: train_loss -0.8476 
2025-03-30 23:46:50.317086: val_loss -0.8052 
2025-03-30 23:46:50.317142: Pseudo dice [np.float32(0.9228), np.float32(0.9252)] 
2025-03-30 23:46:50.317211: Epoch time: 26.79 s 
2025-03-30 23:46:51.100444:  
2025-03-30 23:46:51.100605: Epoch 824 
2025-03-30 23:46:51.100698: Current learning rate: 0.00209 
2025-03-30 23:47:17.880360: train_loss -0.8385 
2025-03-30 23:47:17.880500: val_loss -0.8114 
2025-03-30 23:47:17.880555: Pseudo dice [np.float32(0.9231), np.float32(0.9339)] 
2025-03-30 23:47:17.880648: Epoch time: 26.78 s 
2025-03-30 23:47:17.880700: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2025-03-30 23:47:19.223992:  
2025-03-30 23:47:19.224146: Epoch 825 
2025-03-30 23:47:19.224242: Current learning rate: 0.00208 
2025-03-30 23:47:46.083867: train_loss -0.8471 
2025-03-30 23:47:46.083994: val_loss -0.7987 
2025-03-30 23:47:46.084085: Pseudo dice [np.float32(0.9276), np.float32(0.9216)] 
2025-03-30 23:47:46.084148: Epoch time: 26.86 s 
2025-03-30 23:47:46.084196: Yayy! New best EMA pseudo Dice: 0.92330002784729 
2025-03-30 23:47:49.408854:  
2025-03-30 23:47:49.409015: Epoch 826 
2025-03-30 23:47:49.409126: Current learning rate: 0.00207 
2025-03-30 23:48:16.076531: train_loss -0.8492 
2025-03-30 23:48:16.076682: val_loss -0.797 
2025-03-30 23:48:16.076735: Pseudo dice [np.float32(0.9158), np.float32(0.9211)] 
2025-03-30 23:48:16.076806: Epoch time: 26.67 s 
2025-03-30 23:48:16.849861:  
2025-03-30 23:48:16.850014: Epoch 827 
2025-03-30 23:48:16.850098: Current learning rate: 0.00206 
2025-03-30 23:48:43.598988: train_loss -0.8526 
2025-03-30 23:48:43.599129: val_loss -0.7995 
2025-03-30 23:48:43.599185: Pseudo dice [np.float32(0.9233), np.float32(0.9162)] 
2025-03-30 23:48:43.599247: Epoch time: 26.75 s 
2025-03-30 23:48:44.371964:  
2025-03-30 23:48:44.372124: Epoch 828 
2025-03-30 23:48:44.372205: Current learning rate: 0.00205 
2025-03-30 23:49:11.121643: train_loss -0.8514 
2025-03-30 23:49:11.121785: val_loss -0.8266 
2025-03-30 23:49:11.121850: Pseudo dice [np.float32(0.9316), np.float32(0.9282)] 
2025-03-30 23:49:11.121912: Epoch time: 26.75 s 
2025-03-30 23:49:11.897365:  
2025-03-30 23:49:11.897515: Epoch 829 
2025-03-30 23:49:11.897596: Current learning rate: 0.00204 
2025-03-30 23:49:38.644166: train_loss -0.846 
2025-03-30 23:49:38.644300: val_loss -0.8197 
2025-03-30 23:49:38.644355: Pseudo dice [np.float32(0.9316), np.float32(0.9272)] 
2025-03-30 23:49:38.644417: Epoch time: 26.75 s 
2025-03-30 23:49:38.644465: Yayy! New best EMA pseudo Dice: 0.9239000082015991 
2025-03-30 23:49:40.007460:  
2025-03-30 23:49:40.007619: Epoch 830 
2025-03-30 23:49:40.007710: Current learning rate: 0.00203 
2025-03-30 23:50:06.646405: train_loss -0.8479 
2025-03-30 23:50:06.646528: val_loss -0.7994 
2025-03-30 23:50:06.646583: Pseudo dice [np.float32(0.919), np.float32(0.923)] 
2025-03-30 23:50:06.646643: Epoch time: 26.64 s 
2025-03-30 23:50:07.441060:  
2025-03-30 23:50:07.441188: Epoch 831 
2025-03-30 23:50:07.441278: Current learning rate: 0.00202 
2025-03-30 23:50:34.154835: train_loss -0.8568 
2025-03-30 23:50:34.154957: val_loss -0.8017 
2025-03-30 23:50:34.155014: Pseudo dice [np.float32(0.9291), np.float32(0.9223)] 
2025-03-30 23:50:34.155074: Epoch time: 26.71 s 
2025-03-30 23:50:34.936127:  
2025-03-30 23:50:34.936266: Epoch 832 
2025-03-30 23:50:34.936356: Current learning rate: 0.00201 
2025-03-30 23:51:01.671100: train_loss -0.851 
2025-03-30 23:51:01.671243: val_loss -0.8215 
2025-03-30 23:51:01.671317: Pseudo dice [np.float32(0.9327), np.float32(0.9294)] 
2025-03-30 23:51:01.671405: Epoch time: 26.74 s 
2025-03-30 23:51:01.671456: Yayy! New best EMA pseudo Dice: 0.9244999885559082 
2025-03-30 23:51:03.125276:  
2025-03-30 23:51:03.125414: Epoch 833 
2025-03-30 23:51:03.125510: Current learning rate: 0.002 
2025-03-30 23:51:29.860083: train_loss -0.8536 
2025-03-30 23:51:29.860241: val_loss -0.7876 
2025-03-30 23:51:29.860297: Pseudo dice [np.float32(0.9167), np.float32(0.9073)] 
2025-03-30 23:51:29.860359: Epoch time: 26.74 s 
2025-03-30 23:51:31.238868:  
2025-03-30 23:51:31.239051: Epoch 834 
2025-03-30 23:51:31.239138: Current learning rate: 0.00199 
2025-03-30 23:51:57.996554: train_loss -0.8502 
2025-03-30 23:51:57.996684: val_loss -0.7787 
2025-03-30 23:51:57.996739: Pseudo dice [np.float32(0.9143), np.float32(0.9202)] 
2025-03-30 23:51:57.996813: Epoch time: 26.76 s 
2025-03-30 23:51:58.771743:  
2025-03-30 23:51:58.771971: Epoch 835 
2025-03-30 23:51:58.772075: Current learning rate: 0.00198 
2025-03-30 23:52:25.533942: train_loss -0.8526 
2025-03-30 23:52:25.534075: val_loss -0.8237 
2025-03-30 23:52:25.534161: Pseudo dice [np.float32(0.9326), np.float32(0.9282)] 
2025-03-30 23:52:25.534244: Epoch time: 26.76 s 
2025-03-30 23:52:26.300111:  
2025-03-30 23:52:26.300283: Epoch 836 
2025-03-30 23:52:26.300375: Current learning rate: 0.00196 
2025-03-30 23:52:53.002832: train_loss -0.8547 
2025-03-30 23:52:53.003049: val_loss -0.8219 
2025-03-30 23:52:53.003107: Pseudo dice [np.float32(0.9387), np.float32(0.9256)] 
2025-03-30 23:52:53.003173: Epoch time: 26.7 s 
2025-03-30 23:52:53.783589:  
2025-03-30 23:52:53.783786: Epoch 837 
2025-03-30 23:52:53.783868: Current learning rate: 0.00195 
2025-03-30 23:53:20.508681: train_loss -0.8625 
2025-03-30 23:53:20.508829: val_loss -0.8328 
2025-03-30 23:53:20.508886: Pseudo dice [np.float32(0.9347), np.float32(0.9337)] 
2025-03-30 23:53:20.508967: Epoch time: 26.73 s 
2025-03-30 23:53:20.509056: Yayy! New best EMA pseudo Dice: 0.9253000020980835 
2025-03-30 23:53:21.824273:  
2025-03-30 23:53:21.824436: Epoch 838 
2025-03-30 23:53:21.824507: Current learning rate: 0.00194 
2025-03-30 23:53:48.474052: train_loss -0.8572 
2025-03-30 23:53:48.474188: val_loss -0.7897 
2025-03-30 23:53:48.474243: Pseudo dice [np.float32(0.9217), np.float32(0.9152)] 
2025-03-30 23:53:48.474304: Epoch time: 26.65 s 
2025-03-30 23:53:49.243957:  
2025-03-30 23:53:49.244129: Epoch 839 
2025-03-30 23:53:49.244211: Current learning rate: 0.00193 
2025-03-30 23:54:16.014465: train_loss -0.8583 
2025-03-30 23:54:16.014606: val_loss -0.8376 
2025-03-30 23:54:16.014663: Pseudo dice [np.float32(0.9449), np.float32(0.9352)] 
2025-03-30 23:54:16.014726: Epoch time: 26.77 s 
2025-03-30 23:54:16.014808: Yayy! New best EMA pseudo Dice: 0.9261999726295471 
2025-03-30 23:54:17.331681:  
2025-03-30 23:54:17.331857: Epoch 840 
2025-03-30 23:54:17.331940: Current learning rate: 0.00192 
2025-03-30 23:54:44.027400: train_loss -0.8574 
2025-03-30 23:54:44.027525: val_loss -0.8175 
2025-03-30 23:54:44.027580: Pseudo dice [np.float32(0.9326), np.float32(0.9306)] 
2025-03-30 23:54:44.027640: Epoch time: 26.7 s 
2025-03-30 23:54:44.027688: Yayy! New best EMA pseudo Dice: 0.9266999959945679 
2025-03-30 23:54:45.346253:  
2025-03-30 23:54:45.346407: Epoch 841 
2025-03-30 23:54:45.346502: Current learning rate: 0.00191 
2025-03-30 23:55:12.071005: train_loss -0.8603 
2025-03-30 23:55:12.071164: val_loss -0.7735 
2025-03-30 23:55:12.071222: Pseudo dice [np.float32(0.9138), np.float32(0.9036)] 
2025-03-30 23:55:12.071282: Epoch time: 26.73 s 
2025-03-30 23:55:12.847839:  
2025-03-30 23:55:12.848003: Epoch 842 
2025-03-30 23:55:12.848106: Current learning rate: 0.0019 
2025-03-30 23:55:39.593971: train_loss -0.8558 
2025-03-30 23:55:39.594122: val_loss -0.8185 
2025-03-30 23:55:39.594178: Pseudo dice [np.float32(0.9267), np.float32(0.9346)] 
2025-03-30 23:55:39.594241: Epoch time: 26.75 s 
2025-03-30 23:55:40.370530:  
2025-03-30 23:55:40.370709: Epoch 843 
2025-03-30 23:55:40.370799: Current learning rate: 0.00189 
2025-03-30 23:56:07.089702: train_loss -0.8565 
2025-03-30 23:56:07.089845: val_loss -0.8181 
2025-03-30 23:56:07.089900: Pseudo dice [np.float32(0.9343), np.float32(0.9248)] 
2025-03-30 23:56:07.089961: Epoch time: 26.72 s 
2025-03-30 23:56:07.865060:  
2025-03-30 23:56:07.865224: Epoch 844 
2025-03-30 23:56:07.865314: Current learning rate: 0.00188 
2025-03-30 23:56:34.600064: train_loss -0.8577 
2025-03-30 23:56:34.600189: val_loss -0.8085 
2025-03-30 23:56:34.600244: Pseudo dice [np.float32(0.9293), np.float32(0.9306)] 
2025-03-30 23:56:34.600304: Epoch time: 26.74 s 
2025-03-30 23:56:35.374756:  
2025-03-30 23:56:35.374918: Epoch 845 
2025-03-30 23:56:35.375016: Current learning rate: 0.00187 
2025-03-30 23:57:02.119949: train_loss -0.8592 
2025-03-30 23:57:02.120075: val_loss -0.8207 
2025-03-30 23:57:02.120130: Pseudo dice [np.float32(0.9375), np.float32(0.9252)] 
2025-03-30 23:57:02.120192: Epoch time: 26.75 s 
2025-03-30 23:57:02.120281: Yayy! New best EMA pseudo Dice: 0.926800012588501 
2025-03-30 23:57:03.440194:  
2025-03-30 23:57:03.440390: Epoch 846 
2025-03-30 23:57:03.440469: Current learning rate: 0.00186 
2025-03-30 23:57:30.182101: train_loss -0.8511 
2025-03-30 23:57:30.182248: val_loss -0.8003 
2025-03-30 23:57:30.182324: Pseudo dice [np.float32(0.9221), np.float32(0.9216)] 
2025-03-30 23:57:30.182386: Epoch time: 26.74 s 
2025-03-30 23:57:30.955701:  
2025-03-30 23:57:30.955868: Epoch 847 
2025-03-30 23:57:30.955951: Current learning rate: 0.00185 
2025-03-30 23:57:57.691718: train_loss -0.8531 
2025-03-30 23:57:57.691954: val_loss -0.8162 
2025-03-30 23:57:57.692012: Pseudo dice [np.float32(0.9355), np.float32(0.9236)] 
2025-03-30 23:57:57.692094: Epoch time: 26.74 s 
2025-03-30 23:57:58.468874:  
2025-03-30 23:57:58.469031: Epoch 848 
2025-03-30 23:57:58.469120: Current learning rate: 0.00184 
2025-03-30 23:58:25.180150: train_loss -0.8544 
2025-03-30 23:58:25.180401: val_loss -0.7878 
2025-03-30 23:58:25.180459: Pseudo dice [np.float32(0.9203), np.float32(0.9159)] 
2025-03-30 23:58:25.180518: Epoch time: 26.71 s 
2025-03-30 23:58:25.952234:  
2025-03-30 23:58:25.952375: Epoch 849 
2025-03-30 23:58:25.952523: Current learning rate: 0.00182 
2025-03-30 23:58:52.651052: train_loss -0.841 
2025-03-30 23:58:52.651200: val_loss -0.8076 
2025-03-30 23:58:52.651256: Pseudo dice [np.float32(0.9288), np.float32(0.9169)] 
2025-03-30 23:58:52.651318: Epoch time: 26.7 s 
2025-03-30 23:58:53.963453:  
2025-03-30 23:58:53.963600: Epoch 850 
2025-03-30 23:58:53.963674: Current learning rate: 0.00181 
2025-03-30 23:59:20.666938: train_loss -0.851 
2025-03-30 23:59:20.667096: val_loss -0.8014 
2025-03-30 23:59:20.667168: Pseudo dice [np.float32(0.9266), np.float32(0.917)] 
2025-03-30 23:59:20.667266: Epoch time: 26.7 s 
2025-03-30 23:59:21.439563:  
2025-03-30 23:59:21.439714: Epoch 851 
2025-03-30 23:59:21.439802: Current learning rate: 0.0018 
2025-03-30 23:59:48.182815: train_loss -0.8555 
2025-03-30 23:59:48.182956: val_loss -0.8203 
2025-03-30 23:59:48.183012: Pseudo dice [np.float32(0.935), np.float32(0.9266)] 
2025-03-30 23:59:48.183074: Epoch time: 26.74 s 
2025-03-30 23:59:48.958651:  
2025-03-30 23:59:48.958817: Epoch 852 
2025-03-30 23:59:48.958914: Current learning rate: 0.00179 
2025-03-31 00:00:15.810181: train_loss -0.8602 
2025-03-31 00:00:15.810318: val_loss -0.8108 
2025-03-31 00:00:15.810404: Pseudo dice [np.float32(0.9341), np.float32(0.925)] 
2025-03-31 00:00:15.810479: Epoch time: 26.85 s 
2025-03-31 00:00:17.136701:  
2025-03-31 00:00:17.136884: Epoch 853 
2025-03-31 00:00:17.136974: Current learning rate: 0.00178 
2025-03-31 00:00:43.896876: train_loss -0.8647 
2025-03-31 00:00:43.897056: val_loss -0.8129 
2025-03-31 00:00:43.897113: Pseudo dice [np.float32(0.9343), np.float32(0.9236)] 
2025-03-31 00:00:43.897172: Epoch time: 26.76 s 
2025-03-31 00:00:44.657163:  
2025-03-31 00:00:44.657335: Epoch 854 
2025-03-31 00:00:44.657419: Current learning rate: 0.00177 
2025-03-31 00:01:11.351930: train_loss -0.851 
2025-03-31 00:01:11.352086: val_loss -0.8285 
2025-03-31 00:01:11.352146: Pseudo dice [np.float32(0.9421), np.float32(0.9275)] 
2025-03-31 00:01:11.352208: Epoch time: 26.7 s 
2025-03-31 00:01:11.352257: Yayy! New best EMA pseudo Dice: 0.9272000193595886 
2025-03-31 00:01:12.604996:  
2025-03-31 00:01:12.605160: Epoch 855 
2025-03-31 00:01:12.605231: Current learning rate: 0.00176 
2025-03-31 00:01:39.328616: train_loss -0.8517 
2025-03-31 00:01:39.328799: val_loss -0.7946 
2025-03-31 00:01:39.328870: Pseudo dice [np.float32(0.9254), np.float32(0.92)] 
2025-03-31 00:01:39.328932: Epoch time: 26.72 s 
2025-03-31 00:01:40.091399:  
2025-03-31 00:01:40.091557: Epoch 856 
2025-03-31 00:01:40.091666: Current learning rate: 0.00175 
2025-03-31 00:02:06.826897: train_loss -0.8565 
2025-03-31 00:02:06.827041: val_loss -0.8237 
2025-03-31 00:02:06.827097: Pseudo dice [np.float32(0.936), np.float32(0.9315)] 
2025-03-31 00:02:06.827169: Epoch time: 26.74 s 
2025-03-31 00:02:06.827259: Yayy! New best EMA pseudo Dice: 0.9273999929428101 
2025-03-31 00:02:08.150717:  
2025-03-31 00:02:08.150940: Epoch 857 
2025-03-31 00:02:08.151019: Current learning rate: 0.00174 
2025-03-31 00:02:34.864913: train_loss -0.8625 
2025-03-31 00:02:34.865068: val_loss -0.811 
2025-03-31 00:02:34.865140: Pseudo dice [np.float32(0.9289), np.float32(0.9326)] 
2025-03-31 00:02:34.865223: Epoch time: 26.72 s 
2025-03-31 00:02:34.865290: Yayy! New best EMA pseudo Dice: 0.9277999997138977 
2025-03-31 00:02:36.190296:  
2025-03-31 00:02:36.190452: Epoch 858 
2025-03-31 00:02:36.190546: Current learning rate: 0.00173 
2025-03-31 00:03:02.902408: train_loss -0.856 
2025-03-31 00:03:02.902531: val_loss -0.8256 
2025-03-31 00:03:02.902587: Pseudo dice [np.float32(0.9334), np.float32(0.9286)] 
2025-03-31 00:03:02.902670: Epoch time: 26.71 s 
2025-03-31 00:03:02.902782: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-03-31 00:03:04.232888:  
2025-03-31 00:03:04.233051: Epoch 859 
2025-03-31 00:03:04.233128: Current learning rate: 0.00172 
2025-03-31 00:03:30.898737: train_loss -0.8564 
2025-03-31 00:03:30.898876: val_loss -0.814 
2025-03-31 00:03:30.898932: Pseudo dice [np.float32(0.9302), np.float32(0.9172)] 
2025-03-31 00:03:30.898991: Epoch time: 26.67 s 
2025-03-31 00:03:31.662670:  
2025-03-31 00:03:31.662818: Epoch 860 
2025-03-31 00:03:31.662899: Current learning rate: 0.0017 
2025-03-31 00:03:58.434600: train_loss -0.8668 
2025-03-31 00:03:58.434755: val_loss -0.8039 
2025-03-31 00:03:58.434832: Pseudo dice [np.float32(0.9265), np.float32(0.9225)] 
2025-03-31 00:03:58.434894: Epoch time: 26.77 s 
2025-03-31 00:03:59.198298:  
2025-03-31 00:03:59.198481: Epoch 861 
2025-03-31 00:03:59.198571: Current learning rate: 0.00169 
2025-03-31 00:04:25.954886: train_loss -0.8509 
2025-03-31 00:04:25.955038: val_loss -0.8185 
2025-03-31 00:04:25.955094: Pseudo dice [np.float32(0.933), np.float32(0.9293)] 
2025-03-31 00:04:25.955157: Epoch time: 26.76 s 
2025-03-31 00:04:26.720397:  
2025-03-31 00:04:26.720556: Epoch 862 
2025-03-31 00:04:26.720659: Current learning rate: 0.00168 
2025-03-31 00:04:53.539282: train_loss -0.8479 
2025-03-31 00:04:53.539408: val_loss -0.8074 
2025-03-31 00:04:53.539465: Pseudo dice [np.float32(0.926), np.float32(0.9276)] 
2025-03-31 00:04:53.539524: Epoch time: 26.82 s 
2025-03-31 00:04:54.306992:  
2025-03-31 00:04:54.307178: Epoch 863 
2025-03-31 00:04:54.307280: Current learning rate: 0.00167 
2025-03-31 00:05:21.115289: train_loss -0.8533 
2025-03-31 00:05:21.115439: val_loss -0.7925 
2025-03-31 00:05:21.115494: Pseudo dice [np.float32(0.9179), np.float32(0.9095)] 
2025-03-31 00:05:21.115558: Epoch time: 26.81 s 
2025-03-31 00:05:21.882508:  
2025-03-31 00:05:21.882668: Epoch 864 
2025-03-31 00:05:21.882770: Current learning rate: 0.00166 
2025-03-31 00:05:48.648586: train_loss -0.8521 
2025-03-31 00:05:48.648731: val_loss -0.8032 
2025-03-31 00:05:48.648793: Pseudo dice [np.float32(0.9234), np.float32(0.9221)] 
2025-03-31 00:05:48.648856: Epoch time: 26.77 s 
2025-03-31 00:05:49.406241:  
2025-03-31 00:05:49.406416: Epoch 865 
2025-03-31 00:05:49.406510: Current learning rate: 0.00165 
2025-03-31 00:06:16.115710: train_loss -0.8641 
2025-03-31 00:06:16.115929: val_loss -0.8299 
2025-03-31 00:06:16.115988: Pseudo dice [np.float32(0.9352), np.float32(0.933)] 
2025-03-31 00:06:16.116051: Epoch time: 26.71 s 
2025-03-31 00:06:16.880231:  
2025-03-31 00:06:16.880394: Epoch 866 
2025-03-31 00:06:16.880472: Current learning rate: 0.00164 
2025-03-31 00:06:43.623982: train_loss -0.8637 
2025-03-31 00:06:43.624109: val_loss -0.8181 
2025-03-31 00:06:43.624165: Pseudo dice [np.float32(0.932), np.float32(0.9275)] 
2025-03-31 00:06:43.624226: Epoch time: 26.74 s 
2025-03-31 00:06:44.390334:  
2025-03-31 00:06:44.390490: Epoch 867 
2025-03-31 00:06:44.390585: Current learning rate: 0.00163 
2025-03-31 00:07:11.128970: train_loss -0.8664 
2025-03-31 00:07:11.129142: val_loss -0.8126 
2025-03-31 00:07:11.129239: Pseudo dice [np.float32(0.9312), np.float32(0.9241)] 
2025-03-31 00:07:11.129304: Epoch time: 26.74 s 
2025-03-31 00:07:11.893853:  
2025-03-31 00:07:11.893998: Epoch 868 
2025-03-31 00:07:11.894096: Current learning rate: 0.00162 
2025-03-31 00:07:38.690064: train_loss -0.8717 
2025-03-31 00:07:38.690356: val_loss -0.8119 
2025-03-31 00:07:38.690415: Pseudo dice [np.float32(0.9229), np.float32(0.9288)] 
2025-03-31 00:07:38.690476: Epoch time: 26.8 s 
2025-03-31 00:07:39.469190:  
2025-03-31 00:07:39.469362: Epoch 869 
2025-03-31 00:07:39.469442: Current learning rate: 0.00161 
2025-03-31 00:08:06.194186: train_loss -0.8635 
2025-03-31 00:08:06.194480: val_loss -0.808 
2025-03-31 00:08:06.194541: Pseudo dice [np.float32(0.928), np.float32(0.9285)] 
2025-03-31 00:08:06.194609: Epoch time: 26.73 s 
2025-03-31 00:08:06.962663:  
2025-03-31 00:08:06.962844: Epoch 870 
2025-03-31 00:08:06.962926: Current learning rate: 0.00159 
2025-03-31 00:08:33.685138: train_loss -0.8586 
2025-03-31 00:08:33.685405: val_loss -0.8399 
2025-03-31 00:08:33.685461: Pseudo dice [np.float32(0.9445), np.float32(0.9359)] 
2025-03-31 00:08:33.685521: Epoch time: 26.72 s 
2025-03-31 00:08:33.685567: Yayy! New best EMA pseudo Dice: 0.9283999800682068 
2025-03-31 00:08:34.989940:  
2025-03-31 00:08:34.990111: Epoch 871 
2025-03-31 00:08:34.990185: Current learning rate: 0.00158 
2025-03-31 00:09:01.720194: train_loss -0.8587 
2025-03-31 00:09:01.720319: val_loss -0.7927 
2025-03-31 00:09:01.720372: Pseudo dice [np.float32(0.9227), np.float32(0.913)] 
2025-03-31 00:09:01.720431: Epoch time: 26.73 s 
2025-03-31 00:09:02.488424:  
2025-03-31 00:09:02.488576: Epoch 872 
2025-03-31 00:09:02.488672: Current learning rate: 0.00157 
2025-03-31 00:09:29.233873: train_loss -0.8496 
2025-03-31 00:09:29.234110: val_loss -0.8212 
2025-03-31 00:09:29.234169: Pseudo dice [np.float32(0.9357), np.float32(0.9251)] 
2025-03-31 00:09:29.234235: Epoch time: 26.75 s 
2025-03-31 00:09:30.611267:  
2025-03-31 00:09:30.611454: Epoch 873 
2025-03-31 00:09:30.611552: Current learning rate: 0.00156 
2025-03-31 00:09:57.336185: train_loss -0.8585 
2025-03-31 00:09:57.336323: val_loss -0.8043 
2025-03-31 00:09:57.336379: Pseudo dice [np.float32(0.918), np.float32(0.9216)] 
2025-03-31 00:09:57.336440: Epoch time: 26.73 s 
2025-03-31 00:09:58.101192:  
2025-03-31 00:09:58.101378: Epoch 874 
2025-03-31 00:09:58.101469: Current learning rate: 0.00155 
2025-03-31 00:10:24.866187: train_loss -0.86 
2025-03-31 00:10:24.866310: val_loss -0.8236 
2025-03-31 00:10:24.866365: Pseudo dice [np.float32(0.9335), np.float32(0.9308)] 
2025-03-31 00:10:24.866424: Epoch time: 26.77 s 
2025-03-31 00:10:25.630842:  
2025-03-31 00:10:25.631024: Epoch 875 
2025-03-31 00:10:25.631125: Current learning rate: 0.00154 
2025-03-31 00:10:52.372395: train_loss -0.8633 
2025-03-31 00:10:52.372516: val_loss -0.8164 
2025-03-31 00:10:52.372572: Pseudo dice [np.float32(0.9305), np.float32(0.9259)] 
2025-03-31 00:10:52.372635: Epoch time: 26.74 s 
2025-03-31 00:10:53.153995:  
2025-03-31 00:10:53.154200: Epoch 876 
2025-03-31 00:10:53.154297: Current learning rate: 0.00153 
2025-03-31 00:11:19.896767: train_loss -0.8607 
2025-03-31 00:11:19.896925: val_loss -0.8249 
2025-03-31 00:11:19.896981: Pseudo dice [np.float32(0.9349), np.float32(0.9275)] 
2025-03-31 00:11:19.897048: Epoch time: 26.74 s 
2025-03-31 00:11:20.668572:  
2025-03-31 00:11:20.668704: Epoch 877 
2025-03-31 00:11:20.668816: Current learning rate: 0.00152 
2025-03-31 00:11:47.428934: train_loss -0.8584 
2025-03-31 00:11:47.429081: val_loss -0.8164 
2025-03-31 00:11:47.429138: Pseudo dice [np.float32(0.9349), np.float32(0.9246)] 
2025-03-31 00:11:47.429200: Epoch time: 26.76 s 
2025-03-31 00:11:48.202413:  
2025-03-31 00:11:48.202541: Epoch 878 
2025-03-31 00:11:48.202624: Current learning rate: 0.00151 
2025-03-31 00:12:14.930899: train_loss -0.8565 
2025-03-31 00:12:14.931061: val_loss -0.8171 
2025-03-31 00:12:14.931117: Pseudo dice [np.float32(0.9315), np.float32(0.9303)] 
2025-03-31 00:12:14.931178: Epoch time: 26.73 s 
2025-03-31 00:12:15.710472:  
2025-03-31 00:12:15.710605: Epoch 879 
2025-03-31 00:12:15.710701: Current learning rate: 0.00149 
2025-03-31 00:12:42.447802: train_loss -0.85 
2025-03-31 00:12:42.447948: val_loss -0.8073 
2025-03-31 00:12:42.448004: Pseudo dice [np.float32(0.9266), np.float32(0.9219)] 
2025-03-31 00:12:42.448073: Epoch time: 26.74 s 
2025-03-31 00:12:43.361372:  
2025-03-31 00:12:43.361500: Epoch 880 
2025-03-31 00:12:43.361584: Current learning rate: 0.00148 
2025-03-31 00:13:10.033227: train_loss -0.8478 
2025-03-31 00:13:10.033349: val_loss -0.8256 
2025-03-31 00:13:10.033405: Pseudo dice [np.float32(0.938), np.float32(0.9279)] 
2025-03-31 00:13:10.033463: Epoch time: 26.67 s 
2025-03-31 00:13:10.033511: Yayy! New best EMA pseudo Dice: 0.9283999800682068 
2025-03-31 00:13:11.344713:  
2025-03-31 00:13:11.344882: Epoch 881 
2025-03-31 00:13:11.344962: Current learning rate: 0.00147 
2025-03-31 00:13:38.067407: train_loss -0.8604 
2025-03-31 00:13:38.067534: val_loss -0.8218 
2025-03-31 00:13:38.067601: Pseudo dice [np.float32(0.9283), np.float32(0.9384)] 
2025-03-31 00:13:38.067661: Epoch time: 26.72 s 
2025-03-31 00:13:38.067707: Yayy! New best EMA pseudo Dice: 0.9289000034332275 
2025-03-31 00:13:39.412200:  
2025-03-31 00:13:39.412354: Epoch 882 
2025-03-31 00:13:39.412432: Current learning rate: 0.00146 
2025-03-31 00:14:06.146946: train_loss -0.8541 
2025-03-31 00:14:06.147083: val_loss -0.8263 
2025-03-31 00:14:06.147166: Pseudo dice [np.float32(0.9354), np.float32(0.931)] 
2025-03-31 00:14:06.147229: Epoch time: 26.74 s 
2025-03-31 00:14:06.147278: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2025-03-31 00:14:07.495341:  
2025-03-31 00:14:07.495504: Epoch 883 
2025-03-31 00:14:07.495584: Current learning rate: 0.00145 
2025-03-31 00:14:34.213743: train_loss -0.8579 
2025-03-31 00:14:34.213921: val_loss -0.8242 
2025-03-31 00:14:34.213977: Pseudo dice [np.float32(0.9311), np.float32(0.9331)] 
2025-03-31 00:14:34.214039: Epoch time: 26.72 s 
2025-03-31 00:14:34.214086: Yayy! New best EMA pseudo Dice: 0.9296000003814697 
2025-03-31 00:14:35.545646:  
2025-03-31 00:14:35.545797: Epoch 884 
2025-03-31 00:14:35.545897: Current learning rate: 0.00144 
2025-03-31 00:15:02.284024: train_loss -0.8546 
2025-03-31 00:15:02.284168: val_loss -0.7924 
2025-03-31 00:15:02.284223: Pseudo dice [np.float32(0.9161), np.float32(0.9305)] 
2025-03-31 00:15:02.284285: Epoch time: 26.74 s 
2025-03-31 00:15:03.058578:  
2025-03-31 00:15:03.058763: Epoch 885 
2025-03-31 00:15:03.058849: Current learning rate: 0.00143 
2025-03-31 00:15:29.780925: train_loss -0.8617 
2025-03-31 00:15:29.781069: val_loss -0.7997 
2025-03-31 00:15:29.781124: Pseudo dice [np.float32(0.9273), np.float32(0.9164)] 
2025-03-31 00:15:29.781185: Epoch time: 26.72 s 
2025-03-31 00:15:30.555522:  
2025-03-31 00:15:30.555677: Epoch 886 
2025-03-31 00:15:30.555769: Current learning rate: 0.00142 
2025-03-31 00:15:57.333049: train_loss -0.8524 
2025-03-31 00:15:57.333246: val_loss -0.8185 
2025-03-31 00:15:57.333302: Pseudo dice [np.float32(0.9274), np.float32(0.9318)] 
2025-03-31 00:15:57.333363: Epoch time: 26.78 s 
2025-03-31 00:15:58.100688:  
2025-03-31 00:15:58.100857: Epoch 887 
2025-03-31 00:15:58.100937: Current learning rate: 0.00141 
2025-03-31 00:16:24.839327: train_loss -0.8554 
2025-03-31 00:16:24.839494: val_loss -0.8169 
2025-03-31 00:16:24.839551: Pseudo dice [np.float32(0.935), np.float32(0.9241)] 
2025-03-31 00:16:24.839614: Epoch time: 26.74 s 
2025-03-31 00:16:25.617789:  
2025-03-31 00:16:25.617955: Epoch 888 
2025-03-31 00:16:25.618034: Current learning rate: 0.00139 
2025-03-31 00:16:52.368844: train_loss -0.8573 
2025-03-31 00:16:52.368983: val_loss -0.8177 
2025-03-31 00:16:52.369040: Pseudo dice [np.float32(0.9342), np.float32(0.9266)] 
2025-03-31 00:16:52.369108: Epoch time: 26.75 s 
2025-03-31 00:16:53.140192:  
2025-03-31 00:16:53.140347: Epoch 889 
2025-03-31 00:16:53.140428: Current learning rate: 0.00138 
2025-03-31 00:17:19.897045: train_loss -0.8596 
2025-03-31 00:17:19.897237: val_loss -0.8262 
2025-03-31 00:17:19.897298: Pseudo dice [np.float32(0.9359), np.float32(0.924)] 
2025-03-31 00:17:19.897366: Epoch time: 26.76 s 
2025-03-31 00:17:20.675206:  
2025-03-31 00:17:20.675359: Epoch 890 
2025-03-31 00:17:20.675449: Current learning rate: 0.00137 
2025-03-31 00:17:47.419111: train_loss -0.8651 
2025-03-31 00:17:47.419264: val_loss -0.8308 
2025-03-31 00:17:47.419319: Pseudo dice [np.float32(0.9371), np.float32(0.9354)] 
2025-03-31 00:17:47.419383: Epoch time: 26.75 s 
2025-03-31 00:17:48.192640:  
2025-03-31 00:17:48.192786: Epoch 891 
2025-03-31 00:17:48.192874: Current learning rate: 0.00136 
2025-03-31 00:18:14.922040: train_loss -0.8607 
2025-03-31 00:18:14.922185: val_loss -0.7844 
2025-03-31 00:18:14.922241: Pseudo dice [np.float32(0.9142), np.float32(0.904)] 
2025-03-31 00:18:14.922335: Epoch time: 26.73 s 
2025-03-31 00:18:15.693005:  
2025-03-31 00:18:15.693163: Epoch 892 
2025-03-31 00:18:15.693244: Current learning rate: 0.00135 
2025-03-31 00:18:42.413045: train_loss -0.8491 
2025-03-31 00:18:42.413236: val_loss -0.8003 
2025-03-31 00:18:42.413303: Pseudo dice [np.float32(0.9289), np.float32(0.9172)] 
2025-03-31 00:18:42.413364: Epoch time: 26.72 s 
2025-03-31 00:18:43.179488:  
2025-03-31 00:18:43.179630: Epoch 893 
2025-03-31 00:18:43.179706: Current learning rate: 0.00134 
2025-03-31 00:19:09.968927: train_loss -0.8615 
2025-03-31 00:19:09.969186: val_loss -0.8164 
2025-03-31 00:19:09.969245: Pseudo dice [np.float32(0.9316), np.float32(0.928)] 
2025-03-31 00:19:09.969307: Epoch time: 26.79 s 
2025-03-31 00:19:11.349240:  
2025-03-31 00:19:11.349380: Epoch 894 
2025-03-31 00:19:11.349483: Current learning rate: 0.00133 
2025-03-31 00:19:38.123286: train_loss -0.8561 
2025-03-31 00:19:38.123435: val_loss -0.813 
2025-03-31 00:19:38.123536: Pseudo dice [np.float32(0.9346), np.float32(0.9239)] 
2025-03-31 00:19:38.123600: Epoch time: 26.78 s 
2025-03-31 00:19:38.891541:  
2025-03-31 00:19:38.891708: Epoch 895 
2025-03-31 00:19:38.891804: Current learning rate: 0.00132 
2025-03-31 00:20:05.641165: train_loss -0.8573 
2025-03-31 00:20:05.641287: val_loss -0.8204 
2025-03-31 00:20:05.641343: Pseudo dice [np.float32(0.9363), np.float32(0.9264)] 
2025-03-31 00:20:05.641403: Epoch time: 26.75 s 
2025-03-31 00:20:06.408719:  
2025-03-31 00:20:06.408897: Epoch 896 
2025-03-31 00:20:06.408991: Current learning rate: 0.0013 
2025-03-31 00:20:33.181038: train_loss -0.8561 
2025-03-31 00:20:33.181175: val_loss -0.7818 
2025-03-31 00:20:33.181249: Pseudo dice [np.float32(0.9207), np.float32(0.912)] 
2025-03-31 00:20:33.181333: Epoch time: 26.77 s 
2025-03-31 00:20:33.951271:  
2025-03-31 00:20:33.951420: Epoch 897 
2025-03-31 00:20:33.951502: Current learning rate: 0.00129 
2025-03-31 00:21:00.687524: train_loss -0.8553 
2025-03-31 00:21:00.687657: val_loss -0.8239 
2025-03-31 00:21:00.687713: Pseudo dice [np.float32(0.93), np.float32(0.9282)] 
2025-03-31 00:21:00.687784: Epoch time: 26.74 s 
2025-03-31 00:21:01.468776:  
2025-03-31 00:21:01.468946: Epoch 898 
2025-03-31 00:21:01.469029: Current learning rate: 0.00128 
2025-03-31 00:21:28.246733: train_loss -0.8604 
2025-03-31 00:21:28.246889: val_loss -0.821 
2025-03-31 00:21:28.246946: Pseudo dice [np.float32(0.9339), np.float32(0.9265)] 
2025-03-31 00:21:28.247008: Epoch time: 26.78 s 
2025-03-31 00:21:29.027633:  
2025-03-31 00:21:29.027785: Epoch 899 
2025-03-31 00:21:29.027867: Current learning rate: 0.00127 
2025-03-31 00:21:55.763975: train_loss -0.8641 
2025-03-31 00:21:55.764128: val_loss -0.8318 
2025-03-31 00:21:55.764186: Pseudo dice [np.float32(0.942), np.float32(0.9249)] 
2025-03-31 00:21:55.764247: Epoch time: 26.74 s 
2025-03-31 00:21:57.060554:  
2025-03-31 00:21:57.060707: Epoch 900 
2025-03-31 00:21:57.060788: Current learning rate: 0.00126 
2025-03-31 00:22:23.804103: train_loss -0.8665 
2025-03-31 00:22:23.804253: val_loss -0.8059 
2025-03-31 00:22:23.804308: Pseudo dice [np.float32(0.9294), np.float32(0.9192)] 
2025-03-31 00:22:23.804369: Epoch time: 26.74 s 
2025-03-31 00:22:24.576893:  
2025-03-31 00:22:24.577058: Epoch 901 
2025-03-31 00:22:24.577140: Current learning rate: 0.00125 
2025-03-31 00:22:51.331347: train_loss -0.8661 
2025-03-31 00:22:51.331478: val_loss -0.8278 
2025-03-31 00:22:51.331534: Pseudo dice [np.float32(0.9346), np.float32(0.9383)] 
2025-03-31 00:22:51.331595: Epoch time: 26.76 s 
2025-03-31 00:22:52.102703:  
2025-03-31 00:22:52.102823: Epoch 902 
2025-03-31 00:22:52.102926: Current learning rate: 0.00124 
2025-03-31 00:23:18.861403: train_loss -0.8656 
2025-03-31 00:23:18.861530: val_loss -0.8076 
2025-03-31 00:23:18.861585: Pseudo dice [np.float32(0.9264), np.float32(0.9249)] 
2025-03-31 00:23:18.861646: Epoch time: 26.76 s 
2025-03-31 00:23:19.634229:  
2025-03-31 00:23:19.634394: Epoch 903 
2025-03-31 00:23:19.634486: Current learning rate: 0.00122 
2025-03-31 00:23:46.356305: train_loss -0.8652 
2025-03-31 00:23:46.356443: val_loss -0.8206 
2025-03-31 00:23:46.356498: Pseudo dice [np.float32(0.9411), np.float32(0.9189)] 
2025-03-31 00:23:46.356558: Epoch time: 26.72 s 
2025-03-31 00:23:47.130183:  
2025-03-31 00:23:47.130339: Epoch 904 
2025-03-31 00:23:47.130471: Current learning rate: 0.00121 
2025-03-31 00:24:13.854150: train_loss -0.8678 
2025-03-31 00:24:13.854282: val_loss -0.8236 
2025-03-31 00:24:13.854337: Pseudo dice [np.float32(0.9369), np.float32(0.925)] 
2025-03-31 00:24:13.854400: Epoch time: 26.73 s 
2025-03-31 00:24:14.627695:  
2025-03-31 00:24:14.627872: Epoch 905 
2025-03-31 00:24:14.627961: Current learning rate: 0.0012 
2025-03-31 00:24:41.345455: train_loss -0.8696 
2025-03-31 00:24:41.345598: val_loss -0.8271 
2025-03-31 00:24:41.345653: Pseudo dice [np.float32(0.943), np.float32(0.9239)] 
2025-03-31 00:24:41.345712: Epoch time: 26.72 s 
2025-03-31 00:24:42.122889:  
2025-03-31 00:24:42.123041: Epoch 906 
2025-03-31 00:24:42.123122: Current learning rate: 0.00119 
2025-03-31 00:25:08.869009: train_loss -0.8666 
2025-03-31 00:25:08.869150: val_loss -0.8225 
2025-03-31 00:25:08.869222: Pseudo dice [np.float32(0.9323), np.float32(0.9307)] 
2025-03-31 00:25:08.869289: Epoch time: 26.75 s 
2025-03-31 00:25:09.642398:  
2025-03-31 00:25:09.642580: Epoch 907 
2025-03-31 00:25:09.642679: Current learning rate: 0.00118 
2025-03-31 00:25:36.418426: train_loss -0.8681 
2025-03-31 00:25:36.418683: val_loss -0.8061 
2025-03-31 00:25:36.418741: Pseudo dice [np.float32(0.9281), np.float32(0.9142)] 
2025-03-31 00:25:36.418813: Epoch time: 26.78 s 
2025-03-31 00:25:37.190495:  
2025-03-31 00:25:37.190635: Epoch 908 
2025-03-31 00:25:37.190727: Current learning rate: 0.00117 
2025-03-31 00:26:03.921047: train_loss -0.8706 
2025-03-31 00:26:03.921333: val_loss -0.8531 
2025-03-31 00:26:03.921392: Pseudo dice [np.float32(0.9458), np.float32(0.9417)] 
2025-03-31 00:26:03.921454: Epoch time: 26.73 s 
2025-03-31 00:26:03.921503: Yayy! New best EMA pseudo Dice: 0.9300000071525574 
2025-03-31 00:26:05.207923:  
2025-03-31 00:26:05.208083: Epoch 909 
2025-03-31 00:26:05.208171: Current learning rate: 0.00116 
2025-03-31 00:26:31.937103: train_loss -0.8726 
2025-03-31 00:26:31.937227: val_loss -0.8104 
2025-03-31 00:26:31.937282: Pseudo dice [np.float32(0.9236), np.float32(0.9295)] 
2025-03-31 00:26:31.937343: Epoch time: 26.73 s 
2025-03-31 00:26:32.705743:  
2025-03-31 00:26:32.705896: Epoch 910 
2025-03-31 00:26:32.705973: Current learning rate: 0.00115 
2025-03-31 00:26:59.427239: train_loss -0.8717 
2025-03-31 00:26:59.427548: val_loss -0.8172 
2025-03-31 00:26:59.427606: Pseudo dice [np.float32(0.9367), np.float32(0.9298)] 
2025-03-31 00:26:59.427668: Epoch time: 26.72 s 
2025-03-31 00:26:59.427716: Yayy! New best EMA pseudo Dice: 0.9301000237464905 
2025-03-31 00:27:00.715304:  
2025-03-31 00:27:00.715452: Epoch 911 
2025-03-31 00:27:00.715540: Current learning rate: 0.00113 
2025-03-31 00:27:27.532843: train_loss -0.8676 
2025-03-31 00:27:27.533029: val_loss -0.8158 
2025-03-31 00:27:27.533087: Pseudo dice [np.float32(0.9313), np.float32(0.928)] 
2025-03-31 00:27:27.533153: Epoch time: 26.82 s 
2025-03-31 00:27:28.310724:  
2025-03-31 00:27:28.310897: Epoch 912 
2025-03-31 00:27:28.310977: Current learning rate: 0.00112 
2025-03-31 00:27:55.031287: train_loss -0.8702 
2025-03-31 00:27:55.031432: val_loss -0.8188 
2025-03-31 00:27:55.031528: Pseudo dice [np.float32(0.932), np.float32(0.9325)] 
2025-03-31 00:27:55.031593: Epoch time: 26.72 s 
2025-03-31 00:27:55.031641: Yayy! New best EMA pseudo Dice: 0.9301999807357788 
2025-03-31 00:27:56.574254:  
2025-03-31 00:27:56.574407: Epoch 913 
2025-03-31 00:27:56.574497: Current learning rate: 0.00111 
2025-03-31 00:28:23.299342: train_loss -0.8738 
2025-03-31 00:28:23.299491: val_loss -0.8391 
2025-03-31 00:28:23.299548: Pseudo dice [np.float32(0.94), np.float32(0.938)] 
2025-03-31 00:28:23.299664: Epoch time: 26.73 s 
2025-03-31 00:28:23.299715: Yayy! New best EMA pseudo Dice: 0.9311000108718872 
2025-03-31 00:28:25.231575:  
2025-03-31 00:28:25.231735: Epoch 914 
2025-03-31 00:28:25.231821: Current learning rate: 0.0011 
2025-03-31 00:28:51.946701: train_loss -0.8689 
2025-03-31 00:28:51.946851: val_loss -0.8225 
2025-03-31 00:28:51.946908: Pseudo dice [np.float32(0.9344), np.float32(0.9319)] 
2025-03-31 00:28:51.947001: Epoch time: 26.72 s 
2025-03-31 00:28:51.947048: Yayy! New best EMA pseudo Dice: 0.9312999844551086 
2025-03-31 00:28:53.272561:  
2025-03-31 00:28:53.272715: Epoch 915 
2025-03-31 00:28:53.272799: Current learning rate: 0.00109 
2025-03-31 00:29:19.989925: train_loss -0.8715 
2025-03-31 00:29:19.990087: val_loss -0.8048 
2025-03-31 00:29:19.990155: Pseudo dice [np.float32(0.9231), np.float32(0.9278)] 
2025-03-31 00:29:19.990215: Epoch time: 26.72 s 
2025-03-31 00:29:20.763478:  
2025-03-31 00:29:20.763628: Epoch 916 
2025-03-31 00:29:20.763710: Current learning rate: 0.00108 
2025-03-31 00:29:47.495463: train_loss -0.8769 
2025-03-31 00:29:47.495611: val_loss -0.8351 
2025-03-31 00:29:47.495667: Pseudo dice [np.float32(0.939), np.float32(0.9368)] 
2025-03-31 00:29:47.495731: Epoch time: 26.73 s 
2025-03-31 00:29:47.495796: Yayy! New best EMA pseudo Dice: 0.9314000010490417 
2025-03-31 00:29:48.832949:  
2025-03-31 00:29:48.833116: Epoch 917 
2025-03-31 00:29:48.833195: Current learning rate: 0.00106 
2025-03-31 00:30:15.558221: train_loss -0.8673 
2025-03-31 00:30:15.558348: val_loss -0.8456 
2025-03-31 00:30:15.558404: Pseudo dice [np.float32(0.9425), np.float32(0.9373)] 
2025-03-31 00:30:15.558465: Epoch time: 26.73 s 
2025-03-31 00:30:15.558513: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2025-03-31 00:30:16.891364:  
2025-03-31 00:30:16.891539: Epoch 918 
2025-03-31 00:30:16.891618: Current learning rate: 0.00105 
2025-03-31 00:30:43.575808: train_loss -0.8729 
2025-03-31 00:30:43.575951: val_loss -0.8231 
2025-03-31 00:30:43.576038: Pseudo dice [np.float32(0.9318), np.float32(0.9291)] 
2025-03-31 00:30:43.576108: Epoch time: 26.69 s 
2025-03-31 00:30:44.352326:  
2025-03-31 00:30:44.352489: Epoch 919 
2025-03-31 00:30:44.352577: Current learning rate: 0.00104 
2025-03-31 00:31:11.071031: train_loss -0.8763 
2025-03-31 00:31:11.071170: val_loss -0.8403 
2025-03-31 00:31:11.071226: Pseudo dice [np.float32(0.9388), np.float32(0.9376)] 
2025-03-31 00:31:11.071287: Epoch time: 26.72 s 
2025-03-31 00:31:11.071335: Yayy! New best EMA pseudo Dice: 0.932699978351593 
2025-03-31 00:31:12.402249:  
2025-03-31 00:31:12.402443: Epoch 920 
2025-03-31 00:31:12.402527: Current learning rate: 0.00103 
2025-03-31 00:31:39.095723: train_loss -0.8766 
2025-03-31 00:31:39.095870: val_loss -0.8134 
2025-03-31 00:31:39.095926: Pseudo dice [np.float32(0.9343), np.float32(0.9232)] 
2025-03-31 00:31:39.096003: Epoch time: 26.69 s 
2025-03-31 00:31:39.895082:  
2025-03-31 00:31:39.895267: Epoch 921 
2025-03-31 00:31:39.895348: Current learning rate: 0.00102 
2025-03-31 00:32:06.597801: train_loss -0.8744 
2025-03-31 00:32:06.597944: val_loss -0.8338 
2025-03-31 00:32:06.597999: Pseudo dice [np.float32(0.933), np.float32(0.9365)] 
2025-03-31 00:32:06.598085: Epoch time: 26.7 s 
2025-03-31 00:32:07.371213:  
2025-03-31 00:32:07.371404: Epoch 922 
2025-03-31 00:32:07.371487: Current learning rate: 0.00101 
2025-03-31 00:32:34.132708: train_loss -0.8749 
2025-03-31 00:32:34.132849: val_loss -0.8309 
2025-03-31 00:32:34.132913: Pseudo dice [np.float32(0.9361), np.float32(0.9359)] 
2025-03-31 00:32:34.132980: Epoch time: 26.76 s 
2025-03-31 00:32:34.133036: Yayy! New best EMA pseudo Dice: 0.9329000115394592 
2025-03-31 00:32:35.465959:  
2025-03-31 00:32:35.466142: Epoch 923 
2025-03-31 00:32:35.466217: Current learning rate: 0.001 
2025-03-31 00:33:02.177104: train_loss -0.8693 
2025-03-31 00:33:02.177229: val_loss -0.8522 
2025-03-31 00:33:02.177347: Pseudo dice [np.float32(0.9434), np.float32(0.94)] 
2025-03-31 00:33:02.177437: Epoch time: 26.71 s 
2025-03-31 00:33:02.177487: Yayy! New best EMA pseudo Dice: 0.9337999820709229 
2025-03-31 00:33:03.514422:  
2025-03-31 00:33:03.514585: Epoch 924 
2025-03-31 00:33:03.514666: Current learning rate: 0.00098 
2025-03-31 00:33:30.217455: train_loss -0.8719 
2025-03-31 00:33:30.217590: val_loss -0.8349 
2025-03-31 00:33:30.217644: Pseudo dice [np.float32(0.9399), np.float32(0.935)] 
2025-03-31 00:33:30.217705: Epoch time: 26.7 s 
2025-03-31 00:33:30.217752: Yayy! New best EMA pseudo Dice: 0.9341999888420105 
2025-03-31 00:33:31.561851:  
2025-03-31 00:33:31.562038: Epoch 925 
2025-03-31 00:33:31.562117: Current learning rate: 0.00097 
2025-03-31 00:33:58.228859: train_loss -0.8731 
2025-03-31 00:33:58.228996: val_loss -0.8362 
2025-03-31 00:33:58.229055: Pseudo dice [np.float32(0.9367), np.float32(0.9369)] 
2025-03-31 00:33:58.229145: Epoch time: 26.67 s 
2025-03-31 00:33:58.229195: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-03-31 00:33:59.573321:  
2025-03-31 00:33:59.573485: Epoch 926 
2025-03-31 00:33:59.573565: Current learning rate: 0.00096 
2025-03-31 00:34:26.270700: train_loss -0.869 
2025-03-31 00:34:26.270830: val_loss -0.8443 
2025-03-31 00:34:26.270885: Pseudo dice [np.float32(0.9448), np.float32(0.9339)] 
2025-03-31 00:34:26.270946: Epoch time: 26.7 s 
2025-03-31 00:34:26.270994: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-03-31 00:34:27.610832:  
2025-03-31 00:34:27.610922: Epoch 927 
2025-03-31 00:34:27.610994: Current learning rate: 0.00095 
2025-03-31 00:34:54.336844: train_loss -0.8741 
2025-03-31 00:34:54.339080: val_loss -0.8288 
2025-03-31 00:34:54.339159: Pseudo dice [np.float32(0.9299), np.float32(0.9318)] 
2025-03-31 00:34:54.339226: Epoch time: 26.73 s 
2025-03-31 00:34:55.117481:  
2025-03-31 00:34:55.117579: Epoch 928 
2025-03-31 00:34:55.117658: Current learning rate: 0.00094 
2025-03-31 00:35:21.873396: train_loss -0.871 
2025-03-31 00:35:21.873534: val_loss -0.8312 
2025-03-31 00:35:21.873594: Pseudo dice [np.float32(0.9318), np.float32(0.9404)] 
2025-03-31 00:35:21.873655: Epoch time: 26.76 s 
2025-03-31 00:35:22.660627:  
2025-03-31 00:35:22.660747: Epoch 929 
2025-03-31 00:35:22.660858: Current learning rate: 0.00092 
2025-03-31 00:35:49.415295: train_loss -0.8728 
2025-03-31 00:35:49.415505: val_loss -0.8223 
2025-03-31 00:35:49.415570: Pseudo dice [np.float32(0.9383), np.float32(0.9261)] 
2025-03-31 00:35:49.415644: Epoch time: 26.76 s 
2025-03-31 00:35:50.189687:  
2025-03-31 00:35:50.189856: Epoch 930 
2025-03-31 00:35:50.189946: Current learning rate: 0.00091 
2025-03-31 00:36:16.916533: train_loss -0.8794 
2025-03-31 00:36:16.916683: val_loss -0.8314 
2025-03-31 00:36:16.916742: Pseudo dice [np.float32(0.9407), np.float32(0.9331)] 
2025-03-31 00:36:16.916825: Epoch time: 26.73 s 
2025-03-31 00:36:17.690003:  
2025-03-31 00:36:17.690180: Epoch 931 
2025-03-31 00:36:17.690259: Current learning rate: 0.0009 
2025-03-31 00:36:44.463676: train_loss -0.867 
2025-03-31 00:36:44.463848: val_loss -0.8137 
2025-03-31 00:36:44.463905: Pseudo dice [np.float32(0.9322), np.float32(0.9237)] 
2025-03-31 00:36:44.463968: Epoch time: 26.77 s 
2025-03-31 00:36:45.231796:  
2025-03-31 00:36:45.231949: Epoch 932 
2025-03-31 00:36:45.232049: Current learning rate: 0.00089 
2025-03-31 00:37:12.019904: train_loss -0.8753 
2025-03-31 00:37:12.020051: val_loss -0.8476 
2025-03-31 00:37:12.020141: Pseudo dice [np.float32(0.9472), np.float32(0.9389)] 
2025-03-31 00:37:12.020208: Epoch time: 26.79 s 
2025-03-31 00:37:13.361596:  
2025-03-31 00:37:13.361790: Epoch 933 
2025-03-31 00:37:13.361881: Current learning rate: 0.00088 
2025-03-31 00:37:40.133191: train_loss -0.8723 
2025-03-31 00:37:40.133373: val_loss -0.8274 
2025-03-31 00:37:40.133429: Pseudo dice [np.float32(0.9378), np.float32(0.9277)] 
2025-03-31 00:37:40.133500: Epoch time: 26.77 s 
2025-03-31 00:37:40.902726:  
2025-03-31 00:37:40.902925: Epoch 934 
2025-03-31 00:37:40.903006: Current learning rate: 0.00087 
2025-03-31 00:38:07.672033: train_loss -0.8784 
2025-03-31 00:38:07.672162: val_loss -0.8363 
2025-03-31 00:38:07.672217: Pseudo dice [np.float32(0.9392), np.float32(0.9336)] 
2025-03-31 00:38:07.672278: Epoch time: 26.77 s 
2025-03-31 00:38:08.464763:  
2025-03-31 00:38:08.464960: Epoch 935 
2025-03-31 00:38:08.465045: Current learning rate: 0.00085 
2025-03-31 00:38:35.246012: train_loss -0.8754 
2025-03-31 00:38:35.246145: val_loss -0.8152 
2025-03-31 00:38:35.246201: Pseudo dice [np.float32(0.9361), np.float32(0.9247)] 
2025-03-31 00:38:35.246262: Epoch time: 26.78 s 
2025-03-31 00:38:36.013682:  
2025-03-31 00:38:36.013807: Epoch 936 
2025-03-31 00:38:36.013888: Current learning rate: 0.00084 
2025-03-31 00:39:02.760556: train_loss -0.8782 
2025-03-31 00:39:02.760721: val_loss -0.838 
2025-03-31 00:39:02.760796: Pseudo dice [np.float32(0.9397), np.float32(0.9389)] 
2025-03-31 00:39:02.760867: Epoch time: 26.75 s 
2025-03-31 00:39:03.530905:  
2025-03-31 00:39:03.531068: Epoch 937 
2025-03-31 00:39:03.531148: Current learning rate: 0.00083 
2025-03-31 00:39:30.275811: train_loss -0.8748 
2025-03-31 00:39:30.275941: val_loss -0.836 
2025-03-31 00:39:30.275997: Pseudo dice [np.float32(0.9381), np.float32(0.9344)] 
2025-03-31 00:39:30.276058: Epoch time: 26.75 s 
2025-03-31 00:39:30.276105: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2025-03-31 00:39:31.588908:  
2025-03-31 00:39:31.589065: Epoch 938 
2025-03-31 00:39:31.589147: Current learning rate: 0.00082 
2025-03-31 00:39:58.303280: train_loss -0.8753 
2025-03-31 00:39:58.303440: val_loss -0.8247 
2025-03-31 00:39:58.303513: Pseudo dice [np.float32(0.931), np.float32(0.9304)] 
2025-03-31 00:39:58.303575: Epoch time: 26.72 s 
2025-03-31 00:39:59.084302:  
2025-03-31 00:39:59.084466: Epoch 939 
2025-03-31 00:39:59.084555: Current learning rate: 0.00081 
2025-03-31 00:40:25.860876: train_loss -0.8733 
2025-03-31 00:40:25.861007: val_loss -0.8614 
2025-03-31 00:40:25.861062: Pseudo dice [np.float32(0.9507), np.float32(0.9442)] 
2025-03-31 00:40:25.861122: Epoch time: 26.78 s 
2025-03-31 00:40:25.861170: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-03-31 00:40:27.205787:  
2025-03-31 00:40:27.205946: Epoch 940 
2025-03-31 00:40:27.206025: Current learning rate: 0.00079 
2025-03-31 00:40:53.917230: train_loss -0.8801 
2025-03-31 00:40:53.917367: val_loss -0.8391 
2025-03-31 00:40:53.917423: Pseudo dice [np.float32(0.938), np.float32(0.9376)] 
2025-03-31 00:40:53.917484: Epoch time: 26.71 s 
2025-03-31 00:40:53.917558: Yayy! New best EMA pseudo Dice: 0.9361000061035156 
2025-03-31 00:40:55.284513:  
2025-03-31 00:40:55.284671: Epoch 941 
2025-03-31 00:40:55.284754: Current learning rate: 0.00078 
2025-03-31 00:41:21.967910: train_loss -0.8783 
2025-03-31 00:41:21.968036: val_loss -0.8396 
2025-03-31 00:41:21.968091: Pseudo dice [np.float32(0.9417), np.float32(0.9309)] 
2025-03-31 00:41:21.968152: Epoch time: 26.68 s 
2025-03-31 00:41:21.968200: Yayy! New best EMA pseudo Dice: 0.9361000061035156 
2025-03-31 00:41:23.321330:  
2025-03-31 00:41:23.321449: Epoch 942 
2025-03-31 00:41:23.321530: Current learning rate: 0.00077 
2025-03-31 00:41:50.008683: train_loss -0.8732 
2025-03-31 00:41:50.008827: val_loss -0.8266 
2025-03-31 00:41:50.008884: Pseudo dice [np.float32(0.9369), np.float32(0.9309)] 
2025-03-31 00:41:50.008952: Epoch time: 26.69 s 
2025-03-31 00:41:50.780562:  
2025-03-31 00:41:50.780743: Epoch 943 
2025-03-31 00:41:50.780841: Current learning rate: 0.00076 
2025-03-31 00:42:17.493301: train_loss -0.8747 
2025-03-31 00:42:17.493451: val_loss -0.8326 
2025-03-31 00:42:17.493511: Pseudo dice [np.float32(0.9421), np.float32(0.9298)] 
2025-03-31 00:42:17.493608: Epoch time: 26.71 s 
2025-03-31 00:42:18.269537:  
2025-03-31 00:42:18.269686: Epoch 944 
2025-03-31 00:42:18.269781: Current learning rate: 0.00075 
2025-03-31 00:42:45.008285: train_loss -0.8839 
2025-03-31 00:42:45.008411: val_loss -0.8266 
2025-03-31 00:42:45.008467: Pseudo dice [np.float32(0.9322), np.float32(0.9249)] 
2025-03-31 00:42:45.008528: Epoch time: 26.74 s 
2025-03-31 00:42:45.775262:  
2025-03-31 00:42:45.775425: Epoch 945 
2025-03-31 00:42:45.775505: Current learning rate: 0.00074 
2025-03-31 00:43:12.469877: train_loss -0.8812 
2025-03-31 00:43:12.470047: val_loss -0.819 
2025-03-31 00:43:12.470104: Pseudo dice [np.float32(0.9326), np.float32(0.9304)] 
2025-03-31 00:43:12.470165: Epoch time: 26.7 s 
2025-03-31 00:43:13.250498:  
2025-03-31 00:43:13.250649: Epoch 946 
2025-03-31 00:43:13.250732: Current learning rate: 0.00072 
2025-03-31 00:43:39.990708: train_loss -0.8803 
2025-03-31 00:43:39.990874: val_loss -0.8188 
2025-03-31 00:43:39.990971: Pseudo dice [np.float32(0.9314), np.float32(0.9362)] 
2025-03-31 00:43:39.991032: Epoch time: 26.74 s 
2025-03-31 00:43:40.764237:  
2025-03-31 00:43:40.764371: Epoch 947 
2025-03-31 00:43:40.764456: Current learning rate: 0.00071 
2025-03-31 00:44:07.550456: train_loss -0.8787 
2025-03-31 00:44:07.550606: val_loss -0.8108 
2025-03-31 00:44:07.550663: Pseudo dice [np.float32(0.9254), np.float32(0.9265)] 
2025-03-31 00:44:07.550723: Epoch time: 26.79 s 
2025-03-31 00:44:08.321043:  
2025-03-31 00:44:08.321151: Epoch 948 
2025-03-31 00:44:08.321233: Current learning rate: 0.0007 
2025-03-31 00:44:35.009152: train_loss -0.8753 
2025-03-31 00:44:35.009300: val_loss -0.8444 
2025-03-31 00:44:35.009355: Pseudo dice [np.float32(0.942), np.float32(0.9409)] 
2025-03-31 00:44:35.009415: Epoch time: 26.69 s 
2025-03-31 00:44:35.783934:  
2025-03-31 00:44:35.784074: Epoch 949 
2025-03-31 00:44:35.784153: Current learning rate: 0.00069 
2025-03-31 00:45:02.537323: train_loss -0.8693 
2025-03-31 00:45:02.537453: val_loss -0.8346 
2025-03-31 00:45:02.537509: Pseudo dice [np.float32(0.9404), np.float32(0.9341)] 
2025-03-31 00:45:02.537571: Epoch time: 26.75 s 
2025-03-31 00:45:03.858143:  
2025-03-31 00:45:03.858255: Epoch 950 
2025-03-31 00:45:03.858336: Current learning rate: 0.00067 
2025-03-31 00:45:30.744012: train_loss -0.8819 
2025-03-31 00:45:30.744150: val_loss -0.8351 
2025-03-31 00:45:30.744205: Pseudo dice [np.float32(0.94), np.float32(0.9338)] 
2025-03-31 00:45:30.744266: Epoch time: 26.89 s 
2025-03-31 00:45:31.516211:  
2025-03-31 00:45:31.516351: Epoch 951 
2025-03-31 00:45:31.516433: Current learning rate: 0.00066 
2025-03-31 00:45:58.208023: train_loss -0.8795 
2025-03-31 00:45:58.208274: val_loss -0.8338 
2025-03-31 00:45:58.208333: Pseudo dice [np.float32(0.9394), np.float32(0.9306)] 
2025-03-31 00:45:58.208396: Epoch time: 26.69 s 
2025-03-31 00:45:58.989537:  
2025-03-31 00:45:58.989691: Epoch 952 
2025-03-31 00:45:58.989781: Current learning rate: 0.00065 
2025-03-31 00:46:25.704941: train_loss -0.8821 
2025-03-31 00:46:25.705075: val_loss -0.8396 
2025-03-31 00:46:25.705132: Pseudo dice [np.float32(0.9394), np.float32(0.9371)] 
2025-03-31 00:46:25.705192: Epoch time: 26.72 s 
2025-03-31 00:46:27.079753:  
2025-03-31 00:46:27.079921: Epoch 953 
2025-03-31 00:46:27.080013: Current learning rate: 0.00064 
2025-03-31 00:46:53.804102: train_loss -0.8805 
2025-03-31 00:46:53.804263: val_loss -0.8352 
2025-03-31 00:46:53.804319: Pseudo dice [np.float32(0.9412), np.float32(0.9374)] 
2025-03-31 00:46:53.804380: Epoch time: 26.73 s 
2025-03-31 00:46:54.579430:  
2025-03-31 00:46:54.579617: Epoch 954 
2025-03-31 00:46:54.579702: Current learning rate: 0.00063 
2025-03-31 00:47:21.321041: train_loss -0.883 
2025-03-31 00:47:21.321181: val_loss -0.831 
2025-03-31 00:47:21.321239: Pseudo dice [np.float32(0.9444), np.float32(0.9295)] 
2025-03-31 00:47:21.321301: Epoch time: 26.74 s 
2025-03-31 00:47:22.097531:  
2025-03-31 00:47:22.097682: Epoch 955 
2025-03-31 00:47:22.097787: Current learning rate: 0.00061 
2025-03-31 00:47:48.824120: train_loss -0.8789 
2025-03-31 00:47:48.824244: val_loss -0.8255 
2025-03-31 00:47:48.824303: Pseudo dice [np.float32(0.927), np.float32(0.9353)] 
2025-03-31 00:47:48.824390: Epoch time: 26.73 s 
2025-03-31 00:47:49.600515:  
2025-03-31 00:47:49.600682: Epoch 956 
2025-03-31 00:47:49.600772: Current learning rate: 0.0006 
2025-03-31 00:48:16.340867: train_loss -0.8827 
2025-03-31 00:48:16.341054: val_loss -0.8281 
2025-03-31 00:48:16.341124: Pseudo dice [np.float32(0.9428), np.float32(0.9359)] 
2025-03-31 00:48:16.341188: Epoch time: 26.74 s 
2025-03-31 00:48:17.127356:  
2025-03-31 00:48:17.127535: Epoch 957 
2025-03-31 00:48:17.127615: Current learning rate: 0.00059 
2025-03-31 00:48:43.893620: train_loss -0.8823 
2025-03-31 00:48:43.893755: val_loss -0.8383 
2025-03-31 00:48:43.893821: Pseudo dice [np.float32(0.9322), np.float32(0.9386)] 
2025-03-31 00:48:43.893881: Epoch time: 26.77 s 
2025-03-31 00:48:44.671151:  
2025-03-31 00:48:44.671329: Epoch 958 
2025-03-31 00:48:44.671412: Current learning rate: 0.00058 
2025-03-31 00:49:11.405066: train_loss -0.8824 
2025-03-31 00:49:11.405203: val_loss -0.8386 
2025-03-31 00:49:11.405258: Pseudo dice [np.float32(0.9449), np.float32(0.9297)] 
2025-03-31 00:49:11.405320: Epoch time: 26.73 s 
2025-03-31 00:49:12.186255:  
2025-03-31 00:49:12.186419: Epoch 959 
2025-03-31 00:49:12.186501: Current learning rate: 0.00056 
2025-03-31 00:49:38.921515: train_loss -0.8824 
2025-03-31 00:49:38.921681: val_loss -0.8416 
2025-03-31 00:49:38.921739: Pseudo dice [np.float32(0.943), np.float32(0.9416)] 
2025-03-31 00:49:38.921809: Epoch time: 26.74 s 
2025-03-31 00:49:38.921859: Yayy! New best EMA pseudo Dice: 0.9366000294685364 
2025-03-31 00:49:40.226365:  
2025-03-31 00:49:40.226519: Epoch 960 
2025-03-31 00:49:40.226600: Current learning rate: 0.00055 
2025-03-31 00:50:06.953745: train_loss -0.8842 
2025-03-31 00:50:06.953897: val_loss -0.8349 
2025-03-31 00:50:06.953952: Pseudo dice [np.float32(0.9383), np.float32(0.9276)] 
2025-03-31 00:50:06.954016: Epoch time: 26.73 s 
2025-03-31 00:50:07.737608:  
2025-03-31 00:50:07.737784: Epoch 961 
2025-03-31 00:50:07.737871: Current learning rate: 0.00054 
2025-03-31 00:50:34.504209: train_loss -0.8788 
2025-03-31 00:50:34.504384: val_loss -0.839 
2025-03-31 00:50:34.504441: Pseudo dice [np.float32(0.9388), np.float32(0.9391)] 
2025-03-31 00:50:34.504501: Epoch time: 26.77 s 
2025-03-31 00:50:35.282115:  
2025-03-31 00:50:35.282268: Epoch 962 
2025-03-31 00:50:35.282395: Current learning rate: 0.00053 
2025-03-31 00:51:02.042684: train_loss -0.8794 
2025-03-31 00:51:02.042842: val_loss -0.8553 
2025-03-31 00:51:02.042898: Pseudo dice [np.float32(0.9486), np.float32(0.9422)] 
2025-03-31 00:51:02.042960: Epoch time: 26.76 s 
2025-03-31 00:51:02.043009: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-03-31 00:51:03.378994:  
2025-03-31 00:51:03.379143: Epoch 963 
2025-03-31 00:51:03.379220: Current learning rate: 0.00051 
2025-03-31 00:51:30.083975: train_loss -0.8858 
2025-03-31 00:51:30.084125: val_loss -0.853 
2025-03-31 00:51:30.084180: Pseudo dice [np.float32(0.9442), np.float32(0.9436)] 
2025-03-31 00:51:30.084239: Epoch time: 26.71 s 
2025-03-31 00:51:30.084287: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2025-03-31 00:51:31.427725:  
2025-03-31 00:51:31.427886: Epoch 964 
2025-03-31 00:51:31.427965: Current learning rate: 0.0005 
2025-03-31 00:51:58.130297: train_loss -0.8838 
2025-03-31 00:51:58.130537: val_loss -0.8382 
2025-03-31 00:51:58.130596: Pseudo dice [np.float32(0.938), np.float32(0.932)] 
2025-03-31 00:51:58.130656: Epoch time: 26.7 s 
2025-03-31 00:51:58.908633:  
2025-03-31 00:51:58.908765: Epoch 965 
2025-03-31 00:51:58.908853: Current learning rate: 0.00049 
2025-03-31 00:52:25.633569: train_loss -0.8848 
2025-03-31 00:52:25.633838: val_loss -0.828 
2025-03-31 00:52:25.633898: Pseudo dice [np.float32(0.9329), np.float32(0.9398)] 
2025-03-31 00:52:25.633958: Epoch time: 26.73 s 
2025-03-31 00:52:26.413933:  
2025-03-31 00:52:26.414086: Epoch 966 
2025-03-31 00:52:26.414169: Current learning rate: 0.00048 
2025-03-31 00:52:53.130368: train_loss -0.8847 
2025-03-31 00:52:53.130604: val_loss -0.8444 
2025-03-31 00:52:53.130662: Pseudo dice [np.float32(0.9443), np.float32(0.937)] 
2025-03-31 00:52:53.130724: Epoch time: 26.72 s 
2025-03-31 00:52:53.908266:  
2025-03-31 00:52:53.908389: Epoch 967 
2025-03-31 00:52:53.908469: Current learning rate: 0.00046 
2025-03-31 00:53:20.658903: train_loss -0.8837 
2025-03-31 00:53:20.659148: val_loss -0.8473 
2025-03-31 00:53:20.659205: Pseudo dice [np.float32(0.9452), np.float32(0.9377)] 
2025-03-31 00:53:20.659266: Epoch time: 26.75 s 
2025-03-31 00:53:20.659314: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-31 00:53:21.963651:  
2025-03-31 00:53:21.963874: Epoch 968 
2025-03-31 00:53:21.963957: Current learning rate: 0.00045 
2025-03-31 00:53:48.683913: train_loss -0.888 
2025-03-31 00:53:48.684044: val_loss -0.8369 
2025-03-31 00:53:48.684100: Pseudo dice [np.float32(0.9388), np.float32(0.9344)] 
2025-03-31 00:53:48.684160: Epoch time: 26.72 s 
2025-03-31 00:53:49.468638:  
2025-03-31 00:53:49.468807: Epoch 969 
2025-03-31 00:53:49.468896: Current learning rate: 0.00044 
2025-03-31 00:54:16.209236: train_loss -0.8812 
2025-03-31 00:54:16.209378: val_loss -0.8406 
2025-03-31 00:54:16.209434: Pseudo dice [np.float32(0.9362), np.float32(0.9412)] 
2025-03-31 00:54:16.209532: Epoch time: 26.74 s 
2025-03-31 00:54:16.996924:  
2025-03-31 00:54:16.997070: Epoch 970 
2025-03-31 00:54:16.997164: Current learning rate: 0.00043 
2025-03-31 00:54:43.674351: train_loss -0.8878 
2025-03-31 00:54:43.674487: val_loss -0.8392 
2025-03-31 00:54:43.674542: Pseudo dice [np.float32(0.9438), np.float32(0.9338)] 
2025-03-31 00:54:43.674603: Epoch time: 26.68 s 
2025-03-31 00:54:44.460967:  
2025-03-31 00:54:44.461095: Epoch 971 
2025-03-31 00:54:44.461191: Current learning rate: 0.00041 
2025-03-31 00:55:11.181731: train_loss -0.885 
2025-03-31 00:55:11.181869: val_loss -0.827 
2025-03-31 00:55:11.181925: Pseudo dice [np.float32(0.9335), np.float32(0.9321)] 
2025-03-31 00:55:11.181988: Epoch time: 26.72 s 
2025-03-31 00:55:11.961941:  
2025-03-31 00:55:11.962088: Epoch 972 
2025-03-31 00:55:11.962169: Current learning rate: 0.0004 
2025-03-31 00:55:38.739306: train_loss -0.882 
2025-03-31 00:55:38.739446: val_loss -0.8478 
2025-03-31 00:55:38.739502: Pseudo dice [np.float32(0.9452), np.float32(0.938)] 
2025-03-31 00:55:38.739565: Epoch time: 26.78 s 
2025-03-31 00:55:40.148854:  
2025-03-31 00:55:40.149038: Epoch 973 
2025-03-31 00:55:40.149126: Current learning rate: 0.00039 
2025-03-31 00:56:06.906129: train_loss -0.8844 
2025-03-31 00:56:06.906271: val_loss -0.83 
2025-03-31 00:56:06.906328: Pseudo dice [np.float32(0.9306), np.float32(0.9291)] 
2025-03-31 00:56:06.906395: Epoch time: 26.76 s 
2025-03-31 00:56:07.687593:  
2025-03-31 00:56:07.687734: Epoch 974 
2025-03-31 00:56:07.687845: Current learning rate: 0.00037 
2025-03-31 00:56:38.030921: train_loss -0.8842 
2025-03-31 00:56:38.031053: val_loss -0.8243 
2025-03-31 00:56:38.031109: Pseudo dice [np.float32(0.94), np.float32(0.9201)] 
2025-03-31 00:56:38.031169: Epoch time: 30.34 s 
2025-03-31 00:56:38.814171:  
2025-03-31 00:56:38.814314: Epoch 975 
2025-03-31 00:56:38.814421: Current learning rate: 0.00036 
2025-03-31 00:57:05.579880: train_loss -0.8876 
2025-03-31 00:57:05.580034: val_loss -0.8479 
2025-03-31 00:57:05.580091: Pseudo dice [np.float32(0.9449), np.float32(0.939)] 
2025-03-31 00:57:05.580153: Epoch time: 26.77 s 
2025-03-31 00:57:06.357749:  
2025-03-31 00:57:06.357912: Epoch 976 
2025-03-31 00:57:06.357992: Current learning rate: 0.00035 
2025-03-31 00:57:33.097552: train_loss -0.8817 
2025-03-31 00:57:33.097685: val_loss -0.8408 
2025-03-31 00:57:33.097741: Pseudo dice [np.float32(0.938), np.float32(0.9366)] 
2025-03-31 00:57:33.097823: Epoch time: 26.74 s 
2025-03-31 00:57:33.886081:  
2025-03-31 00:57:33.886196: Epoch 977 
2025-03-31 00:57:33.886275: Current learning rate: 0.00034 
2025-03-31 00:58:00.582078: train_loss -0.8817 
2025-03-31 00:58:00.582224: val_loss -0.822 
2025-03-31 00:58:00.582280: Pseudo dice [np.float32(0.9391), np.float32(0.926)] 
2025-03-31 00:58:00.582341: Epoch time: 26.7 s 
2025-03-31 00:58:01.362162:  
2025-03-31 00:58:01.362290: Epoch 978 
2025-03-31 00:58:01.362370: Current learning rate: 0.00032 
2025-03-31 00:58:28.075135: train_loss -0.8844 
2025-03-31 00:58:28.075263: val_loss -0.8508 
2025-03-31 00:58:28.075318: Pseudo dice [np.float32(0.9462), np.float32(0.9399)] 
2025-03-31 00:58:28.075379: Epoch time: 26.71 s 
2025-03-31 00:58:28.863006:  
2025-03-31 00:58:28.863200: Epoch 979 
2025-03-31 00:58:28.863291: Current learning rate: 0.00031 
2025-03-31 00:58:55.583117: train_loss -0.8856 
2025-03-31 00:58:55.583247: val_loss -0.8372 
2025-03-31 00:58:55.583303: Pseudo dice [np.float32(0.9392), np.float32(0.9351)] 
2025-03-31 00:58:55.583363: Epoch time: 26.72 s 
2025-03-31 00:58:56.363179:  
2025-03-31 00:58:56.363341: Epoch 980 
2025-03-31 00:58:56.363421: Current learning rate: 0.0003 
2025-03-31 00:59:23.086787: train_loss -0.8865 
2025-03-31 00:59:23.086950: val_loss -0.8567 
2025-03-31 00:59:23.087018: Pseudo dice [np.float32(0.9494), np.float32(0.9439)] 
2025-03-31 00:59:23.087085: Epoch time: 26.72 s 
2025-03-31 00:59:23.882133:  
2025-03-31 00:59:23.882311: Epoch 981 
2025-03-31 00:59:23.882393: Current learning rate: 0.00028 
2025-03-31 00:59:50.551001: train_loss -0.8847 
2025-03-31 00:59:50.551126: val_loss -0.8355 
2025-03-31 00:59:50.551181: Pseudo dice [np.float32(0.938), np.float32(0.9361)] 
2025-03-31 00:59:50.551241: Epoch time: 26.67 s 
2025-03-31 00:59:51.333858:  
2025-03-31 00:59:51.334052: Epoch 982 
2025-03-31 00:59:51.334144: Current learning rate: 0.00027 
2025-03-31 01:00:18.040566: train_loss -0.8915 
2025-03-31 01:00:18.040771: val_loss -0.834 
2025-03-31 01:00:18.040832: Pseudo dice [np.float32(0.9395), np.float32(0.9332)] 
2025-03-31 01:00:18.040895: Epoch time: 26.71 s 
2025-03-31 01:00:18.818109:  
2025-03-31 01:00:18.818271: Epoch 983 
2025-03-31 01:00:18.818351: Current learning rate: 0.00026 
2025-03-31 01:00:45.653732: train_loss -0.8872 
2025-03-31 01:00:45.653985: val_loss -0.8488 
2025-03-31 01:00:45.654058: Pseudo dice [np.float32(0.9437), np.float32(0.939)] 
2025-03-31 01:00:45.654120: Epoch time: 26.84 s 
2025-03-31 01:00:45.654169: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-31 01:00:46.962181:  
2025-03-31 01:00:46.962341: Epoch 984 
2025-03-31 01:00:46.962417: Current learning rate: 0.00024 
2025-03-31 01:01:13.702060: train_loss -0.891 
2025-03-31 01:01:13.702202: val_loss -0.8384 
2025-03-31 01:01:13.702258: Pseudo dice [np.float32(0.9426), np.float32(0.9359)] 
2025-03-31 01:01:13.702317: Epoch time: 26.74 s 
2025-03-31 01:01:13.702364: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-31 01:01:17.291004:  
2025-03-31 01:01:17.291204: Epoch 985 
2025-03-31 01:01:17.291301: Current learning rate: 0.00023 
2025-03-31 01:01:44.108430: train_loss -0.8879 
2025-03-31 01:01:44.108589: val_loss -0.8445 
2025-03-31 01:01:44.108645: Pseudo dice [np.float32(0.9437), np.float32(0.937)] 
2025-03-31 01:01:44.108706: Epoch time: 26.82 s 
2025-03-31 01:01:44.108754: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-31 01:01:45.434054:  
2025-03-31 01:01:45.434210: Epoch 986 
2025-03-31 01:01:45.434285: Current learning rate: 0.00021 
2025-03-31 01:02:12.174416: train_loss -0.8834 
2025-03-31 01:02:12.174647: val_loss -0.8524 
2025-03-31 01:02:12.174728: Pseudo dice [np.float32(0.9466), np.float32(0.9444)] 
2025-03-31 01:02:12.174814: Epoch time: 26.74 s 
2025-03-31 01:02:12.174864: Yayy! New best EMA pseudo Dice: 0.9391999840736389 
2025-03-31 01:02:13.498653:  
2025-03-31 01:02:13.498822: Epoch 987 
2025-03-31 01:02:13.498923: Current learning rate: 0.0002 
2025-03-31 01:02:40.216331: train_loss -0.8902 
2025-03-31 01:02:40.216480: val_loss -0.8422 
2025-03-31 01:02:40.216536: Pseudo dice [np.float32(0.9437), np.float32(0.9348)] 
2025-03-31 01:02:40.216598: Epoch time: 26.72 s 
2025-03-31 01:02:40.993321:  
2025-03-31 01:02:40.993466: Epoch 988 
2025-03-31 01:02:40.993540: Current learning rate: 0.00019 
2025-03-31 01:03:07.764205: train_loss -0.8905 
2025-03-31 01:03:07.764366: val_loss -0.8508 
2025-03-31 01:03:07.764423: Pseudo dice [np.float32(0.9485), np.float32(0.9412)] 
2025-03-31 01:03:07.764489: Epoch time: 26.77 s 
2025-03-31 01:03:07.764539: Yayy! New best EMA pseudo Dice: 0.9398000240325928 
2025-03-31 01:03:09.102535:  
2025-03-31 01:03:09.102695: Epoch 989 
2025-03-31 01:03:09.102802: Current learning rate: 0.00017 
2025-03-31 01:03:35.850821: train_loss -0.8867 
2025-03-31 01:03:35.850962: val_loss -0.8268 
2025-03-31 01:03:35.851017: Pseudo dice [np.float32(0.9367), np.float32(0.9351)] 
2025-03-31 01:03:35.851080: Epoch time: 26.75 s 
2025-03-31 01:03:36.626271:  
2025-03-31 01:03:36.626422: Epoch 990 
2025-03-31 01:03:36.626498: Current learning rate: 0.00016 
2025-03-31 01:04:03.367954: train_loss -0.8833 
2025-03-31 01:04:03.368134: val_loss -0.849 
2025-03-31 01:04:03.368190: Pseudo dice [np.float32(0.946), np.float32(0.9384)] 
2025-03-31 01:04:03.368254: Epoch time: 26.74 s 
2025-03-31 01:04:04.136739:  
2025-03-31 01:04:04.136869: Epoch 991 
2025-03-31 01:04:04.136942: Current learning rate: 0.00014 
2025-03-31 01:04:30.896894: train_loss -0.8875 
2025-03-31 01:04:30.897044: val_loss -0.8456 
2025-03-31 01:04:30.897100: Pseudo dice [np.float32(0.9428), np.float32(0.9383)] 
2025-03-31 01:04:30.897174: Epoch time: 26.76 s 
2025-03-31 01:04:32.284651:  
2025-03-31 01:04:32.284848: Epoch 992 
2025-03-31 01:04:32.284935: Current learning rate: 0.00013 
2025-03-31 01:04:59.058587: train_loss -0.8892 
2025-03-31 01:04:59.058726: val_loss -0.8453 
2025-03-31 01:04:59.058812: Pseudo dice [np.float32(0.942), np.float32(0.9396)] 
2025-03-31 01:04:59.058874: Epoch time: 26.77 s 
2025-03-31 01:04:59.058923: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-03-31 01:05:00.394832:  
2025-03-31 01:05:00.395036: Epoch 993 
2025-03-31 01:05:00.395125: Current learning rate: 0.00011 
2025-03-31 01:05:27.096236: train_loss -0.8865 
2025-03-31 01:05:27.096361: val_loss -0.8614 
2025-03-31 01:05:27.096415: Pseudo dice [np.float32(0.9477), np.float32(0.9432)] 
2025-03-31 01:05:27.096475: Epoch time: 26.7 s 
2025-03-31 01:05:27.096523: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-03-31 01:05:30.801112:  
2025-03-31 01:05:30.801259: Epoch 994 
2025-03-31 01:05:30.801349: Current learning rate: 0.0001 
2025-03-31 01:05:57.522826: train_loss -0.8917 
2025-03-31 01:05:57.522986: val_loss -0.8309 
2025-03-31 01:05:57.523064: Pseudo dice [np.float32(0.939), np.float32(0.9319)] 
2025-03-31 01:05:57.523160: Epoch time: 26.72 s 
2025-03-31 01:05:58.310641:  
2025-03-31 01:05:58.310823: Epoch 995 
2025-03-31 01:05:58.310912: Current learning rate: 8e-05 
2025-03-31 01:06:25.076988: train_loss -0.891 
2025-03-31 01:06:25.077165: val_loss -0.8175 
2025-03-31 01:06:25.077221: Pseudo dice [np.float32(0.9282), np.float32(0.9344)] 
2025-03-31 01:06:25.077286: Epoch time: 26.77 s 
2025-03-31 01:06:25.863240:  
2025-03-31 01:06:25.863395: Epoch 996 
2025-03-31 01:06:25.863479: Current learning rate: 7e-05 
2025-03-31 01:06:52.652306: train_loss -0.8917 
2025-03-31 01:06:52.652437: val_loss -0.836 
2025-03-31 01:06:52.652541: Pseudo dice [np.float32(0.9388), np.float32(0.9366)] 
2025-03-31 01:06:52.652617: Epoch time: 26.79 s 
2025-03-31 01:06:53.441722:  
2025-03-31 01:06:53.441877: Epoch 997 
2025-03-31 01:06:53.441961: Current learning rate: 5e-05 
2025-03-31 01:07:20.174166: train_loss -0.8883 
2025-03-31 01:07:20.174299: val_loss -0.8508 
2025-03-31 01:07:20.174355: Pseudo dice [np.float32(0.9425), np.float32(0.9384)] 
2025-03-31 01:07:20.174417: Epoch time: 26.73 s 
2025-03-31 01:07:20.959057:  
2025-03-31 01:07:20.959212: Epoch 998 
2025-03-31 01:07:20.959295: Current learning rate: 4e-05 
2025-03-31 01:07:47.731538: train_loss -0.8899 
2025-03-31 01:07:47.731698: val_loss -0.8191 
2025-03-31 01:07:47.731754: Pseudo dice [np.float32(0.9339), np.float32(0.9306)] 
2025-03-31 01:07:47.731825: Epoch time: 26.77 s 
2025-03-31 01:07:48.513088:  
2025-03-31 01:07:48.513256: Epoch 999 
2025-03-31 01:07:48.513337: Current learning rate: 2e-05 
2025-03-31 01:08:15.268309: train_loss -0.8914 
2025-03-31 01:08:15.268540: val_loss -0.8494 
2025-03-31 01:08:15.268596: Pseudo dice [np.float32(0.9449), np.float32(0.9379)] 
2025-03-31 01:08:15.268661: Epoch time: 26.76 s 
2025-03-31 01:08:16.572537: Training done. 
2025-03-31 01:08:16.717460: Using splits from existing split file: /home/ulixes/segmentation_cv/unet/nnUNet/nnUNet_preprocessed/Dataset001_PetSegmentation/splits_final.json 
2025-03-31 01:08:16.723694: The split file contains 5 splits. 
2025-03-31 01:08:16.723763: Desired fold for training: 0 
2025-03-31 01:08:16.723801: This split has 9329 training and 2331 validation cases. 
2025-03-31 01:08:16.906583: predicting pet_0000 
2025-03-31 01:08:16.918058: pet_0000, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:08:41.217501: predicting pet_0008 
2025-03-31 01:08:41.221553: pet_0008, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:41.246302: predicting pet_0018 
2025-03-31 01:08:41.250200: pet_0018, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.272137: predicting pet_0020 
2025-03-31 01:08:41.276184: pet_0020, shape torch.Size([3, 1, 413, 512]), rank 0 
2025-03-31 01:08:41.296411: predicting pet_0026 
2025-03-31 01:08:41.299868: pet_0026, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:41.320922: predicting pet_0029 
2025-03-31 01:08:41.325425: pet_0029, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:41.348090: predicting pet_0035 
2025-03-31 01:08:41.352830: pet_0035, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:41.376422: predicting pet_0043 
2025-03-31 01:08:41.380602: pet_0043, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:41.404049: predicting pet_0045 
2025-03-31 01:08:41.407518: pet_0045, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:08:41.428703: predicting pet_0049 
2025-03-31 01:08:41.433384: pet_0049, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.453439: predicting pet_0052 
2025-03-31 01:08:41.458195: pet_0052, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:41.478345: predicting pet_0059 
2025-03-31 01:08:41.481944: pet_0059, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.506527: predicting pet_0060 
2025-03-31 01:08:41.512112: pet_0060, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:41.532718: predicting pet_0063 
2025-03-31 01:08:41.538830: pet_0063, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:41.560830: predicting pet_0064 
2025-03-31 01:08:41.564105: pet_0064, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.586549: predicting pet_0066 
2025-03-31 01:08:41.589788: pet_0066, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:41.608371: predicting pet_0068 
2025-03-31 01:08:41.615891: pet_0068, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.633658: predicting pet_0069 
2025-03-31 01:08:41.640473: pet_0069, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.660298: predicting pet_0073 
2025-03-31 01:08:41.667657: pet_0073, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:41.685481: predicting pet_0081 
2025-03-31 01:08:41.689004: pet_0081, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:41.707846: predicting pet_0089 
2025-03-31 01:08:41.711586: pet_0089, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:08:41.730865: predicting pet_0104 
2025-03-31 01:08:41.735262: pet_0104, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:08:41.755248: predicting pet_0110 
2025-03-31 01:08:41.763985: pet_0110, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.783231: predicting pet_0116 
2025-03-31 01:08:41.787074: pet_0116, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:41.805603: predicting pet_0117 
2025-03-31 01:08:41.809237: pet_0117, shape torch.Size([3, 1, 322, 512]), rank 0 
2025-03-31 01:08:41.827960: predicting pet_0123 
2025-03-31 01:08:41.832547: pet_0123, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.853755: predicting pet_0128 
2025-03-31 01:08:41.859968: pet_0128, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.880551: predicting pet_0131 
2025-03-31 01:08:41.885356: pet_0131, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:08:41.907993: predicting pet_0134 
2025-03-31 01:08:41.918818: pet_0134, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:41.938079: predicting pet_0136 
2025-03-31 01:08:41.946101: pet_0136, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:08:41.966593: predicting pet_0141 
2025-03-31 01:08:41.970143: pet_0141, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:41.990359: predicting pet_0143 
2025-03-31 01:08:41.995259: pet_0143, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.014040: predicting pet_0147 
2025-03-31 01:08:42.019160: pet_0147, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:42.041152: predicting pet_0152 
2025-03-31 01:08:42.045023: pet_0152, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:42.064547: predicting pet_0153 
2025-03-31 01:08:42.068922: pet_0153, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:42.088930: predicting pet_0162 
2025-03-31 01:08:42.092926: pet_0162, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:42.113561: predicting pet_0164 
2025-03-31 01:08:42.121471: pet_0164, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:42.140924: predicting pet_0172 
2025-03-31 01:08:42.144952: pet_0172, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:42.164459: predicting pet_0186 
2025-03-31 01:08:42.172349: pet_0186, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:42.190478: predicting pet_0187 
2025-03-31 01:08:42.193699: pet_0187, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:42.211337: predicting pet_0192 
2025-03-31 01:08:42.216455: pet_0192, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:08:42.233707: predicting pet_0210 
2025-03-31 01:08:42.238168: pet_0210, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:08:42.256321: predicting pet_0211 
2025-03-31 01:08:42.262160: pet_0211, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.280329: predicting pet_0212 
2025-03-31 01:08:42.284311: pet_0212, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:42.302002: predicting pet_0214 
2025-03-31 01:08:42.304247: pet_0214, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:42.324610: predicting pet_0216 
2025-03-31 01:08:42.327690: pet_0216, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:42.346440: predicting pet_0221 
2025-03-31 01:08:42.351268: pet_0221, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:42.371242: predicting pet_0224 
2025-03-31 01:08:42.373924: pet_0224, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.393415: predicting pet_0225 
2025-03-31 01:08:42.402080: pet_0225, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.421173: predicting pet_0226 
2025-03-31 01:08:42.425890: pet_0226, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:08:42.445653: predicting pet_0238 
2025-03-31 01:08:42.450140: pet_0238, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:42.470172: predicting pet_0239 
2025-03-31 01:08:42.474865: pet_0239, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.494259: predicting pet_0243 
2025-03-31 01:08:42.497908: pet_0243, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:42.519854: predicting pet_0245 
2025-03-31 01:08:42.523700: pet_0245, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:42.548379: predicting pet_0246 
2025-03-31 01:08:42.552511: pet_0246, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.570974: predicting pet_0250 
2025-03-31 01:08:42.578186: pet_0250, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:42.599213: predicting pet_0262 
2025-03-31 01:08:42.606670: pet_0262, shape torch.Size([3, 1, 384, 512]), rank 0 
2025-03-31 01:08:42.628495: predicting pet_0264 
2025-03-31 01:08:42.634256: pet_0264, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.653225: predicting pet_0267 
2025-03-31 01:08:42.655975: pet_0267, shape torch.Size([3, 1, 512, 367]), rank 0 
2025-03-31 01:08:42.677486: predicting pet_0268 
2025-03-31 01:08:42.681369: pet_0268, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.704648: predicting pet_0272 
2025-03-31 01:08:42.709002: pet_0272, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:42.735605: predicting pet_0279 
2025-03-31 01:08:42.740623: pet_0279, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:08:42.770113: predicting pet_0282 
2025-03-31 01:08:42.778156: pet_0282, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:42.803822: predicting pet_0285 
2025-03-31 01:08:42.814163: pet_0285, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:42.838619: predicting pet_0290 
2025-03-31 01:08:42.846876: pet_0290, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:42.871657: predicting pet_0297 
2025-03-31 01:08:42.876024: pet_0297, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.901572: predicting pet_0303 
2025-03-31 01:08:42.906772: pet_0303, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:42.932312: predicting pet_0306 
2025-03-31 01:08:42.940276: pet_0306, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:42.964842: predicting pet_0309 
2025-03-31 01:08:42.975090: pet_0309, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:42.999257: predicting pet_0311 
2025-03-31 01:08:43.003351: pet_0311, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:43.028197: predicting pet_0315 
2025-03-31 01:08:43.034982: pet_0315, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:43.062167: predicting pet_0335 
2025-03-31 01:08:43.066521: pet_0335, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:08:43.092578: predicting pet_0339 
2025-03-31 01:08:43.099118: pet_0339, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:08:43.122894: predicting pet_0341 
2025-03-31 01:08:43.128658: pet_0341, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:08:43.156897: predicting pet_0348 
2025-03-31 01:08:43.166399: pet_0348, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.191819: predicting pet_0351 
2025-03-31 01:08:43.199716: pet_0351, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:43.225157: predicting pet_0356 
2025-03-31 01:08:43.228737: pet_0356, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:43.253901: predicting pet_0359 
2025-03-31 01:08:43.259135: pet_0359, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.281041: predicting pet_0360 
2025-03-31 01:08:43.284951: pet_0360, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.306283: predicting pet_0367 
2025-03-31 01:08:43.315489: pet_0367, shape torch.Size([3, 1, 409, 512]), rank 0 
2025-03-31 01:08:43.336067: predicting pet_0370 
2025-03-31 01:08:43.339914: pet_0370, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.358580: predicting pet_0376 
2025-03-31 01:08:43.364609: pet_0376, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.385074: predicting pet_0379 
2025-03-31 01:08:43.389223: pet_0379, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:43.407388: predicting pet_0394 
2025-03-31 01:08:43.411160: pet_0394, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.432234: predicting pet_0395 
2025-03-31 01:08:43.438092: pet_0395, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:43.458329: predicting pet_0397 
2025-03-31 01:08:43.461767: pet_0397, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.483564: predicting pet_0412 
2025-03-31 01:08:43.487287: pet_0412, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.508776: predicting pet_0417 
2025-03-31 01:08:43.513014: pet_0417, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.536489: predicting pet_0419 
2025-03-31 01:08:43.540509: pet_0419, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.561755: predicting pet_0426 
2025-03-31 01:08:43.567197: pet_0426, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:43.585797: predicting pet_0427 
2025-03-31 01:08:43.594283: pet_0427, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.617498: predicting pet_0428 
2025-03-31 01:08:43.621661: pet_0428, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:43.643722: predicting pet_0450 
2025-03-31 01:08:43.649332: pet_0450, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:08:43.671159: predicting pet_0453 
2025-03-31 01:08:43.674507: pet_0453, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:43.694598: predicting pet_0454 
2025-03-31 01:08:43.698907: pet_0454, shape torch.Size([3, 1, 346, 512]), rank 0 
2025-03-31 01:08:43.719689: predicting pet_0464 
2025-03-31 01:08:43.723986: pet_0464, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:43.744272: predicting pet_0468 
2025-03-31 01:08:43.748068: pet_0468, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:43.769440: predicting pet_0479 
2025-03-31 01:08:43.776489: pet_0479, shape torch.Size([3, 1, 512, 449]), rank 0 
2025-03-31 01:08:43.797848: predicting pet_0481 
2025-03-31 01:08:43.800793: pet_0481, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.820219: predicting pet_0493 
2025-03-31 01:08:43.823687: pet_0493, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:43.844529: predicting pet_0494 
2025-03-31 01:08:43.848511: pet_0494, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:43.868048: predicting pet_0499 
2025-03-31 01:08:43.872826: pet_0499, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.892006: predicting pet_0502 
2025-03-31 01:08:43.895821: pet_0502, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.917140: predicting pet_0511 
2025-03-31 01:08:43.921392: pet_0511, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:43.944032: predicting pet_0515 
2025-03-31 01:08:43.948477: pet_0515, shape torch.Size([3, 1, 512, 482]), rank 0 
2025-03-31 01:08:43.968227: predicting pet_0516 
2025-03-31 01:08:43.975807: pet_0516, shape torch.Size([3, 1, 512, 480]), rank 0 
2025-03-31 01:08:43.995129: predicting pet_0517 
2025-03-31 01:08:43.999083: pet_0517, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.018975: predicting pet_0518 
2025-03-31 01:08:44.022840: pet_0518, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:44.041897: predicting pet_0530 
2025-03-31 01:08:44.045687: pet_0530, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:44.067383: predicting pet_0532 
2025-03-31 01:08:44.072031: pet_0532, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.093523: predicting pet_0541 
2025-03-31 01:08:44.098312: pet_0541, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:44.118045: predicting pet_0543 
2025-03-31 01:08:44.126787: pet_0543, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.148520: predicting pet_0549 
2025-03-31 01:08:44.153418: pet_0549, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:44.173732: predicting pet_0574 
2025-03-31 01:08:44.178334: pet_0574, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.198819: predicting pet_0575 
2025-03-31 01:08:44.203833: pet_0575, shape torch.Size([3, 1, 322, 512]), rank 0 
2025-03-31 01:08:44.222363: predicting pet_0577 
2025-03-31 01:08:44.232552: pet_0577, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:44.254478: predicting pet_0580 
2025-03-31 01:08:44.258112: pet_0580, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:44.279479: predicting pet_0582 
2025-03-31 01:08:44.285506: pet_0582, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:44.305315: predicting pet_0587 
2025-03-31 01:08:44.311071: pet_0587, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:44.329591: predicting pet_0589 
2025-03-31 01:08:44.333166: pet_0589, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.351793: predicting pet_0593 
2025-03-31 01:08:44.356042: pet_0593, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:44.374732: predicting pet_0615 
2025-03-31 01:08:44.381912: pet_0615, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:44.404555: predicting pet_0616 
2025-03-31 01:08:44.408563: pet_0616, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.427522: predicting pet_0617 
2025-03-31 01:08:44.435814: pet_0617, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:44.456014: predicting pet_0621 
2025-03-31 01:08:44.459500: pet_0621, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.483150: predicting pet_0622 
2025-03-31 01:08:44.489609: pet_0622, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:44.508030: predicting pet_0624 
2025-03-31 01:08:44.513031: pet_0624, shape torch.Size([3, 1, 512, 482]), rank 0 
2025-03-31 01:08:44.533778: predicting pet_0632 
2025-03-31 01:08:44.538126: pet_0632, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:44.559050: predicting pet_0638 
2025-03-31 01:08:44.563492: pet_0638, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.582812: predicting pet_0645 
2025-03-31 01:08:44.591040: pet_0645, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.610360: predicting pet_0648 
2025-03-31 01:08:44.614885: pet_0648, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:44.636968: predicting pet_0664 
2025-03-31 01:08:44.643717: pet_0664, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:44.662898: predicting pet_0667 
2025-03-31 01:08:44.667336: pet_0667, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:44.693080: predicting pet_0669 
2025-03-31 01:08:44.697522: pet_0669, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:44.719578: predicting pet_0671 
2025-03-31 01:08:44.724903: pet_0671, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:44.744110: predicting pet_0672 
2025-03-31 01:08:44.748244: pet_0672, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:44.768560: predicting pet_0676 
2025-03-31 01:08:44.772748: pet_0676, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:44.792696: predicting pet_0682 
2025-03-31 01:08:44.800224: pet_0682, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:44.821672: predicting pet_0691 
2025-03-31 01:08:44.825910: pet_0691, shape torch.Size([3, 1, 384, 512]), rank 0 
2025-03-31 01:08:44.846282: predicting pet_0699 
2025-03-31 01:08:44.851528: pet_0699, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:44.870522: predicting pet_0700 
2025-03-31 01:08:44.874358: pet_0700, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:44.893460: predicting pet_0701 
2025-03-31 01:08:44.896905: pet_0701, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:44.917776: predicting pet_0706 
2025-03-31 01:08:44.921643: pet_0706, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:08:44.943341: predicting pet_0707 
2025-03-31 01:08:44.949586: pet_0707, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:44.969284: predicting pet_0714 
2025-03-31 01:08:44.972683: pet_0714, shape torch.Size([3, 1, 290, 512]), rank 0 
2025-03-31 01:08:44.993079: predicting pet_0722 
2025-03-31 01:08:44.998400: pet_0722, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:08:45.019125: predicting pet_0727 
2025-03-31 01:08:45.027322: pet_0727, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:45.047476: predicting pet_0735 
2025-03-31 01:08:45.052555: pet_0735, shape torch.Size([3, 1, 512, 344]), rank 0 
2025-03-31 01:08:45.072619: predicting pet_0741 
2025-03-31 01:08:45.081165: pet_0741, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:45.102768: predicting pet_0745 
2025-03-31 01:08:45.106246: pet_0745, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:45.125828: predicting pet_0747 
2025-03-31 01:08:45.129537: pet_0747, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:08:45.152233: predicting pet_0754 
2025-03-31 01:08:45.156996: pet_0754, shape torch.Size([3, 1, 408, 512]), rank 0 
2025-03-31 01:08:45.187115: predicting pet_0756 
2025-03-31 01:08:45.201129: pet_0756, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:45.232262: predicting pet_0759 
2025-03-31 01:08:45.241368: pet_0759, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:45.261693: predicting pet_0760 
2025-03-31 01:08:45.265692: pet_0760, shape torch.Size([3, 1, 512, 393]), rank 0 
2025-03-31 01:08:45.286718: predicting pet_0763 
2025-03-31 01:08:45.294533: pet_0763, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:45.314604: predicting pet_0765 
2025-03-31 01:08:45.321950: pet_0765, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:45.341772: predicting pet_0767 
2025-03-31 01:08:45.343468: pet_0767, shape torch.Size([3, 1, 512, 367]), rank 0 
2025-03-31 01:08:45.363501: predicting pet_0781 
2025-03-31 01:08:45.369241: pet_0781, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:45.390120: predicting pet_0789 
2025-03-31 01:08:45.397699: pet_0789, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:45.417814: predicting pet_0791 
2025-03-31 01:08:45.424742: pet_0791, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:45.445801: predicting pet_0796 
2025-03-31 01:08:45.449275: pet_0796, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:45.470904: predicting pet_0797 
2025-03-31 01:08:45.476695: pet_0797, shape torch.Size([3, 1, 512, 385]), rank 0 
2025-03-31 01:08:45.496791: predicting pet_0805 
2025-03-31 01:08:45.502642: pet_0805, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:45.524659: predicting pet_0813 
2025-03-31 01:08:45.529656: pet_0813, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:45.551599: predicting pet_0816 
2025-03-31 01:08:45.558580: pet_0816, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:45.579926: predicting pet_0821 
2025-03-31 01:08:45.588921: pet_0821, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:45.609711: predicting pet_0822 
2025-03-31 01:08:45.615906: pet_0822, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:08:45.635356: predicting pet_0824 
2025-03-31 01:08:45.643795: pet_0824, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:45.663796: predicting pet_0827 
2025-03-31 01:08:45.668093: pet_0827, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:45.689705: predicting pet_0830 
2025-03-31 01:08:45.694359: pet_0830, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:45.715990: predicting pet_0831 
2025-03-31 01:08:45.722433: pet_0831, shape torch.Size([3, 1, 322, 512]), rank 0 
2025-03-31 01:08:45.743824: predicting pet_0833 
2025-03-31 01:08:45.749161: pet_0833, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:45.770628: predicting pet_0843 
2025-03-31 01:08:45.774972: pet_0843, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:45.795474: predicting pet_0846 
2025-03-31 01:08:45.799130: pet_0846, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:45.817323: predicting pet_0853 
2025-03-31 01:08:45.824780: pet_0853, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:45.843709: predicting pet_0863 
2025-03-31 01:08:45.849919: pet_0863, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:45.870041: predicting pet_0871 
2025-03-31 01:08:45.877902: pet_0871, shape torch.Size([3, 1, 512, 449]), rank 0 
2025-03-31 01:08:45.897989: predicting pet_0876 
2025-03-31 01:08:45.904264: pet_0876, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:45.924202: predicting pet_0884 
2025-03-31 01:08:45.929512: pet_0884, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:45.950464: predicting pet_0885 
2025-03-31 01:08:45.957525: pet_0885, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:45.978166: predicting pet_0888 
2025-03-31 01:08:45.982573: pet_0888, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.000953: predicting pet_0889 
2025-03-31 01:08:46.005446: pet_0889, shape torch.Size([3, 1, 512, 385]), rank 0 
2025-03-31 01:08:46.024577: predicting pet_0895 
2025-03-31 01:08:46.028412: pet_0895, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:46.050241: predicting pet_0904 
2025-03-31 01:08:46.058288: pet_0904, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:46.079627: predicting pet_0905 
2025-03-31 01:08:46.087300: pet_0905, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:46.108219: predicting pet_0914 
2025-03-31 01:08:46.113103: pet_0914, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:46.134683: predicting pet_0915 
2025-03-31 01:08:46.139866: pet_0915, shape torch.Size([3, 1, 482, 512]), rank 0 
2025-03-31 01:08:46.162126: predicting pet_0920 
2025-03-31 01:08:46.168562: pet_0920, shape torch.Size([3, 1, 512, 480]), rank 0 
2025-03-31 01:08:46.190238: predicting pet_0921 
2025-03-31 01:08:46.197375: pet_0921, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.220142: predicting pet_0922 
2025-03-31 01:08:46.224136: pet_0922, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.245677: predicting pet_0925 
2025-03-31 01:08:46.253993: pet_0925, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:46.277979: predicting pet_0928 
2025-03-31 01:08:46.283543: pet_0928, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:46.306711: predicting pet_0931 
2025-03-31 01:08:46.313689: pet_0931, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.337445: predicting pet_0932 
2025-03-31 01:08:46.340580: pet_0932, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:08:46.362844: predicting pet_0933 
2025-03-31 01:08:46.368175: pet_0933, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.388851: predicting pet_0946 
2025-03-31 01:08:46.393221: pet_0946, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:08:46.414012: predicting pet_0949 
2025-03-31 01:08:46.422790: pet_0949, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:46.445849: predicting pet_0951 
2025-03-31 01:08:46.452650: pet_0951, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.476927: predicting pet_0952 
2025-03-31 01:08:46.481832: pet_0952, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:46.505185: predicting pet_0953 
2025-03-31 01:08:46.516319: pet_0953, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:46.539229: predicting pet_0970 
2025-03-31 01:08:46.542048: pet_0970, shape torch.Size([3, 1, 364, 512]), rank 0 
2025-03-31 01:08:46.562837: predicting pet_0983 
2025-03-31 01:08:46.567427: pet_0983, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:46.587847: predicting pet_0985 
2025-03-31 01:08:46.595036: pet_0985, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.615782: predicting pet_0992 
2025-03-31 01:08:46.624177: pet_0992, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:46.643384: predicting pet_0993 
2025-03-31 01:08:46.649357: pet_0993, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:46.669638: predicting pet_10001 
2025-03-31 01:08:46.677882: pet_10001, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.699143: predicting pet_10007 
2025-03-31 01:08:46.706060: pet_10007, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.724688: predicting pet_10014 
2025-03-31 01:08:46.728348: pet_10014, shape torch.Size([3, 1, 512, 433]), rank 0 
2025-03-31 01:08:46.747635: predicting pet_10019 
2025-03-31 01:08:46.753458: pet_10019, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.774024: predicting pet_10021 
2025-03-31 01:08:46.778560: pet_10021, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:08:46.798270: predicting pet_10024 
2025-03-31 01:08:46.804220: pet_10024, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.823658: predicting pet_10025 
2025-03-31 01:08:46.830060: pet_10025, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.848787: predicting pet_1003 
2025-03-31 01:08:46.853483: pet_1003, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:46.873457: predicting pet_10031 
2025-03-31 01:08:46.877634: pet_10031, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.896848: predicting pet_10033 
2025-03-31 01:08:46.909342: pet_10033, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.928608: predicting pet_10037 
2025-03-31 01:08:46.933647: pet_10037, shape torch.Size([3, 1, 432, 512]), rank 0 
2025-03-31 01:08:46.954777: predicting pet_10038 
2025-03-31 01:08:46.959579: pet_10038, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:46.978642: predicting pet_1004 
2025-03-31 01:08:46.982652: pet_1004, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:47.003487: predicting pet_10044 
2025-03-31 01:08:47.008668: pet_10044, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.028353: predicting pet_10048 
2025-03-31 01:08:47.029562: pet_10048, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.048304: predicting pet_10054 
2025-03-31 01:08:47.053103: pet_10054, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.074021: predicting pet_10055 
2025-03-31 01:08:47.078840: pet_10055, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:08:47.101255: predicting pet_10060 
2025-03-31 01:08:47.108357: pet_10060, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.129605: predicting pet_10068 
2025-03-31 01:08:47.137518: pet_10068, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.157391: predicting pet_10069 
2025-03-31 01:08:47.162611: pet_10069, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.185127: predicting pet_10078 
2025-03-31 01:08:47.189837: pet_10078, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.212430: predicting pet_10082 
2025-03-31 01:08:47.213554: pet_10082, shape torch.Size([3, 1, 240, 202]), rank 0 
2025-03-31 01:08:47.239288: predicting pet_10083 
2025-03-31 01:08:47.246964: pet_10083, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.270084: predicting pet_10086 
2025-03-31 01:08:47.275019: pet_10086, shape torch.Size([3, 1, 481, 448]), rank 0 
2025-03-31 01:08:47.300617: predicting pet_10088 
2025-03-31 01:08:47.309616: pet_10088, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.329522: predicting pet_10092 
2025-03-31 01:08:47.333510: pet_10092, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.353857: predicting pet_10106 
2025-03-31 01:08:47.359688: pet_10106, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.378903: predicting pet_1012 
2025-03-31 01:08:47.383629: pet_1012, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:47.403018: predicting pet_10126 
2025-03-31 01:08:47.408384: pet_10126, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.429732: predicting pet_10128 
2025-03-31 01:08:47.438331: pet_10128, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.457555: predicting pet_10132 
2025-03-31 01:08:47.467610: pet_10132, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.488680: predicting pet_1014 
2025-03-31 01:08:47.493155: pet_1014, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:47.515242: predicting pet_10147 
2025-03-31 01:08:47.524111: pet_10147, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.544786: predicting pet_10149 
2025-03-31 01:08:47.553817: pet_10149, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.573213: predicting pet_10150 
2025-03-31 01:08:47.582300: pet_10150, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.604939: predicting pet_10159 
2025-03-31 01:08:47.614122: pet_10159, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.634208: predicting pet_10160 
2025-03-31 01:08:47.642377: pet_10160, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.662200: predicting pet_10164 
2025-03-31 01:08:47.670126: pet_10164, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.689192: predicting pet_10172 
2025-03-31 01:08:47.695113: pet_10172, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.714190: predicting pet_10173 
2025-03-31 01:08:47.721147: pet_10173, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.741435: predicting pet_10176 
2025-03-31 01:08:47.747100: pet_10176, shape torch.Size([3, 1, 431, 512]), rank 0 
2025-03-31 01:08:47.769543: predicting pet_10179 
2025-03-31 01:08:47.773584: pet_10179, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.794304: predicting pet_10183 
2025-03-31 01:08:47.800515: pet_10183, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.824488: predicting pet_1020 
2025-03-31 01:08:47.828118: pet_1020, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:47.849581: predicting pet_10210 
2025-03-31 01:08:47.854185: pet_10210, shape torch.Size([3, 1, 402, 512]), rank 0 
2025-03-31 01:08:47.874879: predicting pet_10215 
2025-03-31 01:08:47.883587: pet_10215, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.901743: predicting pet_10224 
2025-03-31 01:08:47.905358: pet_10224, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.927130: predicting pet_10237 
2025-03-31 01:08:47.936025: pet_10237, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:47.955579: predicting pet_10242 
2025-03-31 01:08:47.961135: pet_10242, shape torch.Size([3, 1, 424, 512]), rank 0 
2025-03-31 01:08:47.983032: predicting pet_10247 
2025-03-31 01:08:47.990334: pet_10247, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.011495: predicting pet_10251 
2025-03-31 01:08:48.016610: pet_10251, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.037775: predicting pet_10256 
2025-03-31 01:08:48.042740: pet_10256, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.066099: predicting pet_10260 
2025-03-31 01:08:48.072911: pet_10260, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:48.092623: predicting pet_10263 
2025-03-31 01:08:48.099267: pet_10263, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.121675: predicting pet_10265 
2025-03-31 01:08:48.126354: pet_10265, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:08:48.147306: predicting pet_10278 
2025-03-31 01:08:48.153862: pet_10278, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.173697: predicting pet_10282 
2025-03-31 01:08:48.178125: pet_10282, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.199673: predicting pet_10288 
2025-03-31 01:08:48.204995: pet_10288, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.228571: predicting pet_10294 
2025-03-31 01:08:48.233242: pet_10294, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.253283: predicting pet_1030 
2025-03-31 01:08:48.257028: pet_1030, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:48.280441: predicting pet_10304 
2025-03-31 01:08:48.285409: pet_10304, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.304394: predicting pet_10313 
2025-03-31 01:08:48.311164: pet_10313, shape torch.Size([3, 1, 438, 503]), rank 0 
2025-03-31 01:08:48.332547: predicting pet_10314 
2025-03-31 01:08:48.341289: pet_10314, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.360007: predicting pet_10321 
2025-03-31 01:08:48.363413: pet_10321, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.384022: predicting pet_10324 
2025-03-31 01:08:48.391786: pet_10324, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.409674: predicting pet_10331 
2025-03-31 01:08:48.417592: pet_10331, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.438193: predicting pet_10334 
2025-03-31 01:08:48.445684: pet_10334, shape torch.Size([3, 1, 451, 512]), rank 0 
2025-03-31 01:08:48.465131: predicting pet_10336 
2025-03-31 01:08:48.472300: pet_10336, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.494727: predicting pet_10340 
2025-03-31 01:08:48.503808: pet_10340, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.525730: predicting pet_10344 
2025-03-31 01:08:48.532846: pet_10344, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.552833: predicting pet_10350 
2025-03-31 01:08:48.557443: pet_10350, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.576062: predicting pet_10351 
2025-03-31 01:08:48.581965: pet_10351, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.604544: predicting pet_10357 
2025-03-31 01:08:48.614523: pet_10357, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.633295: predicting pet_1036 
2025-03-31 01:08:48.636980: pet_1036, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:48.661799: predicting pet_10363 
2025-03-31 01:08:48.670321: pet_10363, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.692245: predicting pet_10364 
2025-03-31 01:08:48.698889: pet_10364, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:08:48.718364: predicting pet_10365 
2025-03-31 01:08:48.720666: pet_10365, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.745297: predicting pet_1037 
2025-03-31 01:08:48.752044: pet_1037, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:08:48.771570: predicting pet_10373 
2025-03-31 01:08:48.777672: pet_10373, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:08:48.799470: predicting pet_10376 
2025-03-31 01:08:48.803717: pet_10376, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.825045: predicting pet_10377 
2025-03-31 01:08:48.834389: pet_10377, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:08:48.855688: predicting pet_10387 
2025-03-31 01:08:48.867607: pet_10387, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.887527: predicting pet_10389 
2025-03-31 01:08:48.891306: pet_10389, shape torch.Size([3, 1, 448, 504]), rank 0 
2025-03-31 01:08:48.913812: predicting pet_10396 
2025-03-31 01:08:48.916275: pet_10396, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.938986: predicting pet_10399 
2025-03-31 01:08:48.946785: pet_10399, shape torch.Size([3, 1, 512, 481]), rank 0 
2025-03-31 01:08:48.967768: predicting pet_10402 
2025-03-31 01:08:48.971251: pet_10402, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:48.989258: predicting pet_10404 
2025-03-31 01:08:48.993433: pet_10404, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.014432: predicting pet_1041 
2025-03-31 01:08:49.023786: pet_1041, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:49.044897: predicting pet_10422 
2025-03-31 01:08:49.051533: pet_10422, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.070990: predicting pet_10430 
2025-03-31 01:08:49.076629: pet_10430, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.096231: predicting pet_10432 
2025-03-31 01:08:49.102386: pet_10432, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.124776: predicting pet_10440 
2025-03-31 01:08:49.133691: pet_10440, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.153195: predicting pet_10445 
2025-03-31 01:08:49.160732: pet_10445, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.178893: predicting pet_10447 
2025-03-31 01:08:49.181839: pet_10447, shape torch.Size([3, 1, 432, 512]), rank 0 
2025-03-31 01:08:49.201085: predicting pet_10459 
2025-03-31 01:08:49.205097: pet_10459, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:49.226340: predicting pet_1046 
2025-03-31 01:08:49.230095: pet_1046, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:49.251930: predicting pet_10460 
2025-03-31 01:08:49.257330: pet_10460, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.276078: predicting pet_10462 
2025-03-31 01:08:49.280676: pet_10462, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.300516: predicting pet_10468 
2025-03-31 01:08:49.305593: pet_10468, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.328842: predicting pet_10479 
2025-03-31 01:08:49.332529: pet_10479, shape torch.Size([3, 1, 464, 369]), rank 0 
2025-03-31 01:08:49.358292: predicting pet_10481 
2025-03-31 01:08:49.365981: pet_10481, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.385237: predicting pet_10491 
2025-03-31 01:08:49.389586: pet_10491, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.407802: predicting pet_10492 
2025-03-31 01:08:49.414821: pet_10492, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.437512: predicting pet_10497 
2025-03-31 01:08:49.443416: pet_10497, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.464754: predicting pet_10500 
2025-03-31 01:08:49.474776: pet_10500, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.494546: predicting pet_10502 
2025-03-31 01:08:49.504431: pet_10502, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.525084: predicting pet_10504 
2025-03-31 01:08:49.532494: pet_10504, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.553115: predicting pet_10507 
2025-03-31 01:08:49.561110: pet_10507, shape torch.Size([3, 1, 453, 504]), rank 0 
2025-03-31 01:08:49.582373: predicting pet_10508 
2025-03-31 01:08:49.586734: pet_10508, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.607811: predicting pet_10509 
2025-03-31 01:08:49.618172: pet_10509, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.637928: predicting pet_10512 
2025-03-31 01:08:49.647616: pet_10512, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.669017: predicting pet_10524 
2025-03-31 01:08:49.674029: pet_10524, shape torch.Size([3, 1, 512, 416]), rank 0 
2025-03-31 01:08:49.695418: predicting pet_10526 
2025-03-31 01:08:49.701090: pet_10526, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.721407: predicting pet_1055 
2025-03-31 01:08:49.725552: pet_1055, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:49.745909: predicting pet_10557 
2025-03-31 01:08:49.751107: pet_10557, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.772657: predicting pet_10570 
2025-03-31 01:08:49.778782: pet_10570, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.797914: predicting pet_10572 
2025-03-31 01:08:49.801250: pet_10572, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.822026: predicting pet_10573 
2025-03-31 01:08:49.827848: pet_10573, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.846519: predicting pet_10574 
2025-03-31 01:08:49.851598: pet_10574, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.871185: predicting pet_10576 
2025-03-31 01:08:49.879665: pet_10576, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.899640: predicting pet_10577 
2025-03-31 01:08:49.904662: pet_10577, shape torch.Size([3, 1, 434, 512]), rank 0 
2025-03-31 01:08:49.924334: predicting pet_1058 
2025-03-31 01:08:49.928276: pet_1058, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:49.952224: predicting pet_10581 
2025-03-31 01:08:49.958453: pet_10581, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:49.978029: predicting pet_10583 
2025-03-31 01:08:49.983094: pet_10583, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.003027: predicting pet_10587 
2025-03-31 01:08:50.011170: pet_10587, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.031171: predicting pet_10590 
2025-03-31 01:08:50.035485: pet_10590, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.054730: predicting pet_10593 
2025-03-31 01:08:50.064398: pet_10593, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.086980: predicting pet_10601 
2025-03-31 01:08:50.093610: pet_10601, shape torch.Size([3, 1, 488, 512]), rank 0 
2025-03-31 01:08:50.114506: predicting pet_10605 
2025-03-31 01:08:50.119559: pet_10605, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:08:50.142322: predicting pet_10608 
2025-03-31 01:08:50.145928: pet_10608, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.165041: predicting pet_10609 
2025-03-31 01:08:50.170579: pet_10609, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.190741: predicting pet_10616 
2025-03-31 01:08:50.197709: pet_10616, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.218901: predicting pet_1062 
2025-03-31 01:08:50.222597: pet_1062, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:50.243415: predicting pet_10624 
2025-03-31 01:08:50.250770: pet_10624, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.271231: predicting pet_10630 
2025-03-31 01:08:50.275858: pet_10630, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.298748: predicting pet_10641 
2025-03-31 01:08:50.305162: pet_10641, shape torch.Size([3, 1, 512, 321]), rank 0 
2025-03-31 01:08:50.325328: predicting pet_10642 
2025-03-31 01:08:50.336403: pet_10642, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.355516: predicting pet_10651 
2025-03-31 01:08:50.361323: pet_10651, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.385984: predicting pet_10652 
2025-03-31 01:08:50.392315: pet_10652, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.414458: predicting pet_10659 
2025-03-31 01:08:50.422142: pet_10659, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.441595: predicting pet_1067 
2025-03-31 01:08:50.444638: pet_1067, shape torch.Size([3, 1, 512, 496]), rank 0 
2025-03-31 01:08:50.463560: predicting pet_10675 
2025-03-31 01:08:50.469112: pet_10675, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.487618: predicting pet_10676 
2025-03-31 01:08:50.492013: pet_10676, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.512526: predicting pet_10689 
2025-03-31 01:08:50.518514: pet_10689, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.539895: predicting pet_10690 
2025-03-31 01:08:50.548536: pet_10690, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.572856: predicting pet_10708 
2025-03-31 01:08:50.581897: pet_10708, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:50.601234: predicting pet_10709 
2025-03-31 01:08:50.610557: pet_10709, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.628896: predicting pet_10710 
2025-03-31 01:08:50.640821: pet_10710, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.662741: predicting pet_10714 
2025-03-31 01:08:50.667986: pet_10714, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:08:50.687110: predicting pet_10717 
2025-03-31 01:08:50.697868: pet_10717, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.718531: predicting pet_10726 
2025-03-31 01:08:50.728017: pet_10726, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.748918: predicting pet_10737 
2025-03-31 01:08:50.755681: pet_10737, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.773571: predicting pet_10749 
2025-03-31 01:08:50.783464: pet_10749, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.803900: predicting pet_10751 
2025-03-31 01:08:50.808847: pet_10751, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.830616: predicting pet_10758 
2025-03-31 01:08:50.834752: pet_10758, shape torch.Size([3, 1, 497, 336]), rank 0 
2025-03-31 01:08:50.853557: predicting pet_10761 
2025-03-31 01:08:50.857535: pet_10761, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:08:50.875999: predicting pet_10763 
2025-03-31 01:08:50.884537: pet_10763, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.905779: predicting pet_10764 
2025-03-31 01:08:50.910871: pet_10764, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.933672: predicting pet_10778 
2025-03-31 01:08:50.938627: pet_10778, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:50.959588: predicting pet_1078 
2025-03-31 01:08:50.963052: pet_1078, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:50.985777: predicting pet_10781 
2025-03-31 01:08:50.992514: pet_10781, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.010906: predicting pet_10787 
2025-03-31 01:08:51.017624: pet_10787, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.039196: predicting pet_10792 
2025-03-31 01:08:51.045527: pet_10792, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.070445: predicting pet_10801 
2025-03-31 01:08:51.078253: pet_10801, shape torch.Size([3, 1, 440, 512]), rank 0 
2025-03-31 01:08:51.098087: predicting pet_1081 
2025-03-31 01:08:51.104109: pet_1081, shape torch.Size([3, 1, 496, 512]), rank 0 
2025-03-31 01:08:51.127983: predicting pet_10817 
2025-03-31 01:08:51.137701: pet_10817, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.155747: predicting pet_10819 
2025-03-31 01:08:51.160600: pet_10819, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.182056: predicting pet_10826 
2025-03-31 01:08:51.186846: pet_10826, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.205940: predicting pet_10828 
2025-03-31 01:08:51.210310: pet_10828, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.231611: predicting pet_10842 
2025-03-31 01:08:51.240690: pet_10842, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.258723: predicting pet_10851 
2025-03-31 01:08:51.264616: pet_10851, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.284796: predicting pet_10852 
2025-03-31 01:08:51.289505: pet_10852, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.309047: predicting pet_10864 
2025-03-31 01:08:51.319393: pet_10864, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.338576: predicting pet_10866 
2025-03-31 01:08:51.344970: pet_10866, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.364436: predicting pet_10877 
2025-03-31 01:08:51.370229: pet_10877, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.389825: predicting pet_1088 
2025-03-31 01:08:51.394123: pet_1088, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:51.415379: predicting pet_10884 
2025-03-31 01:08:51.419041: pet_10884, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.439496: predicting pet_10891 
2025-03-31 01:08:51.445053: pet_10891, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.466544: predicting pet_10892 
2025-03-31 01:08:51.475276: pet_10892, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.494419: predicting pet_10893 
2025-03-31 01:08:51.500353: pet_10893, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.519578: predicting pet_10900 
2025-03-31 01:08:51.528492: pet_10900, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.550869: predicting pet_10903 
2025-03-31 01:08:51.555560: pet_10903, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.577004: predicting pet_10920 
2025-03-31 01:08:51.583491: pet_10920, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.602422: predicting pet_10933 
2025-03-31 01:08:51.610983: pet_10933, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.631673: predicting pet_10937 
2025-03-31 01:08:51.639693: pet_10937, shape torch.Size([3, 1, 512, 384]), rank 0 
2025-03-31 01:08:51.661840: predicting pet_1094 
2025-03-31 01:08:51.666142: pet_1094, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:51.684505: predicting pet_10940 
2025-03-31 01:08:51.691372: pet_10940, shape torch.Size([3, 1, 512, 356]), rank 0 
2025-03-31 01:08:51.712474: predicting pet_10941 
2025-03-31 01:08:51.721178: pet_10941, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.742267: predicting pet_10944 
2025-03-31 01:08:51.749393: pet_10944, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.770592: predicting pet_10947 
2025-03-31 01:08:51.776013: pet_10947, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.794553: predicting pet_10948 
2025-03-31 01:08:51.802416: pet_10948, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.822454: predicting pet_1095 
2025-03-31 01:08:51.826742: pet_1095, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:51.847047: predicting pet_10950 
2025-03-31 01:08:51.857541: pet_10950, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.877317: predicting pet_10952 
2025-03-31 01:08:51.881668: pet_10952, shape torch.Size([3, 1, 434, 512]), rank 0 
2025-03-31 01:08:51.902652: predicting pet_10954 
2025-03-31 01:08:51.905908: pet_10954, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.924994: predicting pet_10956 
2025-03-31 01:08:51.930036: pet_10956, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.951434: predicting pet_10958 
2025-03-31 01:08:51.955621: pet_10958, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:51.977748: predicting pet_1096 
2025-03-31 01:08:51.981422: pet_1096, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:52.001172: predicting pet_10961 
2025-03-31 01:08:52.006461: pet_10961, shape torch.Size([3, 1, 512, 401]), rank 0 
2025-03-31 01:08:52.029293: predicting pet_10963 
2025-03-31 01:08:52.039985: pet_10963, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.060967: predicting pet_10977 
2025-03-31 01:08:52.064662: pet_10977, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.085468: predicting pet_10979 
2025-03-31 01:08:52.089934: pet_10979, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.111456: predicting pet_10981 
2025-03-31 01:08:52.117409: pet_10981, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.137116: predicting pet_10985 
2025-03-31 01:08:52.142169: pet_10985, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.163939: predicting pet_10988 
2025-03-31 01:08:52.172250: pet_10988, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.191729: predicting pet_1099 
2025-03-31 01:08:52.195922: pet_1099, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:52.216562: predicting pet_10994 
2025-03-31 01:08:52.226629: pet_10994, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.246781: predicting pet_10998 
2025-03-31 01:08:52.248822: pet_10998, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:52.268117: predicting pet_11003 
2025-03-31 01:08:52.274383: pet_11003, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:08:52.295906: predicting pet_11008 
2025-03-31 01:08:52.301696: pet_11008, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.322949: predicting pet_1101 
2025-03-31 01:08:52.326815: pet_1101, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:52.348605: predicting pet_11012 
2025-03-31 01:08:52.354545: pet_11012, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.374676: predicting pet_11013 
2025-03-31 01:08:52.381448: pet_11013, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.400426: predicting pet_11016 
2025-03-31 01:08:52.412523: pet_11016, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.433659: predicting pet_11020 
2025-03-31 01:08:52.439531: pet_11020, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.458366: predicting pet_11034 
2025-03-31 01:08:52.464220: pet_11034, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.483018: predicting pet_11037 
2025-03-31 01:08:52.489424: pet_11037, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.508067: predicting pet_11038 
2025-03-31 01:08:52.521212: pet_11038, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.540816: predicting pet_11039 
2025-03-31 01:08:52.546381: pet_11039, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.568156: predicting pet_11044 
2025-03-31 01:08:52.572802: pet_11044, shape torch.Size([3, 1, 432, 512]), rank 0 
2025-03-31 01:08:52.596536: predicting pet_11047 
2025-03-31 01:08:52.606495: pet_11047, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.626055: predicting pet_11054 
2025-03-31 01:08:52.631570: pet_11054, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.652264: predicting pet_11055 
2025-03-31 01:08:52.658934: pet_11055, shape torch.Size([3, 1, 449, 497]), rank 0 
2025-03-31 01:08:52.680984: predicting pet_11056 
2025-03-31 01:08:52.686466: pet_11056, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.707906: predicting pet_11062 
2025-03-31 01:08:52.713925: pet_11062, shape torch.Size([3, 1, 391, 512]), rank 0 
2025-03-31 01:08:52.735248: predicting pet_11067 
2025-03-31 01:08:52.740604: pet_11067, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.759678: predicting pet_1107 
2025-03-31 01:08:52.768985: pet_1107, shape torch.Size([3, 1, 512, 385]), rank 0 
2025-03-31 01:08:52.790061: predicting pet_11077 
2025-03-31 01:08:52.795823: pet_11077, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.816227: predicting pet_11086 
2025-03-31 01:08:52.819978: pet_11086, shape torch.Size([3, 1, 434, 512]), rank 0 
2025-03-31 01:08:52.840396: predicting pet_11092 
2025-03-31 01:08:52.849118: pet_11092, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.869136: predicting pet_11099 
2025-03-31 01:08:52.874726: pet_11099, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.895715: predicting pet_11116 
2025-03-31 01:08:52.899988: pet_11116, shape torch.Size([3, 1, 480, 464]), rank 0 
2025-03-31 01:08:52.921751: predicting pet_11126 
2025-03-31 01:08:52.928444: pet_11126, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:52.947041: predicting pet_11134 
2025-03-31 01:08:52.954644: pet_11134, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:08:52.973814: predicting pet_11140 
2025-03-31 01:08:52.980739: pet_11140, shape torch.Size([3, 1, 465, 353]), rank 0 
2025-03-31 01:08:53.000680: predicting pet_11149 
2025-03-31 01:08:53.005665: pet_11149, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.024080: predicting pet_11150 
2025-03-31 01:08:53.028563: pet_11150, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.053421: predicting pet_11152 
2025-03-31 01:08:53.060952: pet_11152, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.081945: predicting pet_11154 
2025-03-31 01:08:53.090388: pet_11154, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:53.112390: predicting pet_11156 
2025-03-31 01:08:53.116639: pet_11156, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:53.136599: predicting pet_11158 
2025-03-31 01:08:53.144923: pet_11158, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.162831: predicting pet_1116 
2025-03-31 01:08:53.168710: pet_1116, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:53.186515: predicting pet_11163 
2025-03-31 01:08:53.191174: pet_11163, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.211418: predicting pet_11169 
2025-03-31 01:08:53.215357: pet_11169, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.235964: predicting pet_11173 
2025-03-31 01:08:53.241961: pet_11173, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.264549: predicting pet_11177 
2025-03-31 01:08:53.273331: pet_11177, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.292521: predicting pet_11180 
2025-03-31 01:08:53.296652: pet_11180, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.315189: predicting pet_11187 
2025-03-31 01:08:53.327160: pet_11187, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.346019: predicting pet_1119 
2025-03-31 01:08:53.352215: pet_1119, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.373594: predicting pet_11195 
2025-03-31 01:08:53.384231: pet_11195, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:08:53.404212: predicting pet_11200 
2025-03-31 01:08:53.410202: pet_11200, shape torch.Size([3, 1, 441, 512]), rank 0 
2025-03-31 01:08:53.429288: predicting pet_11207 
2025-03-31 01:08:53.436531: pet_11207, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.457002: predicting pet_11223 
2025-03-31 01:08:53.464300: pet_11223, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.485240: predicting pet_11228 
2025-03-31 01:08:53.489561: pet_11228, shape torch.Size([3, 1, 410, 481]), rank 0 
2025-03-31 01:08:53.509835: predicting pet_1123 
2025-03-31 01:08:53.519983: pet_1123, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:08:53.541986: predicting pet_11241 
2025-03-31 01:08:53.546587: pet_11241, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.566721: predicting pet_11242 
2025-03-31 01:08:53.570643: pet_11242, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.590860: predicting pet_11251 
2025-03-31 01:08:53.597474: pet_11251, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.618279: predicting pet_11257 
2025-03-31 01:08:53.625108: pet_11257, shape torch.Size([3, 1, 512, 440]), rank 0 
2025-03-31 01:08:53.648362: predicting pet_11266 
2025-03-31 01:08:53.653176: pet_11266, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.672451: predicting pet_11275 
2025-03-31 01:08:53.682266: pet_11275, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.701440: predicting pet_11295 
2025-03-31 01:08:53.704787: pet_11295, shape torch.Size([3, 1, 402, 512]), rank 0 
2025-03-31 01:08:53.723304: predicting pet_11297 
2025-03-31 01:08:53.730029: pet_11297, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.749861: predicting pet_1130 
2025-03-31 01:08:53.754846: pet_1130, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:53.775285: predicting pet_11330 
2025-03-31 01:08:53.781805: pet_11330, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.800653: predicting pet_11347 
2025-03-31 01:08:53.806623: pet_11347, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.828803: predicting pet_11350 
2025-03-31 01:08:53.834114: pet_11350, shape torch.Size([3, 1, 402, 512]), rank 0 
2025-03-31 01:08:53.853768: predicting pet_11353 
2025-03-31 01:08:53.860865: pet_11353, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.886584: predicting pet_11356 
2025-03-31 01:08:53.895479: pet_11356, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.916745: predicting pet_11366 
2025-03-31 01:08:53.927009: pet_11366, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.948334: predicting pet_11387 
2025-03-31 01:08:53.956813: pet_11387, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:53.978670: predicting pet_11389 
2025-03-31 01:08:53.986705: pet_11389, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.005049: predicting pet_1139 
2025-03-31 01:08:54.013730: pet_1139, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.034703: predicting pet_11395 
2025-03-31 01:08:54.044946: pet_11395, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.064628: predicting pet_11396 
2025-03-31 01:08:54.068927: pet_11396, shape torch.Size([3, 1, 398, 512]), rank 0 
2025-03-31 01:08:54.087666: predicting pet_11398 
2025-03-31 01:08:54.092330: pet_11398, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.112243: predicting pet_11400 
2025-03-31 01:08:54.117817: pet_11400, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.136544: predicting pet_11402 
2025-03-31 01:08:54.144469: pet_11402, shape torch.Size([3, 1, 392, 512]), rank 0 
2025-03-31 01:08:54.166112: predicting pet_11408 
2025-03-31 01:08:54.178711: pet_11408, shape torch.Size([3, 1, 401, 512]), rank 0 
2025-03-31 01:08:54.197654: predicting pet_1141 
2025-03-31 01:08:54.201600: pet_1141, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:54.221171: predicting pet_11412 
2025-03-31 01:08:54.225634: pet_11412, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.246499: predicting pet_11413 
2025-03-31 01:08:54.250836: pet_11413, shape torch.Size([3, 1, 361, 512]), rank 0 
2025-03-31 01:08:54.272477: predicting pet_11417 
2025-03-31 01:08:54.285222: pet_11417, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.304615: predicting pet_11419 
2025-03-31 01:08:54.316638: pet_11419, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.336367: predicting pet_1143 
2025-03-31 01:08:54.344341: pet_1143, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:08:54.365362: predicting pet_11431 
2025-03-31 01:08:54.369762: pet_11431, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.390620: predicting pet_11437 
2025-03-31 01:08:54.394269: pet_11437, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.414513: predicting pet_11441 
2025-03-31 01:08:54.428853: pet_11441, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.447726: predicting pet_11446 
2025-03-31 01:08:54.454820: pet_11446, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.476125: predicting pet_11447 
2025-03-31 01:08:54.485350: pet_11447, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.505754: predicting pet_11449 
2025-03-31 01:08:54.514074: pet_11449, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.535098: predicting pet_11451 
2025-03-31 01:08:54.540726: pet_11451, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.560482: predicting pet_11453 
2025-03-31 01:08:54.565156: pet_11453, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.586862: predicting pet_11459 
2025-03-31 01:08:54.592821: pet_11459, shape torch.Size([3, 1, 512, 480]), rank 0 
2025-03-31 01:08:54.612782: predicting pet_11461 
2025-03-31 01:08:54.618693: pet_11461, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.640040: predicting pet_11467 
2025-03-31 01:08:54.647726: pet_11467, shape torch.Size([3, 1, 512, 432]), rank 0 
2025-03-31 01:08:54.670722: predicting pet_11468 
2025-03-31 01:08:54.679561: pet_11468, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.698893: predicting pet_11478 
2025-03-31 01:08:54.710625: pet_11478, shape torch.Size([3, 1, 512, 481]), rank 0 
2025-03-31 01:08:54.730906: predicting pet_11495 
2025-03-31 01:08:54.743932: pet_11495, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.765083: predicting pet_11501 
2025-03-31 01:08:54.771574: pet_11501, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.794034: predicting pet_11504 
2025-03-31 01:08:54.804797: pet_11504, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.826012: predicting pet_11507 
2025-03-31 01:08:54.836015: pet_11507, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.858553: predicting pet_11514 
2025-03-31 01:08:54.866314: pet_11514, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.885608: predicting pet_1152 
2025-03-31 01:08:54.889142: pet_1152, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:54.910555: predicting pet_11525 
2025-03-31 01:08:54.915508: pet_11525, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.936184: predicting pet_11529 
2025-03-31 01:08:54.945617: pet_11529, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.966673: predicting pet_11531 
2025-03-31 01:08:54.975156: pet_11531, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:54.997869: predicting pet_11538 
2025-03-31 01:08:55.004022: pet_11538, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.025126: predicting pet_1154 
2025-03-31 01:08:55.029328: pet_1154, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:55.048231: predicting pet_11540 
2025-03-31 01:08:55.058434: pet_11540, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.077528: predicting pet_11550 
2025-03-31 01:08:55.080951: pet_11550, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.102041: predicting pet_11570 
2025-03-31 01:08:55.105533: pet_11570, shape torch.Size([3, 1, 321, 512]), rank 0 
2025-03-31 01:08:55.126303: predicting pet_11578 
2025-03-31 01:08:55.131942: pet_11578, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.152219: predicting pet_1158 
2025-03-31 01:08:55.158088: pet_1158, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:08:55.177655: predicting pet_11581 
2025-03-31 01:08:55.181821: pet_11581, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.200790: predicting pet_11586 
2025-03-31 01:08:55.207126: pet_11586, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.227920: predicting pet_11587 
2025-03-31 01:08:55.231225: pet_11587, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.252354: predicting pet_11600 
2025-03-31 01:08:55.259308: pet_11600, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.279826: predicting pet_11602 
2025-03-31 01:08:55.288805: pet_11602, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:08:55.309084: predicting pet_11604 
2025-03-31 01:08:55.317810: pet_11604, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:08:55.338140: predicting pet_11608 
2025-03-31 01:08:55.346039: pet_11608, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:08:55.366053: predicting pet_11609 
2025-03-31 01:08:55.370806: pet_11609, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.390214: predicting pet_11611 
2025-03-31 01:08:55.400474: pet_11611, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:55.419797: predicting pet_11612 
2025-03-31 01:08:55.430093: pet_11612, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.451600: predicting pet_11615 
2025-03-31 01:08:55.456733: pet_11615, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.475403: predicting pet_11618 
2025-03-31 01:08:55.480845: pet_11618, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.501281: predicting pet_11623 
2025-03-31 01:08:55.506072: pet_11623, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.527995: predicting pet_1163 
2025-03-31 01:08:55.533625: pet_1163, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:55.557414: predicting pet_11634 
2025-03-31 01:08:55.558804: pet_11634, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.576847: predicting pet_11645 
2025-03-31 01:08:55.585252: pet_11645, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.605861: predicting pet_11651 
2025-03-31 01:08:55.614852: pet_11651, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.632843: predicting pet_1175 
2025-03-31 01:08:55.641067: pet_1175, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:55.662926: predicting pet_1181 
2025-03-31 01:08:55.670240: pet_1181, shape torch.Size([3, 1, 512, 482]), rank 0 
2025-03-31 01:08:55.691398: predicting pet_1193 
2025-03-31 01:08:55.697135: pet_1193, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:55.715773: predicting pet_1196 
2025-03-31 01:08:55.723444: pet_1196, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:55.742252: predicting pet_1208 
2025-03-31 01:08:55.747036: pet_1208, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:55.766044: predicting pet_1211 
2025-03-31 01:08:55.770204: pet_1211, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:55.789012: predicting pet_1220 
2025-03-31 01:08:55.793576: pet_1220, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:08:55.814519: predicting pet_1226 
2025-03-31 01:08:55.824131: pet_1226, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:08:55.845046: predicting pet_1233 
2025-03-31 01:08:55.849516: pet_1233, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:55.868990: predicting pet_1234 
2025-03-31 01:08:55.877552: pet_1234, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:55.896070: predicting pet_1241 
2025-03-31 01:08:55.901475: pet_1241, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:55.920435: predicting pet_1244 
2025-03-31 01:08:55.925564: pet_1244, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:55.946363: predicting pet_1253 
2025-03-31 01:08:55.951077: pet_1253, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:55.969432: predicting pet_1255 
2025-03-31 01:08:55.974706: pet_1255, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:55.994003: predicting pet_1259 
2025-03-31 01:08:56.003641: pet_1259, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:56.026918: predicting pet_1261 
2025-03-31 01:08:56.031636: pet_1261, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.053261: predicting pet_1265 
2025-03-31 01:08:56.057418: pet_1265, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.079666: predicting pet_1267 
2025-03-31 01:08:56.084085: pet_1267, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:56.104476: predicting pet_1272 
2025-03-31 01:08:56.109349: pet_1272, shape torch.Size([3, 1, 512, 481]), rank 0 
2025-03-31 01:08:56.130154: predicting pet_1273 
2025-03-31 01:08:56.133495: pet_1273, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:56.155543: predicting pet_1274 
2025-03-31 01:08:56.162189: pet_1274, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.180691: predicting pet_1276 
2025-03-31 01:08:56.186170: pet_1276, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.206583: predicting pet_1281 
2025-03-31 01:08:56.215494: pet_1281, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.236517: predicting pet_1284 
2025-03-31 01:08:56.247994: pet_1284, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:08:56.268600: predicting pet_1285 
2025-03-31 01:08:56.277501: pet_1285, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.299076: predicting pet_1286 
2025-03-31 01:08:56.303691: pet_1286, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.323981: predicting pet_1290 
2025-03-31 01:08:56.332083: pet_1290, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:56.352280: predicting pet_1291 
2025-03-31 01:08:56.356847: pet_1291, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:56.376190: predicting pet_1294 
2025-03-31 01:08:56.389688: pet_1294, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:56.409417: predicting pet_1299 
2025-03-31 01:08:56.417025: pet_1299, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.438229: predicting pet_1308 
2025-03-31 01:08:56.448332: pet_1308, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:56.468462: predicting pet_1314 
2025-03-31 01:08:56.480019: pet_1314, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:08:56.498541: predicting pet_1320 
2025-03-31 01:08:56.504575: pet_1320, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.524306: predicting pet_1321 
2025-03-31 01:08:56.532923: pet_1321, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:08:56.553663: predicting pet_1325 
2025-03-31 01:08:56.559686: pet_1325, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:56.584670: predicting pet_1327 
2025-03-31 01:08:56.590379: pet_1327, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:56.611697: predicting pet_1335 
2025-03-31 01:08:56.617996: pet_1335, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:08:56.638516: predicting pet_1339 
2025-03-31 01:08:56.642373: pet_1339, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:56.663675: predicting pet_1344 
2025-03-31 01:08:56.666872: pet_1344, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:56.689866: predicting pet_1345 
2025-03-31 01:08:56.694388: pet_1345, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.713924: predicting pet_1348 
2025-03-31 01:08:56.718716: pet_1348, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:56.739383: predicting pet_1351 
2025-03-31 01:08:56.745894: pet_1351, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:08:56.766186: predicting pet_1358 
2025-03-31 01:08:56.775755: pet_1358, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:56.795921: predicting pet_1360 
2025-03-31 01:08:56.800749: pet_1360, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:56.820057: predicting pet_1363 
2025-03-31 01:08:56.828974: pet_1363, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:08:56.849868: predicting pet_1364 
2025-03-31 01:08:56.854879: pet_1364, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:08:56.877870: predicting pet_1371 
2025-03-31 01:08:56.885487: pet_1371, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:56.904504: predicting pet_1382 
2025-03-31 01:08:56.907767: pet_1382, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:56.926690: predicting pet_1387 
2025-03-31 01:08:56.933860: pet_1387, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:56.955184: predicting pet_1393 
2025-03-31 01:08:56.958890: pet_1393, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:56.978458: predicting pet_1394 
2025-03-31 01:08:56.982112: pet_1394, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:57.001232: predicting pet_1398 
2025-03-31 01:08:57.008261: pet_1398, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:08:57.027967: predicting pet_1409 
2025-03-31 01:08:57.033701: pet_1409, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:57.053856: predicting pet_1410 
2025-03-31 01:08:57.060708: pet_1410, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.081141: predicting pet_1415 
2025-03-31 01:08:57.090859: pet_1415, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:57.110648: predicting pet_1419 
2025-03-31 01:08:57.121766: pet_1419, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:57.142208: predicting pet_1421 
2025-03-31 01:08:57.146203: pet_1421, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.168600: predicting pet_1425 
2025-03-31 01:08:57.172735: pet_1425, shape torch.Size([3, 1, 482, 512]), rank 0 
2025-03-31 01:08:57.195696: predicting pet_1430 
2025-03-31 01:08:57.201173: pet_1430, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:57.220963: predicting pet_1431 
2025-03-31 01:08:57.228280: pet_1431, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:57.245743: predicting pet_1432 
2025-03-31 01:08:57.254318: pet_1432, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:57.272904: predicting pet_1435 
2025-03-31 01:08:57.276392: pet_1435, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:57.294958: predicting pet_1436 
2025-03-31 01:08:57.298928: pet_1436, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:57.317899: predicting pet_1442 
2025-03-31 01:08:57.324676: pet_1442, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.342804: predicting pet_1447 
2025-03-31 01:08:57.351926: pet_1447, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:57.371037: predicting pet_1451 
2025-03-31 01:08:57.378227: pet_1451, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:57.399592: predicting pet_1453 
2025-03-31 01:08:57.403958: pet_1453, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.425138: predicting pet_1469 
2025-03-31 01:08:57.431308: pet_1469, shape torch.Size([3, 1, 290, 512]), rank 0 
2025-03-31 01:08:57.452887: predicting pet_1471 
2025-03-31 01:08:57.459045: pet_1471, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.479291: predicting pet_1493 
2025-03-31 01:08:57.484340: pet_1493, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:57.506275: predicting pet_1494 
2025-03-31 01:08:57.510861: pet_1494, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:57.530684: predicting pet_1496 
2025-03-31 01:08:57.538435: pet_1496, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:08:57.558206: predicting pet_1501 
2025-03-31 01:08:57.567354: pet_1501, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.588629: predicting pet_1505 
2025-03-31 01:08:57.595496: pet_1505, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:57.616735: predicting pet_1512 
2025-03-31 01:08:57.620880: pet_1512, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.639566: predicting pet_1516 
2025-03-31 01:08:57.643357: pet_1516, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.664739: predicting pet_1521 
2025-03-31 01:08:57.674454: pet_1521, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.693354: predicting pet_1522 
2025-03-31 01:08:57.699646: pet_1522, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.724683: predicting pet_1528 
2025-03-31 01:08:57.728209: pet_1528, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.750069: predicting pet_1531 
2025-03-31 01:08:57.760253: pet_1531, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:57.780185: predicting pet_1540 
2025-03-31 01:08:57.788088: pet_1540, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:57.810198: predicting pet_1542 
2025-03-31 01:08:57.818304: pet_1542, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.836671: predicting pet_1544 
2025-03-31 01:08:57.840365: pet_1544, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:57.860887: predicting pet_1553 
2025-03-31 01:08:57.873410: pet_1553, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:57.892981: predicting pet_1559 
2025-03-31 01:08:57.901153: pet_1559, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:57.919985: predicting pet_1566 
2025-03-31 01:08:57.929488: pet_1566, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:57.949554: predicting pet_1577 
2025-03-31 01:08:57.958024: pet_1577, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:57.976347: predicting pet_1582 
2025-03-31 01:08:57.986242: pet_1582, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:08:58.006886: predicting pet_1587 
2025-03-31 01:08:58.011530: pet_1587, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.031352: predicting pet_1592 
2025-03-31 01:08:58.036451: pet_1592, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:58.057487: predicting pet_1601 
2025-03-31 01:08:58.062697: pet_1601, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:58.080902: predicting pet_1607 
2025-03-31 01:08:58.086718: pet_1607, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:58.106417: predicting pet_1612 
2025-03-31 01:08:58.110356: pet_1612, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:58.129023: predicting pet_1618 
2025-03-31 01:08:58.135843: pet_1618, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:58.154364: predicting pet_1634 
2025-03-31 01:08:58.162310: pet_1634, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:58.185442: predicting pet_1645 
2025-03-31 01:08:58.197183: pet_1645, shape torch.Size([3, 1, 482, 512]), rank 0 
2025-03-31 01:08:58.216228: predicting pet_1651 
2025-03-31 01:08:58.223261: pet_1651, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:08:58.243483: predicting pet_1655 
2025-03-31 01:08:58.248655: pet_1655, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.269603: predicting pet_1663 
2025-03-31 01:08:58.275273: pet_1663, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:58.295772: predicting pet_1667 
2025-03-31 01:08:58.304590: pet_1667, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:58.324679: predicting pet_1679 
2025-03-31 01:08:58.336473: pet_1679, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:58.355314: predicting pet_1692 
2025-03-31 01:08:58.362953: pet_1692, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:58.383192: predicting pet_1694 
2025-03-31 01:08:58.392068: pet_1694, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.411933: predicting pet_1697 
2025-03-31 01:08:58.420981: pet_1697, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.441191: predicting pet_1698 
2025-03-31 01:08:58.449938: pet_1698, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:58.471623: predicting pet_1704 
2025-03-31 01:08:58.477242: pet_1704, shape torch.Size([3, 1, 512, 450]), rank 0 
2025-03-31 01:08:58.499836: predicting pet_1717 
2025-03-31 01:08:58.504150: pet_1717, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:58.525341: predicting pet_1719 
2025-03-31 01:08:58.531906: pet_1719, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:58.551800: predicting pet_1722 
2025-03-31 01:08:58.556316: pet_1722, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:58.576230: predicting pet_1729 
2025-03-31 01:08:58.581729: pet_1729, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:58.600329: predicting pet_1733 
2025-03-31 01:08:58.607304: pet_1733, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:58.627427: predicting pet_1741 
2025-03-31 01:08:58.632290: pet_1741, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:08:58.654574: predicting pet_1746 
2025-03-31 01:08:58.660404: pet_1746, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.678830: predicting pet_1751 
2025-03-31 01:08:58.683811: pet_1751, shape torch.Size([3, 1, 512, 384]), rank 0 
2025-03-31 01:08:58.703611: predicting pet_1773 
2025-03-31 01:08:58.710265: pet_1773, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.732192: predicting pet_1775 
2025-03-31 01:08:58.736270: pet_1775, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:58.755274: predicting pet_1776 
2025-03-31 01:08:58.760684: pet_1776, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:58.780924: predicting pet_1779 
2025-03-31 01:08:58.786487: pet_1779, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.805585: predicting pet_1790 
2025-03-31 01:08:58.809910: pet_1790, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.831124: predicting pet_1793 
2025-03-31 01:08:58.838521: pet_1793, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:58.859811: predicting pet_1799 
2025-03-31 01:08:58.869011: pet_1799, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.888124: predicting pet_1802 
2025-03-31 01:08:58.891619: pet_1802, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:58.912030: predicting pet_1804 
2025-03-31 01:08:58.916388: pet_1804, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:58.938440: predicting pet_1806 
2025-03-31 01:08:58.945544: pet_1806, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:58.965074: predicting pet_1817 
2025-03-31 01:08:58.969635: pet_1817, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:58.988908: predicting pet_1819 
2025-03-31 01:08:58.991825: pet_1819, shape torch.Size([3, 1, 290, 512]), rank 0 
2025-03-31 01:08:59.010991: predicting pet_1827 
2025-03-31 01:08:59.015435: pet_1827, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.033907: predicting pet_1830 
2025-03-31 01:08:59.037957: pet_1830, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.061379: predicting pet_1838 
2025-03-31 01:08:59.070128: pet_1838, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.089976: predicting pet_1845 
2025-03-31 01:08:59.097459: pet_1845, shape torch.Size([3, 1, 512, 448]), rank 0 
2025-03-31 01:08:59.116388: predicting pet_1850 
2025-03-31 01:08:59.122954: pet_1850, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.142338: predicting pet_1857 
2025-03-31 01:08:59.146028: pet_1857, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:59.167287: predicting pet_1858 
2025-03-31 01:08:59.172814: pet_1858, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.192015: predicting pet_1862 
2025-03-31 01:08:59.197059: pet_1862, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.216502: predicting pet_1865 
2025-03-31 01:08:59.224195: pet_1865, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:59.245106: predicting pet_1870 
2025-03-31 01:08:59.251063: pet_1870, shape torch.Size([3, 1, 512, 480]), rank 0 
2025-03-31 01:08:59.270239: predicting pet_1877 
2025-03-31 01:08:59.273698: pet_1877, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.294625: predicting pet_1879 
2025-03-31 01:08:59.302349: pet_1879, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:59.320388: predicting pet_1880 
2025-03-31 01:08:59.328619: pet_1880, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.349607: predicting pet_1881 
2025-03-31 01:08:59.353492: pet_1881, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.372482: predicting pet_1883 
2025-03-31 01:08:59.380447: pet_1883, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.399961: predicting pet_1893 
2025-03-31 01:08:59.405324: pet_1893, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.425375: predicting pet_1894 
2025-03-31 01:08:59.430198: pet_1894, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:08:59.448137: predicting pet_1897 
2025-03-31 01:08:59.451800: pet_1897, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.469203: predicting pet_1898 
2025-03-31 01:08:59.476046: pet_1898, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.493205: predicting pet_1906 
2025-03-31 01:08:59.500810: pet_1906, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:59.520617: predicting pet_1915 
2025-03-31 01:08:59.527143: pet_1915, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.545032: predicting pet_1939 
2025-03-31 01:08:59.552267: pet_1939, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.569178: predicting pet_1941 
2025-03-31 01:08:59.573884: pet_1941, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:08:59.591211: predicting pet_1943 
2025-03-31 01:08:59.597075: pet_1943, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.619578: predicting pet_1948 
2025-03-31 01:08:59.623589: pet_1948, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.645346: predicting pet_1949 
2025-03-31 01:08:59.652941: pet_1949, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.672475: predicting pet_1951 
2025-03-31 01:08:59.676098: pet_1951, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:59.698054: predicting pet_1954 
2025-03-31 01:08:59.702333: pet_1954, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.721656: predicting pet_1956 
2025-03-31 01:08:59.726283: pet_1956, shape torch.Size([3, 1, 512, 384]), rank 0 
2025-03-31 01:08:59.747183: predicting pet_1959 
2025-03-31 01:08:59.753833: pet_1959, shape torch.Size([3, 1, 384, 512]), rank 0 
2025-03-31 01:08:59.773581: predicting pet_1967 
2025-03-31 01:08:59.778004: pet_1967, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.798449: predicting pet_1968 
2025-03-31 01:08:59.803031: pet_1968, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.822407: predicting pet_1979 
2025-03-31 01:08:59.832507: pet_1979, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:08:59.853180: predicting pet_1990 
2025-03-31 01:08:59.861796: pet_1990, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:08:59.882035: predicting pet_1995 
2025-03-31 01:08:59.891158: pet_1995, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:08:59.910126: predicting pet_2009 
2025-03-31 01:08:59.919131: pet_2009, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:08:59.939734: predicting pet_2012 
2025-03-31 01:08:59.943850: pet_2012, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:08:59.962219: predicting pet_2016 
2025-03-31 01:08:59.969515: pet_2016, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:08:59.989688: predicting pet_2019 
2025-03-31 01:08:59.993230: pet_2019, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:00.011729: predicting pet_2022 
2025-03-31 01:09:00.016136: pet_2022, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.037128: predicting pet_2028 
2025-03-31 01:09:00.041556: pet_2028, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.059587: predicting pet_2036 
2025-03-31 01:09:00.068854: pet_2036, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.085979: predicting pet_2037 
2025-03-31 01:09:00.094150: pet_2037, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.115420: predicting pet_2038 
2025-03-31 01:09:00.120024: pet_2038, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:00.140008: predicting pet_2044 
2025-03-31 01:09:00.147525: pet_2044, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:00.166500: predicting pet_2045 
2025-03-31 01:09:00.172421: pet_2045, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:00.191071: predicting pet_2050 
2025-03-31 01:09:00.198440: pet_2050, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:09:00.218472: predicting pet_2055 
2025-03-31 01:09:00.225005: pet_2055, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:00.244658: predicting pet_2060 
2025-03-31 01:09:00.252322: pet_2060, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:00.271840: predicting pet_2062 
2025-03-31 01:09:00.278256: pet_2062, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.299489: predicting pet_2063 
2025-03-31 01:09:00.307819: pet_2063, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.330087: predicting pet_2065 
2025-03-31 01:09:00.335149: pet_2065, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:00.356869: predicting pet_2073 
2025-03-31 01:09:00.362017: pet_2073, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:00.382130: predicting pet_2081 
2025-03-31 01:09:00.394810: pet_2081, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:09:00.414816: predicting pet_2086 
2025-03-31 01:09:00.420102: pet_2086, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.442405: predicting pet_2098 
2025-03-31 01:09:00.450609: pet_2098, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:00.470926: predicting pet_2102 
2025-03-31 01:09:00.475883: pet_2102, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.499964: predicting pet_2106 
2025-03-31 01:09:00.507839: pet_2106, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:00.527852: predicting pet_2107 
2025-03-31 01:09:00.533932: pet_2107, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.552984: predicting pet_2108 
2025-03-31 01:09:00.558162: pet_2108, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:00.577816: predicting pet_2110 
2025-03-31 01:09:00.581392: pet_2110, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.601928: predicting pet_2111 
2025-03-31 01:09:00.608245: pet_2111, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:09:00.628442: predicting pet_2112 
2025-03-31 01:09:00.632351: pet_2112, shape torch.Size([3, 1, 512, 448]), rank 0 
2025-03-31 01:09:00.655804: predicting pet_2125 
2025-03-31 01:09:00.659396: pet_2125, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.680438: predicting pet_2127 
2025-03-31 01:09:00.687565: pet_2127, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:00.708786: predicting pet_2144 
2025-03-31 01:09:00.718742: pet_2144, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.738712: predicting pet_2145 
2025-03-31 01:09:00.742195: pet_2145, shape torch.Size([3, 1, 384, 512]), rank 0 
2025-03-31 01:09:00.762164: predicting pet_2150 
2025-03-31 01:09:00.766963: pet_2150, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:00.787157: predicting pet_2151 
2025-03-31 01:09:00.794335: pet_2151, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:09:00.813488: predicting pet_2156 
2025-03-31 01:09:00.820157: pet_2156, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:09:00.839711: predicting pet_2159 
2025-03-31 01:09:00.844337: pet_2159, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:00.865908: predicting pet_2174 
2025-03-31 01:09:00.870852: pet_2174, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:09:00.891454: predicting pet_2179 
2025-03-31 01:09:00.897180: pet_2179, shape torch.Size([3, 1, 512, 482]), rank 0 
2025-03-31 01:09:00.918158: predicting pet_2180 
2025-03-31 01:09:00.923952: pet_2180, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.942798: predicting pet_2182 
2025-03-31 01:09:00.951179: pet_2182, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.970224: predicting pet_2187 
2025-03-31 01:09:00.974568: pet_2187, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:00.996341: predicting pet_2197 
2025-03-31 01:09:01.005000: pet_2197, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.027180: predicting pet_2198 
2025-03-31 01:09:01.034946: pet_2198, shape torch.Size([3, 1, 512, 440]), rank 0 
2025-03-31 01:09:01.053798: predicting pet_2212 
2025-03-31 01:09:01.057431: pet_2212, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:01.077728: predicting pet_2213 
2025-03-31 01:09:01.089032: pet_2213, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:01.109865: predicting pet_2216 
2025-03-31 01:09:01.113942: pet_2216, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.136751: predicting pet_2219 
2025-03-31 01:09:01.143493: pet_2219, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:09:01.163299: predicting pet_2221 
2025-03-31 01:09:01.167695: pet_2221, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.186354: predicting pet_2227 
2025-03-31 01:09:01.196300: pet_2227, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.218342: predicting pet_2233 
2025-03-31 01:09:01.223274: pet_2233, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:01.244700: predicting pet_2240 
2025-03-31 01:09:01.253530: pet_2240, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.275320: predicting pet_2244 
2025-03-31 01:09:01.280527: pet_2244, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.300534: predicting pet_2247 
2025-03-31 01:09:01.305211: pet_2247, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:01.323491: predicting pet_2250 
2025-03-31 01:09:01.330400: pet_2250, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:01.349308: predicting pet_2253 
2025-03-31 01:09:01.357170: pet_2253, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.377522: predicting pet_2254 
2025-03-31 01:09:01.385463: pet_2254, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:01.404958: predicting pet_2262 
2025-03-31 01:09:01.409596: pet_2262, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.428015: predicting pet_2264 
2025-03-31 01:09:01.432702: pet_2264, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.450822: predicting pet_2269 
2025-03-31 01:09:01.456930: pet_2269, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.477337: predicting pet_2271 
2025-03-31 01:09:01.485189: pet_2271, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.503757: predicting pet_2277 
2025-03-31 01:09:01.508109: pet_2277, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:01.527168: predicting pet_2288 
2025-03-31 01:09:01.531813: pet_2288, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.551522: predicting pet_2289 
2025-03-31 01:09:01.556378: pet_2289, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.575650: predicting pet_2290 
2025-03-31 01:09:01.578995: pet_2290, shape torch.Size([3, 1, 512, 385]), rank 0 
2025-03-31 01:09:01.597509: predicting pet_2302 
2025-03-31 01:09:01.605263: pet_2302, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:09:01.625329: predicting pet_2305 
2025-03-31 01:09:01.630442: pet_2305, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.649271: predicting pet_2312 
2025-03-31 01:09:01.654386: pet_2312, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:09:01.674607: predicting pet_2316 
2025-03-31 01:09:01.679960: pet_2316, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:09:01.699282: predicting pet_2319 
2025-03-31 01:09:01.705889: pet_2319, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.725870: predicting pet_2342 
2025-03-31 01:09:01.733708: pet_2342, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.752595: predicting pet_2343 
2025-03-31 01:09:01.759012: pet_2343, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:01.780165: predicting pet_2344 
2025-03-31 01:09:01.785332: pet_2344, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.805604: predicting pet_2346 
2025-03-31 01:09:01.811453: pet_2346, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.830700: predicting pet_2348 
2025-03-31 01:09:01.837791: pet_2348, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:01.856580: predicting pet_2362 
2025-03-31 01:09:01.864672: pet_2362, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.884720: predicting pet_2366 
2025-03-31 01:09:01.888441: pet_2366, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:01.910196: predicting pet_2376 
2025-03-31 01:09:01.918869: pet_2376, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:01.938252: predicting pet_2385 
2025-03-31 01:09:01.942679: pet_2385, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:01.963930: predicting pet_2390 
2025-03-31 01:09:01.968512: pet_2390, shape torch.Size([3, 1, 512, 290]), rank 0 
2025-03-31 01:09:01.988070: predicting pet_2396 
2025-03-31 01:09:01.992504: pet_2396, shape torch.Size([3, 1, 290, 512]), rank 0 
2025-03-31 01:09:02.011310: predicting pet_2399 
2025-03-31 01:09:02.021393: pet_2399, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:02.041630: predicting pet_2403 
2025-03-31 01:09:02.047611: pet_2403, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:02.066985: predicting pet_2404 
2025-03-31 01:09:02.075202: pet_2404, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.093796: predicting pet_2408 
2025-03-31 01:09:02.098562: pet_2408, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:09:02.118587: predicting pet_2411 
2025-03-31 01:09:02.124943: pet_2411, shape torch.Size([3, 1, 512, 370]), rank 0 
2025-03-31 01:09:02.145052: predicting pet_2412 
2025-03-31 01:09:02.149529: pet_2412, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:02.171290: predicting pet_2415 
2025-03-31 01:09:02.177279: pet_2415, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:02.196914: predicting pet_2420 
2025-03-31 01:09:02.201583: pet_2420, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:02.224747: predicting pet_2428 
2025-03-31 01:09:02.228977: pet_2428, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.251742: predicting pet_2431 
2025-03-31 01:09:02.255126: pet_2431, shape torch.Size([3, 1, 296, 512]), rank 0 
2025-03-31 01:09:02.274044: predicting pet_2435 
2025-03-31 01:09:02.279322: pet_2435, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:02.300947: predicting pet_2438 
2025-03-31 01:09:02.306033: pet_2438, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:09:02.325732: predicting pet_2445 
2025-03-31 01:09:02.330296: pet_2445, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:09:02.351425: predicting pet_2451 
2025-03-31 01:09:02.359829: pet_2451, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.380301: predicting pet_2455 
2025-03-31 01:09:02.386557: pet_2455, shape torch.Size([3, 1, 335, 512]), rank 0 
2025-03-31 01:09:02.408439: predicting pet_2458 
2025-03-31 01:09:02.414273: pet_2458, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:09:02.434780: predicting pet_2465 
2025-03-31 01:09:02.438006: pet_2465, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:09:02.457639: predicting pet_2468 
2025-03-31 01:09:02.464329: pet_2468, shape torch.Size([3, 1, 512, 450]), rank 0 
2025-03-31 01:09:02.484299: predicting pet_2469 
2025-03-31 01:09:02.488617: pet_2469, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.508496: predicting pet_2474 
2025-03-31 01:09:02.514195: pet_2474, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.534279: predicting pet_2482 
2025-03-31 01:09:02.538747: pet_2482, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.561495: predicting pet_2483 
2025-03-31 01:09:02.569722: pet_2483, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:02.590645: predicting pet_2488 
2025-03-31 01:09:02.595075: pet_2488, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:02.618890: predicting pet_2490 
2025-03-31 01:09:02.626646: pet_2490, shape torch.Size([3, 1, 512, 482]), rank 0 
2025-03-31 01:09:02.647642: predicting pet_2493 
2025-03-31 01:09:02.655160: pet_2493, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:02.678106: predicting pet_2496 
2025-03-31 01:09:02.683789: pet_2496, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:02.705147: predicting pet_2499 
2025-03-31 01:09:02.712363: pet_2499, shape torch.Size([3, 1, 466, 512]), rank 0 
2025-03-31 01:09:02.731360: predicting pet_2501 
2025-03-31 01:09:02.740269: pet_2501, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:02.758660: predicting pet_2503 
2025-03-31 01:09:02.765405: pet_2503, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:02.784338: predicting pet_2504 
2025-03-31 01:09:02.792935: pet_2504, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:02.813883: predicting pet_2505 
2025-03-31 01:09:02.823495: pet_2505, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:02.843529: predicting pet_2507 
2025-03-31 01:09:02.851299: pet_2507, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:02.870685: predicting pet_2508 
2025-03-31 01:09:02.875788: pet_2508, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:09:02.897053: predicting pet_2513 
2025-03-31 01:09:02.901579: pet_2513, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.922827: predicting pet_2517 
2025-03-31 01:09:02.930169: pet_2517, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:02.948416: predicting pet_2528 
2025-03-31 01:09:02.952677: pet_2528, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:02.972115: predicting pet_2530 
2025-03-31 01:09:02.978275: pet_2530, shape torch.Size([3, 1, 512, 322]), rank 0 
2025-03-31 01:09:02.997329: predicting pet_2534 
2025-03-31 01:09:03.001383: pet_2534, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:03.022866: predicting pet_2539 
2025-03-31 01:09:03.027707: pet_2539, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:03.047459: predicting pet_2542 
2025-03-31 01:09:03.053969: pet_2542, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.073010: predicting pet_2550 
2025-03-31 01:09:03.079012: pet_2550, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.098800: predicting pet_2555 
2025-03-31 01:09:03.103436: pet_2555, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.125020: predicting pet_2568 
2025-03-31 01:09:03.130281: pet_2568, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:03.149638: predicting pet_2578 
2025-03-31 01:09:03.153710: pet_2578, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:03.171732: predicting pet_2598 
2025-03-31 01:09:03.177838: pet_2598, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:03.196895: predicting pet_2604 
2025-03-31 01:09:03.207004: pet_2604, shape torch.Size([3, 1, 512, 384]), rank 0 
2025-03-31 01:09:03.225610: predicting pet_2608 
2025-03-31 01:09:03.229749: pet_2608, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:03.249627: predicting pet_2616 
2025-03-31 01:09:03.259164: pet_2616, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:03.277862: predicting pet_2637 
2025-03-31 01:09:03.284707: pet_2637, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:09:03.303895: predicting pet_2649 
2025-03-31 01:09:03.308813: pet_2649, shape torch.Size([3, 1, 512, 361]), rank 0 
2025-03-31 01:09:03.326533: predicting pet_2650 
2025-03-31 01:09:03.337936: pet_2650, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.356142: predicting pet_2654 
2025-03-31 01:09:03.363411: pet_2654, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:03.382535: predicting pet_2657 
2025-03-31 01:09:03.392689: pet_2657, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.411591: predicting pet_2659 
2025-03-31 01:09:03.422211: pet_2659, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.443223: predicting pet_2664 
2025-03-31 01:09:03.450020: pet_2664, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:03.468648: predicting pet_2667 
2025-03-31 01:09:03.477023: pet_2667, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:03.498302: predicting pet_2682 
2025-03-31 01:09:03.506044: pet_2682, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:03.524995: predicting pet_2684 
2025-03-31 01:09:03.534804: pet_2684, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:09:03.557784: predicting pet_2698 
2025-03-31 01:09:03.561549: pet_2698, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.584082: predicting pet_2702 
2025-03-31 01:09:03.588474: pet_2702, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.608249: predicting pet_2714 
2025-03-31 01:09:03.616223: pet_2714, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.638718: predicting pet_2715 
2025-03-31 01:09:03.642431: pet_2715, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:03.668374: predicting pet_2719 
2025-03-31 01:09:03.674944: pet_2719, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:03.693900: predicting pet_2722 
2025-03-31 01:09:03.700828: pet_2722, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:09:03.719553: predicting pet_2724 
2025-03-31 01:09:03.725414: pet_2724, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.743866: predicting pet_2728 
2025-03-31 01:09:03.754667: pet_2728, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:03.774515: predicting pet_2731 
2025-03-31 01:09:03.785721: pet_2731, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:09:03.804849: predicting pet_2732 
2025-03-31 01:09:03.811415: pet_2732, shape torch.Size([3, 1, 384, 512]), rank 0 
2025-03-31 01:09:03.829998: predicting pet_2733 
2025-03-31 01:09:03.835218: pet_2733, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:03.855622: predicting pet_2746 
2025-03-31 01:09:03.860734: pet_2746, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.878311: predicting pet_2764 
2025-03-31 01:09:03.883381: pet_2764, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.902716: predicting pet_2770 
2025-03-31 01:09:03.907198: pet_2770, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:03.929049: predicting pet_2771 
2025-03-31 01:09:03.933911: pet_2771, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.953842: predicting pet_2776 
2025-03-31 01:09:03.961155: pet_2776, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:03.979979: predicting pet_2777 
2025-03-31 01:09:03.986219: pet_2777, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:04.006615: predicting pet_2781 
2025-03-31 01:09:04.010520: pet_2781, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.030403: predicting pet_2789 
2025-03-31 01:09:04.038298: pet_2789, shape torch.Size([3, 1, 482, 512]), rank 0 
2025-03-31 01:09:04.056996: predicting pet_2790 
2025-03-31 01:09:04.064277: pet_2790, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.087211: predicting pet_2794 
2025-03-31 01:09:04.092981: pet_2794, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.113080: predicting pet_2795 
2025-03-31 01:09:04.118840: pet_2795, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:09:04.139121: predicting pet_2796 
2025-03-31 01:09:04.148917: pet_2796, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:04.169322: predicting pet_2797 
2025-03-31 01:09:04.174543: pet_2797, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:04.193314: predicting pet_2802 
2025-03-31 01:09:04.206348: pet_2802, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:04.225172: predicting pet_2817 
2025-03-31 01:09:04.231000: pet_2817, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:09:04.251641: predicting pet_2818 
2025-03-31 01:09:04.260545: pet_2818, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.281633: predicting pet_2828 
2025-03-31 01:09:04.284902: pet_2828, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.303432: predicting pet_2830 
2025-03-31 01:09:04.308860: pet_2830, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.330012: predicting pet_2835 
2025-03-31 01:09:04.333846: pet_2835, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:04.354718: predicting pet_2841 
2025-03-31 01:09:04.361195: pet_2841, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:09:04.381284: predicting pet_2844 
2025-03-31 01:09:04.386184: pet_2844, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.407230: predicting pet_2845 
2025-03-31 01:09:04.412106: pet_2845, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.430899: predicting pet_2847 
2025-03-31 01:09:04.442523: pet_2847, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.461660: predicting pet_2848 
2025-03-31 01:09:04.466439: pet_2848, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.486870: predicting pet_2852 
2025-03-31 01:09:04.492079: pet_2852, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:04.510802: predicting pet_2856 
2025-03-31 01:09:04.515996: pet_2856, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.535083: predicting pet_2858 
2025-03-31 01:09:04.540400: pet_2858, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.559311: predicting pet_2872 
2025-03-31 01:09:04.565063: pet_2872, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:04.584499: predicting pet_2875 
2025-03-31 01:09:04.591563: pet_2875, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.609992: predicting pet_2878 
2025-03-31 01:09:04.618831: pet_2878, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.638900: predicting pet_2881 
2025-03-31 01:09:04.647878: pet_2881, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.666752: predicting pet_2883 
2025-03-31 01:09:04.671084: pet_2883, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:04.693718: predicting pet_2888 
2025-03-31 01:09:04.699022: pet_2888, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.719149: predicting pet_2896 
2025-03-31 01:09:04.723408: pet_2896, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:04.744522: predicting pet_2899 
2025-03-31 01:09:04.750945: pet_2899, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:04.773366: predicting pet_2900 
2025-03-31 01:09:04.776954: pet_2900, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:09:04.796379: predicting pet_2901 
2025-03-31 01:09:04.801359: pet_2901, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.823682: predicting pet_2903 
2025-03-31 01:09:04.827869: pet_2903, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:04.849229: predicting pet_2911 
2025-03-31 01:09:04.854695: pet_2911, shape torch.Size([3, 1, 482, 512]), rank 0 
2025-03-31 01:09:04.877264: predicting pet_2912 
2025-03-31 01:09:04.885803: pet_2912, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.907568: predicting pet_2915 
2025-03-31 01:09:04.912710: pet_2915, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:04.933240: predicting pet_2917 
2025-03-31 01:09:04.941877: pet_2917, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:04.960675: predicting pet_2923 
2025-03-31 01:09:04.965174: pet_2923, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:09:04.983743: predicting pet_2926 
2025-03-31 01:09:04.988792: pet_2926, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:09:05.009333: predicting pet_2931 
2025-03-31 01:09:05.020255: pet_2931, shape torch.Size([3, 1, 512, 384]), rank 0 
2025-03-31 01:09:05.039536: predicting pet_2932 
2025-03-31 01:09:05.042801: pet_2932, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:05.061904: predicting pet_2934 
2025-03-31 01:09:05.068060: pet_2934, shape torch.Size([3, 1, 258, 512]), rank 0 
2025-03-31 01:09:05.088874: predicting pet_2948 
2025-03-31 01:09:05.093655: pet_2948, shape torch.Size([3, 1, 512, 424]), rank 0 
2025-03-31 01:09:05.113964: predicting pet_2968 
2025-03-31 01:09:05.120015: pet_2968, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.140956: predicting pet_2973 
2025-03-31 01:09:05.147264: pet_2973, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.169607: predicting pet_2984 
2025-03-31 01:09:05.180884: pet_2984, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.200475: predicting pet_2985 
2025-03-31 01:09:05.208655: pet_2985, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.227710: predicting pet_2988 
2025-03-31 01:09:05.231703: pet_2988, shape torch.Size([3, 1, 396, 512]), rank 0 
2025-03-31 01:09:05.250638: predicting pet_3006 
2025-03-31 01:09:05.258019: pet_3006, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:09:05.279017: predicting pet_3009 
2025-03-31 01:09:05.291220: pet_3009, shape torch.Size([3, 1, 433, 512]), rank 0 
2025-03-31 01:09:05.315446: predicting pet_3011 
2025-03-31 01:09:05.320019: pet_3011, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.339298: predicting pet_3019 
2025-03-31 01:09:05.344778: pet_3019, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.366482: predicting pet_3021 
2025-03-31 01:09:05.380512: pet_3021, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.399911: predicting pet_3028 
2025-03-31 01:09:05.406154: pet_3028, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.423993: predicting pet_3035 
2025-03-31 01:09:05.434981: pet_3035, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.453847: predicting pet_3054 
2025-03-31 01:09:05.459298: pet_3054, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.479355: predicting pet_3057 
2025-03-31 01:09:05.490005: pet_3057, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.509715: predicting pet_3061 
2025-03-31 01:09:05.519178: pet_3061, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.538765: predicting pet_3062 
2025-03-31 01:09:05.548804: pet_3062, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.567142: predicting pet_3071 
2025-03-31 01:09:05.574796: pet_3071, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.596040: predicting pet_3074 
2025-03-31 01:09:05.602064: pet_3074, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.621369: predicting pet_3076 
2025-03-31 01:09:05.629636: pet_3076, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.649368: predicting pet_3081 
2025-03-31 01:09:05.657950: pet_3081, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.682224: predicting pet_3083 
2025-03-31 01:09:05.689955: pet_3083, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.710091: predicting pet_3088 
2025-03-31 01:09:05.716619: pet_3088, shape torch.Size([3, 1, 425, 512]), rank 0 
2025-03-31 01:09:05.737637: predicting pet_3091 
2025-03-31 01:09:05.745100: pet_3091, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:09:05.766412: predicting pet_3094 
2025-03-31 01:09:05.778705: pet_3094, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.798845: predicting pet_3095 
2025-03-31 01:09:05.807845: pet_3095, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.827985: predicting pet_3098 
2025-03-31 01:09:05.840300: pet_3098, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.860919: predicting pet_3099 
2025-03-31 01:09:05.868882: pet_3099, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.888535: predicting pet_3100 
2025-03-31 01:09:05.895072: pet_3100, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.914156: predicting pet_3101 
2025-03-31 01:09:05.920306: pet_3101, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.939355: predicting pet_3103 
2025-03-31 01:09:05.953196: pet_3103, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:05.973296: predicting pet_3107 
2025-03-31 01:09:05.983358: pet_3107, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.002677: predicting pet_3112 
2025-03-31 01:09:06.014390: pet_3112, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.033735: predicting pet_3113 
2025-03-31 01:09:06.039422: pet_3113, shape torch.Size([3, 1, 420, 512]), rank 0 
2025-03-31 01:09:06.059011: predicting pet_3115 
2025-03-31 01:09:06.066312: pet_3115, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.085544: predicting pet_3132 
2025-03-31 01:09:06.093712: pet_3132, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.117492: predicting pet_3140 
2025-03-31 01:09:06.124563: pet_3140, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.144029: predicting pet_3144 
2025-03-31 01:09:06.150541: pet_3144, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.169466: predicting pet_3145 
2025-03-31 01:09:06.176512: pet_3145, shape torch.Size([3, 1, 408, 512]), rank 0 
2025-03-31 01:09:06.197359: predicting pet_3146 
2025-03-31 01:09:06.208481: pet_3146, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.228895: predicting pet_3147 
2025-03-31 01:09:06.236309: pet_3147, shape torch.Size([3, 1, 385, 490]), rank 0 
2025-03-31 01:09:06.260013: predicting pet_3161 
2025-03-31 01:09:06.269676: pet_3161, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.290235: predicting pet_3163 
2025-03-31 01:09:06.297101: pet_3163, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.318726: predicting pet_3164 
2025-03-31 01:09:06.329394: pet_3164, shape torch.Size([3, 1, 512, 464]), rank 0 
2025-03-31 01:09:06.349330: predicting pet_3165 
2025-03-31 01:09:06.356209: pet_3165, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.376011: predicting pet_3170 
2025-03-31 01:09:06.382907: pet_3170, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.403635: predicting pet_3172 
2025-03-31 01:09:06.412965: pet_3172, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.432132: predicting pet_3176 
2025-03-31 01:09:06.439581: pet_3176, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.458692: predicting pet_3177 
2025-03-31 01:09:06.464350: pet_3177, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.485013: predicting pet_3178 
2025-03-31 01:09:06.492948: pet_3178, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.514220: predicting pet_3182 
2025-03-31 01:09:06.517033: pet_3182, shape torch.Size([3, 1, 512, 416]), rank 0 
2025-03-31 01:09:06.538461: predicting pet_3184 
2025-03-31 01:09:06.545585: pet_3184, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.566916: predicting pet_3185 
2025-03-31 01:09:06.574159: pet_3185, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.593099: predicting pet_3187 
2025-03-31 01:09:06.599082: pet_3187, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.622490: predicting pet_3190 
2025-03-31 01:09:06.635265: pet_3190, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.655127: predicting pet_3192 
2025-03-31 01:09:06.666220: pet_3192, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.685444: predicting pet_3194 
2025-03-31 01:09:06.695685: pet_3194, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.716221: predicting pet_3195 
2025-03-31 01:09:06.727082: pet_3195, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:09:06.749171: predicting pet_3197 
2025-03-31 01:09:06.758616: pet_3197, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.779436: predicting pet_3202 
2025-03-31 01:09:06.785828: pet_3202, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.804460: predicting pet_3207 
2025-03-31 01:09:06.809366: pet_3207, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.828323: predicting pet_3215 
2025-03-31 01:09:06.837604: pet_3215, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.857876: predicting pet_3217 
2025-03-31 01:09:06.868064: pet_3217, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.886771: predicting pet_3222 
2025-03-31 01:09:06.890787: pet_3222, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.912244: predicting pet_3225 
2025-03-31 01:09:06.922327: pet_3225, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.940953: predicting pet_3235 
2025-03-31 01:09:06.948055: pet_3235, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:06.969602: predicting pet_3236 
2025-03-31 01:09:06.980045: pet_3236, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.000797: predicting pet_3239 
2025-03-31 01:09:07.008013: pet_3239, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.026954: predicting pet_3246 
2025-03-31 01:09:07.031847: pet_3246, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:07.051553: predicting pet_3257 
2025-03-31 01:09:07.061411: pet_3257, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.081052: predicting pet_3275 
2025-03-31 01:09:07.087426: pet_3275, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.107562: predicting pet_3278 
2025-03-31 01:09:07.112051: pet_3278, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.133663: predicting pet_3283 
2025-03-31 01:09:07.144005: pet_3283, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.162968: predicting pet_3285 
2025-03-31 01:09:07.170697: pet_3285, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.191303: predicting pet_3289 
2025-03-31 01:09:07.198484: pet_3289, shape torch.Size([3, 1, 498, 512]), rank 0 
2025-03-31 01:09:07.219719: predicting pet_3291 
2025-03-31 01:09:07.225079: pet_3291, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.245609: predicting pet_3296 
2025-03-31 01:09:07.253999: pet_3296, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.275240: predicting pet_3298 
2025-03-31 01:09:07.285303: pet_3298, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.303944: predicting pet_3304 
2025-03-31 01:09:07.313766: pet_3304, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.333930: predicting pet_3305 
2025-03-31 01:09:07.342640: pet_3305, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.363008: predicting pet_3309 
2025-03-31 01:09:07.368295: pet_3309, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.389162: predicting pet_3310 
2025-03-31 01:09:07.396675: pet_3310, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.415966: predicting pet_3320 
2025-03-31 01:09:07.420527: pet_3320, shape torch.Size([3, 1, 512, 419]), rank 0 
2025-03-31 01:09:07.441254: predicting pet_3321 
2025-03-31 01:09:07.447154: pet_3321, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.466364: predicting pet_3322 
2025-03-31 01:09:07.473879: pet_3322, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.493374: predicting pet_3326 
2025-03-31 01:09:07.504173: pet_3326, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.525433: predicting pet_3331 
2025-03-31 01:09:07.533389: pet_3331, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.552465: predicting pet_3333 
2025-03-31 01:09:07.561930: pet_3333, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.583015: predicting pet_3334 
2025-03-31 01:09:07.589693: pet_3334, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.608576: predicting pet_3346 
2025-03-31 01:09:07.619609: pet_3346, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.640432: predicting pet_3347 
2025-03-31 01:09:07.643619: pet_3347, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.665329: predicting pet_3353 
2025-03-31 01:09:07.672510: pet_3353, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.693589: predicting pet_3357 
2025-03-31 01:09:07.703648: pet_3357, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.723916: predicting pet_3371 
2025-03-31 01:09:07.730632: pet_3371, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.751012: predicting pet_3374 
2025-03-31 01:09:07.757039: pet_3374, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.775749: predicting pet_3385 
2025-03-31 01:09:07.779655: pet_3385, shape torch.Size([3, 1, 512, 392]), rank 0 
2025-03-31 01:09:07.803226: predicting pet_3386 
2025-03-31 01:09:07.810451: pet_3386, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:09:07.829567: predicting pet_3393 
2025-03-31 01:09:07.837505: pet_3393, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.860464: predicting pet_3396 
2025-03-31 01:09:07.868062: pet_3396, shape torch.Size([3, 1, 459, 512]), rank 0 
2025-03-31 01:09:07.889379: predicting pet_3399 
2025-03-31 01:09:07.896936: pet_3399, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.918768: predicting pet_3402 
2025-03-31 01:09:07.925919: pet_3402, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.946358: predicting pet_3405 
2025-03-31 01:09:07.952955: pet_3405, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:07.972809: predicting pet_3406 
2025-03-31 01:09:07.980323: pet_3406, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.000647: predicting pet_3409 
2025-03-31 01:09:08.007635: pet_3409, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.027291: predicting pet_3410 
2025-03-31 01:09:08.035428: pet_3410, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.056082: predicting pet_3420 
2025-03-31 01:09:08.065809: pet_3420, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.085581: predicting pet_3421 
2025-03-31 01:09:08.094537: pet_3421, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.114259: predicting pet_3425 
2025-03-31 01:09:08.123171: pet_3425, shape torch.Size([3, 1, 386, 465]), rank 0 
2025-03-31 01:09:08.144255: predicting pet_3431 
2025-03-31 01:09:08.152547: pet_3431, shape torch.Size([3, 1, 512, 418]), rank 0 
2025-03-31 01:09:08.173206: predicting pet_3432 
2025-03-31 01:09:08.181842: pet_3432, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.202697: predicting pet_3437 
2025-03-31 01:09:08.213865: pet_3437, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.237135: predicting pet_3444 
2025-03-31 01:09:08.247399: pet_3444, shape torch.Size([3, 1, 512, 439]), rank 0 
2025-03-31 01:09:08.269294: predicting pet_3449 
2025-03-31 01:09:08.277307: pet_3449, shape torch.Size([3, 1, 496, 512]), rank 0 
2025-03-31 01:09:08.297170: predicting pet_3453 
2025-03-31 01:09:08.304590: pet_3453, shape torch.Size([3, 1, 512, 464]), rank 0 
2025-03-31 01:09:08.324577: predicting pet_3465 
2025-03-31 01:09:08.332407: pet_3465, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.352170: predicting pet_3468 
2025-03-31 01:09:08.357533: pet_3468, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.376993: predicting pet_3469 
2025-03-31 01:09:08.389150: pet_3469, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.412852: predicting pet_3471 
2025-03-31 01:09:08.420235: pet_3471, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.442391: predicting pet_3473 
2025-03-31 01:09:08.454948: pet_3473, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.475438: predicting pet_3476 
2025-03-31 01:09:08.480947: pet_3476, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:09:08.501462: predicting pet_3480 
2025-03-31 01:09:08.509550: pet_3480, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.531351: predicting pet_3494 
2025-03-31 01:09:08.536113: pet_3494, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.557448: predicting pet_3496 
2025-03-31 01:09:08.576032: pet_3496, shape torch.Size([3, 1, 401, 512]), rank 0 
2025-03-31 01:09:08.602533: predicting pet_3500 
2025-03-31 01:09:08.617349: pet_3500, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:08.659101: predicting pet_3501 
2025-03-31 01:09:08.677285: pet_3501, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.711300: predicting pet_3503 
2025-03-31 01:09:08.734911: pet_3503, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.760788: predicting pet_3509 
2025-03-31 01:09:08.778014: pet_3509, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.802506: predicting pet_3523 
2025-03-31 01:09:08.811120: pet_3523, shape torch.Size([3, 1, 488, 496]), rank 0 
2025-03-31 01:09:08.836355: predicting pet_3528 
2025-03-31 01:09:08.850269: pet_3528, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.873870: predicting pet_3537 
2025-03-31 01:09:08.882406: pet_3537, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:08.906853: predicting pet_3540 
2025-03-31 01:09:08.913416: pet_3540, shape torch.Size([3, 1, 355, 512]), rank 0 
2025-03-31 01:09:08.942458: predicting pet_3547 
2025-03-31 01:09:08.951677: pet_3547, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:08.979246: predicting pet_3548 
2025-03-31 01:09:08.983990: pet_3548, shape torch.Size([3, 1, 432, 512]), rank 0 
2025-03-31 01:09:09.014225: predicting pet_3551 
2025-03-31 01:09:09.023534: pet_3551, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.049531: predicting pet_3553 
2025-03-31 01:09:09.058241: pet_3553, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.085397: predicting pet_3569 
2025-03-31 01:09:09.097660: pet_3569, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.123984: predicting pet_3575 
2025-03-31 01:09:09.135108: pet_3575, shape torch.Size([3, 1, 459, 512]), rank 0 
2025-03-31 01:09:09.157853: predicting pet_3580 
2025-03-31 01:09:09.167640: pet_3580, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.187614: predicting pet_3593 
2025-03-31 01:09:09.199745: pet_3593, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:09:09.219180: predicting pet_3594 
2025-03-31 01:09:09.226576: pet_3594, shape torch.Size([3, 1, 432, 504]), rank 0 
2025-03-31 01:09:09.245498: predicting pet_3600 
2025-03-31 01:09:09.251509: pet_3600, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.270429: predicting pet_3605 
2025-03-31 01:09:09.276047: pet_3605, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.295367: predicting pet_3606 
2025-03-31 01:09:09.304432: pet_3606, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.321404: predicting pet_3607 
2025-03-31 01:09:09.329867: pet_3607, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.348046: predicting pet_3611 
2025-03-31 01:09:09.356051: pet_3611, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.374307: predicting pet_3614 
2025-03-31 01:09:09.381437: pet_3614, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.399702: predicting pet_3618 
2025-03-31 01:09:09.407523: pet_3618, shape torch.Size([3, 1, 392, 512]), rank 0 
2025-03-31 01:09:09.427737: predicting pet_3619 
2025-03-31 01:09:09.436126: pet_3619, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.455565: predicting pet_3622 
2025-03-31 01:09:09.463966: pet_3622, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.485336: predicting pet_3629 
2025-03-31 01:09:09.494539: pet_3629, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.513324: predicting pet_3630 
2025-03-31 01:09:09.520642: pet_3630, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.542302: predicting pet_3632 
2025-03-31 01:09:09.551790: pet_3632, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.570330: predicting pet_3636 
2025-03-31 01:09:09.578608: pet_3636, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.599377: predicting pet_3637 
2025-03-31 01:09:09.611740: pet_3637, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.630949: predicting pet_3646 
2025-03-31 01:09:09.637604: pet_3646, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:09.657056: predicting pet_3651 
2025-03-31 01:09:09.668298: pet_3651, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.689106: predicting pet_3653 
2025-03-31 01:09:09.699338: pet_3653, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.721578: predicting pet_3667 
2025-03-31 01:09:09.731170: pet_3667, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.752169: predicting pet_3668 
2025-03-31 01:09:09.763055: pet_3668, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.781857: predicting pet_3671 
2025-03-31 01:09:09.789264: pet_3671, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.808309: predicting pet_3682 
2025-03-31 01:09:09.816753: pet_3682, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.837735: predicting pet_3686 
2025-03-31 01:09:09.849967: pet_3686, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.870935: predicting pet_3687 
2025-03-31 01:09:09.880514: pet_3687, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.900990: predicting pet_3690 
2025-03-31 01:09:09.914835: pet_3690, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.934224: predicting pet_3702 
2025-03-31 01:09:09.943405: pet_3702, shape torch.Size([3, 1, 408, 512]), rank 0 
2025-03-31 01:09:09.963881: predicting pet_3705 
2025-03-31 01:09:09.975399: pet_3705, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:09.996163: predicting pet_3709 
2025-03-31 01:09:10.004536: pet_3709, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.024562: predicting pet_3712 
2025-03-31 01:09:10.033970: pet_3712, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.053620: predicting pet_3714 
2025-03-31 01:09:10.058110: pet_3714, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:09:10.078627: predicting pet_3717 
2025-03-31 01:09:10.084852: pet_3717, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.104458: predicting pet_3726 
2025-03-31 01:09:10.115148: pet_3726, shape torch.Size([3, 1, 512, 472]), rank 0 
2025-03-31 01:09:10.135751: predicting pet_3727 
2025-03-31 01:09:10.143633: pet_3727, shape torch.Size([3, 1, 512, 482]), rank 0 
2025-03-31 01:09:10.163131: predicting pet_3730 
2025-03-31 01:09:10.170977: pet_3730, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.191225: predicting pet_3734 
2025-03-31 01:09:10.198484: pet_3734, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:09:10.218802: predicting pet_3736 
2025-03-31 01:09:10.229716: pet_3736, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.248727: predicting pet_3750 
2025-03-31 01:09:10.258414: pet_3750, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.279095: predicting pet_3754 
2025-03-31 01:09:10.287827: pet_3754, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.307750: predicting pet_3755 
2025-03-31 01:09:10.318464: pet_3755, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.338119: predicting pet_3762 
2025-03-31 01:09:10.347707: pet_3762, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.367362: predicting pet_3764 
2025-03-31 01:09:10.371130: pet_3764, shape torch.Size([3, 1, 512, 448]), rank 0 
2025-03-31 01:09:10.391123: predicting pet_3769 
2025-03-31 01:09:10.400157: pet_3769, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.420230: predicting pet_3779 
2025-03-31 01:09:10.428875: pet_3779, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.451193: predicting pet_3780 
2025-03-31 01:09:10.458781: pet_3780, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.478281: predicting pet_3786 
2025-03-31 01:09:10.491498: pet_3786, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.511644: predicting pet_3787 
2025-03-31 01:09:10.518230: pet_3787, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.537297: predicting pet_3802 
2025-03-31 01:09:10.543061: pet_3802, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.561321: predicting pet_3803 
2025-03-31 01:09:10.567122: pet_3803, shape torch.Size([3, 1, 390, 512]), rank 0 
2025-03-31 01:09:10.585207: predicting pet_3804 
2025-03-31 01:09:10.592333: pet_3804, shape torch.Size([3, 1, 389, 512]), rank 0 
2025-03-31 01:09:10.610152: predicting pet_3805 
2025-03-31 01:09:10.616454: pet_3805, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.636364: predicting pet_3810 
2025-03-31 01:09:10.641529: pet_3810, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.659960: predicting pet_3812 
2025-03-31 01:09:10.668265: pet_3812, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.686808: predicting pet_3819 
2025-03-31 01:09:10.694069: pet_3819, shape torch.Size([3, 1, 512, 386]), rank 0 
2025-03-31 01:09:10.715364: predicting pet_3828 
2025-03-31 01:09:10.719377: pet_3828, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.739033: predicting pet_3830 
2025-03-31 01:09:10.753119: pet_3830, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.773137: predicting pet_3843 
2025-03-31 01:09:10.780197: pet_3843, shape torch.Size([3, 1, 512, 416]), rank 0 
2025-03-31 01:09:10.800628: predicting pet_3844 
2025-03-31 01:09:10.811586: pet_3844, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.833232: predicting pet_3848 
2025-03-31 01:09:10.843612: pet_3848, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:09:10.863536: predicting pet_3854 
2025-03-31 01:09:10.873304: pet_3854, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.894809: predicting pet_3855 
2025-03-31 01:09:10.905655: pet_3855, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.925619: predicting pet_3857 
2025-03-31 01:09:10.931821: pet_3857, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:10.954459: predicting pet_3859 
2025-03-31 01:09:10.963326: pet_3859, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:10.983237: predicting pet_3864 
2025-03-31 01:09:10.989380: pet_3864, shape torch.Size([3, 1, 412, 512]), rank 0 
2025-03-31 01:09:11.009851: predicting pet_3865 
2025-03-31 01:09:11.019104: pet_3865, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.040712: predicting pet_3867 
2025-03-31 01:09:11.047104: pet_3867, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:11.067744: predicting pet_3872 
2025-03-31 01:09:11.079475: pet_3872, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.100098: predicting pet_3874 
2025-03-31 01:09:11.111854: pet_3874, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.132242: predicting pet_3878 
2025-03-31 01:09:11.140825: pet_3878, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.160831: predicting pet_3881 
2025-03-31 01:09:11.169195: pet_3881, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.188562: predicting pet_3899 
2025-03-31 01:09:11.199292: pet_3899, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.221834: predicting pet_3912 
2025-03-31 01:09:11.229891: pet_3912, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.248863: predicting pet_3914 
2025-03-31 01:09:11.263590: pet_3914, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:09:11.285800: predicting pet_3916 
2025-03-31 01:09:11.293395: pet_3916, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.312823: predicting pet_3920 
2025-03-31 01:09:11.323838: pet_3920, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.343913: predicting pet_3923 
2025-03-31 01:09:11.353638: pet_3923, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.375710: predicting pet_3925 
2025-03-31 01:09:11.384774: pet_3925, shape torch.Size([3, 1, 354, 497]), rank 0 
2025-03-31 01:09:11.403872: predicting pet_3932 
2025-03-31 01:09:11.416595: pet_3932, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.437606: predicting pet_3949 
2025-03-31 01:09:11.445547: pet_3949, shape torch.Size([3, 1, 432, 512]), rank 0 
2025-03-31 01:09:11.465589: predicting pet_3951 
2025-03-31 01:09:11.477179: pet_3951, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.497791: predicting pet_3952 
2025-03-31 01:09:11.506168: pet_3952, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.526384: predicting pet_3953 
2025-03-31 01:09:11.536411: pet_3953, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.556919: predicting pet_3955 
2025-03-31 01:09:11.567692: pet_3955, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.588308: predicting pet_3958 
2025-03-31 01:09:11.597786: pet_3958, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.618723: predicting pet_3960 
2025-03-31 01:09:11.629790: pet_3960, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.650120: predicting pet_3964 
2025-03-31 01:09:11.658816: pet_3964, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.677963: predicting pet_3965 
2025-03-31 01:09:11.687068: pet_3965, shape torch.Size([3, 1, 488, 512]), rank 0 
2025-03-31 01:09:11.707204: predicting pet_3967 
2025-03-31 01:09:11.717571: pet_3967, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.737772: predicting pet_3974 
2025-03-31 01:09:11.746904: pet_3974, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.766637: predicting pet_3975 
2025-03-31 01:09:11.771516: pet_3975, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.790313: predicting pet_3985 
2025-03-31 01:09:11.797906: pet_3985, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.817427: predicting pet_3991 
2025-03-31 01:09:11.825230: pet_3991, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.843743: predicting pet_3997 
2025-03-31 01:09:11.849087: pet_3997, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.869513: predicting pet_4002 
2025-03-31 01:09:11.877091: pet_4002, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.899685: predicting pet_4007 
2025-03-31 01:09:11.908414: pet_4007, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:09:11.931374: predicting pet_4016 
2025-03-31 01:09:11.940834: pet_4016, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:11.960993: predicting pet_4019 
2025-03-31 01:09:11.968961: pet_4019, shape torch.Size([3, 1, 512, 425]), rank 0 
2025-03-31 01:09:11.989338: predicting pet_4029 
2025-03-31 01:09:11.995062: pet_4029, shape torch.Size([3, 1, 378, 512]), rank 0 
2025-03-31 01:09:12.018110: predicting pet_4032 
2025-03-31 01:09:12.023324: pet_4032, shape torch.Size([3, 1, 512, 290]), rank 0 
2025-03-31 01:09:12.043420: predicting pet_4035 
2025-03-31 01:09:12.047403: pet_4035, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.066117: predicting pet_4038 
2025-03-31 01:09:12.076686: pet_4038, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.099215: predicting pet_4040 
2025-03-31 01:09:12.107588: pet_4040, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.126352: predicting pet_4041 
2025-03-31 01:09:12.132355: pet_4041, shape torch.Size([3, 1, 394, 512]), rank 0 
2025-03-31 01:09:12.152488: predicting pet_4051 
2025-03-31 01:09:12.159841: pet_4051, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.179523: predicting pet_4056 
2025-03-31 01:09:12.186389: pet_4056, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.205400: predicting pet_4057 
2025-03-31 01:09:12.215130: pet_4057, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.235529: predicting pet_4060 
2025-03-31 01:09:12.244222: pet_4060, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.265922: predicting pet_4063 
2025-03-31 01:09:12.274337: pet_4063, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:12.294455: predicting pet_4070 
2025-03-31 01:09:12.302284: pet_4070, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.323509: predicting pet_4080 
2025-03-31 01:09:12.332369: pet_4080, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.350793: predicting pet_4084 
2025-03-31 01:09:12.360151: pet_4084, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.378690: predicting pet_4086 
2025-03-31 01:09:12.388897: pet_4086, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.408786: predicting pet_4091 
2025-03-31 01:09:12.419736: pet_4091, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:09:12.440860: predicting pet_4100 
2025-03-31 01:09:12.448190: pet_4100, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.469000: predicting pet_4103 
2025-03-31 01:09:12.475872: pet_4103, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.497591: predicting pet_4111 
2025-03-31 01:09:12.505420: pet_4111, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.528174: predicting pet_4113 
2025-03-31 01:09:12.536816: pet_4113, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.558818: predicting pet_4117 
2025-03-31 01:09:12.568331: pet_4117, shape torch.Size([3, 1, 497, 372]), rank 0 
2025-03-31 01:09:12.590902: predicting pet_4125 
2025-03-31 01:09:12.601843: pet_4125, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.623148: predicting pet_4132 
2025-03-31 01:09:12.631820: pet_4132, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.652469: predicting pet_4138 
2025-03-31 01:09:12.659886: pet_4138, shape torch.Size([3, 1, 402, 472]), rank 0 
2025-03-31 01:09:12.680602: predicting pet_4140 
2025-03-31 01:09:12.692634: pet_4140, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.713015: predicting pet_4149 
2025-03-31 01:09:12.722833: pet_4149, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.742425: predicting pet_4151 
2025-03-31 01:09:12.746322: pet_4151, shape torch.Size([3, 1, 418, 480]), rank 0 
2025-03-31 01:09:12.766415: predicting pet_4152 
2025-03-31 01:09:12.778970: pet_4152, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.800423: predicting pet_4161 
2025-03-31 01:09:12.808017: pet_4161, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.828418: predicting pet_4176 
2025-03-31 01:09:12.837199: pet_4176, shape torch.Size([3, 1, 512, 480]), rank 0 
2025-03-31 01:09:12.859884: predicting pet_4177 
2025-03-31 01:09:12.869765: pet_4177, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.891245: predicting pet_4181 
2025-03-31 01:09:12.897429: pet_4181, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:12.916671: predicting pet_4183 
2025-03-31 01:09:12.922498: pet_4183, shape torch.Size([3, 1, 433, 512]), rank 0 
2025-03-31 01:09:12.941157: predicting pet_4199 
2025-03-31 01:09:12.951082: pet_4199, shape torch.Size([3, 1, 504, 512]), rank 0 
2025-03-31 01:09:12.971551: predicting pet_4221 
2025-03-31 01:09:12.983873: pet_4221, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.004454: predicting pet_4222 
2025-03-31 01:09:13.013366: pet_4222, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.034008: predicting pet_4224 
2025-03-31 01:09:13.044992: pet_4224, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.066681: predicting pet_4229 
2025-03-31 01:09:13.074195: pet_4229, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:13.097340: predicting pet_4233 
2025-03-31 01:09:13.106609: pet_4233, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.127160: predicting pet_4239 
2025-03-31 01:09:13.132352: pet_4239, shape torch.Size([3, 1, 512, 368]), rank 0 
2025-03-31 01:09:13.152735: predicting pet_4245 
2025-03-31 01:09:13.163202: pet_4245, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.184275: predicting pet_4253 
2025-03-31 01:09:13.193346: pet_4253, shape torch.Size([3, 1, 432, 512]), rank 0 
2025-03-31 01:09:13.215242: predicting pet_4255 
2025-03-31 01:09:13.224187: pet_4255, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.245314: predicting pet_4261 
2025-03-31 01:09:13.255603: pet_4261, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.276072: predicting pet_4264 
2025-03-31 01:09:13.287549: pet_4264, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.308036: predicting pet_4279 
2025-03-31 01:09:13.317541: pet_4279, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.337333: predicting pet_4281 
2025-03-31 01:09:13.351429: pet_4281, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.371680: predicting pet_4282 
2025-03-31 01:09:13.380851: pet_4282, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.402445: predicting pet_4283 
2025-03-31 01:09:13.412364: pet_4283, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.431864: predicting pet_4287 
2025-03-31 01:09:13.440308: pet_4287, shape torch.Size([3, 1, 512, 449]), rank 0 
2025-03-31 01:09:13.458707: predicting pet_4288 
2025-03-31 01:09:13.467424: pet_4288, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.486474: predicting pet_4289 
2025-03-31 01:09:13.494666: pet_4289, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.513342: predicting pet_4292 
2025-03-31 01:09:13.521031: pet_4292, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:09:13.540917: predicting pet_4293 
2025-03-31 01:09:13.548270: pet_4293, shape torch.Size([3, 1, 432, 496]), rank 0 
2025-03-31 01:09:13.568261: predicting pet_4299 
2025-03-31 01:09:13.579030: pet_4299, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.600212: predicting pet_4324 
2025-03-31 01:09:13.609219: pet_4324, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.630485: predicting pet_4326 
2025-03-31 01:09:13.639754: pet_4326, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.659348: predicting pet_4332 
2025-03-31 01:09:13.669882: pet_4332, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.690694: predicting pet_4333 
2025-03-31 01:09:13.701822: pet_4333, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.721460: predicting pet_4334 
2025-03-31 01:09:13.729693: pet_4334, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.749624: predicting pet_4336 
2025-03-31 01:09:13.760496: pet_4336, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.779264: predicting pet_4338 
2025-03-31 01:09:13.787547: pet_4338, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.807942: predicting pet_4340 
2025-03-31 01:09:13.815105: pet_4340, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.850492: predicting pet_4344 
2025-03-31 01:09:13.864664: pet_4344, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.893181: predicting pet_4371 
2025-03-31 01:09:13.917410: pet_4371, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.946200: predicting pet_4375 
2025-03-31 01:09:13.969857: pet_4375, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:13.993792: predicting pet_4379 
2025-03-31 01:09:14.001804: pet_4379, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:14.024212: predicting pet_4387 
2025-03-31 01:09:14.045943: pet_4387, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:14.067258: predicting pet_4393 
2025-03-31 01:09:14.090217: pet_4393, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:14.114416: predicting pet_4394 
2025-03-31 01:09:14.138272: pet_4394, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:14.165380: predicting pet_4397 
2025-03-31 01:09:14.308031: pet_4397, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:14.327922: predicting pet_4403 
2025-03-31 01:09:14.717668: pet_4403, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:14.737411: predicting pet_4404 
2025-03-31 01:09:15.295722: pet_4404, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:15.314935: predicting pet_4409 
2025-03-31 01:09:15.483182: pet_4409, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:15.502673: predicting pet_4411 
2025-03-31 01:09:15.605494: pet_4411, shape torch.Size([3, 1, 297, 512]), rank 0 
2025-03-31 01:09:15.624910: predicting pet_4414 
2025-03-31 01:09:15.904096: pet_4414, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:15.923233: predicting pet_4415 
2025-03-31 01:09:15.978105: pet_4415, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:15.996897: predicting pet_4423 
2025-03-31 01:09:16.014025: pet_4423, shape torch.Size([3, 1, 392, 504]), rank 0 
2025-03-31 01:09:16.033844: predicting pet_4425 
2025-03-31 01:09:16.085889: pet_4425, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:16.104278: predicting pet_4426 
2025-03-31 01:09:16.145860: pet_4426, shape torch.Size([3, 1, 390, 512]), rank 0 
2025-03-31 01:09:16.165902: predicting pet_4439 
2025-03-31 01:09:16.202334: pet_4439, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:16.220823: predicting pet_4440 
2025-03-31 01:09:16.255893: pet_4440, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:16.275535: predicting pet_4455 
2025-03-31 01:09:16.329056: pet_4455, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:16.347622: predicting pet_4464 
2025-03-31 01:09:16.383664: pet_4464, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:16.402739: predicting pet_4474 
2025-03-31 01:09:16.461197: pet_4474, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:16.480660: predicting pet_4479 
2025-03-31 01:09:16.523447: pet_4479, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:16.542864: predicting pet_4482 
2025-03-31 01:09:16.573513: pet_4482, shape torch.Size([3, 1, 408, 512]), rank 0 
2025-03-31 01:09:20.044144: predicting pet_4484 
2025-03-31 01:09:20.085688: pet_4484, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.113122: predicting pet_4486 
2025-03-31 01:09:20.178159: pet_4486, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.202034: predicting pet_4491 
2025-03-31 01:09:20.244643: pet_4491, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.266847: predicting pet_4492 
2025-03-31 01:09:20.312499: pet_4492, shape torch.Size([3, 1, 512, 480]), rank 0 
2025-03-31 01:09:20.336420: predicting pet_4493 
2025-03-31 01:09:20.379190: pet_4493, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.398890: predicting pet_4497 
2025-03-31 01:09:20.468514: pet_4497, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.487640: predicting pet_4499 
2025-03-31 01:09:20.535352: pet_4499, shape torch.Size([3, 1, 453, 512]), rank 0 
2025-03-31 01:09:20.555372: predicting pet_4509 
2025-03-31 01:09:20.619189: pet_4509, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.637087: predicting pet_4522 
2025-03-31 01:09:20.689726: pet_4522, shape torch.Size([3, 1, 389, 512]), rank 0 
2025-03-31 01:09:20.709226: predicting pet_4523 
2025-03-31 01:09:20.760103: pet_4523, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.778613: predicting pet_4544 
2025-03-31 01:09:20.823157: pet_4544, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.841386: predicting pet_4545 
2025-03-31 01:09:20.887776: pet_4545, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.906480: predicting pet_4558 
2025-03-31 01:09:20.952301: pet_4558, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:20.970906: predicting pet_4566 
2025-03-31 01:09:21.022512: pet_4566, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.041283: predicting pet_4568 
2025-03-31 01:09:21.061343: pet_4568, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.081578: predicting pet_4573 
2025-03-31 01:09:21.091734: pet_4573, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.109603: predicting pet_4576 
2025-03-31 01:09:21.118626: pet_4576, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.137194: predicting pet_4581 
2025-03-31 01:09:21.145295: pet_4581, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.165227: predicting pet_4587 
2025-03-31 01:09:21.172972: pet_4587, shape torch.Size([3, 1, 370, 512]), rank 0 
2025-03-31 01:09:21.194886: predicting pet_4605 
2025-03-31 01:09:21.205204: pet_4605, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.224918: predicting pet_4612 
2025-03-31 01:09:21.232685: pet_4612, shape torch.Size([3, 1, 402, 512]), rank 0 
2025-03-31 01:09:21.254153: predicting pet_4618 
2025-03-31 01:09:21.261881: pet_4618, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.280215: predicting pet_4619 
2025-03-31 01:09:21.287494: pet_4619, shape torch.Size([3, 1, 487, 464]), rank 0 
2025-03-31 01:09:21.308053: predicting pet_4624 
2025-03-31 01:09:21.317363: pet_4624, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.338284: predicting pet_4626 
2025-03-31 01:09:21.346882: pet_4626, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.366208: predicting pet_4631 
2025-03-31 01:09:21.375564: pet_4631, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.395184: predicting pet_4635 
2025-03-31 01:09:21.403600: pet_4635, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:09:21.423771: predicting pet_4637 
2025-03-31 01:09:21.432562: pet_4637, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.453725: predicting pet_4638 
2025-03-31 01:09:21.462991: pet_4638, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.483208: predicting pet_4640 
2025-03-31 01:09:21.492674: pet_4640, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.513412: predicting pet_4643 
2025-03-31 01:09:21.523443: pet_4643, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.544534: predicting pet_4645 
2025-03-31 01:09:21.552713: pet_4645, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.571872: predicting pet_4646 
2025-03-31 01:09:21.605177: pet_4646, shape torch.Size([3, 1, 442, 512]), rank 0 
2025-03-31 01:09:21.631180: predicting pet_4658 
2025-03-31 01:09:21.642234: pet_4658, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.667069: predicting pet_4662 
2025-03-31 01:09:21.676849: pet_4662, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.701941: predicting pet_4667 
2025-03-31 01:09:21.711355: pet_4667, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.735846: predicting pet_4668 
2025-03-31 01:09:21.743412: pet_4668, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:21.768702: predicting pet_4669 
2025-03-31 01:09:21.779372: pet_4669, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.805544: predicting pet_4670 
2025-03-31 01:09:21.813557: pet_4670, shape torch.Size([3, 1, 512, 370]), rank 0 
2025-03-31 01:09:21.839120: predicting pet_4677 
2025-03-31 01:09:21.849885: pet_4677, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.875336: predicting pet_4679 
2025-03-31 01:09:21.884424: pet_4679, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.915256: predicting pet_4680 
2025-03-31 01:09:21.924549: pet_4680, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.951204: predicting pet_4681 
2025-03-31 01:09:21.960020: pet_4681, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:21.985028: predicting pet_4685 
2025-03-31 01:09:21.997121: pet_4685, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.027385: predicting pet_4688 
2025-03-31 01:09:22.033435: pet_4688, shape torch.Size([3, 1, 273, 481]), rank 0 
2025-03-31 01:09:22.060057: predicting pet_4718 
2025-03-31 01:09:22.070417: pet_4718, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.095290: predicting pet_4730 
2025-03-31 01:09:22.106234: pet_4730, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.132630: predicting pet_4742 
2025-03-31 01:09:22.143793: pet_4742, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.168046: predicting pet_4744 
2025-03-31 01:09:22.176985: pet_4744, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.200696: predicting pet_4750 
2025-03-31 01:09:22.209193: pet_4750, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.234498: predicting pet_4760 
2025-03-31 01:09:22.241606: pet_4760, shape torch.Size([3, 1, 392, 512]), rank 0 
2025-03-31 01:09:22.266592: predicting pet_4765 
2025-03-31 01:09:22.276359: pet_4765, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.300074: predicting pet_4771 
2025-03-31 01:09:22.305327: pet_4771, shape torch.Size([3, 1, 353, 512]), rank 0 
2025-03-31 01:09:22.326076: predicting pet_4773 
2025-03-31 01:09:22.335811: pet_4773, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.354983: predicting pet_4781 
2025-03-31 01:09:22.365585: pet_4781, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:09:22.389394: predicting pet_4796 
2025-03-31 01:09:22.398591: pet_4796, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.419291: predicting pet_4804 
2025-03-31 01:09:22.427410: pet_4804, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.447043: predicting pet_4817 
2025-03-31 01:09:22.460033: pet_4817, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.478919: predicting pet_4818 
2025-03-31 01:09:22.485176: pet_4818, shape torch.Size([3, 1, 392, 512]), rank 0 
2025-03-31 01:09:22.504861: predicting pet_4824 
2025-03-31 01:09:22.516589: pet_4824, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.537653: predicting pet_4825 
2025-03-31 01:09:22.546904: pet_4825, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.567301: predicting pet_4826 
2025-03-31 01:09:22.573614: pet_4826, shape torch.Size([3, 1, 480, 488]), rank 0 
2025-03-31 01:09:22.595726: predicting pet_4832 
2025-03-31 01:09:22.605617: pet_4832, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.626221: predicting pet_4839 
2025-03-31 01:09:22.635472: pet_4839, shape torch.Size([3, 1, 504, 512]), rank 0 
2025-03-31 01:09:22.656946: predicting pet_4840 
2025-03-31 01:09:22.662285: pet_4840, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.682683: predicting pet_4841 
2025-03-31 01:09:22.692316: pet_4841, shape torch.Size([3, 1, 512, 481]), rank 0 
2025-03-31 01:09:22.711541: predicting pet_4847 
2025-03-31 01:09:22.719471: pet_4847, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.740172: predicting pet_4850 
2025-03-31 01:09:22.749404: pet_4850, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.769557: predicting pet_4860 
2025-03-31 01:09:22.778934: pet_4860, shape torch.Size([3, 1, 400, 512]), rank 0 
2025-03-31 01:09:22.797434: predicting pet_4866 
2025-03-31 01:09:22.808289: pet_4866, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.828108: predicting pet_4872 
2025-03-31 01:09:22.838905: pet_4872, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.862300: predicting pet_4874 
2025-03-31 01:09:22.870943: pet_4874, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.890632: predicting pet_4880 
2025-03-31 01:09:22.897699: pet_4880, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.915968: predicting pet_4882 
2025-03-31 01:09:22.924200: pet_4882, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.943340: predicting pet_4898 
2025-03-31 01:09:22.954501: pet_4898, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:22.974114: predicting pet_4902 
2025-03-31 01:09:22.982952: pet_4902, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.002413: predicting pet_4903 
2025-03-31 01:09:23.014264: pet_4903, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.035032: predicting pet_4911 
2025-03-31 01:09:23.042350: pet_4911, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.062923: predicting pet_4912 
2025-03-31 01:09:23.070413: pet_4912, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:09:23.089150: predicting pet_4932 
2025-03-31 01:09:23.099504: pet_4932, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.119197: predicting pet_4948 
2025-03-31 01:09:23.131883: pet_4948, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.152885: predicting pet_4962 
2025-03-31 01:09:23.160143: pet_4962, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.180481: predicting pet_4966 
2025-03-31 01:09:23.193117: pet_4966, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.213219: predicting pet_4967 
2025-03-31 01:09:23.218862: pet_4967, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.239899: predicting pet_4968 
2025-03-31 01:09:23.249856: pet_4968, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.273916: predicting pet_4977 
2025-03-31 01:09:23.284568: pet_4977, shape torch.Size([3, 1, 496, 512]), rank 0 
2025-03-31 01:09:23.304912: predicting pet_4986 
2025-03-31 01:09:23.312333: pet_4986, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.334242: predicting pet_4993 
2025-03-31 01:09:23.345091: pet_4993, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.367383: predicting pet_5002 
2025-03-31 01:09:23.375875: pet_5002, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.394361: predicting pet_5005 
2025-03-31 01:09:23.402956: pet_5005, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.421591: predicting pet_5011 
2025-03-31 01:09:23.430451: pet_5011, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.449288: predicting pet_5013 
2025-03-31 01:09:23.460683: pet_5013, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.479861: predicting pet_5015 
2025-03-31 01:09:23.487209: pet_5015, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.507533: predicting pet_5016 
2025-03-31 01:09:23.512983: pet_5016, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.533189: predicting pet_5022 
2025-03-31 01:09:23.542594: pet_5022, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.563138: predicting pet_5024 
2025-03-31 01:09:23.573258: pet_5024, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.594918: predicting pet_5028 
2025-03-31 01:09:23.604784: pet_5028, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.623786: predicting pet_5029 
2025-03-31 01:09:23.632360: pet_5029, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.654864: predicting pet_5031 
2025-03-31 01:09:23.666608: pet_5031, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.686409: predicting pet_5034 
2025-03-31 01:09:23.695083: pet_5034, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.715993: predicting pet_5043 
2025-03-31 01:09:23.727544: pet_5043, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.747524: predicting pet_5050 
2025-03-31 01:09:23.757830: pet_5050, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.778482: predicting pet_5056 
2025-03-31 01:09:23.781174: pet_5056, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.802112: predicting pet_5057 
2025-03-31 01:09:23.811644: pet_5057, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.833115: predicting pet_5067 
2025-03-31 01:09:23.845056: pet_5067, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.865258: predicting pet_5068 
2025-03-31 01:09:23.870199: pet_5068, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.889119: predicting pet_5070 
2025-03-31 01:09:23.898072: pet_5070, shape torch.Size([3, 1, 357, 512]), rank 0 
2025-03-31 01:09:23.917958: predicting pet_5075 
2025-03-31 01:09:23.928291: pet_5075, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.948972: predicting pet_5076 
2025-03-31 01:09:23.957374: pet_5076, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:23.976587: predicting pet_5077 
2025-03-31 01:09:23.988208: pet_5077, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.006830: predicting pet_5078 
2025-03-31 01:09:24.013964: pet_5078, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.032713: predicting pet_5082 
2025-03-31 01:09:24.044478: pet_5082, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.063933: predicting pet_5090 
2025-03-31 01:09:24.070537: pet_5090, shape torch.Size([3, 1, 411, 512]), rank 0 
2025-03-31 01:09:24.090708: predicting pet_5091 
2025-03-31 01:09:24.101076: pet_5091, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.121715: predicting pet_5095 
2025-03-31 01:09:24.133374: pet_5095, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.153992: predicting pet_5096 
2025-03-31 01:09:24.161914: pet_5096, shape torch.Size([3, 1, 355, 512]), rank 0 
2025-03-31 01:09:24.181181: predicting pet_5099 
2025-03-31 01:09:24.193385: pet_5099, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.213261: predicting pet_5101 
2025-03-31 01:09:24.222970: pet_5101, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.241030: predicting pet_5106 
2025-03-31 01:09:24.246670: pet_5106, shape torch.Size([3, 1, 336, 512]), rank 0 
2025-03-31 01:09:24.264528: predicting pet_5110 
2025-03-31 01:09:24.273102: pet_5110, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.292323: predicting pet_5114 
2025-03-31 01:09:24.300568: pet_5114, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:24.320605: predicting pet_5121 
2025-03-31 01:09:24.328607: pet_5121, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.347371: predicting pet_5123 
2025-03-31 01:09:24.358620: pet_5123, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.377892: predicting pet_5124 
2025-03-31 01:09:24.387652: pet_5124, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.406873: predicting pet_5125 
2025-03-31 01:09:24.416291: pet_5125, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.436776: predicting pet_5132 
2025-03-31 01:09:24.443285: pet_5132, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.464118: predicting pet_5133 
2025-03-31 01:09:24.475377: pet_5133, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.495304: predicting pet_5139 
2025-03-31 01:09:24.504835: pet_5139, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.525352: predicting pet_5143 
2025-03-31 01:09:24.535503: pet_5143, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.554893: predicting pet_5144 
2025-03-31 01:09:24.563148: pet_5144, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.583311: predicting pet_5147 
2025-03-31 01:09:24.592295: pet_5147, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.613768: predicting pet_5148 
2025-03-31 01:09:24.625205: pet_5148, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.650546: predicting pet_5153 
2025-03-31 01:09:24.659650: pet_5153, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.679716: predicting pet_5170 
2025-03-31 01:09:24.691481: pet_5170, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.711310: predicting pet_5171 
2025-03-31 01:09:24.718155: pet_5171, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.738712: predicting pet_5174 
2025-03-31 01:09:24.746273: pet_5174, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.765136: predicting pet_5186 
2025-03-31 01:09:24.770058: pet_5186, shape torch.Size([3, 1, 512, 448]), rank 0 
2025-03-31 01:09:24.790645: predicting pet_5187 
2025-03-31 01:09:24.802255: pet_5187, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.822462: predicting pet_5201 
2025-03-31 01:09:24.830124: pet_5201, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.851304: predicting pet_5207 
2025-03-31 01:09:24.857148: pet_5207, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.877461: predicting pet_5214 
2025-03-31 01:09:24.886845: pet_5214, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:09:24.912477: predicting pet_5221 
2025-03-31 01:09:24.921157: pet_5221, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.940624: predicting pet_5232 
2025-03-31 01:09:24.951538: pet_5232, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:24.973066: predicting pet_5243 
2025-03-31 01:09:24.981680: pet_5243, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.000113: predicting pet_5245 
2025-03-31 01:09:25.010954: pet_5245, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.031277: predicting pet_5256 
2025-03-31 01:09:25.034743: pet_5256, shape torch.Size([3, 1, 395, 499]), rank 0 
2025-03-31 01:09:25.054917: predicting pet_5259 
2025-03-31 01:09:25.063046: pet_5259, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.083064: predicting pet_5264 
2025-03-31 01:09:25.093202: pet_5264, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.113630: predicting pet_5268 
2025-03-31 01:09:25.118211: pet_5268, shape torch.Size([3, 1, 344, 472]), rank 0 
2025-03-31 01:09:25.139518: predicting pet_5278 
2025-03-31 01:09:25.150877: pet_5278, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.170295: predicting pet_5280 
2025-03-31 01:09:25.179625: pet_5280, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.199833: predicting pet_5293 
2025-03-31 01:09:25.207536: pet_5293, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:09:25.227212: predicting pet_5295 
2025-03-31 01:09:25.236621: pet_5295, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.259089: predicting pet_5296 
2025-03-31 01:09:25.268432: pet_5296, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.288697: predicting pet_5298 
2025-03-31 01:09:25.294626: pet_5298, shape torch.Size([3, 1, 512, 361]), rank 0 
2025-03-31 01:09:25.314787: predicting pet_5303 
2025-03-31 01:09:25.325086: pet_5303, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.345330: predicting pet_5305 
2025-03-31 01:09:25.353734: pet_5305, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.372153: predicting pet_5311 
2025-03-31 01:09:25.382109: pet_5311, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.402249: predicting pet_5326 
2025-03-31 01:09:25.411110: pet_5326, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.431683: predicting pet_5339 
2025-03-31 01:09:25.441706: pet_5339, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.462389: predicting pet_5353 
2025-03-31 01:09:25.470028: pet_5353, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.488935: predicting pet_5356 
2025-03-31 01:09:25.498539: pet_5356, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.518721: predicting pet_5367 
2025-03-31 01:09:25.528334: pet_5367, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.547224: predicting pet_5374 
2025-03-31 01:09:25.556508: pet_5374, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.576122: predicting pet_5377 
2025-03-31 01:09:25.583799: pet_5377, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.602675: predicting pet_5384 
2025-03-31 01:09:25.611517: pet_5384, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.632765: predicting pet_5397 
2025-03-31 01:09:25.639857: pet_5397, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.658943: predicting pet_5401 
2025-03-31 01:09:25.668820: pet_5401, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.688830: predicting pet_5404 
2025-03-31 01:09:25.697415: pet_5404, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.717161: predicting pet_5405 
2025-03-31 01:09:25.727559: pet_5405, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.748784: predicting pet_5407 
2025-03-31 01:09:25.756040: pet_5407, shape torch.Size([3, 1, 417, 481]), rank 0 
2025-03-31 01:09:25.776555: predicting pet_5409 
2025-03-31 01:09:25.786393: pet_5409, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:09:25.807158: predicting pet_5410 
2025-03-31 01:09:25.817462: pet_5410, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.838978: predicting pet_5416 
2025-03-31 01:09:25.846051: pet_5416, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.865583: predicting pet_5424 
2025-03-31 01:09:25.875241: pet_5424, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.894201: predicting pet_5427 
2025-03-31 01:09:25.901043: pet_5427, shape torch.Size([3, 1, 408, 481]), rank 0 
2025-03-31 01:09:25.921528: predicting pet_5431 
2025-03-31 01:09:25.931588: pet_5431, shape torch.Size([3, 1, 419, 512]), rank 0 
2025-03-31 01:09:25.950490: predicting pet_5432 
2025-03-31 01:09:25.961252: pet_5432, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:25.981107: predicting pet_5433 
2025-03-31 01:09:25.990784: pet_5433, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.009909: predicting pet_5438 
2025-03-31 01:09:26.021041: pet_5438, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.041633: predicting pet_5442 
2025-03-31 01:09:26.049801: pet_5442, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.069366: predicting pet_5450 
2025-03-31 01:09:26.079611: pet_5450, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.097744: predicting pet_5453 
2025-03-31 01:09:26.106203: pet_5453, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.126504: predicting pet_5456 
2025-03-31 01:09:26.134379: pet_5456, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.154432: predicting pet_5458 
2025-03-31 01:09:26.162940: pet_5458, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.184717: predicting pet_5459 
2025-03-31 01:09:26.195820: pet_5459, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.215120: predicting pet_5462 
2025-03-31 01:09:26.224064: pet_5462, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.244485: predicting pet_5466 
2025-03-31 01:09:26.253893: pet_5466, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.274143: predicting pet_5474 
2025-03-31 01:09:26.283867: pet_5474, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.305862: predicting pet_5479 
2025-03-31 01:09:26.315709: pet_5479, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.337153: predicting pet_5480 
2025-03-31 01:09:26.345525: pet_5480, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.363844: predicting pet_5484 
2025-03-31 01:09:26.370739: pet_5484, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:09:26.390690: predicting pet_5486 
2025-03-31 01:09:26.399590: pet_5486, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.419351: predicting pet_5495 
2025-03-31 01:09:26.427799: pet_5495, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.446716: predicting pet_5499 
2025-03-31 01:09:26.456639: pet_5499, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.475668: predicting pet_5501 
2025-03-31 01:09:26.484086: pet_5501, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.503292: predicting pet_5505 
2025-03-31 01:09:26.510810: pet_5505, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.529755: predicting pet_5506 
2025-03-31 01:09:26.539554: pet_5506, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.560727: predicting pet_5507 
2025-03-31 01:09:26.571136: pet_5507, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.591693: predicting pet_5510 
2025-03-31 01:09:26.599413: pet_5510, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.618938: predicting pet_5537 
2025-03-31 01:09:26.629186: pet_5537, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.648725: predicting pet_5542 
2025-03-31 01:09:26.656387: pet_5542, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.675672: predicting pet_5547 
2025-03-31 01:09:26.687652: pet_5547, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.707972: predicting pet_5548 
2025-03-31 01:09:26.717294: pet_5548, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.738730: predicting pet_5552 
2025-03-31 01:09:26.744311: pet_5552, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:26.769665: predicting pet_5560 
2025-03-31 01:09:26.780238: pet_5560, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.799710: predicting pet_5568 
2025-03-31 01:09:26.806513: pet_5568, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.827283: predicting pet_5574 
2025-03-31 01:09:26.833387: pet_5574, shape torch.Size([3, 1, 512, 355]), rank 0 
2025-03-31 01:09:26.854329: predicting pet_5583 
2025-03-31 01:09:26.865105: pet_5583, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.888327: predicting pet_5587 
2025-03-31 01:09:26.895857: pet_5587, shape torch.Size([3, 1, 480, 497]), rank 0 
2025-03-31 01:09:26.914572: predicting pet_5591 
2025-03-31 01:09:26.916990: pet_5591, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:26.937855: predicting pet_5608 
2025-03-31 01:09:26.946518: pet_5608, shape torch.Size([3, 1, 402, 512]), rank 0 
2025-03-31 01:09:26.968929: predicting pet_5612 
2025-03-31 01:09:26.975679: pet_5612, shape torch.Size([3, 1, 402, 464]), rank 0 
2025-03-31 01:09:26.996280: predicting pet_5616 
2025-03-31 01:09:27.006976: pet_5616, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.029131: predicting pet_5617 
2025-03-31 01:09:27.037434: pet_5617, shape torch.Size([3, 1, 512, 385]), rank 0 
2025-03-31 01:09:27.059966: predicting pet_5623 
2025-03-31 01:09:27.067647: pet_5623, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.086484: predicting pet_5626 
2025-03-31 01:09:27.099134: pet_5626, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.120027: predicting pet_5627 
2025-03-31 01:09:27.131306: pet_5627, shape torch.Size([3, 1, 496, 496]), rank 0 
2025-03-31 01:09:27.150203: predicting pet_5630 
2025-03-31 01:09:27.154742: pet_5630, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.173552: predicting pet_5632 
2025-03-31 01:09:27.183717: pet_5632, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.203152: predicting pet_5633 
2025-03-31 01:09:27.212411: pet_5633, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.231866: predicting pet_5635 
2025-03-31 01:09:27.241256: pet_5635, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.261245: predicting pet_5637 
2025-03-31 01:09:27.270984: pet_5637, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.291668: predicting pet_5639 
2025-03-31 01:09:27.298916: pet_5639, shape torch.Size([3, 1, 368, 512]), rank 0 
2025-03-31 01:09:27.320384: predicting pet_5640 
2025-03-31 01:09:27.330928: pet_5640, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.352021: predicting pet_5641 
2025-03-31 01:09:27.360631: pet_5641, shape torch.Size([3, 1, 512, 464]), rank 0 
2025-03-31 01:09:27.381073: predicting pet_5642 
2025-03-31 01:09:27.391517: pet_5642, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.411356: predicting pet_5643 
2025-03-31 01:09:27.422263: pet_5643, shape torch.Size([3, 1, 512, 497]), rank 0 
2025-03-31 01:09:27.443105: predicting pet_5654 
2025-03-31 01:09:27.451757: pet_5654, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.471340: predicting pet_5664 
2025-03-31 01:09:27.478876: pet_5664, shape torch.Size([3, 1, 512, 416]), rank 0 
2025-03-31 01:09:27.499928: predicting pet_5671 
2025-03-31 01:09:27.509940: pet_5671, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.530194: predicting pet_5672 
2025-03-31 01:09:27.538964: pet_5672, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.558155: predicting pet_5677 
2025-03-31 01:09:27.566978: pet_5677, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.587196: predicting pet_5680 
2025-03-31 01:09:27.597257: pet_5680, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.617426: predicting pet_5681 
2025-03-31 01:09:27.623829: pet_5681, shape torch.Size([3, 1, 433, 512]), rank 0 
2025-03-31 01:09:27.642483: predicting pet_5692 
2025-03-31 01:09:27.653641: pet_5692, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.673151: predicting pet_5698 
2025-03-31 01:09:27.678454: pet_5698, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.697375: predicting pet_5700 
2025-03-31 01:09:27.706219: pet_5700, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.725654: predicting pet_5701 
2025-03-31 01:09:27.734565: pet_5701, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.754238: predicting pet_5703 
2025-03-31 01:09:27.763708: pet_5703, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.783904: predicting pet_5704 
2025-03-31 01:09:27.793435: pet_5704, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.812922: predicting pet_5708 
2025-03-31 01:09:27.819972: pet_5708, shape torch.Size([3, 1, 371, 512]), rank 0 
2025-03-31 01:09:27.840093: predicting pet_5710 
2025-03-31 01:09:27.848377: pet_5710, shape torch.Size([3, 1, 473, 512]), rank 0 
2025-03-31 01:09:27.870435: predicting pet_5712 
2025-03-31 01:09:27.877031: pet_5712, shape torch.Size([3, 1, 480, 416]), rank 0 
2025-03-31 01:09:27.896572: predicting pet_5713 
2025-03-31 01:09:27.905447: pet_5713, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.925323: predicting pet_5721 
2025-03-31 01:09:27.935163: pet_5721, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.956387: predicting pet_5723 
2025-03-31 01:09:27.965681: pet_5723, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:27.987090: predicting pet_5732 
2025-03-31 01:09:27.997439: pet_5732, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.016942: predicting pet_5736 
2025-03-31 01:09:28.027730: pet_5736, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.047333: predicting pet_5737 
2025-03-31 01:09:28.055046: pet_5737, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.075245: predicting pet_5744 
2025-03-31 01:09:28.084778: pet_5744, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.104521: predicting pet_5751 
2025-03-31 01:09:28.116722: pet_5751, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.136397: predicting pet_5760 
2025-03-31 01:09:28.145740: pet_5760, shape torch.Size([3, 1, 417, 497]), rank 0 
2025-03-31 01:09:28.166191: predicting pet_5765 
2025-03-31 01:09:28.179821: pet_5765, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.199635: predicting pet_5767 
2025-03-31 01:09:28.211334: pet_5767, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.230143: predicting pet_5779 
2025-03-31 01:09:28.237365: pet_5779, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.258570: predicting pet_5782 
2025-03-31 01:09:28.266922: pet_5782, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.290070: predicting pet_5787 
2025-03-31 01:09:28.298595: pet_5787, shape torch.Size([3, 1, 389, 512]), rank 0 
2025-03-31 01:09:28.317504: predicting pet_5790 
2025-03-31 01:09:28.327010: pet_5790, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.345951: predicting pet_5797 
2025-03-31 01:09:28.353522: pet_5797, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:28.373940: predicting pet_5802 
2025-03-31 01:09:28.381959: pet_5802, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.403090: predicting pet_5807 
2025-03-31 01:09:28.413235: pet_5807, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.434600: predicting pet_5810 
2025-03-31 01:09:28.443005: pet_5810, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:28.463914: predicting pet_5814 
2025-03-31 01:09:28.472921: pet_5814, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.492059: predicting pet_5818 
2025-03-31 01:09:28.500962: pet_5818, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.519948: predicting pet_5820 
2025-03-31 01:09:28.528229: pet_5820, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.546017: predicting pet_5822 
2025-03-31 01:09:28.553695: pet_5822, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.572054: predicting pet_5826 
2025-03-31 01:09:28.582639: pet_5826, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.603872: predicting pet_5832 
2025-03-31 01:09:28.613302: pet_5832, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.631629: predicting pet_5835 
2025-03-31 01:09:28.639284: pet_5835, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.658840: predicting pet_5840 
2025-03-31 01:09:28.669310: pet_5840, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.689503: predicting pet_5841 
2025-03-31 01:09:28.698478: pet_5841, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.717218: predicting pet_5853 
2025-03-31 01:09:28.726795: pet_5853, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.748268: predicting pet_5861 
2025-03-31 01:09:28.757598: pet_5861, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.778858: predicting pet_5864 
2025-03-31 01:09:28.784624: pet_5864, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:09:28.804829: predicting pet_5866 
2025-03-31 01:09:28.814794: pet_5866, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.834401: predicting pet_5875 
2025-03-31 01:09:28.843661: pet_5875, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.864031: predicting pet_5886 
2025-03-31 01:09:28.871565: pet_5886, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:09:28.891300: predicting pet_5892 
2025-03-31 01:09:28.899784: pet_5892, shape torch.Size([3, 1, 401, 481]), rank 0 
2025-03-31 01:09:28.921487: predicting pet_5895 
2025-03-31 01:09:28.929880: pet_5895, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.949023: predicting pet_5898 
2025-03-31 01:09:28.960415: pet_5898, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:28.979411: predicting pet_5899 
2025-03-31 01:09:28.997089: pet_5899, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.018188: predicting pet_5903 
2025-03-31 01:09:29.027101: pet_5903, shape torch.Size([3, 1, 408, 497]), rank 0 
2025-03-31 01:09:29.047596: predicting pet_5904 
2025-03-31 01:09:29.057198: pet_5904, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.077627: predicting pet_5910 
2025-03-31 01:09:29.086196: pet_5910, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.106015: predicting pet_5923 
2025-03-31 01:09:29.115897: pet_5923, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.136102: predicting pet_5926 
2025-03-31 01:09:29.144231: pet_5926, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.163502: predicting pet_5932 
2025-03-31 01:09:29.171570: pet_5932, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.191013: predicting pet_5934 
2025-03-31 01:09:29.212863: pet_5934, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.233237: predicting pet_5936 
2025-03-31 01:09:29.241188: pet_5936, shape torch.Size([3, 1, 387, 512]), rank 0 
2025-03-31 01:09:29.260907: predicting pet_5942 
2025-03-31 01:09:29.269100: pet_5942, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.288255: predicting pet_5946 
2025-03-31 01:09:29.297554: pet_5946, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.317773: predicting pet_5950 
2025-03-31 01:09:29.328497: pet_5950, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.349979: predicting pet_5953 
2025-03-31 01:09:29.357791: pet_5953, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.379903: predicting pet_5961 
2025-03-31 01:09:29.389725: pet_5961, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.408286: predicting pet_5967 
2025-03-31 01:09:29.416521: pet_5967, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.438799: predicting pet_5973 
2025-03-31 01:09:29.450644: pet_5973, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.470816: predicting pet_5984 
2025-03-31 01:09:29.479170: pet_5984, shape torch.Size([3, 1, 423, 512]), rank 0 
2025-03-31 01:09:29.500496: predicting pet_5988 
2025-03-31 01:09:29.504662: pet_5988, shape torch.Size([3, 1, 388, 512]), rank 0 
2025-03-31 01:09:29.525630: predicting pet_5994 
2025-03-31 01:09:29.534346: pet_5994, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.554640: predicting pet_5999 
2025-03-31 01:09:29.567869: pet_5999, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.588813: predicting pet_6006 
2025-03-31 01:09:29.592649: pet_6006, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.611112: predicting pet_6007 
2025-03-31 01:09:29.623889: pet_6007, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.644862: predicting pet_6008 
2025-03-31 01:09:29.655297: pet_6008, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.676561: predicting pet_6013 
2025-03-31 01:09:29.685803: pet_6013, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:09:29.707251: predicting pet_6018 
2025-03-31 01:09:29.717388: pet_6018, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.737235: predicting pet_6028 
2025-03-31 01:09:29.746862: pet_6028, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.765468: predicting pet_6029 
2025-03-31 01:09:29.771928: pet_6029, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.792671: predicting pet_6031 
2025-03-31 01:09:29.802337: pet_6031, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.823019: predicting pet_6036 
2025-03-31 01:09:29.830479: pet_6036, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.850007: predicting pet_6040 
2025-03-31 01:09:29.863531: pet_6040, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.883526: predicting pet_6041 
2025-03-31 01:09:29.894133: pet_6041, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.914496: predicting pet_6044 
2025-03-31 01:09:29.925908: pet_6044, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.945905: predicting pet_6046 
2025-03-31 01:09:29.957217: pet_6046, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:29.976875: predicting pet_6050 
2025-03-31 01:09:29.987006: pet_6050, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.006972: predicting pet_6052 
2025-03-31 01:09:30.016291: pet_6052, shape torch.Size([3, 1, 466, 512]), rank 0 
2025-03-31 01:09:30.036694: predicting pet_6055 
2025-03-31 01:09:30.044592: pet_6055, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:09:30.066403: predicting pet_6069 
2025-03-31 01:09:30.072348: pet_6069, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:30.093607: predicting pet_6070 
2025-03-31 01:09:30.106801: pet_6070, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.126639: predicting pet_6073 
2025-03-31 01:09:30.136616: pet_6073, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.156742: predicting pet_6081 
2025-03-31 01:09:30.165827: pet_6081, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.186499: predicting pet_6083 
2025-03-31 01:09:30.196217: pet_6083, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.218034: predicting pet_6088 
2025-03-31 01:09:30.228368: pet_6088, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.248542: predicting pet_6092 
2025-03-31 01:09:30.256785: pet_6092, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.275659: predicting pet_6095 
2025-03-31 01:09:30.282313: pet_6095, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.302732: predicting pet_6097 
2025-03-31 01:09:30.310195: pet_6097, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.329074: predicting pet_6111 
2025-03-31 01:09:30.340500: pet_6111, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.360826: predicting pet_6115 
2025-03-31 01:09:30.371909: pet_6115, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.392081: predicting pet_6116 
2025-03-31 01:09:30.399836: pet_6116, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.419549: predicting pet_6122 
2025-03-31 01:09:30.427330: pet_6122, shape torch.Size([3, 1, 512, 354]), rank 0 
2025-03-31 01:09:30.450076: predicting pet_6126 
2025-03-31 01:09:30.460496: pet_6126, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.482570: predicting pet_6129 
2025-03-31 01:09:30.488312: pet_6129, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.508541: predicting pet_6131 
2025-03-31 01:09:30.516102: pet_6131, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.534795: predicting pet_6139 
2025-03-31 01:09:30.543876: pet_6139, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.563960: predicting pet_6140 
2025-03-31 01:09:30.571296: pet_6140, shape torch.Size([3, 1, 419, 512]), rank 0 
2025-03-31 01:09:30.591897: predicting pet_6141 
2025-03-31 01:09:30.599107: pet_6141, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.619241: predicting pet_6144 
2025-03-31 01:09:30.631437: pet_6144, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.654139: predicting pet_6148 
2025-03-31 01:09:30.663262: pet_6148, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.682841: predicting pet_6149 
2025-03-31 01:09:30.691556: pet_6149, shape torch.Size([3, 1, 400, 512]), rank 0 
2025-03-31 01:09:30.714152: predicting pet_6150 
2025-03-31 01:09:30.723471: pet_6150, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.744865: predicting pet_6155 
2025-03-31 01:09:30.756830: pet_6155, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.775651: predicting pet_6160 
2025-03-31 01:09:30.781412: pet_6160, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.800150: predicting pet_6162 
2025-03-31 01:09:30.808567: pet_6162, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.829106: predicting pet_6163 
2025-03-31 01:09:30.839750: pet_6163, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.861131: predicting pet_6169 
2025-03-31 01:09:30.871160: pet_6169, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.891164: predicting pet_6171 
2025-03-31 01:09:30.901939: pet_6171, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.922104: predicting pet_6180 
2025-03-31 01:09:30.933556: pet_6180, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.953013: predicting pet_6182 
2025-03-31 01:09:30.961690: pet_6182, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:30.982696: predicting pet_6192 
2025-03-31 01:09:30.993703: pet_6192, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.013375: predicting pet_6193 
2025-03-31 01:09:31.024474: pet_6193, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.044089: predicting pet_6194 
2025-03-31 01:09:31.050906: pet_6194, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.070890: predicting pet_6197 
2025-03-31 01:09:31.078875: pet_6197, shape torch.Size([3, 1, 433, 512]), rank 0 
2025-03-31 01:09:31.102582: predicting pet_6198 
2025-03-31 01:09:31.107625: pet_6198, shape torch.Size([3, 1, 348, 512]), rank 0 
2025-03-31 01:09:31.130569: predicting pet_6201 
2025-03-31 01:09:31.138269: pet_6201, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.160431: predicting pet_6204 
2025-03-31 01:09:31.166306: pet_6204, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.190635: predicting pet_6207 
2025-03-31 01:09:31.200239: pet_6207, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.223226: predicting pet_6221 
2025-03-31 01:09:31.232086: pet_6221, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.252326: predicting pet_6228 
2025-03-31 01:09:31.258461: pet_6228, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.283402: predicting pet_6231 
2025-03-31 01:09:31.293240: pet_6231, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:31.314833: predicting pet_6234 
2025-03-31 01:09:31.321990: pet_6234, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.341481: predicting pet_6245 
2025-03-31 01:09:31.351198: pet_6245, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.371721: predicting pet_6253 
2025-03-31 01:09:31.381549: pet_6253, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:31.401638: predicting pet_6254 
2025-03-31 01:09:31.408785: pet_6254, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.429858: predicting pet_6263 
2025-03-31 01:09:31.441329: pet_6263, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.460783: predicting pet_6265 
2025-03-31 01:09:31.465633: pet_6265, shape torch.Size([3, 1, 400, 504]), rank 0 
2025-03-31 01:09:31.485383: predicting pet_6286 
2025-03-31 01:09:31.493962: pet_6286, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:09:31.518559: predicting pet_6291 
2025-03-31 01:09:31.529963: pet_6291, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.550537: predicting pet_6292 
2025-03-31 01:09:31.556141: pet_6292, shape torch.Size([3, 1, 416, 480]), rank 0 
2025-03-31 01:09:31.576164: predicting pet_6296 
2025-03-31 01:09:31.583577: pet_6296, shape torch.Size([3, 1, 400, 512]), rank 0 
2025-03-31 01:09:31.604285: predicting pet_6298 
2025-03-31 01:09:31.615650: pet_6298, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.636350: predicting pet_6300 
2025-03-31 01:09:31.643747: pet_6300, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:09:31.662742: predicting pet_6304 
2025-03-31 01:09:31.669564: pet_6304, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:31.690743: predicting pet_6305 
2025-03-31 01:09:31.701485: pet_6305, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.722683: predicting pet_6307 
2025-03-31 01:09:31.730494: pet_6307, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.749822: predicting pet_6313 
2025-03-31 01:09:31.758154: pet_6313, shape torch.Size([3, 1, 370, 512]), rank 0 
2025-03-31 01:09:31.778972: predicting pet_6318 
2025-03-31 01:09:31.787019: pet_6318, shape torch.Size([3, 1, 456, 512]), rank 0 
2025-03-31 01:09:31.806701: predicting pet_6327 
2025-03-31 01:09:31.815890: pet_6327, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.836676: predicting pet_6333 
2025-03-31 01:09:31.844429: pet_6333, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.864502: predicting pet_6335 
2025-03-31 01:09:31.872545: pet_6335, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.891399: predicting pet_6340 
2025-03-31 01:09:31.899097: pet_6340, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.917774: predicting pet_6358 
2025-03-31 01:09:31.925159: pet_6358, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.944016: predicting pet_6365 
2025-03-31 01:09:31.951508: pet_6365, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.970248: predicting pet_6378 
2025-03-31 01:09:31.978951: pet_6378, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:31.996778: predicting pet_6382 
2025-03-31 01:09:32.005491: pet_6382, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.025326: predicting pet_6385 
2025-03-31 01:09:32.034129: pet_6385, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.052682: predicting pet_6399 
2025-03-31 01:09:32.062134: pet_6399, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.081852: predicting pet_6402 
2025-03-31 01:09:32.088394: pet_6402, shape torch.Size([3, 1, 512, 399]), rank 0 
2025-03-31 01:09:32.108530: predicting pet_6412 
2025-03-31 01:09:32.114533: pet_6412, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:09:32.134417: predicting pet_6421 
2025-03-31 01:09:32.145367: pet_6421, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.166635: predicting pet_6424 
2025-03-31 01:09:32.172217: pet_6424, shape torch.Size([3, 1, 468, 512]), rank 0 
2025-03-31 01:09:32.194916: predicting pet_6427 
2025-03-31 01:09:32.201656: pet_6427, shape torch.Size([3, 1, 512, 456]), rank 0 
2025-03-31 01:09:32.223726: predicting pet_6432 
2025-03-31 01:09:32.230829: pet_6432, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:09:32.251228: predicting pet_6437 
2025-03-31 01:09:32.271245: pet_6437, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.290959: predicting pet_6442 
2025-03-31 01:09:32.297882: pet_6442, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.317388: predicting pet_6448 
2025-03-31 01:09:32.326384: pet_6448, shape torch.Size([3, 1, 404, 512]), rank 0 
2025-03-31 01:09:32.347710: predicting pet_6450 
2025-03-31 01:09:32.358562: pet_6450, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.378243: predicting pet_6452 
2025-03-31 01:09:32.387511: pet_6452, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.407546: predicting pet_6453 
2025-03-31 01:09:32.416947: pet_6453, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.435925: predicting pet_6470 
2025-03-31 01:09:32.441864: pet_6470, shape torch.Size([3, 1, 488, 356]), rank 0 
2025-03-31 01:09:32.464240: predicting pet_6471 
2025-03-31 01:09:32.474175: pet_6471, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.495393: predicting pet_6474 
2025-03-31 01:09:32.502040: pet_6474, shape torch.Size([3, 1, 512, 405]), rank 0 
2025-03-31 01:09:32.521747: predicting pet_6475 
2025-03-31 01:09:32.529512: pet_6475, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:09:32.550650: predicting pet_6476 
2025-03-31 01:09:32.561696: pet_6476, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.583541: predicting pet_6478 
2025-03-31 01:09:32.592340: pet_6478, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.611991: predicting pet_6481 
2025-03-31 01:09:32.629444: pet_6481, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.649674: predicting pet_6485 
2025-03-31 01:09:32.656122: pet_6485, shape torch.Size([3, 1, 377, 512]), rank 0 
2025-03-31 01:09:32.676540: predicting pet_6498 
2025-03-31 01:09:32.684545: pet_6498, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.704372: predicting pet_6505 
2025-03-31 01:09:32.712484: pet_6505, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.733046: predicting pet_6512 
2025-03-31 01:09:32.739448: pet_6512, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.763124: predicting pet_6516 
2025-03-31 01:09:32.772395: pet_6516, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.792434: predicting pet_6520 
2025-03-31 01:09:32.805927: pet_6520, shape torch.Size([3, 1, 485, 512]), rank 0 
2025-03-31 01:09:32.828474: predicting pet_6524 
2025-03-31 01:09:32.842266: pet_6524, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.862813: predicting pet_6533 
2025-03-31 01:09:32.872552: pet_6533, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.896454: predicting pet_6534 
2025-03-31 01:09:32.903866: pet_6534, shape torch.Size([3, 1, 385, 512]), rank 0 
2025-03-31 01:09:32.924699: predicting pet_6535 
2025-03-31 01:09:32.939233: pet_6535, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.959462: predicting pet_6536 
2025-03-31 01:09:32.965018: pet_6536, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:32.984409: predicting pet_6541 
2025-03-31 01:09:32.994541: pet_6541, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.015777: predicting pet_6547 
2025-03-31 01:09:33.023345: pet_6547, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.043638: predicting pet_6559 
2025-03-31 01:09:33.051254: pet_6559, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:09:33.069916: predicting pet_6568 
2025-03-31 01:09:33.081155: pet_6568, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.100499: predicting pet_6570 
2025-03-31 01:09:33.116183: pet_6570, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.137382: predicting pet_6592 
2025-03-31 01:09:33.144774: pet_6592, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.163862: predicting pet_6598 
2025-03-31 01:09:33.172661: pet_6598, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.194896: predicting pet_6605 
2025-03-31 01:09:33.201482: pet_6605, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.219872: predicting pet_6607 
2025-03-31 01:09:33.230951: pet_6607, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.251361: predicting pet_6610 
2025-03-31 01:09:33.261057: pet_6610, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.283134: predicting pet_6615 
2025-03-31 01:09:33.289257: pet_6615, shape torch.Size([3, 1, 338, 464]), rank 0 
2025-03-31 01:09:33.308500: predicting pet_6625 
2025-03-31 01:09:33.320842: pet_6625, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.339576: predicting pet_6627 
2025-03-31 01:09:33.348736: pet_6627, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.370290: predicting pet_6633 
2025-03-31 01:09:33.379537: pet_6633, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.402618: predicting pet_6635 
2025-03-31 01:09:33.416121: pet_6635, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.435804: predicting pet_6638 
2025-03-31 01:09:33.448924: pet_6638, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.467920: predicting pet_6639 
2025-03-31 01:09:33.475066: pet_6639, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.496869: predicting pet_6640 
2025-03-31 01:09:33.507530: pet_6640, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.526816: predicting pet_6641 
2025-03-31 01:09:33.535203: pet_6641, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.557072: predicting pet_6653 
2025-03-31 01:09:33.572095: pet_6653, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.591670: predicting pet_6655 
2025-03-31 01:09:33.604940: pet_6655, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.625487: predicting pet_6659 
2025-03-31 01:09:33.630260: pet_6659, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.649516: predicting pet_6661 
2025-03-31 01:09:33.655774: pet_6661, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.675946: predicting pet_6662 
2025-03-31 01:09:33.688280: pet_6662, shape torch.Size([3, 1, 435, 512]), rank 0 
2025-03-31 01:09:33.708681: predicting pet_6663 
2025-03-31 01:09:33.715432: pet_6663, shape torch.Size([3, 1, 512, 385]), rank 0 
2025-03-31 01:09:33.737599: predicting pet_6671 
2025-03-31 01:09:33.744801: pet_6671, shape torch.Size([3, 1, 490, 448]), rank 0 
2025-03-31 01:09:33.764398: predicting pet_6675 
2025-03-31 01:09:33.773885: pet_6675, shape torch.Size([3, 1, 472, 512]), rank 0 
2025-03-31 01:09:33.793950: predicting pet_6676 
2025-03-31 01:09:33.803376: pet_6676, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.826070: predicting pet_6680 
2025-03-31 01:09:33.837981: pet_6680, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.858538: predicting pet_6682 
2025-03-31 01:09:33.868991: pet_6682, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.889307: predicting pet_6689 
2025-03-31 01:09:33.898926: pet_6689, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.919569: predicting pet_6691 
2025-03-31 01:09:33.924798: pet_6691, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.943888: predicting pet_6694 
2025-03-31 01:09:33.953178: pet_6694, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:33.974879: predicting pet_6696 
2025-03-31 01:09:33.985161: pet_6696, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.004617: predicting pet_6702 
2025-03-31 01:09:34.014629: pet_6702, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.034683: predicting pet_6706 
2025-03-31 01:09:34.042865: pet_6706, shape torch.Size([3, 1, 384, 512]), rank 0 
2025-03-31 01:09:34.062927: predicting pet_6717 
2025-03-31 01:09:34.074116: pet_6717, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.093852: predicting pet_6721 
2025-03-31 01:09:34.101593: pet_6721, shape torch.Size([3, 1, 419, 512]), rank 0 
2025-03-31 01:09:34.123397: predicting pet_6722 
2025-03-31 01:09:34.134058: pet_6722, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.153728: predicting pet_6750 
2025-03-31 01:09:34.169293: pet_6750, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.189563: predicting pet_6751 
2025-03-31 01:09:34.198659: pet_6751, shape torch.Size([3, 1, 398, 512]), rank 0 
2025-03-31 01:09:34.218701: predicting pet_6752 
2025-03-31 01:09:34.233764: pet_6752, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.253009: predicting pet_6756 
2025-03-31 01:09:34.259517: pet_6756, shape torch.Size([3, 1, 503, 416]), rank 0 
2025-03-31 01:09:34.281965: predicting pet_6758 
2025-03-31 01:09:34.292874: pet_6758, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:09:34.313287: predicting pet_6767 
2025-03-31 01:09:34.322719: pet_6767, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.343904: predicting pet_6776 
2025-03-31 01:09:34.352301: pet_6776, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:09:34.371031: predicting pet_6778 
2025-03-31 01:09:34.379480: pet_6778, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.399740: predicting pet_6780 
2025-03-31 01:09:34.408710: pet_6780, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.428225: predicting pet_6783 
2025-03-31 01:09:34.437151: pet_6783, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.456958: predicting pet_6791 
2025-03-31 01:09:34.466082: pet_6791, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.486107: predicting pet_6798 
2025-03-31 01:09:34.498040: pet_6798, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.518025: predicting pet_6803 
2025-03-31 01:09:34.526905: pet_6803, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.545436: predicting pet_6811 
2025-03-31 01:09:34.558338: pet_6811, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.578768: predicting pet_6818 
2025-03-31 01:09:34.584731: pet_6818, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.604750: predicting pet_6820 
2025-03-31 01:09:34.613173: pet_6820, shape torch.Size([3, 1, 512, 496]), rank 0 
2025-03-31 01:09:34.633128: predicting pet_6821 
2025-03-31 01:09:34.644529: pet_6821, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.664032: predicting pet_6827 
2025-03-31 01:09:34.673231: pet_6827, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.693737: predicting pet_6830 
2025-03-31 01:09:34.697984: pet_6830, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.717414: predicting pet_6831 
2025-03-31 01:09:34.725832: pet_6831, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.745236: predicting pet_6832 
2025-03-31 01:09:34.753129: pet_6832, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:09:34.773499: predicting pet_6834 
2025-03-31 01:09:34.783173: pet_6834, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.803053: predicting pet_6842 
2025-03-31 01:09:34.812395: pet_6842, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.833783: predicting pet_6854 
2025-03-31 01:09:34.841486: pet_6854, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.861432: predicting pet_6860 
2025-03-31 01:09:34.870940: pet_6860, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.891281: predicting pet_6863 
2025-03-31 01:09:34.899300: pet_6863, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.917486: predicting pet_6865 
2025-03-31 01:09:34.926402: pet_6865, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.944775: predicting pet_6866 
2025-03-31 01:09:34.952560: pet_6866, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:34.973830: predicting pet_6874 
2025-03-31 01:09:34.985073: pet_6874, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.005402: predicting pet_6880 
2025-03-31 01:09:35.018602: pet_6880, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.037358: predicting pet_6884 
2025-03-31 01:09:35.045616: pet_6884, shape torch.Size([3, 1, 512, 496]), rank 0 
2025-03-31 01:09:35.067329: predicting pet_6885 
2025-03-31 01:09:35.076617: pet_6885, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.096060: predicting pet_6887 
2025-03-31 01:09:35.106147: pet_6887, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.127545: predicting pet_6891 
2025-03-31 01:09:35.139106: pet_6891, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.160292: predicting pet_6894 
2025-03-31 01:09:35.168791: pet_6894, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.187656: predicting pet_6898 
2025-03-31 01:09:35.197750: pet_6898, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.217847: predicting pet_6902 
2025-03-31 01:09:35.227031: pet_6902, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.246911: predicting pet_6904 
2025-03-31 01:09:35.258239: pet_6904, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.278323: predicting pet_6909 
2025-03-31 01:09:35.285590: pet_6909, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.305269: predicting pet_6913 
2025-03-31 01:09:35.312754: pet_6913, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:09:35.333790: predicting pet_6915 
2025-03-31 01:09:35.344622: pet_6915, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.365080: predicting pet_6916 
2025-03-31 01:09:35.373874: pet_6916, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.394628: predicting pet_6923 
2025-03-31 01:09:35.403913: pet_6923, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.423263: predicting pet_6924 
2025-03-31 01:09:35.434638: pet_6924, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.455002: predicting pet_6931 
2025-03-31 01:09:35.464720: pet_6931, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.486099: predicting pet_6932 
2025-03-31 01:09:35.493477: pet_6932, shape torch.Size([3, 1, 496, 488]), rank 0 
2025-03-31 01:09:35.514091: predicting pet_6937 
2025-03-31 01:09:35.524067: pet_6937, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.547029: predicting pet_6939 
2025-03-31 01:09:35.555000: pet_6939, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.574690: predicting pet_6941 
2025-03-31 01:09:35.581338: pet_6941, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.600664: predicting pet_6951 
2025-03-31 01:09:35.610063: pet_6951, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.630122: predicting pet_6966 
2025-03-31 01:09:35.637674: pet_6966, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.658596: predicting pet_6978 
2025-03-31 01:09:35.667671: pet_6978, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.686552: predicting pet_6980 
2025-03-31 01:09:35.696077: pet_6980, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.717113: predicting pet_6983 
2025-03-31 01:09:35.724233: pet_6983, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:09:35.745042: predicting pet_6984 
2025-03-31 01:09:35.754966: pet_6984, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.774107: predicting pet_6987 
2025-03-31 01:09:35.784409: pet_6987, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.804821: predicting pet_6990 
2025-03-31 01:09:35.814268: pet_6990, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.835282: predicting pet_6994 
2025-03-31 01:09:35.841678: pet_6994, shape torch.Size([3, 1, 345, 464]), rank 0 
2025-03-31 01:09:35.863321: predicting pet_7001 
2025-03-31 01:09:35.870870: pet_7001, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.890083: predicting pet_7006 
2025-03-31 01:09:35.900844: pet_7006, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.919670: predicting pet_7008 
2025-03-31 01:09:35.930394: pet_7008, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.952617: predicting pet_7011 
2025-03-31 01:09:35.962609: pet_7011, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:35.983192: predicting pet_7034 
2025-03-31 01:09:35.989439: pet_7034, shape torch.Size([3, 1, 345, 497]), rank 0 
2025-03-31 01:09:36.008700: predicting pet_7036 
2025-03-31 01:09:36.013584: pet_7036, shape torch.Size([3, 1, 296, 480]), rank 0 
2025-03-31 01:09:36.034266: predicting pet_7038 
2025-03-31 01:09:36.041596: pet_7038, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.060624: predicting pet_7040 
2025-03-31 01:09:36.072949: pet_7040, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.092078: predicting pet_7044 
2025-03-31 01:09:36.101556: pet_7044, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.122093: predicting pet_7048 
2025-03-31 01:09:36.134409: pet_7048, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.155125: predicting pet_7055 
2025-03-31 01:09:36.165581: pet_7055, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.184720: predicting pet_7060 
2025-03-31 01:09:36.196685: pet_7060, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:09:36.217089: predicting pet_7064 
2025-03-31 01:09:36.224834: pet_7064, shape torch.Size([3, 1, 370, 497]), rank 0 
2025-03-31 01:09:36.245454: predicting pet_7066 
2025-03-31 01:09:36.256181: pet_7066, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.278511: predicting pet_7067 
2025-03-31 01:09:36.284887: pet_7067, shape torch.Size([3, 1, 512, 355]), rank 0 
2025-03-31 01:09:36.305432: predicting pet_7084 
2025-03-31 01:09:36.315806: pet_7084, shape torch.Size([3, 1, 512, 470]), rank 0 
2025-03-31 01:09:36.335925: predicting pet_7086 
2025-03-31 01:09:36.344941: pet_7086, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.364118: predicting pet_7088 
2025-03-31 01:09:36.370433: pet_7088, shape torch.Size([3, 1, 512, 387]), rank 0 
2025-03-31 01:09:36.393015: predicting pet_7094 
2025-03-31 01:09:36.403060: pet_7094, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.423519: predicting pet_7098 
2025-03-31 01:09:36.434050: pet_7098, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.454149: predicting pet_7108 
2025-03-31 01:09:36.465402: pet_7108, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.484834: predicting pet_7109 
2025-03-31 01:09:36.493948: pet_7109, shape torch.Size([3, 1, 497, 408]), rank 0 
2025-03-31 01:09:36.514635: predicting pet_7112 
2025-03-31 01:09:36.524418: pet_7112, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.544618: predicting pet_7113 
2025-03-31 01:09:36.553082: pet_7113, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.573029: predicting pet_7114 
2025-03-31 01:09:36.580038: pet_7114, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.599838: predicting pet_7115 
2025-03-31 01:09:36.610292: pet_7115, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.630419: predicting pet_7123 
2025-03-31 01:09:36.637930: pet_7123, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.657358: predicting pet_7135 
2025-03-31 01:09:36.669063: pet_7135, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.688514: predicting pet_7136 
2025-03-31 01:09:36.697671: pet_7136, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.718578: predicting pet_7138 
2025-03-31 01:09:36.726937: pet_7138, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.746535: predicting pet_7139 
2025-03-31 01:09:36.757290: pet_7139, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.778216: predicting pet_7142 
2025-03-31 01:09:36.788805: pet_7142, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.808595: predicting pet_7149 
2025-03-31 01:09:36.818134: pet_7149, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.839893: predicting pet_7159 
2025-03-31 01:09:36.849219: pet_7159, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.869767: predicting pet_7160 
2025-03-31 01:09:36.879974: pet_7160, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.900341: predicting pet_7161 
2025-03-31 01:09:36.910596: pet_7161, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:09:36.931062: predicting pet_7169 
2025-03-31 01:09:36.943521: pet_7169, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.964146: predicting pet_7174 
2025-03-31 01:09:36.970605: pet_7174, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:36.989207: predicting pet_7177 
2025-03-31 01:09:36.998594: pet_7177, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.019617: predicting pet_7184 
2025-03-31 01:09:37.028503: pet_7184, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.049316: predicting pet_7189 
2025-03-31 01:09:37.060788: pet_7189, shape torch.Size([3, 1, 466, 481]), rank 0 
2025-03-31 01:09:37.082484: predicting pet_7191 
2025-03-31 01:09:37.095652: pet_7191, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.115155: predicting pet_7197 
2025-03-31 01:09:37.123332: pet_7197, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.143796: predicting pet_7205 
2025-03-31 01:09:37.152554: pet_7205, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.173781: predicting pet_7210 
2025-03-31 01:09:37.185216: pet_7210, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.204038: predicting pet_7223 
2025-03-31 01:09:37.212892: pet_7223, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.231935: predicting pet_7229 
2025-03-31 01:09:37.240162: pet_7229, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.257453: predicting pet_7231 
2025-03-31 01:09:37.264191: pet_7231, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.285342: predicting pet_7238 
2025-03-31 01:09:37.294148: pet_7238, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.314592: predicting pet_7240 
2025-03-31 01:09:37.323926: pet_7240, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.343182: predicting pet_7243 
2025-03-31 01:09:37.352160: pet_7243, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.370885: predicting pet_7248 
2025-03-31 01:09:37.379901: pet_7248, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.398809: predicting pet_7254 
2025-03-31 01:09:37.407282: pet_7254, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.428434: predicting pet_7255 
2025-03-31 01:09:37.437250: pet_7255, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.455577: predicting pet_7279 
2025-03-31 01:09:37.465599: pet_7279, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.485575: predicting pet_7280 
2025-03-31 01:09:37.494800: pet_7280, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.515290: predicting pet_7283 
2025-03-31 01:09:37.526534: pet_7283, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.546908: predicting pet_7286 
2025-03-31 01:09:37.553969: pet_7286, shape torch.Size([3, 1, 512, 402]), rank 0 
2025-03-31 01:09:37.576771: predicting pet_7290 
2025-03-31 01:09:37.587467: pet_7290, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.607244: predicting pet_7293 
2025-03-31 01:09:37.613698: pet_7293, shape torch.Size([3, 1, 512, 356]), rank 0 
2025-03-31 01:09:37.634587: predicting pet_7306 
2025-03-31 01:09:37.644316: pet_7306, shape torch.Size([3, 1, 512, 391]), rank 0 
2025-03-31 01:09:37.664693: predicting pet_7317 
2025-03-31 01:09:37.674984: pet_7317, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.694645: predicting pet_7327 
2025-03-31 01:09:37.704823: pet_7327, shape torch.Size([3, 1, 456, 512]), rank 0 
2025-03-31 01:09:37.726121: predicting pet_7330 
2025-03-31 01:09:37.739310: pet_7330, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.758743: predicting pet_7331 
2025-03-31 01:09:37.766838: pet_7331, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.787378: predicting pet_7332 
2025-03-31 01:09:37.799826: pet_7332, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.818912: predicting pet_7336 
2025-03-31 01:09:37.826773: pet_7336, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.846398: predicting pet_7341 
2025-03-31 01:09:37.854879: pet_7341, shape torch.Size([3, 1, 512, 448]), rank 0 
2025-03-31 01:09:37.874112: predicting pet_7348 
2025-03-31 01:09:37.883292: pet_7348, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.901070: predicting pet_7350 
2025-03-31 01:09:37.909171: pet_7350, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.927059: predicting pet_7358 
2025-03-31 01:09:37.939966: pet_7358, shape torch.Size([3, 1, 497, 497]), rank 0 
2025-03-31 01:09:37.958693: predicting pet_7360 
2025-03-31 01:09:37.969348: pet_7360, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:37.989048: predicting pet_7363 
2025-03-31 01:09:37.993445: pet_7363, shape torch.Size([3, 1, 384, 512]), rank 0 
2025-03-31 01:09:38.011798: predicting pet_7372 
2025-03-31 01:09:38.020674: pet_7372, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.039291: predicting pet_7373 
2025-03-31 01:09:38.047268: pet_7373, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.065648: predicting pet_7381 
2025-03-31 01:09:38.073077: pet_7381, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.091835: predicting pet_7384 
2025-03-31 01:09:38.104254: pet_7384, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.123776: predicting pet_7388 
2025-03-31 01:09:38.134521: pet_7388, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.152174: predicting pet_7409 
2025-03-31 01:09:38.162421: pet_7409, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.182944: predicting pet_7413 
2025-03-31 01:09:38.193308: pet_7413, shape torch.Size([3, 1, 512, 416]), rank 0 
2025-03-31 01:09:38.212032: predicting pet_7421 
2025-03-31 01:09:38.218393: pet_7421, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.237907: predicting pet_7423 
2025-03-31 01:09:38.247183: pet_7423, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.266272: predicting pet_7433 
2025-03-31 01:09:38.277059: pet_7433, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.297430: predicting pet_7435 
2025-03-31 01:09:38.307035: pet_7435, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.326206: predicting pet_7444 
2025-03-31 01:09:38.337346: pet_7444, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.356510: predicting pet_7446 
2025-03-31 01:09:38.364291: pet_7446, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.383497: predicting pet_7448 
2025-03-31 01:09:38.392347: pet_7448, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.415554: predicting pet_7451 
2025-03-31 01:09:38.433274: pet_7451, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.452391: predicting pet_7455 
2025-03-31 01:09:38.461888: pet_7455, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:09:38.484550: predicting pet_7456 
2025-03-31 01:09:38.495072: pet_7456, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.515181: predicting pet_7464 
2025-03-31 01:09:38.523715: pet_7464, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.544108: predicting pet_7469 
2025-03-31 01:09:38.551847: pet_7469, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.570306: predicting pet_7471 
2025-03-31 01:09:38.577926: pet_7471, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.601860: predicting pet_7485 
2025-03-31 01:09:38.608623: pet_7485, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.629693: predicting pet_7486 
2025-03-31 01:09:38.634043: pet_7486, shape torch.Size([3, 1, 436, 512]), rank 0 
2025-03-31 01:09:38.653204: predicting pet_7493 
2025-03-31 01:09:38.667446: pet_7493, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.687857: predicting pet_7503 
2025-03-31 01:09:38.700357: pet_7503, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.721833: predicting pet_7512 
2025-03-31 01:09:38.732990: pet_7512, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.754855: predicting pet_7516 
2025-03-31 01:09:38.763653: pet_7516, shape torch.Size([3, 1, 451, 512]), rank 0 
2025-03-31 01:09:38.786869: predicting pet_7522 
2025-03-31 01:09:38.798047: pet_7522, shape torch.Size([3, 1, 512, 417]), rank 0 
2025-03-31 01:09:38.817416: predicting pet_7537 
2025-03-31 01:09:38.828228: pet_7537, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.847970: predicting pet_7539 
2025-03-31 01:09:38.856927: pet_7539, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.876456: predicting pet_7540 
2025-03-31 01:09:38.885662: pet_7540, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.906143: predicting pet_7548 
2025-03-31 01:09:38.916581: pet_7548, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.937205: predicting pet_7550 
2025-03-31 01:09:38.946439: pet_7550, shape torch.Size([3, 1, 388, 512]), rank 0 
2025-03-31 01:09:38.968723: predicting pet_7551 
2025-03-31 01:09:38.977419: pet_7551, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:38.997748: predicting pet_7555 
2025-03-31 01:09:39.007491: pet_7555, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.027958: predicting pet_7556 
2025-03-31 01:09:39.040699: pet_7556, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.061020: predicting pet_7562 
2025-03-31 01:09:39.071803: pet_7562, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.092126: predicting pet_7580 
2025-03-31 01:09:39.104519: pet_7580, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.123320: predicting pet_7582 
2025-03-31 01:09:39.128482: pet_7582, shape torch.Size([3, 1, 504, 448]), rank 0 
2025-03-31 01:09:39.149929: predicting pet_7598 
2025-03-31 01:09:39.161263: pet_7598, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.184756: predicting pet_7603 
2025-03-31 01:09:39.197631: pet_7603, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.217133: predicting pet_7606 
2025-03-31 01:09:39.225873: pet_7606, shape torch.Size([3, 1, 512, 384]), rank 0 
2025-03-31 01:09:39.246618: predicting pet_7610 
2025-03-31 01:09:39.255219: pet_7610, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.276026: predicting pet_7611 
2025-03-31 01:09:39.287254: pet_7611, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.307793: predicting pet_7616 
2025-03-31 01:09:39.320849: pet_7616, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.340531: predicting pet_7618 
2025-03-31 01:09:39.349975: pet_7618, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.371388: predicting pet_7622 
2025-03-31 01:09:39.434923: pet_7622, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.457585: predicting pet_7623 
2025-03-31 01:09:39.511321: pet_7623, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.531060: predicting pet_7630 
2025-03-31 01:09:39.570427: pet_7630, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.589498: predicting pet_7632 
2025-03-31 01:09:39.643020: pet_7632, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.662553: predicting pet_7633 
2025-03-31 01:09:39.722387: pet_7633, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.741586: predicting pet_7634 
2025-03-31 01:09:39.781797: pet_7634, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.800889: predicting pet_7653 
2025-03-31 01:09:39.862976: pet_7653, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.882703: predicting pet_7654 
2025-03-31 01:09:39.935718: pet_7654, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:39.954696: predicting pet_7655 
2025-03-31 01:09:39.998212: pet_7655, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.017462: predicting pet_7656 
2025-03-31 01:09:40.060260: pet_7656, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.079802: predicting pet_7668 
2025-03-31 01:09:40.119126: pet_7668, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.139571: predicting pet_7677 
2025-03-31 01:09:40.200596: pet_7677, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.219723: predicting pet_7687 
2025-03-31 01:09:40.275633: pet_7687, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.295368: predicting pet_7688 
2025-03-31 01:09:40.339571: pet_7688, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.358866: predicting pet_7690 
2025-03-31 01:09:40.398932: pet_7690, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:09:40.419165: predicting pet_7701 
2025-03-31 01:09:40.464518: pet_7701, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.484918: predicting pet_7707 
2025-03-31 01:09:40.505678: pet_7707, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.525091: predicting pet_7713 
2025-03-31 01:09:40.558818: pet_7713, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.578300: predicting pet_7718 
2025-03-31 01:09:40.617574: pet_7718, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.636579: predicting pet_7722 
2025-03-31 01:09:40.681477: pet_7722, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.700654: predicting pet_7733 
2025-03-31 01:09:40.763995: pet_7733, shape torch.Size([3, 1, 425, 512]), rank 0 
2025-03-31 01:09:40.786050: predicting pet_7734 
2025-03-31 01:09:40.840617: pet_7734, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:40.860928: predicting pet_7738 
2025-03-31 01:09:40.883217: pet_7738, shape torch.Size([3, 1, 512, 464]), rank 0 
2025-03-31 01:09:40.902963: predicting pet_7746 
2025-03-31 01:09:40.938096: pet_7746, shape torch.Size([3, 1, 438, 512]), rank 0 
2025-03-31 01:09:40.959390: predicting pet_7749 
2025-03-31 01:09:41.000823: pet_7749, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.021018: predicting pet_7753 
2025-03-31 01:09:41.073333: pet_7753, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.092583: predicting pet_7761 
2025-03-31 01:09:41.123780: pet_7761, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.142689: predicting pet_7769 
2025-03-31 01:09:41.190906: pet_7769, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.209656: predicting pet_7772 
2025-03-31 01:09:41.244711: pet_7772, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.264001: predicting pet_7782 
2025-03-31 01:09:41.287871: pet_7782, shape torch.Size([3, 1, 512, 465]), rank 0 
2025-03-31 01:09:41.307811: predicting pet_7786 
2025-03-31 01:09:41.313912: pet_7786, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.333868: predicting pet_7788 
2025-03-31 01:09:41.341680: pet_7788, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.361835: predicting pet_7791 
2025-03-31 01:09:41.369657: pet_7791, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.390546: predicting pet_7799 
2025-03-31 01:09:41.398860: pet_7799, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.418262: predicting pet_7802 
2025-03-31 01:09:41.428862: pet_7802, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.449540: predicting pet_7804 
2025-03-31 01:09:41.457243: pet_7804, shape torch.Size([3, 1, 496, 512]), rank 0 
2025-03-31 01:09:41.476042: predicting pet_7812 
2025-03-31 01:09:41.484839: pet_7812, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.504638: predicting pet_7820 
2025-03-31 01:09:41.511064: pet_7820, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.533210: predicting pet_7824 
2025-03-31 01:09:41.544863: pet_7824, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.564893: predicting pet_7833 
2025-03-31 01:09:41.574483: pet_7833, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.595348: predicting pet_7855 
2025-03-31 01:09:41.603667: pet_7855, shape torch.Size([3, 1, 404, 512]), rank 0 
2025-03-31 01:09:41.624464: predicting pet_7856 
2025-03-31 01:09:41.633537: pet_7856, shape torch.Size([3, 1, 432, 512]), rank 0 
2025-03-31 01:09:41.654227: predicting pet_7859 
2025-03-31 01:09:41.662939: pet_7859, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.682154: predicting pet_7867 
2025-03-31 01:09:41.689722: pet_7867, shape torch.Size([3, 1, 402, 512]), rank 0 
2025-03-31 01:09:41.710505: predicting pet_7870 
2025-03-31 01:09:41.719404: pet_7870, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.738580: predicting pet_7877 
2025-03-31 01:09:41.747355: pet_7877, shape torch.Size([3, 1, 496, 512]), rank 0 
2025-03-31 01:09:41.768715: predicting pet_7878 
2025-03-31 01:09:41.778595: pet_7878, shape torch.Size([3, 1, 448, 512]), rank 0 
2025-03-31 01:09:41.797768: predicting pet_7879 
2025-03-31 01:09:41.807891: pet_7879, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.829442: predicting pet_7880 
2025-03-31 01:09:41.834069: pet_7880, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.853557: predicting pet_7888 
2025-03-31 01:09:41.868073: pet_7888, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.887181: predicting pet_7901 
2025-03-31 01:09:41.897168: pet_7901, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.916871: predicting pet_7912 
2025-03-31 01:09:41.925183: pet_7912, shape torch.Size([3, 1, 421, 512]), rank 0 
2025-03-31 01:09:41.943675: predicting pet_7917 
2025-03-31 01:09:41.953650: pet_7917, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:41.973610: predicting pet_7922 
2025-03-31 01:09:41.982682: pet_7922, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.003218: predicting pet_7932 
2025-03-31 01:09:42.009934: pet_7932, shape torch.Size([3, 1, 363, 512]), rank 0 
2025-03-31 01:09:42.029874: predicting pet_7937 
2025-03-31 01:09:42.038378: pet_7937, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.058393: predicting pet_7945 
2025-03-31 01:09:42.069122: pet_7945, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.090663: predicting pet_7947 
2025-03-31 01:09:42.098876: pet_7947, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.117673: predicting pet_7956 
2025-03-31 01:09:42.124810: pet_7956, shape torch.Size([3, 1, 418, 512]), rank 0 
2025-03-31 01:09:42.146299: predicting pet_7959 
2025-03-31 01:09:42.159987: pet_7959, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.179932: predicting pet_7964 
2025-03-31 01:09:42.191868: pet_7964, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.210382: predicting pet_7974 
2025-03-31 01:09:42.217065: pet_7974, shape torch.Size([3, 1, 400, 512]), rank 0 
2025-03-31 01:09:42.238245: predicting pet_7975 
2025-03-31 01:09:42.245334: pet_7975, shape torch.Size([3, 1, 512, 400]), rank 0 
2025-03-31 01:09:42.264190: predicting pet_7980 
2025-03-31 01:09:42.272703: pet_7980, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.291789: predicting pet_7983 
2025-03-31 01:09:42.304341: pet_7983, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.323533: predicting pet_7985 
2025-03-31 01:09:42.333164: pet_7985, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.353254: predicting pet_7986 
2025-03-31 01:09:42.359704: pet_7986, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:09:42.381725: predicting pet_7987 
2025-03-31 01:09:42.390631: pet_7987, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.409443: predicting pet_7988 
2025-03-31 01:09:42.419505: pet_7988, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.439071: predicting pet_7990 
2025-03-31 01:09:42.448491: pet_7990, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.469756: predicting pet_7991 
2025-03-31 01:09:42.480807: pet_7991, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.501645: predicting pet_7993 
2025-03-31 01:09:42.506030: pet_7993, shape torch.Size([3, 1, 512, 400]), rank 0 
2025-03-31 01:09:42.527435: predicting pet_7999 
2025-03-31 01:09:42.537691: pet_7999, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.557158: predicting pet_8000 
2025-03-31 01:09:42.567916: pet_8000, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.587574: predicting pet_8010 
2025-03-31 01:09:42.595743: pet_8010, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.616846: predicting pet_8012 
2025-03-31 01:09:42.627062: pet_8012, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.647823: predicting pet_8014 
2025-03-31 01:09:42.657852: pet_8014, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.677689: predicting pet_8019 
2025-03-31 01:09:42.687321: pet_8019, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.707565: predicting pet_8022 
2025-03-31 01:09:42.715931: pet_8022, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.736533: predicting pet_8024 
2025-03-31 01:09:42.744642: pet_8024, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.764740: predicting pet_8026 
2025-03-31 01:09:42.774285: pet_8026, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.795846: predicting pet_8029 
2025-03-31 01:09:42.803586: pet_8029, shape torch.Size([3, 1, 388, 512]), rank 0 
2025-03-31 01:09:42.824017: predicting pet_8032 
2025-03-31 01:09:42.832735: pet_8032, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.852410: predicting pet_8037 
2025-03-31 01:09:42.860894: pet_8037, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.884076: predicting pet_8039 
2025-03-31 01:09:42.893622: pet_8039, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.914890: predicting pet_8046 
2025-03-31 01:09:42.924292: pet_8046, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.946670: predicting pet_8047 
2025-03-31 01:09:42.955781: pet_8047, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:42.976600: predicting pet_8048 
2025-03-31 01:09:42.986826: pet_8048, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.010136: predicting pet_8050 
2025-03-31 01:09:43.018929: pet_8050, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.040643: predicting pet_8055 
2025-03-31 01:09:43.049938: pet_8055, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.070062: predicting pet_8057 
2025-03-31 01:09:43.077506: pet_8057, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.095680: predicting pet_8058 
2025-03-31 01:09:43.104063: pet_8058, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.122675: predicting pet_8065 
2025-03-31 01:09:43.130977: pet_8065, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.150788: predicting pet_8078 
2025-03-31 01:09:43.160660: pet_8078, shape torch.Size([3, 1, 482, 512]), rank 0 
2025-03-31 01:09:43.182477: predicting pet_8079 
2025-03-31 01:09:43.194572: pet_8079, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.214293: predicting pet_8084 
2025-03-31 01:09:43.219600: pet_8084, shape torch.Size([3, 1, 496, 512]), rank 0 
2025-03-31 01:09:43.239108: predicting pet_8089 
2025-03-31 01:09:43.250455: pet_8089, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.271178: predicting pet_8095 
2025-03-31 01:09:43.280627: pet_8095, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.300552: predicting pet_8098 
2025-03-31 01:09:43.309552: pet_8098, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.328474: predicting pet_8108 
2025-03-31 01:09:43.337962: pet_8108, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.357716: predicting pet_8123 
2025-03-31 01:09:43.366685: pet_8123, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.387860: predicting pet_8125 
2025-03-31 01:09:43.404024: pet_8125, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.424515: predicting pet_8132 
2025-03-31 01:09:43.460993: pet_8132, shape torch.Size([3, 1, 512, 416]), rank 0 
2025-03-31 01:09:43.482020: predicting pet_8135 
2025-03-31 01:09:43.529547: pet_8135, shape torch.Size([3, 1, 424, 497]), rank 0 
2025-03-31 01:09:43.549411: predicting pet_8143 
2025-03-31 01:09:43.585252: pet_8143, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:43.608077: predicting pet_8145 
2025-03-31 01:09:44.333218: pet_8145, shape torch.Size([3, 1, 512, 480]), rank 0 
2025-03-31 01:09:44.357889: predicting pet_8154 
2025-03-31 01:09:45.091322: pet_8154, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:45.111183: predicting pet_8160 
2025-03-31 01:09:46.062635: pet_8160, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:46.083203: predicting pet_8170 
2025-03-31 01:09:47.809791: pet_8170, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:50.570569: predicting pet_8173 
2025-03-31 01:09:50.712120: pet_8173, shape torch.Size([3, 1, 496, 471]), rank 0 
2025-03-31 01:09:50.731599: predicting pet_8184 
2025-03-31 01:09:50.936473: pet_8184, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:50.957953: predicting pet_8188 
2025-03-31 01:09:51.171004: pet_8188, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:51.193026: predicting pet_8194 
2025-03-31 01:09:51.411941: pet_8194, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:51.432427: predicting pet_8197 
2025-03-31 01:09:51.646023: pet_8197, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:51.665411: predicting pet_8200 
2025-03-31 01:09:51.925525: pet_8200, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:51.946329: predicting pet_8216 
2025-03-31 01:09:52.317055: pet_8216, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:52.337928: predicting pet_8218 
2025-03-31 01:09:52.867506: pet_8218, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:52.886821: predicting pet_8222 
2025-03-31 01:09:53.337479: pet_8222, shape torch.Size([3, 1, 512, 396]), rank 0 
2025-03-31 01:09:53.357364: predicting pet_8225 
2025-03-31 01:09:53.777464: pet_8225, shape torch.Size([3, 1, 512, 392]), rank 0 
2025-03-31 01:09:53.798604: predicting pet_8226 
2025-03-31 01:09:54.504458: pet_8226, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:54.524195: predicting pet_8228 
2025-03-31 01:09:55.015201: pet_8228, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:55.034692: predicting pet_8233 
2025-03-31 01:09:55.608535: pet_8233, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:55.628119: predicting pet_8234 
2025-03-31 01:09:55.895272: pet_8234, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:55.914634: predicting pet_8251 
2025-03-31 01:09:56.050803: pet_8251, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.070431: predicting pet_8253 
2025-03-31 01:09:56.123370: pet_8253, shape torch.Size([3, 1, 410, 512]), rank 0 
2025-03-31 01:09:56.143524: predicting pet_8254 
2025-03-31 01:09:56.299933: pet_8254, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.319491: predicting pet_8260 
2025-03-31 01:09:56.376922: pet_8260, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.396371: predicting pet_8262 
2025-03-31 01:09:56.442178: pet_8262, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.461113: predicting pet_8266 
2025-03-31 01:09:56.489388: pet_8266, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.508769: predicting pet_8284 
2025-03-31 01:09:56.558018: pet_8284, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.577249: predicting pet_8285 
2025-03-31 01:09:56.607841: pet_8285, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.627311: predicting pet_8288 
2025-03-31 01:09:56.677907: pet_8288, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.696993: predicting pet_8290 
2025-03-31 01:09:56.736750: pet_8290, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.756289: predicting pet_8291 
2025-03-31 01:09:56.796199: pet_8291, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.815258: predicting pet_8294 
2025-03-31 01:09:56.853461: pet_8294, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.872856: predicting pet_8302 
2025-03-31 01:09:56.924027: pet_8302, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:56.943379: predicting pet_8305 
2025-03-31 01:09:56.998325: pet_8305, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:57.017068: predicting pet_8317 
2025-03-31 01:09:57.028615: pet_8317, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:57.047405: predicting pet_8324 
2025-03-31 01:09:57.122834: pet_8324, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:57.141893: predicting pet_8325 
2025-03-31 01:09:57.179201: pet_8325, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:57.198492: predicting pet_8337 
2025-03-31 01:09:57.246500: pet_8337, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.402377: predicting pet_8347 
2025-03-31 01:09:59.412541: pet_8347, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.432635: predicting pet_8348 
2025-03-31 01:09:59.442552: pet_8348, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.462813: predicting pet_8349 
2025-03-31 01:09:59.471480: pet_8349, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.492204: predicting pet_8355 
2025-03-31 01:09:59.502306: pet_8355, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.522042: predicting pet_8359 
2025-03-31 01:09:59.528394: pet_8359, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.547518: predicting pet_8364 
2025-03-31 01:09:59.553977: pet_8364, shape torch.Size([3, 1, 392, 496]), rank 0 
2025-03-31 01:09:59.575459: predicting pet_8365 
2025-03-31 01:09:59.586164: pet_8365, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.605095: predicting pet_8374 
2025-03-31 01:09:59.614060: pet_8374, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.634070: predicting pet_8378 
2025-03-31 01:09:59.643811: pet_8378, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.663555: predicting pet_8382 
2025-03-31 01:09:59.671321: pet_8382, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.692652: predicting pet_8385 
2025-03-31 01:09:59.699610: pet_8385, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.720546: predicting pet_8399 
2025-03-31 01:09:59.730787: pet_8399, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.751384: predicting pet_8401 
2025-03-31 01:09:59.759201: pet_8401, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.778479: predicting pet_8418 
2025-03-31 01:09:59.788288: pet_8418, shape torch.Size([3, 1, 512, 464]), rank 0 
2025-03-31 01:09:59.810981: predicting pet_8439 
2025-03-31 01:09:59.820659: pet_8439, shape torch.Size([3, 1, 389, 512]), rank 0 
2025-03-31 01:09:59.844182: predicting pet_8468 
2025-03-31 01:09:59.853502: pet_8468, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.873449: predicting pet_8473 
2025-03-31 01:09:59.884220: pet_8473, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.906655: predicting pet_8476 
2025-03-31 01:09:59.913797: pet_8476, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.934476: predicting pet_8478 
2025-03-31 01:09:59.944043: pet_8478, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.963991: predicting pet_8489 
2025-03-31 01:09:59.974681: pet_8489, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:09:59.995077: predicting pet_8491 
2025-03-31 01:10:00.004609: pet_8491, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.025632: predicting pet_8497 
2025-03-31 01:10:00.030361: pet_8497, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.050426: predicting pet_8498 
2025-03-31 01:10:00.061713: pet_8498, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.081138: predicting pet_8499 
2025-03-31 01:10:00.090782: pet_8499, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.112230: predicting pet_8500 
2025-03-31 01:10:00.120950: pet_8500, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.142409: predicting pet_8501 
2025-03-31 01:10:00.154851: pet_8501, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.174218: predicting pet_8507 
2025-03-31 01:10:00.182612: pet_8507, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.203099: predicting pet_8511 
2025-03-31 01:10:00.208135: pet_8511, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.228949: predicting pet_8520 
2025-03-31 01:10:00.234783: pet_8520, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.255450: predicting pet_8523 
2025-03-31 01:10:00.266558: pet_8523, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.286663: predicting pet_8527 
2025-03-31 01:10:00.295088: pet_8527, shape torch.Size([3, 1, 404, 512]), rank 0 
2025-03-31 01:10:00.314258: predicting pet_8528 
2025-03-31 01:10:00.322754: pet_8528, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.343313: predicting pet_8529 
2025-03-31 01:10:00.353128: pet_8529, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.373983: predicting pet_8531 
2025-03-31 01:10:00.385090: pet_8531, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.406880: predicting pet_8536 
2025-03-31 01:10:00.415231: pet_8536, shape torch.Size([3, 1, 497, 480]), rank 0 
2025-03-31 01:10:00.435803: predicting pet_8538 
2025-03-31 01:10:00.448167: pet_8538, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.467437: predicting pet_8543 
2025-03-31 01:10:00.477421: pet_8543, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.497005: predicting pet_8550 
2025-03-31 01:10:00.506807: pet_8550, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.526684: predicting pet_8560 
2025-03-31 01:10:00.532663: pet_8560, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.553330: predicting pet_8564 
2025-03-31 01:10:00.562625: pet_8564, shape torch.Size([3, 1, 487, 512]), rank 0 
2025-03-31 01:10:00.583671: predicting pet_8567 
2025-03-31 01:10:00.594478: pet_8567, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.615703: predicting pet_8568 
2025-03-31 01:10:00.621293: pet_8568, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.640310: predicting pet_8578 
2025-03-31 01:10:00.648927: pet_8578, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.669672: predicting pet_8583 
2025-03-31 01:10:00.678580: pet_8583, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.698486: predicting pet_8587 
2025-03-31 01:10:00.706273: pet_8587, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.725435: predicting pet_8590 
2025-03-31 01:10:00.734602: pet_8590, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:10:00.754992: predicting pet_8594 
2025-03-31 01:10:00.765342: pet_8594, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.784973: predicting pet_8595 
2025-03-31 01:10:00.792953: pet_8595, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:10:00.813425: predicting pet_8597 
2025-03-31 01:10:00.822479: pet_8597, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.842715: predicting pet_8604 
2025-03-31 01:10:00.853108: pet_8604, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.873562: predicting pet_8605 
2025-03-31 01:10:00.883901: pet_8605, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.904188: predicting pet_8606 
2025-03-31 01:10:00.910394: pet_8606, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.930435: predicting pet_8613 
2025-03-31 01:10:00.939736: pet_8613, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:00.961038: predicting pet_8616 
2025-03-31 01:10:00.965169: pet_8616, shape torch.Size([3, 1, 472, 456]), rank 0 
2025-03-31 01:10:00.987040: predicting pet_8618 
2025-03-31 01:10:00.996254: pet_8618, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.016813: predicting pet_8619 
2025-03-31 01:10:01.021149: pet_8619, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.040006: predicting pet_8625 
2025-03-31 01:10:01.048453: pet_8625, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.068308: predicting pet_8640 
2025-03-31 01:10:01.079069: pet_8640, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.100300: predicting pet_8641 
2025-03-31 01:10:01.111594: pet_8641, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.132890: predicting pet_8642 
2025-03-31 01:10:01.139964: pet_8642, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.159685: predicting pet_8643 
2025-03-31 01:10:01.166959: pet_8643, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.186433: predicting pet_8645 
2025-03-31 01:10:01.194342: pet_8645, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.214276: predicting pet_8647 
2025-03-31 01:10:01.221616: pet_8647, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.241972: predicting pet_8653 
2025-03-31 01:10:01.249845: pet_8653, shape torch.Size([3, 1, 393, 512]), rank 0 
2025-03-31 01:10:01.270270: predicting pet_8657 
2025-03-31 01:10:01.279094: pet_8657, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.300256: predicting pet_8658 
2025-03-31 01:10:01.310539: pet_8658, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.330468: predicting pet_8659 
2025-03-31 01:10:01.337329: pet_8659, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:10:01.357055: predicting pet_8660 
2025-03-31 01:10:01.366106: pet_8660, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.384851: predicting pet_8664 
2025-03-31 01:10:01.395012: pet_8664, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.416102: predicting pet_8674 
2025-03-31 01:10:01.424211: pet_8674, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.442271: predicting pet_8677 
2025-03-31 01:10:01.451497: pet_8677, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.470523: predicting pet_8679 
2025-03-31 01:10:01.480241: pet_8679, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.499392: predicting pet_8682 
2025-03-31 01:10:01.507352: pet_8682, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.527361: predicting pet_8693 
2025-03-31 01:10:01.536934: pet_8693, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.556580: predicting pet_8704 
2025-03-31 01:10:01.564481: pet_8704, shape torch.Size([3, 1, 512, 408]), rank 0 
2025-03-31 01:10:01.583257: predicting pet_8709 
2025-03-31 01:10:01.592425: pet_8709, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.614734: predicting pet_8714 
2025-03-31 01:10:01.626195: pet_8714, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.646152: predicting pet_8715 
2025-03-31 01:10:01.656603: pet_8715, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.680147: predicting pet_8723 
2025-03-31 01:10:01.688696: pet_8723, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.708985: predicting pet_8726 
2025-03-31 01:10:01.716103: pet_8726, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.736386: predicting pet_8733 
2025-03-31 01:10:01.741052: pet_8733, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.762885: predicting pet_8736 
2025-03-31 01:10:01.769490: pet_8736, shape torch.Size([3, 1, 512, 353]), rank 0 
2025-03-31 01:10:01.791562: predicting pet_8737 
2025-03-31 01:10:01.798478: pet_8737, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.819296: predicting pet_8738 
2025-03-31 01:10:01.825022: pet_8738, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.843426: predicting pet_8739 
2025-03-31 01:10:01.848972: pet_8739, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.870792: predicting pet_8740 
2025-03-31 01:10:01.880301: pet_8740, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.902040: predicting pet_8741 
2025-03-31 01:10:01.910814: pet_8741, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.930054: predicting pet_8743 
2025-03-31 01:10:01.938356: pet_8743, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.960306: predicting pet_8747 
2025-03-31 01:10:01.970202: pet_8747, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:01.990480: predicting pet_8753 
2025-03-31 01:10:02.000354: pet_8753, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.021556: predicting pet_8760 
2025-03-31 01:10:02.030978: pet_8760, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.051557: predicting pet_8765 
2025-03-31 01:10:02.056193: pet_8765, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.077193: predicting pet_8766 
2025-03-31 01:10:02.080918: pet_8766, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.102788: predicting pet_8773 
2025-03-31 01:10:02.112928: pet_8773, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.134842: predicting pet_8783 
2025-03-31 01:10:02.142618: pet_8783, shape torch.Size([3, 1, 404, 512]), rank 0 
2025-03-31 01:10:02.162392: predicting pet_8787 
2025-03-31 01:10:02.172638: pet_8787, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.194788: predicting pet_8799 
2025-03-31 01:10:02.203459: pet_8799, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.225126: predicting pet_8803 
2025-03-31 01:10:02.235532: pet_8803, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.255834: predicting pet_8804 
2025-03-31 01:10:02.263230: pet_8804, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.283769: predicting pet_8815 
2025-03-31 01:10:02.292475: pet_8815, shape torch.Size([3, 1, 465, 512]), rank 0 
2025-03-31 01:10:02.313653: predicting pet_8822 
2025-03-31 01:10:02.321687: pet_8822, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.342239: predicting pet_8832 
2025-03-31 01:10:02.348400: pet_8832, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.370544: predicting pet_8838 
2025-03-31 01:10:02.381355: pet_8838, shape torch.Size([3, 1, 512, 450]), rank 0 
2025-03-31 01:10:02.402031: predicting pet_8844 
2025-03-31 01:10:02.411205: pet_8844, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.431221: predicting pet_8846 
2025-03-31 01:10:02.440325: pet_8846, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.458517: predicting pet_8848 
2025-03-31 01:10:02.465403: pet_8848, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.485628: predicting pet_8849 
2025-03-31 01:10:02.492623: pet_8849, shape torch.Size([3, 1, 441, 512]), rank 0 
2025-03-31 01:10:02.512430: predicting pet_8859 
2025-03-31 01:10:02.522840: pet_8859, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.543021: predicting pet_8860 
2025-03-31 01:10:02.551738: pet_8860, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.570332: predicting pet_8863 
2025-03-31 01:10:02.579007: pet_8863, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.598797: predicting pet_8864 
2025-03-31 01:10:02.605807: pet_8864, shape torch.Size([3, 1, 512, 448]), rank 0 
2025-03-31 01:10:02.627125: predicting pet_8871 
2025-03-31 01:10:02.634124: pet_8871, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.653020: predicting pet_8876 
2025-03-31 01:10:02.660117: pet_8876, shape torch.Size([3, 1, 418, 496]), rank 0 
2025-03-31 01:10:02.681066: predicting pet_8877 
2025-03-31 01:10:02.690347: pet_8877, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.710231: predicting pet_8878 
2025-03-31 01:10:02.718360: pet_8878, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:10:02.738347: predicting pet_8881 
2025-03-31 01:10:02.746398: pet_8881, shape torch.Size([3, 1, 481, 497]), rank 0 
2025-03-31 01:10:02.768049: predicting pet_8884 
2025-03-31 01:10:02.778398: pet_8884, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.798370: predicting pet_8889 
2025-03-31 01:10:02.806015: pet_8889, shape torch.Size([3, 1, 440, 512]), rank 0 
2025-03-31 01:10:02.825914: predicting pet_8896 
2025-03-31 01:10:02.831500: pet_8896, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.851036: predicting pet_8908 
2025-03-31 01:10:02.860371: pet_8908, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.880109: predicting pet_8912 
2025-03-31 01:10:02.889541: pet_8912, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.911056: predicting pet_8914 
2025-03-31 01:10:02.919114: pet_8914, shape torch.Size([3, 1, 466, 512]), rank 0 
2025-03-31 01:10:02.940066: predicting pet_8918 
2025-03-31 01:10:02.948739: pet_8918, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:02.967977: predicting pet_8921 
2025-03-31 01:10:02.976350: pet_8921, shape torch.Size([3, 1, 354, 512]), rank 0 
2025-03-31 01:10:02.997710: predicting pet_8925 
2025-03-31 01:10:03.005311: pet_8925, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.025488: predicting pet_8930 
2025-03-31 01:10:03.031839: pet_8930, shape torch.Size([3, 1, 369, 480]), rank 0 
2025-03-31 01:10:03.052869: predicting pet_8945 
2025-03-31 01:10:03.064152: pet_8945, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.087481: predicting pet_8947 
2025-03-31 01:10:03.096630: pet_8947, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.117342: predicting pet_8953 
2025-03-31 01:10:03.125892: pet_8953, shape torch.Size([3, 1, 496, 512]), rank 0 
2025-03-31 01:10:03.146976: predicting pet_8954 
2025-03-31 01:10:03.154924: pet_8954, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.174833: predicting pet_8958 
2025-03-31 01:10:03.185655: pet_8958, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.205456: predicting pet_8968 
2025-03-31 01:10:03.213055: pet_8968, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:10:03.234602: predicting pet_8971 
2025-03-31 01:10:03.240037: pet_8971, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.261334: predicting pet_8980 
2025-03-31 01:10:03.263510: pet_8980, shape torch.Size([3, 1, 256, 403]), rank 0 
2025-03-31 01:10:03.283552: predicting pet_8981 
2025-03-31 01:10:03.292553: pet_8981, shape torch.Size([3, 1, 409, 512]), rank 0 
2025-03-31 01:10:03.313766: predicting pet_8985 
2025-03-31 01:10:03.323176: pet_8985, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.343057: predicting pet_8992 
2025-03-31 01:10:03.351601: pet_8992, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.369590: predicting pet_8994 
2025-03-31 01:10:03.377704: pet_8994, shape torch.Size([3, 1, 512, 401]), rank 0 
2025-03-31 01:10:03.395026: predicting pet_9004 
2025-03-31 01:10:03.401179: pet_9004, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.419181: predicting pet_9005 
2025-03-31 01:10:03.429387: pet_9005, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.448576: predicting pet_9011 
2025-03-31 01:10:03.457330: pet_9011, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.478141: predicting pet_9013 
2025-03-31 01:10:03.484879: pet_9013, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.504722: predicting pet_9018 
2025-03-31 01:10:03.514991: pet_9018, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.535493: predicting pet_9027 
2025-03-31 01:10:03.541998: pet_9027, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:10:03.561691: predicting pet_9038 
2025-03-31 01:10:03.569470: pet_9038, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.588427: predicting pet_9039 
2025-03-31 01:10:03.599685: pet_9039, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.621607: predicting pet_9047 
2025-03-31 01:10:03.628162: pet_9047, shape torch.Size([3, 1, 337, 512]), rank 0 
2025-03-31 01:10:03.647991: predicting pet_9056 
2025-03-31 01:10:03.656587: pet_9056, shape torch.Size([3, 1, 480, 464]), rank 0 
2025-03-31 01:10:03.676822: predicting pet_9064 
2025-03-31 01:10:03.686885: pet_9064, shape torch.Size([3, 1, 450, 512]), rank 0 
2025-03-31 01:10:03.707812: predicting pet_9072 
2025-03-31 01:10:03.714300: pet_9072, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.732810: predicting pet_9076 
2025-03-31 01:10:03.743812: pet_9076, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.763825: predicting pet_9077 
2025-03-31 01:10:03.774333: pet_9077, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.793235: predicting pet_9083 
2025-03-31 01:10:03.797516: pet_9083, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.816277: predicting pet_9093 
2025-03-31 01:10:03.826083: pet_9093, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:10:03.848252: predicting pet_9094 
2025-03-31 01:10:03.857482: pet_9094, shape torch.Size([3, 1, 512, 497]), rank 0 
2025-03-31 01:10:03.877249: predicting pet_9100 
2025-03-31 01:10:03.885975: pet_9100, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.905067: predicting pet_9113 
2025-03-31 01:10:03.914112: pet_9113, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.933419: predicting pet_9134 
2025-03-31 01:10:03.944138: pet_9134, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.964114: predicting pet_9135 
2025-03-31 01:10:03.969314: pet_9135, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:03.988075: predicting pet_9146 
2025-03-31 01:10:03.997363: pet_9146, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.018221: predicting pet_9148 
2025-03-31 01:10:04.024914: pet_9148, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.043555: predicting pet_9154 
2025-03-31 01:10:04.050551: pet_9154, shape torch.Size([3, 1, 512, 496]), rank 0 
2025-03-31 01:10:04.072632: predicting pet_9157 
2025-03-31 01:10:04.081472: pet_9157, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:10:04.104055: predicting pet_9158 
2025-03-31 01:10:04.111375: pet_9158, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.129797: predicting pet_9159 
2025-03-31 01:10:04.139423: pet_9159, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.161038: predicting pet_9166 
2025-03-31 01:10:04.167651: pet_9166, shape torch.Size([3, 1, 376, 512]), rank 0 
2025-03-31 01:10:04.190958: predicting pet_9172 
2025-03-31 01:10:04.199987: pet_9172, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.221009: predicting pet_9173 
2025-03-31 01:10:04.226957: pet_9173, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:10:04.246965: predicting pet_9176 
2025-03-31 01:10:04.257059: pet_9176, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.276542: predicting pet_9179 
2025-03-31 01:10:04.286967: pet_9179, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.310834: predicting pet_9189 
2025-03-31 01:10:04.319942: pet_9189, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.341388: predicting pet_9192 
2025-03-31 01:10:04.349676: pet_9192, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.370077: predicting pet_9198 
2025-03-31 01:10:04.379823: pet_9198, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.398975: predicting pet_9201 
2025-03-31 01:10:04.406944: pet_9201, shape torch.Size([3, 1, 512, 370]), rank 0 
2025-03-31 01:10:04.428041: predicting pet_9204 
2025-03-31 01:10:04.439555: pet_9204, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.459237: predicting pet_9205 
2025-03-31 01:10:04.467776: pet_9205, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.487479: predicting pet_9216 
2025-03-31 01:10:04.494548: pet_9216, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.514168: predicting pet_9217 
2025-03-31 01:10:04.520680: pet_9217, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.540740: predicting pet_9218 
2025-03-31 01:10:04.549976: pet_9218, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.570976: predicting pet_9225 
2025-03-31 01:10:04.580023: pet_9225, shape torch.Size([3, 1, 512, 464]), rank 0 
2025-03-31 01:10:04.601662: predicting pet_9227 
2025-03-31 01:10:04.610543: pet_9227, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.631369: predicting pet_9230 
2025-03-31 01:10:04.637319: pet_9230, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.658458: predicting pet_9234 
2025-03-31 01:10:04.666949: pet_9234, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.687791: predicting pet_9237 
2025-03-31 01:10:04.695452: pet_9237, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.716491: predicting pet_9239 
2025-03-31 01:10:04.725433: pet_9239, shape torch.Size([3, 1, 404, 512]), rank 0 
2025-03-31 01:10:04.746198: predicting pet_9243 
2025-03-31 01:10:04.756105: pet_9243, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.776361: predicting pet_9249 
2025-03-31 01:10:04.786020: pet_9249, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.806012: predicting pet_9251 
2025-03-31 01:10:04.814306: pet_9251, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.833315: predicting pet_9256 
2025-03-31 01:10:04.844878: pet_9256, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.868886: predicting pet_9259 
2025-03-31 01:10:04.879097: pet_9259, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.900485: predicting pet_9260 
2025-03-31 01:10:04.909269: pet_9260, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.928088: predicting pet_9261 
2025-03-31 01:10:04.937189: pet_9261, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:10:04.956391: predicting pet_9264 
2025-03-31 01:10:04.965136: pet_9264, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:04.986178: predicting pet_9267 
2025-03-31 01:10:04.996812: pet_9267, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.015659: predicting pet_9268 
2025-03-31 01:10:05.024639: pet_9268, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.046304: predicting pet_9269 
2025-03-31 01:10:05.056038: pet_9269, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.074461: predicting pet_9272 
2025-03-31 01:10:05.080879: pet_9272, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.099855: predicting pet_9274 
2025-03-31 01:10:05.110293: pet_9274, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.131157: predicting pet_9275 
2025-03-31 01:10:05.143075: pet_9275, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.164819: predicting pet_9281 
2025-03-31 01:10:05.174353: pet_9281, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.193660: predicting pet_9284 
2025-03-31 01:10:05.201243: pet_9284, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.221938: predicting pet_9285 
2025-03-31 01:10:05.234694: pet_9285, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.257526: predicting pet_9289 
2025-03-31 01:10:05.264251: pet_9289, shape torch.Size([3, 1, 430, 512]), rank 0 
2025-03-31 01:10:05.285146: predicting pet_9305 
2025-03-31 01:10:05.293613: pet_9305, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.314969: predicting pet_9314 
2025-03-31 01:10:05.324333: pet_9314, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.346066: predicting pet_9317 
2025-03-31 01:10:05.348486: pet_9317, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.367478: predicting pet_9325 
2025-03-31 01:10:05.376945: pet_9325, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.396287: predicting pet_9338 
2025-03-31 01:10:05.405650: pet_9338, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.426926: predicting pet_9347 
2025-03-31 01:10:05.436103: pet_9347, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.456288: predicting pet_9348 
2025-03-31 01:10:05.467134: pet_9348, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.487235: predicting pet_9349 
2025-03-31 01:10:05.495842: pet_9349, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.514875: predicting pet_9353 
2025-03-31 01:10:05.520059: pet_9353, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.540934: predicting pet_9355 
2025-03-31 01:10:05.549258: pet_9355, shape torch.Size([3, 1, 512, 497]), rank 0 
2025-03-31 01:10:05.570634: predicting pet_9357 
2025-03-31 01:10:05.579659: pet_9357, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.603286: predicting pet_9360 
2025-03-31 01:10:05.614668: pet_9360, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.633936: predicting pet_9363 
2025-03-31 01:10:05.644062: pet_9363, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.663383: predicting pet_9364 
2025-03-31 01:10:05.671788: pet_9364, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.694039: predicting pet_9365 
2025-03-31 01:10:05.703659: pet_9365, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.724418: predicting pet_9369 
2025-03-31 01:10:05.733091: pet_9369, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.753275: predicting pet_9378 
2025-03-31 01:10:05.760972: pet_9378, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.782624: predicting pet_9381 
2025-03-31 01:10:05.793027: pet_9381, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.812626: predicting pet_9385 
2025-03-31 01:10:05.824538: pet_9385, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.845662: predicting pet_9390 
2025-03-31 01:10:05.855703: pet_9390, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.874359: predicting pet_9392 
2025-03-31 01:10:05.883319: pet_9392, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.902527: predicting pet_9394 
2025-03-31 01:10:05.909062: pet_9394, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.928658: predicting pet_9401 
2025-03-31 01:10:05.931641: pet_9401, shape torch.Size([3, 1, 472, 504]), rank 0 
2025-03-31 01:10:05.951126: predicting pet_9403 
2025-03-31 01:10:05.960335: pet_9403, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:05.980694: predicting pet_9408 
2025-03-31 01:10:05.990610: pet_9408, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.010042: predicting pet_9419 
2025-03-31 01:10:06.022736: pet_9419, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.041962: predicting pet_9420 
2025-03-31 01:10:06.049307: pet_9420, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.071213: predicting pet_9432 
2025-03-31 01:10:06.081026: pet_9432, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.100364: predicting pet_9434 
2025-03-31 01:10:06.109020: pet_9434, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.131436: predicting pet_9435 
2025-03-31 01:10:06.140114: pet_9435, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.162224: predicting pet_9439 
2025-03-31 01:10:06.170575: pet_9439, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.189500: predicting pet_9448 
2025-03-31 01:10:06.197025: pet_9448, shape torch.Size([3, 1, 420, 512]), rank 0 
2025-03-31 01:10:06.217669: predicting pet_9450 
2025-03-31 01:10:06.229388: pet_9450, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.249552: predicting pet_9457 
2025-03-31 01:10:06.258636: pet_9457, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:10:06.279378: predicting pet_9462 
2025-03-31 01:10:06.287956: pet_9462, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.307381: predicting pet_9464 
2025-03-31 01:10:06.315618: pet_9464, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.337498: predicting pet_9466 
2025-03-31 01:10:06.344549: pet_9466, shape torch.Size([3, 1, 400, 512]), rank 0 
2025-03-31 01:10:06.365702: predicting pet_9468 
2025-03-31 01:10:06.373240: pet_9468, shape torch.Size([3, 1, 480, 510]), rank 0 
2025-03-31 01:10:06.393768: predicting pet_9474 
2025-03-31 01:10:06.402850: pet_9474, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.422500: predicting pet_9476 
2025-03-31 01:10:06.430884: pet_9476, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:10:06.451403: predicting pet_9480 
2025-03-31 01:10:06.465470: pet_9480, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.484766: predicting pet_9482 
2025-03-31 01:10:06.495074: pet_9482, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.516110: predicting pet_9485 
2025-03-31 01:10:06.523775: pet_9485, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.542226: predicting pet_9488 
2025-03-31 01:10:06.550674: pet_9488, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.570374: predicting pet_9507 
2025-03-31 01:10:06.579307: pet_9507, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.599888: predicting pet_9514 
2025-03-31 01:10:06.608168: pet_9514, shape torch.Size([3, 1, 497, 512]), rank 0 
2025-03-31 01:10:06.628114: predicting pet_9521 
2025-03-31 01:10:06.636791: pet_9521, shape torch.Size([3, 1, 392, 512]), rank 0 
2025-03-31 01:10:06.659009: predicting pet_9522 
2025-03-31 01:10:06.669079: pet_9522, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.688115: predicting pet_9527 
2025-03-31 01:10:06.697524: pet_9527, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.719449: predicting pet_9528 
2025-03-31 01:10:06.728721: pet_9528, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.748016: predicting pet_9534 
2025-03-31 01:10:06.758433: pet_9534, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.778998: predicting pet_9535 
2025-03-31 01:10:06.785736: pet_9535, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.806488: predicting pet_9537 
2025-03-31 01:10:06.816077: pet_9537, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.835861: predicting pet_9538 
2025-03-31 01:10:06.844386: pet_9538, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.865967: predicting pet_9560 
2025-03-31 01:10:06.873917: pet_9560, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.894868: predicting pet_9561 
2025-03-31 01:10:06.901801: pet_9561, shape torch.Size([3, 1, 417, 512]), rank 0 
2025-03-31 01:10:06.920993: predicting pet_9564 
2025-03-31 01:10:06.931548: pet_9564, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.950669: predicting pet_9566 
2025-03-31 01:10:06.957076: pet_9566, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:06.975750: predicting pet_9567 
2025-03-31 01:10:06.986586: pet_9567, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.006588: predicting pet_9568 
2025-03-31 01:10:07.016004: pet_9568, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.036072: predicting pet_9577 
2025-03-31 01:10:07.045293: pet_9577, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.065748: predicting pet_9578 
2025-03-31 01:10:07.077295: pet_9578, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.098611: predicting pet_9587 
2025-03-31 01:10:07.106557: pet_9587, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:10:07.128385: predicting pet_9588 
2025-03-31 01:10:07.135461: pet_9588, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.153960: predicting pet_9589 
2025-03-31 01:10:07.161565: pet_9589, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.180897: predicting pet_9594 
2025-03-31 01:10:07.191956: pet_9594, shape torch.Size([3, 1, 512, 438]), rank 0 
2025-03-31 01:10:07.210418: predicting pet_9598 
2025-03-31 01:10:07.219550: pet_9598, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.238831: predicting pet_9599 
2025-03-31 01:10:07.249074: pet_9599, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.268463: predicting pet_9605 
2025-03-31 01:10:07.277809: pet_9605, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.297223: predicting pet_9612 
2025-03-31 01:10:07.306590: pet_9612, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.325538: predicting pet_9613 
2025-03-31 01:10:07.332732: pet_9613, shape torch.Size([3, 1, 392, 512]), rank 0 
2025-03-31 01:10:07.351999: predicting pet_9625 
2025-03-31 01:10:07.361104: pet_9625, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.379945: predicting pet_9629 
2025-03-31 01:10:07.389292: pet_9629, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.410916: predicting pet_9630 
2025-03-31 01:10:07.418751: pet_9630, shape torch.Size([3, 1, 434, 512]), rank 0 
2025-03-31 01:10:07.440728: predicting pet_9633 
2025-03-31 01:10:07.445997: pet_9633, shape torch.Size([3, 1, 512, 352]), rank 0 
2025-03-31 01:10:07.464593: predicting pet_9636 
2025-03-31 01:10:07.477241: pet_9636, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.496773: predicting pet_9637 
2025-03-31 01:10:07.505725: pet_9637, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.525414: predicting pet_9645 
2025-03-31 01:10:07.532866: pet_9645, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.553769: predicting pet_9647 
2025-03-31 01:10:07.561700: pet_9647, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.582607: predicting pet_9652 
2025-03-31 01:10:07.594702: pet_9652, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.613495: predicting pet_9663 
2025-03-31 01:10:07.617749: pet_9663, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.638071: predicting pet_9676 
2025-03-31 01:10:07.647053: pet_9676, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.667773: predicting pet_9679 
2025-03-31 01:10:07.675187: pet_9679, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.696887: predicting pet_9681 
2025-03-31 01:10:07.704735: pet_9681, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.723665: predicting pet_9692 
2025-03-31 01:10:07.734647: pet_9692, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.755327: predicting pet_9693 
2025-03-31 01:10:07.761056: pet_9693, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.783983: predicting pet_9711 
2025-03-31 01:10:07.793746: pet_9711, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.813168: predicting pet_9716 
2025-03-31 01:10:07.820739: pet_9716, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.839960: predicting pet_9720 
2025-03-31 01:10:07.853423: pet_9720, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.874650: predicting pet_9723 
2025-03-31 01:10:07.885983: pet_9723, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.906775: predicting pet_9727 
2025-03-31 01:10:07.912723: pet_9727, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:10:07.932975: predicting pet_9739 
2025-03-31 01:10:07.940413: pet_9739, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:10:07.961956: predicting pet_9740 
2025-03-31 01:10:07.974555: pet_9740, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:07.996901: predicting pet_9748 
2025-03-31 01:10:08.008146: pet_9748, shape torch.Size([3, 1, 464, 512]), rank 0 
2025-03-31 01:10:08.030138: predicting pet_9762 
2025-03-31 01:10:08.037913: pet_9762, shape torch.Size([3, 1, 449, 512]), rank 0 
2025-03-31 01:10:08.058034: predicting pet_9770 
2025-03-31 01:10:08.068004: pet_9770, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.090491: predicting pet_9776 
2025-03-31 01:10:08.098523: pet_9776, shape torch.Size([3, 1, 512, 464]), rank 0 
2025-03-31 01:10:08.119451: predicting pet_9779 
2025-03-31 01:10:08.128523: pet_9779, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.148187: predicting pet_9792 
2025-03-31 01:10:08.159022: pet_9792, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.178432: predicting pet_9793 
2025-03-31 01:10:08.191530: pet_9793, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.213661: predicting pet_9796 
2025-03-31 01:10:08.222788: pet_9796, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.242530: predicting pet_9797 
2025-03-31 01:10:08.251242: pet_9797, shape torch.Size([3, 1, 480, 512]), rank 0 
2025-03-31 01:10:08.272555: predicting pet_9798 
2025-03-31 01:10:08.283625: pet_9798, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.303077: predicting pet_9802 
2025-03-31 01:10:08.308681: pet_9802, shape torch.Size([3, 1, 384, 480]), rank 0 
2025-03-31 01:10:08.327348: predicting pet_9815 
2025-03-31 01:10:08.336607: pet_9815, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.360057: predicting pet_9832 
2025-03-31 01:10:08.365117: pet_9832, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.384574: predicting pet_9835 
2025-03-31 01:10:08.394000: pet_9835, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.414894: predicting pet_9836 
2025-03-31 01:10:08.425277: pet_9836, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.445439: predicting pet_9837 
2025-03-31 01:10:08.454393: pet_9837, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.475510: predicting pet_9841 
2025-03-31 01:10:08.484128: pet_9841, shape torch.Size([3, 1, 512, 488]), rank 0 
2025-03-31 01:10:08.505228: predicting pet_9844 
2025-03-31 01:10:08.513272: pet_9844, shape torch.Size([3, 1, 392, 512]), rank 0 
2025-03-31 01:10:08.535718: predicting pet_9849 
2025-03-31 01:10:08.541639: pet_9849, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.563263: predicting pet_9853 
2025-03-31 01:10:08.572233: pet_9853, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.590646: predicting pet_9862 
2025-03-31 01:10:08.599919: pet_9862, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.620407: predicting pet_9865 
2025-03-31 01:10:08.628013: pet_9865, shape torch.Size([3, 1, 489, 512]), rank 0 
2025-03-31 01:10:08.648450: predicting pet_9869 
2025-03-31 01:10:08.659290: pet_9869, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.680868: predicting pet_9876 
2025-03-31 01:10:08.687332: pet_9876, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.707965: predicting pet_9877 
2025-03-31 01:10:08.717157: pet_9877, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.737332: predicting pet_9880 
2025-03-31 01:10:08.746997: pet_9880, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.767320: predicting pet_9882 
2025-03-31 01:10:08.777195: pet_9882, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.797708: predicting pet_9890 
2025-03-31 01:10:08.807476: pet_9890, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.827825: predicting pet_9907 
2025-03-31 01:10:08.835314: pet_9907, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.855810: predicting pet_9909 
2025-03-31 01:10:08.865218: pet_9909, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.885884: predicting pet_9911 
2025-03-31 01:10:08.894161: pet_9911, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.916309: predicting pet_9914 
2025-03-31 01:10:08.924272: pet_9914, shape torch.Size([3, 1, 481, 512]), rank 0 
2025-03-31 01:10:08.946428: predicting pet_9927 
2025-03-31 01:10:08.955755: pet_9927, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.975949: predicting pet_9931 
2025-03-31 01:10:08.980518: pet_9931, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:08.999188: predicting pet_9933 
2025-03-31 01:10:09.005791: pet_9933, shape torch.Size([3, 1, 386, 512]), rank 0 
2025-03-31 01:10:09.027157: predicting pet_9934 
2025-03-31 01:10:09.036038: pet_9934, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.055265: predicting pet_9952 
2025-03-31 01:10:09.066117: pet_9952, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.086796: predicting pet_9956 
2025-03-31 01:10:09.095544: pet_9956, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.117819: predicting pet_9958 
2025-03-31 01:10:09.127533: pet_9958, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.149166: predicting pet_9967 
2025-03-31 01:10:09.158070: pet_9967, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.179443: predicting pet_9972 
2025-03-31 01:10:09.193116: pet_9972, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.212490: predicting pet_9983 
2025-03-31 01:10:09.221300: pet_9983, shape torch.Size([3, 1, 416, 512]), rank 0 
2025-03-31 01:10:09.242110: predicting pet_9985 
2025-03-31 01:10:09.250007: pet_9985, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.269922: predicting pet_9994 
2025-03-31 01:10:09.277142: pet_9994, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.297458: predicting pet_9996 
2025-03-31 01:10:09.306557: pet_9996, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:09.325351: predicting pet_9998 
2025-03-31 01:10:09.334558: pet_9998, shape torch.Size([3, 1, 352, 512]), rank 0 
2025-03-31 01:10:09.354019: predicting pet_9999 
2025-03-31 01:10:09.363470: pet_9999, shape torch.Size([3, 1, 512, 512]), rank 0 
2025-03-31 01:10:15.131069: Validation complete 
2025-03-31 01:10:15.131139: Mean Validation Dice:  0.9233876709561766 
